<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Understanding EM algorithm | 不正经数据科学家</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="本文主要内容为用一个简短的例子解释EM算法。">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding EM algorithm">
<meta property="og:url" content="https://frankchen.xyz/2016/11/18/Understanding-EM-algorithm/index.html">
<meta property="og:site_name" content="不正经数据科学家">
<meta property="og:description" content="本文主要内容为用一个简短的例子解释EM算法。">
<meta property="og:locale">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/1.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/2.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/3.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/4.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/5.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/6.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/7.png">
<meta property="og:image" content="https://frankchen.xyz/images/2016/11/8.png">
<meta property="article:published_time" content="2016-11-18T13:54:19.000Z">
<meta property="article:modified_time" content="2017-01-13T09:49:08.000Z">
<meta property="article:author" content="frankchen0130">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://frankchen.xyz/images/2016/11/1.png">
  
    <link rel="alternate" href="/atom.xml" title="不正经数据科学家" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">不正经数据科学家</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Marketing/Python/Clojure/Game</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://frankchen.xyz"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Understanding-EM-algorithm" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2016/11/18/Understanding-EM-algorithm/" class="article-date">
  <time class="dt-published" datetime="2016-11-18T13:54:19.000Z" itemprop="datePublished">2016-11-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Understanding EM algorithm
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本文主要内容为用一个简短的例子解释EM算法。</p>
<span id="more"></span>

<p>EM算法是聚类中常用的机器学习算法，但是相比喜闻乐见的k-means算法，大家可能对于EM算法的了解可能没有那么直观深入，所以本文主要利用一个简单的例子，在对比k-means算法的过程中，帮助大家建立一个清晰明确的对EM算法的理解。</p>
<p>当我们在聚类的领域谈论k-means算法时，分组的概念是非常清晰直观的–每个样本点只属于它离得最近的那个中心点所属的分组。如果给出一些样本点和中心，那么我们很容易给这些点打标签。</p>
<p>但是对于EM算法而言，分组的概念就么那么直观了（因为EM算法考虑每个样本点都有一定的概率属于所有的分组）。在我们介=引入EM算法之前，我们先复习一下k-means里面的分组概念。</p>
<h2 id="k-means里面的分组概念"><a href="#k-means里面的分组概念" class="headerlink" title="k-means里面的分组概念"></a>k-means里面的分组概念</h2><p>假设我们有如下的三个样本点（2D平面情况下的点）：</p>
<table>
<thead>
<tr>
<th align="center">数据集</th>
<th align="center">X</th>
<th align="center">Y</th>
</tr>
</thead>
<tbody><tr>
<td align="center">点0</td>
<td align="center">10</td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">点1</td>
<td align="center">2</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">点2</td>
<td align="center">3</td>
<td align="center">7</td>
</tr>
</tbody></table>
<p><img src="/images/2016/11/1.png" alt="image"></p>
<p>如果在上面的数据集上跑k-means算法，假定中心点如下：</p>
<table>
<thead>
<tr>
<th align="center">中心</th>
<th align="center">X</th>
<th align="center">Y</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A</td>
<td align="center">3</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">B</td>
<td align="center">6</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">4</td>
<td align="center">6</td>
</tr>
</tbody></table>
<p><img src="/images/2016/11/2.png" alt="image"></p>
<p>使用欧几里得距离，可以分配聚类如下</p>
<table>
<thead>
<tr>
<th>距离</th>
<th>群组A中心</th>
<th>群组B中心</th>
<th>群组C中心</th>
<th>群组分配</th>
</tr>
</thead>
<tbody><tr>
<td>点0</td>
<td>7.071</td>
<td><strong>4.472</strong></td>
<td>6.083</td>
<td>群组B</td>
</tr>
<tr>
<td>点1</td>
<td><strong>3.162</strong></td>
<td>4.472</td>
<td>5.385</td>
<td>群组A</td>
</tr>
<tr>
<td>点2</td>
<td>3.000</td>
<td>5.000</td>
<td><strong>1.414</strong></td>
<td>群组C</td>
</tr>
</tbody></table>
<p><img src="/images/2016/11/3.png" alt="image"></p>
<p>到此，我们可以给出一个回答：到底把一个点归类到一个群组意味着什么？举例来说，点1只被分配到分组A，也就是点1的100%属于群组A并且0%属于群组B和群组C。那么根据这个定义，我们可以得到如下表格，</p>
<table>
<thead>
<tr>
<th></th>
<th align="right">群组A</th>
<th align="center">群组B</th>
<th>群组C</th>
</tr>
</thead>
<tbody><tr>
<td>点0</td>
<td align="right">0</td>
<td align="center"><strong>1</strong></td>
<td>0</td>
</tr>
<tr>
<td>点1</td>
<td align="right"><strong>1</strong></td>
<td align="center">0</td>
<td>0</td>
</tr>
<tr>
<td>点2</td>
<td align="right">0</td>
<td align="center">0</td>
<td><strong>1</strong></td>
</tr>
<tr>
<td>成员个数</td>
<td align="right">1</td>
<td align="center">1</td>
<td>1</td>
</tr>
</tbody></table>
<p>注意到，对于一个群组来说，其得到的每一行的和都是1（因为一个点的百分比就是之和就是1）；另外，每一列的和就是这个群组的成员点的个数。推而广之：</p>
<ul>
<li>每一行的和总是1，因为一个点的百分比之和是1</li>
<li>每一列的和就是分配到这个群组的点的个数</li>
</ul>
<h2 id="EM算法中的群组分配"><a href="#EM算法中的群组分配" class="headerlink" title="EM算法中的群组分配"></a>EM算法中的群组分配</h2><p>到此为止，我们做的似乎不错，但是存在一个问题，我们这里每个点都只能属于一个群组，不过这一点有时候不是那么合理，比如点0分配到群组B似乎没什么问题，但是比如点1距离群组A和群组B的距离差别不那么大，那么只因为距离群组A近那么一点点就只把它分配到群组A，难道没什么问题吗？我们可能更加想表达这样一种概念：点1更可能属于群组A，但是我们也想保留点1也有一些可能属于群组B的不确定性。</p>
<table>
<thead>
<tr>
<th>距离</th>
<th>群组A中心</th>
<th>群组B中心</th>
<th>群组C中心</th>
<th>群组分配</th>
</tr>
</thead>
<tbody><tr>
<td>点0</td>
<td>7.071</td>
<td>4.472</td>
<td>6.083</td>
<td>群组B</td>
</tr>
<tr>
<td>点1</td>
<td>3.162</td>
<td>4.472</td>
<td>5.385</td>
<td>群组A</td>
</tr>
<tr>
<td>点2</td>
<td>3.000</td>
<td>5.000</td>
<td>1.414</td>
<td>群组C</td>
</tr>
</tbody></table>
<p>我们如何表述这种不确定性呢？这就是<strong>分组权重</strong>的由来。分组权重表达了一个点有多可能属于某个群组。比如之前的形式是这样的，</p>
<table>
<thead>
<tr>
<th></th>
<th align="right">群组A</th>
<th align="center">群组B</th>
<th>群组C</th>
</tr>
</thead>
<tbody><tr>
<td>点0</td>
<td align="right">0</td>
<td align="center">1</td>
<td>0</td>
</tr>
<tr>
<td>点1</td>
<td align="right">1</td>
<td align="center">0</td>
<td>0</td>
</tr>
<tr>
<td>点2</td>
<td align="right">0</td>
<td align="center">0</td>
<td>1</td>
</tr>
<tr>
<td>成员个数</td>
<td align="right">1</td>
<td align="center">1</td>
<td>1</td>
</tr>
</tbody></table>
<p>把上表的0和1换成分数（不要质疑这些分数怎么来的，等下会给出合理解释，：））</p>
<table>
<thead>
<tr>
<th></th>
<th align="right">群组A</th>
<th align="center">群组B</th>
<th>群组C</th>
</tr>
</thead>
<tbody><tr>
<td>点0</td>
<td align="right">0.007</td>
<td align="center">0.938</td>
<td>0.055</td>
</tr>
<tr>
<td>点1</td>
<td align="right">0.812</td>
<td align="center">0.154</td>
<td>0.034</td>
</tr>
<tr>
<td>点2</td>
<td align="right">0.234</td>
<td align="center">0.016</td>
<td>0.750</td>
</tr>
<tr>
<td>软计数</td>
<td align="right">1.053</td>
<td align="center">1.108</td>
<td>0.839</td>
</tr>
</tbody></table>
<p>上表中，点0以93.8%的概率属于群组B，同时下一行中，点1以81.2%的概率属于群组A。这些分数也就是<strong>分组权重</strong>。比如，点0属于分组A的权重就是0.7%。</p>
<p><strong>和k-means算法中每个点只能属于一个群组不同，这里每个点都以某种程度地属于每一个群组。</strong>例如，93.8%的点0属于群组，其余的属于其他的群组。</p>
<p><img src="/images/2016/11/4.png" alt="image"></p>
<p>那么，在上面的分配矩阵里面，每一行和每一列的含义如下，</p>
<ul>
<li>每一行的和都是1，因为每个点都100%属于所有的群组，将这一些部分加起来和必定是1</li>
<li>每一列的和是这个群组的“软计数”，它代表着所有的点属于这个群组的百分比之和</li>
<li>所有的群组的软计数之和就是样本点的总数</li>
</ul>
<h2 id="步骤E：给定分组参数计算分组权重"><a href="#步骤E：给定分组参数计算分组权重" class="headerlink" title="步骤E：给定分组参数计算分组权重"></a>步骤E：给定分组参数计算分组权重</h2><p>分组权重是怎么来的？来自给定分组的分布的时候，我们观察样本点可能是什么。而EM算法中的每一个群组都由一个<strong>分组权重</strong>，一个<strong>均值向量</strong>，一个<strong>协方差矩阵</strong>构成。其中，均值表示群组的中心，协方差体现群组的范围，而分组权重体现了样本点与此分组的关联程度。所有，每个群组都由一个多变量高斯分布所定义。</p>
<p>回顾上面的例子，加上一个不确定度的椭圆，如下，</p>
<p><img src="/images/2016/11/5.png" alt="image"></p>
<p>图中每个椭圆表示着协方差矩阵，在这个例子中，每个群组都是用的是对角协方差矩阵[[3,0],[0,3]]。因为对角线外元素都是0，所有图中的椭圆实际上看起来是圆。并且，由于并没有什么理由认为哪个群组比其他群组更加重要，那么我们定义每个群组的分组权重都是1/3。</p>
<p>那么，点0属于群组A的概率是多少？这里用来衡量潜在的高斯分布的标准是概率密度函数（probability density function，PDF），使用<code>scipy.stats.multivariate_normal.pdf</code>可计算出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">3</span>,<span class="number">4</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1.275199678019219e-05</span></span><br></pre></td></tr></table></figure>

<p>我们还要将这个概率乘以分组权重才行，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">3</span>,<span class="number">4</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">4.2506655934e-06</span></span><br></pre></td></tr></table></figure>

<p>点0属于群组A的似然值是4.251e-6。单看看不出什么，我们还要依次计算群组B和群组C的值。分别计算B和C的PDF并且乘以分组权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">6</span>,<span class="number">3</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.000630854709005</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">4</span>,<span class="number">6</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">3.71046481027e-05</span></span><br></pre></td></tr></table></figure>

<p>那么，总结一下，</p>
<table>
<thead>
<tr>
<th></th>
<th>群组A</th>
<th>群组B</th>
<th>群组C</th>
</tr>
</thead>
<tbody><tr>
<td>点(10,5)的PDF乘以分组权重</td>
<td>4.251e-6</td>
<td>6.309e-4</td>
<td>3.710e-5</td>
</tr>
</tbody></table>
<p>很明显，群组B的似然值是最高的，这容易理解因为点0距离群组B中心的距离最近。</p>
<p><img src="/images/2016/11/6.png" alt="image"></p>
<p>似然值看起来太小了，我么可以对其做一个归一化：都除以所有群组的似然值的和得到百分比值。</p>
<table>
<thead>
<tr>
<th>点0</th>
<th>群组A</th>
<th>群组B</th>
<th>群组C</th>
<th>总和</th>
</tr>
</thead>
<tbody><tr>
<td>似然值</td>
<td>4.251e-6</td>
<td>6.309e-4</td>
<td>3.710e-5</td>
<td>6.722e-4</td>
</tr>
<tr>
<td>似然值，处以总和</td>
<td>4.251e-6 / 6.722e-4 = 0.007</td>
<td>6.309e-4 / 6.722e-4 = 0.938</td>
<td>3.710e-5 / 6.722e-4 = 0.055</td>
<td>-</td>
</tr>
</tbody></table>
<p>最下一行就是点0分组责任！注意到因为归一化，这一行的总和是1。小结一下：</p>
<ul>
<li>对于每一个点我们计算了其高斯分布的PDF值，通过使用高斯分布的均值和协方差计算得到</li>
<li>将PDF乘以分组权重，得到似然度</li>
<li>将似然程度归一化</li>
</ul>
<p>依次，我们可以得到点1和点2的矩阵，这里略去不表，最后将三个点的矩阵汇总得到以下，</p>
<table>
<thead>
<tr>
<th>Responsibility matrix</th>
<th>Cluster A</th>
<th>Cluster B</th>
<th>Cluster C</th>
</tr>
</thead>
<tbody><tr>
<td>Data point 0</td>
<td>0.007</td>
<td>0.938</td>
<td>0.055</td>
</tr>
<tr>
<td>Data point 1</td>
<td>0.812</td>
<td>0.154</td>
<td>0.034</td>
</tr>
<tr>
<td>Data point 2</td>
<td>0.234</td>
<td>0.016</td>
<td>0.750</td>
</tr>
<tr>
<td>Soft counts</td>
<td>1.053</td>
<td>1.108</td>
<td>0.839</td>
</tr>
</tbody></table>
<h2 id="步骤M：给定分组责任计算分组参数"><a href="#步骤M：给定分组责任计算分组参数" class="headerlink" title="步骤M：给定分组责任计算分组参数"></a>步骤M：给定分组责任计算分组参数</h2><p>现在我们手里已经有了分组的责任了，我们可以依据这些重新更新参数：分组权重、均值和协方差。虽然我们开始是乱猜的这些参数，但是通过更新我们可以得到一些更好的估计。</p>
<p><strong>分组权重。</strong>群组的相对重要程度由它的软计数来决定。由于分组权重必须和为1，所有这里也需要做归一化，</p>
<p>|    |Cluster A    |Cluster B    |Cluster C    |Sum|<br>|-|-|-|-|<br>|Soft counts    |1.053|    1.108|    0.839|    3.000|<br>|Soft counts, divided by the sum    |1.053 / 3.000 = 0.351|    1.108 / 3.000 = 0.369    |0.839 / 3.000 = 0.280|-|</p>
<p>归一化后的软计数，就是分组权重的新的估计。</p>
<p><strong>均值。</strong>使用分组责任计算所有点坐标的百分比，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[Weighted <span class="built_in">sum</span> of data points <span class="keyword">for</span> cluster A]</span><br><span class="line">= [Fraction of data point <span class="number">0</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">0</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">1</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">1</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">2</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">2</span>]</span><br><span class="line">= <span class="number">0.007</span>*[data point <span class="number">0</span>] + <span class="number">0.812</span>*[data point <span class="number">1</span>] + <span class="number">0.234</span>*[data point <span class="number">2</span>]</span><br><span class="line">= <span class="number">0.007</span>*(<span class="number">10</span>,<span class="number">5</span>) + <span class="number">0.812</span>*(<span class="number">2</span>,<span class="number">1</span>)  + <span class="number">0.234</span>*(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">= (<span class="number">0.063</span>,<span class="number">0.035</span>) + (<span class="number">1.624</span>,<span class="number">0.812</span>) + (<span class="number">0.702</span>,<span class="number">1.638</span>)</span><br><span class="line">= (<span class="number">2.396</span>,<span class="number">2.485</span>)</span><br></pre></td></tr></table></figure>

<p>再除以软计数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[mean of cluster A]</span><br><span class="line">= (<span class="number">2.396</span>,<span class="number">2.485</span>)/<span class="number">1.053</span></span><br><span class="line">= (<span class="number">2.275</span>,<span class="number">2.360</span>)</span><br></pre></td></tr></table></figure>

<p>类似地计算B和C的均值，得到如下，</p>
<table>
<thead>
<tr>
<th>New means</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody><tr>
<td>Cluster A</td>
<td>2.275</td>
<td>2.360</td>
</tr>
<tr>
<td>Cluster B</td>
<td>8.787</td>
<td>4.473</td>
</tr>
<tr>
<td>Cluster C</td>
<td>3.418</td>
<td>6.626</td>
</tr>
</tbody></table>
<p>让我们画出均值的之前和之后的估计。注意到群组A的均值移动地更加靠近点1，因为群组A是主要的，类似的也发生在B和C上，</p>
<p><img src="/images/2016/11/7.png" alt="image"></p>
<p><strong>协方差。</strong> 协方差也是由分数来计算的，但是这里需要矩阵形式，所以实际上是由向量叉乘得到的，</p>
<p>$$x_i - \hat{\mu}_k$$</p>
<p>假设上面是d维向量，计算其与自身的内积，</p>
<p>$$(x_i - \hat{\mu}_k)(x_i - \hat{\mu}_k)^T$$</p>
<p>对012每个点都根据其坐标和A的均值计算协方差矩阵，与分组责任相乘：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[Weighted <span class="built_in">sum</span> of outer products]</span><br><span class="line">= [Fraction of data point <span class="number">0</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">0</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">1</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">1</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">2</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">2</span>]</span><br><span class="line">=  <span class="number">0.007</span>*[[<span class="number">59.676</span>,<span class="number">20.394</span>], [<span class="number">20.394</span>,<span class="number">6.970</span>]]</span><br><span class="line">  + <span class="number">0.812</span>*[[<span class="number">0.076</span>,<span class="number">0.374</span>], [<span class="number">0.374</span>,<span class="number">1.850</span>]]</span><br><span class="line">  + <span class="number">0.234</span>*[[<span class="number">0.526</span>,<span class="number">3.364</span>], [<span class="number">3.364</span>,<span class="number">21.530</span>]]</span><br><span class="line">= [[<span class="number">0.602</span>, <span class="number">1.234</span>], [<span class="number">1.234</span>, <span class="number">6.589</span>]]</span><br><span class="line"></span><br><span class="line">[New covariance <span class="keyword">for</span> cluster A]</span><br><span class="line">= [[<span class="number">0.602</span>,<span class="number">1.234</span>], [<span class="number">1.234</span>,<span class="number">6.589</span>]]/<span class="number">1.053</span></span><br><span class="line">= [[<span class="number">0.572</span>,<span class="number">1.172</span>], [<span class="number">1.172</span>,<span class="number">6.257</span>]]</span><br></pre></td></tr></table></figure>

<p>对于BC重复以上，得到，</p>
<table>
<thead>
<tr>
<th>New covariances</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Cluster A</td>
<td>[[0.572,1.172], [1.172,6.257]]</td>
</tr>
<tr>
<td>Cluster B</td>
<td>[[8.132,3.606], [3.606,2.004]]</td>
</tr>
<tr>
<td>Cluster C</td>
<td>[[3.078,-0.518], [-0.518,1.581]]</td>
</tr>
</tbody></table>
<p><img src="/images/2016/11/8.png" alt="image"></p>
<p>长于一口气！这么多的计算，我们到底更新的效果是什么？首先，所有的群组都有了更小的不确定度，从图上来看，椭圆变得更小了；其次，群组改变了形状来适应数据，比如群组B向着点1的方向延长了。总之，每次均值和协方差更新以后，群组都改变形状以更好地表示数据里的模式。</p>
<h2 id="EM算法：交替步骤E和步骤M"><a href="#EM算法：交替步骤E和步骤M" class="headerlink" title="EM算法：交替步骤E和步骤M"></a>EM算法：交替步骤E和步骤M</h2><p>现在我们对于分组的参数有了更好地估计，那么我们可以回过头去计算分组的责任，于是我们可以得到一个更好的参数的估计。实际上，我们可以交替着使用步骤E和步骤M来逐步提高分组的性能。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/ml-clustering-and-retrieval/supplement/s9OBQ/optional-a-worked-out-example-for-em">华盛顿大学机器学习：聚类与检索</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://frankchen.xyz/2016/11/18/Understanding-EM-algorithm/" data-id="cktiql5dv003a6e8zeim01yzs" data-title="Understanding EM algorithm" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/11/25/Devide-and-Conquer-Counting-Inversions-with-Python/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Devide and Conquer Counting Inversions with Python
        
      </div>
    </a>
  
  
    <a href="/2016/11/17/Way-to-solving-the-DS-Store-problem-of-Mac/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Way to solving the .DS_Store problem of Mac</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/note/">note</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tutorial/">tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DS-Store/" rel="tag">.DS_Store</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/" rel="tag">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Coursera/" rel="tag">Coursera</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNN/" rel="tag">DNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/" rel="tag">Data Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Structure/" rel="tag">Data Structure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Funny/" rel="tag">Funny</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Go/" rel="tag">Go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hbase/" rel="tag">Hbase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Interview/" rel="tag">Interview</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter-Notebook/" rel="tag">Jupyter Notebook</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaggle/" rel="tag">Kaggle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Keras/" rel="tag">Keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LDA/" rel="tag">LDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/" rel="tag">LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Life/" rel="tag">Life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/" rel="tag">Mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/" rel="tag">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Numpy/" rel="tag">Numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OOP/" rel="tag">OOP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Old-Driver/" rel="tag">Old Driver</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pandas/" rel="tag">Pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyQt5/" rel="tag">PyQt5</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pycharm/" rel="tag">Pycharm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recommendation-System/" rel="tag">Recommendation System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL/" rel="tag">SQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tex/" rel="tag">Tex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Time-Management/" rel="tag">Time Management</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VPN/" rel="tag">VPN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/amazon/" rel="tag">amazon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bash/" rel="tag">bash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chicken-soup/" rel="tag">chicken-soup</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/" rel="tag">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/re/" rel="tag">re</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/" rel="tag">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/time-series/" rel="tag">time series</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tips/" rel="tag">tips</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tutorial/" rel="tag">tutorial</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/DS-Store/" style="font-size: 10px;">.DS_Store</a> <a href="/tags/Algorithm/" style="font-size: 15.71px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Coursera/" style="font-size: 10px;">Coursera</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/Data-Science/" style="font-size: 17.14px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 10px;">Data Structure</a> <a href="/tags/Deep-Learning/" style="font-size: 17.14px;">Deep Learning</a> <a href="/tags/Docker/" style="font-size: 11.43px;">Docker</a> <a href="/tags/Funny/" style="font-size: 14.29px;">Funny</a> <a href="/tags/Go/" style="font-size: 10px;">Go</a> <a href="/tags/Hadoop/" style="font-size: 11.43px;">Hadoop</a> <a href="/tags/Hbase/" style="font-size: 11.43px;">Hbase</a> <a href="/tags/Hive/" style="font-size: 10px;">Hive</a> <a href="/tags/Interview/" style="font-size: 10px;">Interview</a> <a href="/tags/Java/" style="font-size: 12.86px;">Java</a> <a href="/tags/Jupyter-Notebook/" style="font-size: 10px;">Jupyter Notebook</a> <a href="/tags/Kaggle/" style="font-size: 10px;">Kaggle</a> <a href="/tags/Keras/" style="font-size: 11.43px;">Keras</a> <a href="/tags/LDA/" style="font-size: 10px;">LDA</a> <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/Life/" style="font-size: 10px;">Life</a> <a href="/tags/Linux/" style="font-size: 18.57px;">Linux</a> <a href="/tags/Mac/" style="font-size: 14.29px;">Mac</a> <a href="/tags/Machine-Learning/" style="font-size: 12.86px;">Machine Learning</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Note/" style="font-size: 10px;">Note</a> <a href="/tags/Numpy/" style="font-size: 11.43px;">Numpy</a> <a href="/tags/OOP/" style="font-size: 10px;">OOP</a> <a href="/tags/Old-Driver/" style="font-size: 11.43px;">Old Driver</a> <a href="/tags/Pandas/" style="font-size: 12.86px;">Pandas</a> <a href="/tags/PyQt5/" style="font-size: 10px;">PyQt5</a> <a href="/tags/Pycharm/" style="font-size: 10px;">Pycharm</a> <a href="/tags/Python/" style="font-size: 11.43px;">Python</a> <a href="/tags/RNN/" style="font-size: 14.29px;">RNN</a> <a href="/tags/Recommendation-System/" style="font-size: 10px;">Recommendation System</a> <a href="/tags/SQL/" style="font-size: 11.43px;">SQL</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/TensorFlow/" style="font-size: 12.86px;">TensorFlow</a> <a href="/tags/Tex/" style="font-size: 10px;">Tex</a> <a href="/tags/Time-Management/" style="font-size: 10px;">Time Management</a> <a href="/tags/VPN/" style="font-size: 10px;">VPN</a> <a href="/tags/amazon/" style="font-size: 10px;">amazon</a> <a href="/tags/bash/" style="font-size: 10px;">bash</a> <a href="/tags/chicken-soup/" style="font-size: 12.86px;">chicken-soup</a> <a href="/tags/git/" style="font-size: 11.43px;">git</a> <a href="/tags/life/" style="font-size: 10px;">life</a> <a href="/tags/nginx/" style="font-size: 10px;">nginx</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/re/" style="font-size: 10px;">re</a> <a href="/tags/scala/" style="font-size: 10px;">scala</a> <a href="/tags/spark/" style="font-size: 11.43px;">spark</a> <a href="/tags/time-series/" style="font-size: 10px;">time series</a> <a href="/tags/tips/" style="font-size: 10px;">tips</a> <a href="/tags/tutorial/" style="font-size: 12.86px;">tutorial</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 11.43px;">运维</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/09/14/recent-two-years/">近两年经历，有感</a>
          </li>
        
          <li>
            <a href="/2019/10/24/amazon-vat-cal/">用python 自动计算亚马逊vat税款</a>
          </li>
        
          <li>
            <a href="/2018/12/20/attachments/">python 发送带各种附件的邮件示例</a>
          </li>
        
          <li>
            <a href="/2018/09/11/Pyqt5-GUI-package-on-Windows/">PyQt5 编写并在Windows上用Cx_Freeze打包GUI程序</a>
          </li>
        
          <li>
            <a href="/2018/08/22/learning-from-donald-trump/">向特朗普同志学习</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 frankchen0130<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>