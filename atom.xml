<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>不正经数据科学家</title>
  
  <subtitle>Enjoy everything fun and challenging</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://frankchen.xyz/"/>
  <updated>2018-04-10T08:15:51.972Z</updated>
  <id>http://frankchen.xyz/</id>
  
  <author>
    <name>江南消夏</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>处理大数据集的建议</title>
    <link href="http://frankchen.xyz/2018/04/10/handle-big-datasets/"/>
    <id>http://frankchen.xyz/2018/04/10/handle-big-datasets/</id>
    <published>2018-04-10T07:07:34.000Z</published>
    <updated>2018-04-10T08:15:51.972Z</updated>
    
    <content type="html"><![CDATA[<p>最近的一些比赛如<a href="https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection" target="_blank" rel="external">TalkingData AdTracking Fraud Detection Challenge | Kaggle</a>提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。<br><a id="more"></a></p><h2 id="1-及时删除无用变量并垃圾回收"><a href="#1-及时删除无用变量并垃圾回收" class="headerlink" title="1.及时删除无用变量并垃圾回收"></a>1.及时删除无用变量并垃圾回收</h2><p>通常我们在特征工程中会涉及大量的转换操作，产生很多的中间变量等，除了使用<code>del</code>以外，使用<code>gc.collect()</code>也是个不错的选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">temp = pd.read_csv(<span class="string">'../input/train_sample.csv'</span>)</div><div class="line"></div><div class="line"><span class="comment">#do something to the file</span></div><div class="line">temp[<span class="string">'os'</span>] = temp[<span class="string">'os'</span>].astype(<span class="string">'str'</span>)</div><div class="line"><span class="comment">#delete when no longer needed</span></div><div class="line"><span class="keyword">del</span> temp</div><div class="line"><span class="comment">#collect residual garbage</span></div><div class="line">gc.collect()</div></pre></td></tr></table></figure><h2 id="2-预定义数据类型"><a href="#2-预定义数据类型" class="headerlink" title="2.预定义数据类型"></a>2.预定义数据类型</h2><p>pandas一般会自己推断数据类型，不过倾向于使用耗费空间大的，如下面例子所示，预定义数据类型节省了超过一半的空间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">dtypes = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'uint32'</span>,</div><div class="line">        <span class="string">'app'</span>           : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'device'</span>        : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'os'</span>            : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'channel'</span>       : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'uint8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">dtypes2 = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'int32'</span>,</div><div class="line">        <span class="string">'app'</span>           : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'device'</span>        : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'os'</span>            : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'channel'</span>       : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'int8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,dtype=dtypes,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,dtype=dtypes2,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null int64</div><div class="line">app                100000 non-null int64</div><div class="line">device             100000 non-null int64</div><div class="line">os                 100000 non-null int64</div><div class="line">channel            100000 non-null int64</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null int64</div><div class="line">dtypes: datetime64[ns](1), int64(6), object(1)</div><div class="line">memory usage: 6.1+ MB</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null uint32</div><div class="line">app                100000 non-null uint16</div><div class="line">device             100000 non-null uint16</div><div class="line">os                 100000 non-null uint16</div><div class="line">channel            100000 non-null uint16</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null uint8</div><div class="line">dtypes: datetime64[ns](1), object(1), uint16(4), uint32(1), uint8(1)</div><div class="line">memory usage: 2.8+ MB</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null int32</div><div class="line">app                100000 non-null int16</div><div class="line">device             100000 non-null int16</div><div class="line">os                 100000 non-null int16</div><div class="line">channel            100000 non-null int16</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null int8</div><div class="line">dtypes: datetime64[ns](1), int16(4), int32(1), int8(1), object(1)</div><div class="line">memory usage: 2.8+ MB</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="3-只使用csv文件内的指定行"><a href="#3-只使用csv文件内的指定行" class="headerlink" title="3.只使用csv文件内的指定行"></a>3.只使用csv文件内的指定行</h2><h3 id="a-指定行数"><a href="#a-指定行数" class="headerlink" title="a) 指定行数"></a>a) 指定行数</h3><p>直接使用nrows指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, nrows=<span class="number">1e5</span>, dtype=dtypes)</div></pre></td></tr></table></figure><h3 id="b-跳过行数"><a href="#b-跳过行数" class="headerlink" title="b) 跳过行数"></a>b) 跳过行数</h3><p>比如我们跳过前500w取100w下面保留了head，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, skiprows=range(<span class="number">1</span>, <span class="number">5000000</span>), nrows=<span class="number">1000000</span>, dtype=dtypes)</div></pre></td></tr></table></figure><h3 id="c-sampling"><a href="#c-sampling" class="headerlink" title="c) sampling"></a>c) sampling</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> subprocess</div><div class="line">print(<span class="string">'# Line count:'</span>)</div><div class="line"><span class="keyword">for</span> file <span class="keyword">in</span> [<span class="string">'train.csv'</span>, <span class="string">'test.csv'</span>, <span class="string">'train_sample.csv'</span>]:</div><div class="line">    lines = subprocess.run([<span class="string">'wc'</span>, <span class="string">'-l'</span>, <span class="string">'../input/&#123;&#125;'</span>.format(file)], stdout=subprocess.PIPE).stdout.decode(<span class="string">'utf-8'</span>)</div><div class="line">    print(lines, end=<span class="string">''</span>, flush=<span class="keyword">True</span>)</div><div class="line"><span class="string">'''</span></div><div class="line"># Line count:</div><div class="line">184903891 ../input/train.csv</div><div class="line">18790470 ../input/test.csv</div><div class="line">100001 ../input/train_sample.csv</div><div class="line">'''</div></pre></td></tr></table></figure><p>train一共有<code>lines=184903891</code> 行，那么假设我们需要采样出100w行，那么我们需要跳过<code>lines - 1 - 1000000</code>行，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#generate list of lines to skip</span></div><div class="line">skiplines = np.random.choice(np.arange(<span class="number">1</span>, lines), size=lines<span class="number">-1</span><span class="number">-1000000</span>, replace=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="comment">#sort the list</span></div><div class="line">skiplines=np.sort(skiplines)</div><div class="line"><span class="comment">#check our list</span></div><div class="line">print(<span class="string">'lines to skip:'</span>, len(skiplines))</div><div class="line">print(<span class="string">'remaining lines in sample:'</span>, lines-len(skiplines), <span class="string">'(remember that it includes the heading!)'</span>)</div><div class="line"></div><div class="line"><span class="comment">###################SANITY CHECK###################</span></div><div class="line"><span class="comment">#find lines that weren't skipped by checking difference between each consecutive line</span></div><div class="line"><span class="comment">#how many out of first 100000 will be imported into the csv?</span></div><div class="line">diff = skiplines[<span class="number">1</span>:<span class="number">100000</span>]-skiplines[<span class="number">2</span>:<span class="number">100001</span>]</div><div class="line">remain = sum(diff!=<span class="number">-1</span>)</div><div class="line">print(<span class="string">'Ratio of lines from first 100000 lines:'</span>,  <span class="string">'&#123;0:.5f&#125;'</span>.format(remain/<span class="number">100000</span>) ) </div><div class="line">print(<span class="string">'Ratio imported from all lines:'</span>, <span class="string">'&#123;0:.5f&#125;'</span>.format((lines-len(skiplines))/lines) )</div><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, skiprows=skiplines, dtype=dtypes)</div><div class="line">train.head()</div><div class="line"><span class="keyword">del</span> skiplines</div><div class="line">gc.collect()</div></pre></td></tr></table></figure><h2 id="4-使用pandas-的生成器，用chunk处理"><a href="#4-使用pandas-的生成器，用chunk处理" class="headerlink" title="4.使用pandas 的生成器，用chunk处理"></a>4.使用pandas 的生成器，用chunk处理</h2><p>这里我们使用np.where过滤掉‘is_attributed’为0的部分（例如<code>[xv if c else yv for (c,xv,yv) in zip(condition,x,y)]</code>）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#set up an empty dataframe</span></div><div class="line">df_converted = pd.DataFrame()</div><div class="line"></div><div class="line"><span class="comment">#we are going to work with chunks of size 1 million rows</span></div><div class="line">chunksize = <span class="number">10</span> ** <span class="number">6</span></div><div class="line"></div><div class="line"><span class="comment">#in each chunk, filter for values that have 'is_attributed'==1, and merge these values into one dataframe</span></div><div class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> pd.read_csv(<span class="string">'../input/train.csv'</span>, chunksize=chunksize, dtype=dtypes):</div><div class="line">    filtered = (chunk[(np.where(chunk[<span class="string">'is_attributed'</span>]==<span class="number">1</span>, <span class="keyword">True</span>, <span class="keyword">False</span>))])</div><div class="line">    df_converted = pd.concat([df_converted, filtered], ignore_index=<span class="keyword">True</span>, )</div></pre></td></tr></table></figure></p><h2 id="5-只载入若干列"><a href="#5-只载入若干列" class="headerlink" title="5.只载入若干列"></a>5.只载入若干列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#wanted columns</span></div><div class="line">columns = [<span class="string">'ip'</span>, <span class="string">'click_time'</span>, <span class="string">'is_attributed'</span>]</div><div class="line">dtypes = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'uint32'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'uint8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">ips_df = pd.read_csv(<span class="string">'../input/train.csv'</span>, usecols=columns, dtype=dtypes)</div><div class="line">print(ips_df.info())</div><div class="line">ips_df.head()</div><div class="line"><span class="string">'''</span></div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 184903890 entries, 0 to 184903889</div><div class="line">Data columns (total 3 columns):</div><div class="line">ip               uint32</div><div class="line">click_time       object</div><div class="line">is_attributed    uint8</div><div class="line">dtypes: object(1), uint32(1), uint8(1)</div><div class="line">memory usage: 2.2+ GB</div><div class="line">None'''</div></pre></td></tr></table></figure><h2 id="6-结合多种方法创意性的处理数据"><a href="#6-结合多种方法创意性的处理数据" class="headerlink" title="6.结合多种方法创意性的处理数据"></a>6.结合多种方法创意性的处理数据</h2><p>例如无法使用整个数据来groupby那么可以分块来做，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">size=<span class="number">100000</span></div><div class="line">all_rows = len(ips_df)</div><div class="line">num_parts = all_rows//size</div><div class="line"></div><div class="line"><span class="comment">#generate the first batch</span></div><div class="line">ip_sums = ips_df[<span class="number">0</span>:size][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line"></div><div class="line"><span class="comment">#add remaining batches</span></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> range(<span class="number">1</span>,num_parts):</div><div class="line">    start = p*size</div><div class="line">    end = p*size + size</div><div class="line">    <span class="keyword">if</span> end &lt; all_rows:</div><div class="line">        group = ips_df[start:end][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        group = ips_df[start:][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line">    ip_sums = ip_sums.merge(group, on=<span class="string">'ip'</span>, how=<span class="string">'outer'</span>)</div><div class="line">    ip_sums.columns = [<span class="string">'ip'</span>, <span class="string">'sum1'</span>,<span class="string">'sum2'</span>]</div><div class="line">    ip_sums[<span class="string">'conversions_per_ip'</span>] = np.nansum((ip_sums[<span class="string">'sum1'</span>], ip_sums[<span class="string">'sum2'</span>]), axis = <span class="number">0</span>)</div><div class="line">    ip_sums.drop(columns=[<span class="string">'sum1'</span>, <span class="string">'sum2'</span>], axis = <span class="number">0</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><h2 id="7-使用dask代替pandas"><a href="#7-使用dask代替pandas" class="headerlink" title="7.使用dask代替pandas"></a>7.使用dask代替pandas</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import dask</div><div class="line">import dask.dataframe as dd</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近的一些比赛如&lt;a href=&quot;https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection&quot;&gt;TalkingData AdTracking Fraud Detection Challenge | Kaggle&lt;/a&gt;提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Kaggle" scheme="http://frankchen.xyz/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之 sklearn中的pipeline</title>
    <link href="http://frankchen.xyz/2018/04/08/pipeline-in-machine-learning/"/>
    <id>http://frankchen.xyz/2018/04/08/pipeline-in-machine-learning/</id>
    <published>2018-04-08T08:13:42.000Z</published>
    <updated>2018-04-10T06:04:14.946Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15231874915799.jpg" alt=""><br><a id="more"></a><br>如图所示，利用pipeline我们可以方便的减少代码量同时让机器学习的流程变得直观，<br><img src="/images/15231783974167.jpg" alt=""></p><p>例如我们需要做如下操作，容易看出，训练测试集重复了代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">vect = CountVectorizer()</div><div class="line">tfidf = TfidfTransformer()</div><div class="line">clf = SGDClassifier()</div><div class="line"></div><div class="line">vX = vect.fit_transform(Xtrain)</div><div class="line">tfidfX = tfidf.fit_transform(vX)</div><div class="line">predicted = clf.fit_predict(tfidfX)</div><div class="line"></div><div class="line"><span class="comment"># Now evaluate all steps on test set</span></div><div class="line">vX = vect.fit_transform(Xtest)</div><div class="line">tfidfX = tfidf.fit_transform(vX)</div><div class="line">predicted = clf.fit_predict(tfidfX)</div></pre></td></tr></table></figure><p>利用pipeline，上面代码可以抽象为，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">pipeline = Pipeline([</div><div class="line">    (<span class="string">'vect'</span>, CountVectorizer()),</div><div class="line">    (<span class="string">'tfidf'</span>, TfidfTransformer()),</div><div class="line">    (<span class="string">'clf'</span>, SGDClassifier()),</div><div class="line">])</div><div class="line">predicted = pipeline.fit(Xtrain).predict(Xtrain)</div><div class="line"><span class="comment"># Now evaluate all steps on test set</span></div><div class="line">predicted = pipeline.predict(Xtest)</div></pre></td></tr></table></figure><p>注意，pipeline最后一步如果有predict()方法我们才可以对pipeline使用fit_predict()，同理，最后一步如果有transform()方法我们才可以对pipeline使用fit_transform()方法。</p><h2 id="使用pipeline做cross-validation"><a href="#使用pipeline做cross-validation" class="headerlink" title="使用pipeline做cross validation"></a>使用pipeline做cross validation</h2><p>看如下案例，即先对输入手写数字的数据进行PCA降维，再通过逻辑回归预测标签。其中我们通过pipeline对<br>PCA的降维维数n_components和逻辑回归的正则项C大小做交叉验证，主要步骤有：</p><ol><li>依次实例化各成分对象如<code>pca = decomposition.PCA()</code></li><li>以(name, object)的tuble为元素组装pipeline如<code>Pipeline(steps=[(&#39;pca&#39;, pca), (&#39;logistic&#39;, logistic)])</code></li><li>初始化CV参数如<code>n_components = [20, 40, 64]</code></li><li>实例化CV对象如<code>estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, logistic__C=Cs))</code>，其中注意参数的传递方式，即key为pipeline元素名+函数参数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, decomposition, datasets</div><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line">logistic = linear_model.LogisticRegression()</div><div class="line"></div><div class="line">pca = decomposition.PCA()</div><div class="line">pipe = Pipeline(steps=[(<span class="string">'pca'</span>, pca), (<span class="string">'logistic'</span>, logistic)])</div><div class="line"></div><div class="line">digits = datasets.load_digits()</div><div class="line">X_digits = digits.data</div><div class="line">y_digits = digits.target</div><div class="line"></div><div class="line"><span class="comment"># Prediction</span></div><div class="line">n_components = [<span class="number">20</span>, <span class="number">40</span>, <span class="number">64</span>]</div><div class="line">Cs = np.logspace(<span class="number">-4</span>, <span class="number">4</span>, <span class="number">3</span>)</div><div class="line"></div><div class="line">pca.fit(X_digits)</div><div class="line">estimator = GridSearchCV(pipe,</div><div class="line">                         dict(pca__n_components=n_components, logistic__C=Cs))</div><div class="line">estimator.fit(X_digits, y_digits)</div><div class="line"></div><div class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">4</span>, <span class="number">3</span>))</div><div class="line">plt.clf()</div><div class="line">plt.axes([<span class="number">.2</span>, <span class="number">.2</span>, <span class="number">.7</span>, <span class="number">.7</span>])</div><div class="line">plt.plot(pca.explained_variance_, linewidth=<span class="number">2</span>)</div><div class="line">plt.axis(<span class="string">'tight'</span>)</div><div class="line">plt.xlabel(<span class="string">'n_components'</span>)</div><div class="line">plt.ylabel(<span class="string">'explained_variance_'</span>)</div><div class="line">plt.axvline(</div><div class="line">    estimator.best_estimator_.named_steps[<span class="string">'pca'</span>].n_components,</div><div class="line">    linestyle=<span class="string">':'</span>,</div><div class="line">    label=<span class="string">'n_components chosen'</span>)</div><div class="line">plt.legend(prop=dict(size=<span class="number">12</span>))</div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="自定义transformer"><a href="#自定义transformer" class="headerlink" title="自定义transformer"></a>自定义transformer</h2><h2 id="FeatureUnion"><a href="#FeatureUnion" class="headerlink" title="FeatureUnion"></a>FeatureUnion</h2><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html" target="_blank" rel="external">sklearn.pipeline.FeatureUnion — scikit-learn 0.19.1 documentation</a> 和pipeline的序列执行不同，FeatureUnion指的是并行地应用许多transformer在input上，再将结果合并，所以自然地适合特征工程中的增加特征，而FeatureUnion与pipeline组合可以方便的完成许多复杂的操作，例如如下的例子，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">pipeline = Pipeline([</div><div class="line">  (<span class="string">'extract_essays'</span>, EssayExractor()),</div><div class="line">  (<span class="string">'features'</span>, FeatureUnion([</div><div class="line">    (<span class="string">'ngram_tf_idf'</span>, Pipeline([</div><div class="line">      (<span class="string">'counts'</span>, CountVectorizer()),</div><div class="line">      (<span class="string">'tf_idf'</span>, TfidfTransformer())</div><div class="line">    ])),</div><div class="line">    (<span class="string">'essay_length'</span>, LengthTransformer()),</div><div class="line">    (<span class="string">'misspellings'</span>, MispellingCountTransformer())</div><div class="line">  ])),</div><div class="line">  (<span class="string">'classifier'</span>, MultinomialNB())</div><div class="line">])</div></pre></td></tr></table></figure><p>整个<code>features</code>是一个FeatureUnion，而其中的ngram_tf_idf又是一个包括两步的pipeline。<br><img src="/images/15233302459256.jpg" alt=""></p><p>下面的例子中，使用FeatureUnion结合PCA降维后特征以及选择原特征中的几个作为特征组合再喂给SVM分类，最后用grid_search 做了 pca的<code>n_components</code>、SelectKBest的<code>k</code>以及SVM的<code>C</code>的CV。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline, FeatureUnion</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</div><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</div><div class="line"></div><div class="line">iris = load_iris()</div><div class="line"></div><div class="line">X, y = iris.data, iris.target</div><div class="line"></div><div class="line">print(X.shape, y.shape)</div><div class="line"></div><div class="line"><span class="comment"># This dataset is way too high-dimensional. Better do PCA:</span></div><div class="line">pca = PCA()</div><div class="line"></div><div class="line"><span class="comment"># Maybe some original features where good, too?</span></div><div class="line">selection = SelectKBest()</div><div class="line"></div><div class="line"><span class="comment"># Build estimator from PCA and Univariate selection:</span></div><div class="line"></div><div class="line">svm = SVC(kernel=<span class="string">"linear"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Do grid search over k, n_components and C:</span></div><div class="line"></div><div class="line">pipeline = Pipeline([(<span class="string">"features"</span>,</div><div class="line">                      FeatureUnion([(<span class="string">"pca"</span>, pca), (<span class="string">"univ_select"</span>,</div><div class="line">                                                   selection)])), (<span class="string">"svm"</span>,</div><div class="line">                                                                   svm)])</div><div class="line"></div><div class="line">param_grid = dict(</div><div class="line">    features__pca__n_components=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</div><div class="line">    features__univ_select__k=[<span class="number">1</span>, <span class="number">2</span>],</div><div class="line">    svm__C=[<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>])</div><div class="line"></div><div class="line">grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=<span class="number">10</span>)</div><div class="line">grid_search.fit(X, y)</div><div class="line"></div><div class="line">print(grid_search.best_estimator_)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15231874915799.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>VPS搭建私人BT离线服务器</title>
    <link href="http://frankchen.xyz/2018/04/08/private-BT-server/"/>
    <id>http://frankchen.xyz/2018/04/08/private-BT-server/</id>
    <published>2018-04-08T03:13:51.000Z</published>
    <updated>2018-04-08T03:47:02.802Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15231584798585.jpg" alt=""><br>使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。<br><a id="more"></a> </p><h2 id="安装及配置-Transmission"><a href="#安装及配置-Transmission" class="headerlink" title="安装及配置 Transmission"></a>安装及配置 Transmission</h2><ul><li>安装 <code>sudo apt-get install transmission-daemon</code></li><li>配置 停止服务（否则配置文件锁定，无法修改）<code>sudo service transmission-daemon stop</code></li><li>编辑配置文件</li></ul><p><code>sudo vim /etc/transmission-daemon/settings.json</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="string">"ratio-limit"</span>: 0.0100, </div><div class="line">    <span class="string">"ratio-limit-enabled"</span>: <span class="literal">true</span>,  </div><div class="line">    <span class="string">"rpc-password"</span>: <span class="string">"*******"</span>,   </div><div class="line">    <span class="string">"rpc-username"</span>: <span class="string">"frank"</span>,</div><div class="line">    <span class="string">"download-dir"</span>: <span class="string">"/var/www/html/Downloads"</span>, </div><div class="line">&#125;</div></pre></td></tr></table></figure><p> 我只列出了我修改过且无法在 Transmission Web-GUI 中无法完成修改的几项，四项依次是下载完成做种率，开启限制做种率，Web-GUI 密码，Web-GUI 用户名。像保存路径，下载/ 上传速度限制，都可以在 Web-GUI 中直接设定，为了方便之后对下载文件的 Web 管理，我直接将保存路径改到了 Web 发布路径下的一个子目录。</p><p> 重启服务</p><p> <code>sudo service transmission-daemon start</code></p><p> 此时在浏览器打开<code>VPS的IP地址/域名:9091</code>并输入刚刚设置的用户名及密码应该就可以访问 Transmission 的 Web-GUI了。<br> <img src="/images/Screen%20Shot%202018-04-08%20at%2011.25.35.png" alt="Screen Shot 2018-04-08 at 11.25.35"></p><p> 可是在添加了第一个任务后出现保存路径写入权限的问题。<br>解决办法如<a href="https://askubuntu.com/questions/221081/permission-denied-when-downloading-with-transmission-deamon" target="_blank" rel="external">Permission denied when downloading with transmission deamon - Ask Ubuntu</a>所示：</p><p>我们的下载地址是 <code>/var/www/html/Downloads</code> 用户名是<code>znwindy</code>:<br>那么 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将本用户加入 `debian-transmission`组</span></div><div class="line">sudo usermod <span class="_">-a</span> -G debian-transmission znwindy</div><div class="line"><span class="comment"># 文件夹所有者</span></div><div class="line">sudo chgrp debian-transmission /var/www/html/Downloads</div><div class="line"><span class="comment"># 组添加写权限</span></div><div class="line">sudo chmod -R 755 /var/www</div><div class="line"><span class="comment"># 停止后台deamon </span></div><div class="line"></div><div class="line">sudo service transmission-daemon stop</div><div class="line"><span class="comment"># 更改 file creation mask</span></div><div class="line">sudo vim /etc/transmission-daemon/settings.json</div><div class="line"><span class="comment"># 把"umask": 18 改为 "umask": 2</span></div><div class="line"><span class="comment"># 重启服务</span></div><div class="line">sudo service transmission-daemon start</div></pre></td></tr></table></figure><p>即可解决写的问题。</p><h2 id="配置-Apache-加密区域"><a href="#配置-Apache-加密区域" class="headerlink" title="配置 Apache 加密区域"></a>配置 Apache 加密区域</h2><p>安装apache2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install apache2</div></pre></td></tr></table></figure><p>Adjust the Firewall</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo ufw app list</div><div class="line">sudo ufw allow <span class="string">'Apache Full'</span></div><div class="line">sudo ufw status</div><div class="line">sudo systemctl status apache2</div></pre></td></tr></table></figure><p>密码生成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo htpasswd -c /etc/apache2/.htpasswd 用户名</div></pre></td></tr></table></figure><p>然后会被提示输入两次该 “用户名” 的密码。</p><p>修改虚拟 host 的配置文件<br><code>sudo vim /etc/apache2/sites-enabled/000-default.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;Directory <span class="string">"/var/www/html"</span>&gt;</div><div class="line">        AuthType Basic</div><div class="line">        AuthName <span class="string">"Restricted Content"</span></div><div class="line">        AuthUserFile /etc/apache2/.htpasswd</div><div class="line">        Require valid-user</div><div class="line">&lt;/Directory&gt;</div></pre></td></tr></table></figure><p>保存后重启</p><p><code>sudo service apache2 restart</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过 HTTP 将下载的任务取回本地，速度也很快！这样，通过访问 Transmission Web-GUI “投喂” 种子，磁力链，然后在下载完成后通过 HTTP 方式从 VPS 将资源取回本地，甚至直接对 .mp3、.mp4 等文件格式进行在线播放，实现了一个简化版的迅雷离线下载，可是它却在下载某些特定资源时远比迅雷离线管用。</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/24478342" target="_blank" rel="external">在 VPS 上搭建私人离线下载</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15231584798585.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。&lt;br&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
      <category term="Old Driver" scheme="http://frankchen.xyz/tags/Old-Driver/"/>
    
  </entry>
  
  <entry>
    <title>numpy 中增加channel的方法</title>
    <link href="http://frankchen.xyz/2018/03/29/numpy-add-channel/"/>
    <id>http://frankchen.xyz/2018/03/29/numpy-add-channel/</id>
    <published>2018-03-29T12:15:30.000Z</published>
    <updated>2018-03-29T12:48:49.127Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15223277046847.jpg" alt=""><br>numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。</p><a id="more"></a><p>在机器学习中，所有的数据都是向量和矩阵，而怎么根据我们所要解决的问题来调整模型以及数据的格式，也就是矩阵的维度和大小是一项重要的基本功，那么本文就具体介绍下numpy中数组的转换，也就是增加channel的方法。</p><h2 id="一维转二维"><a href="#一维转二维" class="headerlink" title="一维转二维"></a>一维转二维</h2><p>例如我们有一个一维的numpy array，有如下方法可以转为二维</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">a = np.arange(<span class="number">10</span>)</div><div class="line">a</div><div class="line">a.shape</div><div class="line">b = a[:,<span class="keyword">None</span>]</div><div class="line">b</div><div class="line">b.shape</div><div class="line"><span class="string">'''</span></div><div class="line">array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</div><div class="line">(10,)</div><div class="line">array([[0],</div><div class="line">       [1],</div><div class="line">       [2],</div><div class="line">       [3],</div><div class="line">       [4],</div><div class="line">       [5],</div><div class="line">       [6],</div><div class="line">       [7],</div><div class="line">       [8],</div><div class="line">       [9]])</div><div class="line">(10, 1)</div><div class="line">'''</div></pre></td></tr></table></figure><p> 可以看到，<code>a</code>确实被转为了二维，以下方法是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">c = a[:,np.newaxis]</div><div class="line">c</div><div class="line">(c == b).all()</div><div class="line">np.newaxis == <span class="keyword">None</span></div><div class="line"><span class="string">'''</span></div><div class="line">array([[0],</div><div class="line">       [1],</div><div class="line">       [2],</div><div class="line">       [3],</div><div class="line">       [4],</div><div class="line">       [5],</div><div class="line">       [6],</div><div class="line">       [7],</div><div class="line">       [8],</div><div class="line">       [9]])</div><div class="line">True</div><div class="line">True</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="转为多维"><a href="#转为多维" class="headerlink" title="转为多维"></a>转为多维</h2><p>时间序列预测中，我们一般需要的是(sample，time_stamp，feature)的3 个channel的数据，即一个三维矩阵，包含若干个sample，每个sample包含若干个时间序列点，而每个时间序列点有包括若干个feature，哪怕我们只是做单变量的时间序列预测，输入RNN网络例如LSTM的时候，数据也必须是三维的格式，下面我们讲一讲这么做的方法。</p><p>例如我们有一个若干个时间点每个时间点有两个特征的数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">a = np.arange(<span class="number">24</span>).reshape((<span class="number">-1</span>,<span class="number">2</span>))</div><div class="line">a.shape</div><div class="line">a</div><div class="line"><span class="string">'''</span></div><div class="line">(12, 2)</div><div class="line">array([[ 0,  1],</div><div class="line">       [ 2,  3],</div><div class="line">       [ 4,  5],</div><div class="line">       [ 6,  7],</div><div class="line">       [ 8,  9],</div><div class="line">       [10, 11],</div><div class="line">       [12, 13],</div><div class="line">       [14, 15],</div><div class="line">       [16, 17],</div><div class="line">       [18, 19],</div><div class="line">       [20, 21],</div><div class="line">       [22, 23]])</div><div class="line">'''</div></pre></td></tr></table></figure><p>我们将a转化为三个channel，即可以</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">b = a[:,<span class="keyword">None</span>,:]</div><div class="line">b.shape</div><div class="line">b</div><div class="line"><span class="string">'''</span></div><div class="line">(12, 1, 2)</div><div class="line">array([[[ 0,  1]],</div><div class="line"></div><div class="line">       [[ 2,  3]],</div><div class="line"></div><div class="line">       [[ 4,  5]],</div><div class="line"></div><div class="line">       [[ 6,  7]],</div><div class="line"></div><div class="line">       [[ 8,  9]],</div><div class="line"></div><div class="line">       [[10, 11]],</div><div class="line"></div><div class="line">       [[12, 13]],</div><div class="line"></div><div class="line">       [[14, 15]],</div><div class="line"></div><div class="line">       [[16, 17]],</div><div class="line"></div><div class="line">       [[18, 19]],</div><div class="line"></div><div class="line">       [[20, 21]],</div><div class="line"></div><div class="line">       [[22, 23]]])</div><div class="line">       '''</div></pre></td></tr></table></figure><p>以上对应着pandas的Dataframe，及我们对Dataframe取values属性，会得到一个二维矩阵，做法就如同上面一样，但是如果是Series的话，取values属性得到的是一个一维的，这时候我们的做法则是，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">c = np.arange(<span class="number">12</span>)</div><div class="line">c</div><div class="line">d = c[:,<span class="keyword">None</span>,<span class="keyword">None</span>]</div><div class="line">d.shape</div><div class="line">d</div><div class="line"><span class="string">'''</span></div><div class="line">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</div><div class="line">(12, 1, 1)</div><div class="line">array([[[ 0]],</div><div class="line"></div><div class="line">       [[ 1]],</div><div class="line"></div><div class="line">       [[ 2]],</div><div class="line"></div><div class="line">       [[ 3]],</div><div class="line"></div><div class="line">       [[ 4]],</div><div class="line"></div><div class="line">       [[ 5]],</div><div class="line"></div><div class="line">       [[ 6]],</div><div class="line"></div><div class="line">       [[ 7]],</div><div class="line"></div><div class="line">       [[ 8]],</div><div class="line"></div><div class="line">       [[ 9]],</div><div class="line"></div><div class="line">       [[10]],</div><div class="line"></div><div class="line">       [[11]]])</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="减少维度"><a href="#减少维度" class="headerlink" title="减少维度"></a>减少维度</h2><p>若要减少数据的维度，我们可以用的方法如下，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">d = np.arange(<span class="number">12</span>)[:,<span class="keyword">None</span>,<span class="keyword">None</span>]</div><div class="line">d.shape</div><div class="line">d</div><div class="line">e = np.squeeze(d)</div><div class="line">e.shape</div><div class="line">e</div><div class="line"><span class="string">'''(12, 1, 1)</span></div><div class="line">array([[[ 0]],</div><div class="line"></div><div class="line">       [[ 1]],</div><div class="line"></div><div class="line">       [[ 2]],</div><div class="line"></div><div class="line">       [[ 3]],</div><div class="line"></div><div class="line">       [[ 4]],</div><div class="line"></div><div class="line">       [[ 5]],</div><div class="line"></div><div class="line">       [[ 6]],</div><div class="line"></div><div class="line">       [[ 7]],</div><div class="line"></div><div class="line">       [[ 8]],</div><div class="line"></div><div class="line">       [[ 9]],</div><div class="line"></div><div class="line">       [[10]],</div><div class="line"></div><div class="line">       [[11]]])</div><div class="line">(12,)</div><div class="line">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])'''</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15223277046847.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python 正则实用例子</title>
    <link href="http://frankchen.xyz/2018/02/24/re-basic-of-python/"/>
    <id>http://frankchen.xyz/2018/02/24/re-basic-of-python/</id>
    <published>2018-02-24T10:52:00.000Z</published>
    <updated>2018-02-24T11:09:45.871Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15194705842254.png" alt=""></p><p>本文主要关于python的正则表达式的符号与方法。</p><a id="more"></a><ul><li>findall: 找寻所有匹配，返回所有组合的列表</li><li>search: 找寻第一个匹配并返回</li><li>sub: 替换符合规律的内容，并返回替换后的内容</li></ul><p><strong>.</strong>：匹配除了换行符以外的任意字符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xy123'</span></div><div class="line">b = re.findall(<span class="string">'x...'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['xy12']</span></div></pre></td></tr></table></figure><p><strong>*</strong>：匹配前一个字符0次或者无限次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xyxy123'</span></div><div class="line">b = re.findall(<span class="string">'x*'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['x', '', 'x', '', '', '', '', '']</span></div></pre></td></tr></table></figure><p><strong>?</strong>：匹配前一个字符0次或者1次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xy123'</span></div><div class="line">b = re.findall(<span class="string">'x?'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['x', '', '', '', '', '']</span></div></pre></td></tr></table></figure><p><strong>.*</strong>：贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">b = re.findall(<span class="string">'xx.*xx'</span>,secret_code)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['xxIxxfasdjifja134xxlovexx23345sdfxxyouxx']</span></div></pre></td></tr></table></figure><p><strong>.*?</strong>：非贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">c = re.findall(<span class="string">'xx.*?xx'</span>,secret_code)</div><div class="line">print(c)</div><div class="line"><span class="comment"># ['xxIxx', 'xxlovexx', 'xxyouxx']</span></div></pre></td></tr></table></figure><p><strong>()</strong>：括号内结果返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">d = re.findall(<span class="string">'xx(.*?)xx'</span>,secret_code)</div><div class="line">print(d)</div><div class="line"><span class="keyword">for</span> each <span class="keyword">in</span> d:</div><div class="line">    print(each)</div><div class="line"><span class="comment"># ['I', 'love', 'you']</span></div><div class="line"><span class="comment"># I</span></div><div class="line"><span class="comment"># love</span></div><div class="line"><span class="comment"># you</span></div></pre></td></tr></table></figure><p><strong>re.S</strong>使得.的作用域包括换行符”\n”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">s = <span class="string">'''sdfxxhello</span></div><div class="line">xxfsdfxxworldxxasdf'''</div><div class="line"></div><div class="line">d = re.findall(<span class="string">'xx(.*?)xx'</span>,s,re.S)</div><div class="line">print(d)</div><div class="line"><span class="comment">#  ['hello\n', 'world']</span></div></pre></td></tr></table></figure><p>对比findall与search的区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">s2 = <span class="string">'asdfxxIxx123xxlovexxdfd'</span></div><div class="line">f = re.search(<span class="string">'xx(.*?)xx123xx(.*?)xx'</span>,s2).group(<span class="number">2</span>)</div><div class="line">print(f)</div><div class="line">f2 = re.findall(<span class="string">'xx(.*?)xx123xx(.*?)xx'</span>,s2)</div><div class="line">print(f2[<span class="number">0</span>][<span class="number">1</span>])</div><div class="line"><span class="comment"># love</span></div><div class="line"><span class="comment"># love</span></div></pre></td></tr></table></figure><p>虽然两者结果相同，但是search是搭配group来得到第二个匹配，而findall的结果是[(‘I’, ‘love’)]，包含元组的列表，所以需要f2[0][1]来引入。</p><p><strong>sub</strong>的使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">s = <span class="string">'123rrrrr123'</span></div><div class="line">output = re.sub(<span class="string">'123(.*?)123'</span>,<span class="string">'123%d123'</span>%<span class="number">789</span>,s)</div><div class="line">print(output)</div><div class="line"><span class="comment"># 123789123</span></div></pre></td></tr></table></figure><p>例如我们需要将文档中的所有的png图片改变路径，即需要找到所有的<code>.png</code>结尾，再将其都加上路径，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiply</span><span class="params">(m)</span>:</span></div><div class="line">    <span class="comment"># Convert group 0 to an integer.</span></div><div class="line">    v = m.group(<span class="number">0</span>)</div><div class="line">    print(v)</div><div class="line">    <span class="comment"># Multiply integer by 2.</span></div><div class="line">    <span class="comment"># ... Convert back into string and return it.</span></div><div class="line">    print(<span class="string">'basic/'</span>+v)</div><div class="line">    <span class="keyword">return</span> <span class="string">'basic/'</span>+v</div></pre></td></tr></table></figure><p>结果如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>autoencoder.png</div><div class="line">    basic/autoencoder.png</div><div class="line">    RNN.png</div><div class="line">    basic/RNN.png</div><div class="line">    rnn_step_forward.png</div><div class="line">    basic/rnn_step_forward.png</div><div class="line">    rnns.png</div><div class="line">    basic/rnns.png</div><div class="line">    rnn_cell_backprop.png</div><div class="line">    basic/rnn_cell_backprop.png</div><div class="line">    LSTM.png</div><div class="line">    basic/LSTM.png</div><div class="line">    LSTM_rnn.png</div><div class="line">    basic/LSTM_rnn.png</div><div class="line">    attn_mechanism.png</div><div class="line">    basic/attn_mechanism.png</div><div class="line">    attn_model.png</div><div class="line">    basic/attn_model.png</div></pre></td></tr></table></figure><p>仿照上面案例，我们可以方便的对我们的任务进行定制。</p><p><strong>subn</strong> 相比sub，subn返回元组，第二个元素表示替换发生的次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(m)</span>:</span></div><div class="line">    <span class="comment"># Convert.</span></div><div class="line">    v = int(m.group(<span class="number">0</span>))</div><div class="line">    <span class="comment"># Add 2.</span></div><div class="line">    <span class="keyword">return</span> str(v + <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># Call re.subn.</span></div><div class="line">result = re.subn(<span class="string">"\d+"</span>, add, <span class="string">"1 2 3 4 5"</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Result string:"</span>, result[<span class="number">0</span>])</div><div class="line">print(<span class="string">"Number of substitutions:"</span>, result[<span class="number">1</span>])</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span></div><div class="line">Result string: <span class="number">11</span> <span class="number">21</span> <span class="number">31</span> <span class="number">41</span> <span class="number">51</span></div><div class="line">Number of substitutions: <span class="number">5</span></div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15194705842254.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文主要关于python的正则表达式的符号与方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="re" scheme="http://frankchen.xyz/tags/re/"/>
    
  </entry>
  
  <entry>
    <title>Tex 写（中文）毕业论文全攻略</title>
    <link href="http://frankchen.xyz/2018/02/08/Writing-Graduation-Thesis-in-Tex/"/>
    <id>http://frankchen.xyz/2018/02/08/Writing-Graduation-Thesis-in-Tex/</id>
    <published>2018-02-07T17:36:41.000Z</published>
    <updated>2018-02-07T18:11:41.628Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15180252634406.png" alt=""></p><p>用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！</p><a id="more"></a><p>这里我们并不存在鄙视链，说什么Tex 优于 Word之类的，其实Word作为极其复杂的文本处理软件，我相信Tex能做到的，Word一定有其实现方式，只不过大部分人都只会用到Word的一小部分功能，相比Word，Tex解决方案更加便捷优雅，比如自动排号（章节、表格、参考文献的编号），全局设置的字体、间距格式等等。相比Word事无巨细的维护修改成本，Tex 的解决方案更加programmer，即软件开发，后期主要工作是迭代维护，若能在前期即考虑这点，后期能省下极多的脑细胞和精力。好了不说多，发车吧~</p><h2 id="总论"><a href="#总论" class="headerlink" title="总论"></a>总论</h2><p> 总体来说，是用上交Tex模板结合Atom编辑器在本地编辑<a href="https://atom.io/" target="_blank" rel="external">Atom</a>（这个用什么编辑器随意）以及Dropbox同步到云端<a href="https://www.dropbox.com/h" target="_blank" rel="external">Dropbox</a>以及云端上在sharelatex服务器上即时编译所见即所得。</p><h2 id="工具使用方法"><a href="#工具使用方法" class="headerlink" title="工具使用方法"></a>工具使用方法</h2><p>首先我们在sharelatex官网<a href="https://www.sharelatex.com/project" target="_blank" rel="external">Your Projects - ShareLaTeX, Online LaTeX Editor</a>注册账号，免费账号即可，如果需要多人协作可以用邀请小号的方式让自己增加权限（sharelatex新建账号不验证邮箱。。所以你懂的），接下来在上交模板<a href="https://github.com/sjtug/SJTUThesis" target="_blank" rel="external">sjtug/SJTUThesis: 上海交通大学 XeLaTeX 学位论文模板 A XeLaTeX template for Shanghai Jiao Tong University (SJTU) thesis.</a>处点击此处添加最新版模板到我们的sharelatex项目，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.25.png" alt="Screen Shot 2018-02-08 at 01.58.25"></p><p><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.56.png" alt="Screen Shot 2018-02-08 at 01.58.56"></p><p>如图，再点进去，先别急着修改，我们先设置个网盘同步，Dropbox需要梯子，在sharelatex的账号设置处链接到Dropbox，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.00.57.png" alt="Screen Shot 2018-02-08 at 02.00.57"></p><p>同时Dropbox安装一个桌面版，需要设置代理，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.02.29.png" alt="Screen Shot 2018-02-08 at 02.02.29"><br>如图，我们使用ss作为代理。</p><p>接下来安装Atom编辑器，在插件里装一个如下插件，这里我们需要它只是为了注释这一个功能，因为我们不需要本地编译。<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.03.38.png" alt="Screen Shot 2018-02-08 at 02.03.38"></p><p>接下来我们就可以在本地用Atom编辑Dropbox网盘在本地的Tex项目，只要我们保存，Dropbox就会同步到sharelatex，如果开启自动编译云端就会展示当下编译的PDF效果，如图<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.07.11.png" alt="Screen Shot 2018-02-08 at 02.07.11"></p><h2 id="Tex模板使用说明"><a href="#Tex模板使用说明" class="headerlink" title="Tex模板使用说明"></a>Tex模板使用说明</h2><p>详见此处<a href="http://sjtug.org/SJTUThesis/README.pdf" target="_blank" rel="external">README.pdf</a>，主要思路就是把各章、摘要、参考文献等分为不同的tex文件，图表等资源放在一处文件夹内，逐个引用，有全局的的设置文件，编译时将这些零件拼接为pdf，后续会添加更多心得。</p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ol><li><a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="external">MathJax basic tutorial and quick reference - Mathematics Meta Stack Exchange</a>：一个常用Latex公式符号的全集</li><li>如果上面没找到，可以试试这里，手写识别latex字符<a href="http://detexify.kirelabs.org/classify.html" target="_blank" rel="external">Detexify LaTeX handwritten symbol recognition</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15180252634406.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tex" scheme="http://frankchen.xyz/tags/Tex/"/>
    
  </entry>
  
  <entry>
    <title>理解TSNE算法</title>
    <link href="http://frankchen.xyz/2018/01/30/Understanding-TSNE/"/>
    <id>http://frankchen.xyz/2018/01/30/Understanding-TSNE/</id>
    <published>2018-01-30T03:39:39.000Z</published>
    <updated>2018-01-30T08:17:42.455Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15172836269060.jpg" alt=""></p><p>结合<a href="http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf" target="_blank" rel="external">论文</a>公式与几个python实现理解t-SNE算法。<br><a id="more"></a></p><p>t-SNE 是一种数据可视化工具，它可以将高维数据降维到2-3维以用于画图，局部相似性被这种embedding所保留。</p><p>t-SNE把原空间的数据点之间的距离转换为高斯分布概率，如果两点在高维空间距离越近，那么这个概率值越大。注意到高斯分布的这个标准差$\sigma_i$ 对每个点都是不同的，这也是算法的创新点之一，因为理论上空间不同位置的点的密度是不同的，条件概率如此计算，</p><p>$$p_{j|i} = \frac{\exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}_j) / (2 \sigma_i^2)})}{\sum_{i \neq k} \exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}_k) / (2 \sigma_i^2)})}, \quad p_{i|i} = 0,$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.18.45.png" alt="Screen Shot 2018-01-30 at 15.18.45"></p><p>图中公式是理论方式，实际是先计算条件概率再用下面公式来产生联合分布，</p><p>$$p_{ij} = \frac{p_{j|i} + p_{i|j}}{2N}.$$</p><p>其中 $\sigma_i$ 将自动确定。这个过程可以通过设置算法的困惑性来影响。</p><p>用一个长尾分布(Student-t Distribution，简称为t分布)来表示 embed空间的相似性<br>$$q_{ij} = \frac{(1 + ||\boldsymbol{y}_i - \boldsymbol{y}_j)||^2)^{-1}}{\sum_{k \neq l} (1 + ||\boldsymbol{y}_k - \boldsymbol{y}_l)||^2)^{-1}},$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.28.56.png" alt="Screen Shot 2018-01-30 at 15.28.56"></p><p>损失函数是两个分布之间的 Kullback-Leibler divergence（KL散度）</p><p>$$KL(P|Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$</p><p>而为什么说tsne保留的是局部相似性呢？我们从KL散度的公式出发来解释，<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.33.19.png" alt="Screen Shot 2018-01-30 at 15.33.19"><br>可以看到，当$p_{ij}$很大而$q_{ij}$很小（高维空间距离近，低维空间距离远）惩罚很大，反之惩罚小（高维空间距离远，低维空间距离近）。</p><p>而为什么高维空间用高斯分布，低维空间用Student-t Distribution呢？</p><p><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.32.png" alt="Screen Shot 2018-01-30 at 15.41.32"><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.43.png" alt="Screen Shot 2018-01-30 at 15.41.43"><br>原因就是因为降维是必然要带来信息损失，我们要保存局部信息那么必然要损失全局信息，比如我们要把上面的这个2维空间的三个成直角边的点降维到1维，那么把它们放平就保存了局部信息（左中和中右之间的距离保持不变），但是牺牲了全局信息（左右之间的距离变大了）。而Student-t Distribution就能放大这种密度，如下图（tsne默认t分布自由度为1），t分布相比高斯分布更加长尾。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.48.47.png" alt="Screen Shot 2018-01-30 at 15.48.47"><br>梯度计算时有优化技巧，如果按下图中的原公式计算，复杂度为$O(N^2)$ Barnes-Hut 树方法就可以优化到$ O(NlogN)$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.59.02.png" alt="Screen Shot 2018-01-30 at 15.59.02"><br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.17.png" alt="Screen Shot 2018-01-30 at 16.01.17"><br>原理类似于用上图中ABC三点中心的距离乘以三来代替计算三者各自的距离。<br>那么把用barnes树结构来进行深度优先搜索，分别判断其距离是否大于阈值，分块计算距离，这样复杂度就降低了。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.38.png" alt="Screen Shot 2018-01-30 at 16.01.38"></p><p>以下是计算损失KL散度的公式，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence</span><span class="params">(params, P, degrees_of_freedom, n_samples, n_components,</span></span></div><div class="line">                   skip_num_points=<span class="number">0</span>):</div><div class="line">    <span class="string">"""t-SNE objective function: gradient of the KL divergence</span></div><div class="line">    of p_ijs and q_ijs and the absolute error."""</div><div class="line">    X_embedded = params.reshape(n_samples, n_components)</div><div class="line"></div><div class="line">    <span class="comment"># Q is a heavy-tailed distribution: Student's t-distribution</span></div><div class="line">    n = pdist(X_embedded, <span class="string">"sqeuclidean"</span>)</div><div class="line">    n += <span class="number">1.</span></div><div class="line">    n /= degrees_of_freedom</div><div class="line">    n **= (degrees_of_freedom + <span class="number">1.0</span>) / <span class="number">-2.0</span></div><div class="line">    Q = np.maximum(n / (<span class="number">2.0</span> * np.sum(n)), MACHINE_EPSILON)</div><div class="line"></div><div class="line">    <span class="comment"># Optimization trick below: np.dot(x, y) is faster than</span></div><div class="line">    <span class="comment"># np.sum(x * y) because it calls BLAS</span></div><div class="line"></div><div class="line">    <span class="comment"># Objective: C (Kullback-Leibler divergence of P and Q)</span></div><div class="line">    kl_divergence = <span class="number">2.0</span> * np.dot(P, np.log(P / Q))</div><div class="line"></div><div class="line">    <span class="comment"># Gradient: dC/dY</span></div><div class="line">    grad = np.ndarray((n_samples, n_components))</div><div class="line">    PQd = squareform((P - Q) * n)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(skip_num_points, n_samples):</div><div class="line">        np.dot(_ravel(PQd[i]), X_embedded[i] - X_embedded, out=grad[i])</div><div class="line">    grad = grad.ravel()</div><div class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</div><div class="line">    grad *= c</div></pre></td></tr></table></figure><p>用梯度下降（和一些tricks）优化，值得注意的是损失函数非对称，并且不同的训练会导致结果的不同。</p><p>sklearn里对于binary search计算 联合分布下面的(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_utils.pyx" target="_blank" rel="external">_utils._binary_search_perplexity</a>)和Barnes-Hut 树计算梯度(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_barnes_hut_tsne.pyx" target="_blank" rel="external">_barnes_hut_tsne.gradient</a>)都是C实现，有空再来研究。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_joint_probabilities</span><span class="params">(distances, desired_perplexity, verbose)</span>:</span></div><div class="line">    <span class="string">"""Compute joint probabilities p_ij from distances."""</span></div><div class="line">    <span class="comment"># Compute conditional probabilities such that they approximately match</span></div><div class="line">    <span class="comment"># the desired perplexity</span></div><div class="line">    distances = astype(distances, np.float32, copy=<span class="keyword">False</span>)</div><div class="line">    </div><div class="line">    conditional_P = _utils._binary_search_perplexity(</div><div class="line">        distances, <span class="keyword">None</span>, desired_perplexity, verbose)</div><div class="line">    P = conditional_P + conditional_P.T</div><div class="line">    sum_P = np.maximum(np.sum(P), MACHINE_EPSILON)</div><div class="line">    P = np.maximum(squareform(P) / sum_P, MACHINE_EPSILON)</div><div class="line">    <span class="keyword">return</span> P</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence_bh</span><span class="params">(params, P, neighbors, degrees_of_freedom, n_samples,</span></span></div><div class="line">                      n_components, angle=<span class="number">0.5</span>, skip_num_points=<span class="number">0</span>,</div><div class="line">                      verbose=False):</div><div class="line">    <span class="string">"""t-SNE objective function: KL divergence of p_ijs and q_ijs."""</span></div><div class="line">    params = astype(params, np.float32, copy=<span class="keyword">False</span>)</div><div class="line">    X_embedded = params.reshape(n_samples, n_components)</div><div class="line">    neighbors = astype(neighbors, np.int64, copy=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">if</span> len(P.shape) == <span class="number">1</span>:</div><div class="line">        sP = squareform(P).astype(np.float32)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        sP = P.astype(np.float32)</div><div class="line"></div><div class="line">    grad = np.zeros(X_embedded.shape, dtype=np.float32)</div><div class="line">    error = _barnes_hut_tsne.gradient(sP, X_embedded, neighbors,</div><div class="line">                                      grad, angle, n_components, verbose,</div><div class="line">                                      dof=degrees_of_freedom)</div><div class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</div><div class="line">    grad = grad.ravel()</div><div class="line">    grad *= c</div><div class="line"></div><div class="line">    <span class="keyword">return</span> error, grad</div></pre></td></tr></table></figure><p><a href="http://lvdmaaten.github.io/tsne/" target="_blank" rel="external">t-SNE – Laurens van der Maaten</a>这个链接是作者收集的各种tsne变种及相关实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15172836269060.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;结合&lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&quot;&gt;论文&lt;/a&gt;公式与几个python实现理解t-SNE算法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Data Science Pipelines |  特征工程中的管道</title>
    <link href="http://frankchen.xyz/2018/01/12/Data-Science-Notes/"/>
    <id>http://frankchen.xyz/2018/01/12/Data-Science-Notes/</id>
    <published>2018-01-12T06:22:50.000Z</published>
    <updated>2018-04-08T08:13:01.013Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15161698020879.png" alt=""></p><p>暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。</p><a id="more"></a><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><ol><li><p>以一个Kaggle上的House Price为案例，机器学习流程分成两个大步骤 ：即<br>EDA与特征工程（只使用Pandas, StatsModel，scipy,numpy, seaborn等库）</p><ul><li><p>输入： 原始Train, Test 数据集，将原始Train和Test 合并成一个数据集combined</p></li><li><p>处理： Pandas Pipe</p><p>  根据各种可能和各种特征工程方法定义各种函数（输入combined, 输入pre_combined)<br>  用PandasPipe 将这个函数像搭积木一样连在一起。用列表按序存放这些函数）<br>  这个列表就是，1. 基本的填充空值, 2. 转换数据类型， 3. 空白函数（为了对齐美观而以，啥事不做），4. log 转换，类别数据哑元处理， 5. 导出到hdf5文件， 6.检查R2值<br>  利用各种排列组合，或者各种参数组合，可以产生丰富的pipes，每一个pipes都可以产生一个预处理过的文件。</p></li><li><p>输出：某文件夹下 的N个预处理过的hdf5文件。 针对各种特征工程的排列组合，或者是Kaggle上面的各种新奇的特征工程方法。</p></li></ul></li><li><p>机器学习阶段（训练和产生模型，目标是尽可能获得尽可能低的RMSE值（针对训练数据），同时要具有范化的能力（针对测试数据））</p><ul><li>第一步，建立基准，筛选出最好的一个（几个）预处理文件（随机数设成固定值）</li><li>第二步，针对筛选出来的预处理文件，进行调参。找到最合适的几个算法（通常是RMSE值最低，且不同Kernel）（随机数设成固定值）    </li><li>第三步，用调好的参数来预处理文件中的Traing数据的做average 和stacking</li><li>第四部，生成csv文件，提交到Kaggle 看看得分如何。</li></ul></li></ol><h2 id="准备阶段-与-NoteBook-Head"><a href="#准备阶段-与-NoteBook-Head" class="headerlink" title="准备阶段 与 NoteBook Head"></a>准备阶段 与 NoteBook Head</h2><p>过滤warning：有句话说的好，在计算机科学里，我们只在意错误不在意warning</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> warnings</div><div class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</div></pre></td></tr></table></figure><hr><p>工作目录切换到当前python文件所在目录<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line">os.chdir(os.path.dirname(os.path.abspath(__file__)))</div></pre></td></tr></table></figure></p><hr><p>Notebook交互输出所有结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</div><div class="line">InteractiveShell.ast_node_interactivity=<span class="string">'all'</span></div></pre></td></tr></table></figure><p>结果如下<br><img src="/images/Screen%20Shot%202018-01-12%20at%2015.27.58.png" alt="Screen Shot 2018-01-12 at 15.27.58"></p><p>以上可以通过设置固定下来，方法如下：</p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.51.01.png" alt="Screen Shot 2018-02-05 at 14.51.01"></p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.50.29.png" alt="Screen Shot 2018-02-05 at 14.50.29"></p><hr><p>一般对train以及test做一个concat，并记录train的条数ntrain<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">"train.csv.gz"</span>)</div><div class="line">test = pd.read_csv(<span class="string">"test.csv.gz"</span>)</div><div class="line"></div><div class="line">combined = pd.concat([train,test],axis =<span class="number">0</span>, ignore_index =<span class="keyword">True</span>)</div><div class="line">ntrain = train.shape[<span class="number">0</span>]</div><div class="line">Y_train = train[<span class="string">"SalePrice"</span>]</div><div class="line">X_train = train.drop([<span class="string">"Id"</span>,<span class="string">"SalePrice"</span>],axis=<span class="number">1</span>)</div><div class="line">print(<span class="string">"train data shape:\t "</span>,train.shape)</div><div class="line">print(<span class="string">"test data shape:\t "</span>,test.shape)</div><div class="line">print(<span class="string">"combined data shape:\t"</span>,combined.shape)</div></pre></td></tr></table></figure></p><h2 id="EDA相关"><a href="#EDA相关" class="headerlink" title="EDA相关"></a>EDA相关</h2><p>1D Scatter</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">nca = NCA(num_dims=<span class="number">1</span>)</div><div class="line">nca.fit(xx_t, yy)</div><div class="line">xxxxx = nca.transform(xx)</div><div class="line">zeros=np.zeros_like(xxxxx)</div><div class="line">plt.scatter(xxxxx, zeros+<span class="number">1</span>,c=yy[:,np.newaxis])</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/myplot.png" alt="myplot"></p><hr><p>缺失值分析</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cols_missing_value = combined.isnull().sum()/combined.shape[<span class="number">0</span>]</div><div class="line">cols_missing_value = cols_missing_value[cols_missing_value&gt;<span class="number">0</span>]</div><div class="line">print(<span class="string">"How many features is bad/missing value? The answer is:"</span>,cols_missing_value.shape[<span class="number">0</span>])</div><div class="line">cols_missing_value.sort_values(ascending=<span class="keyword">False</span>).head(<span class="number">10</span>).plot.barh()</div></pre></td></tr></table></figure><p><img src="/images/15161679439549.jpg" alt=""></p><p>有缺失 - 需要填充或者删除，通常用均值或者中指，或者用人工分析（人工分析是提分关键）</p><hr><p>将若干个Dataframe画在同一个图里面相同坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">fig, ax = plt.subplots()</div><div class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果</span></div><div class="line"><span class="keyword">for</span> desc, group <span class="keyword">in</span> Energy_sources:</div><div class="line">    group.plot(x = group.index, y=<span class="string">'Value'</span>, label=desc,ax = ax, title=<span class="string">'Carbon Emissions per Energy Source'</span>, fontsize = <span class="number">20</span>)</div><div class="line">    ax.set_xlabel(<span class="string">'Time(Monthly)'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'Carbon Emissions in MMT'</span>)</div><div class="line">    ax.xaxis.label.set_size(<span class="number">20</span>)</div><div class="line">    ax.yaxis.label.set_size(<span class="number">20</span>)</div><div class="line">    ax.legend(fontsize = <span class="number">16</span>)</div></pre></td></tr></table></figure><p>结果如下图，<br><img src="/images/15157398435931.jpg" alt=""></p><hr><p>画a*b的子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fig, axes = plt.subplots(<span class="number">3</span>,<span class="number">3</span>, figsize = (<span class="number">30</span>, <span class="number">20</span>))</div><div class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果 也就是下面的Energy_sources</span></div><div class="line"><span class="keyword">for</span> (desc, group), ax <span class="keyword">in</span> zip(Energy_sources, axes.flatten()):</div><div class="line">    group.plot(x = group.index, y=<span class="string">'Value'</span>,ax = ax, title=desc, fontsize = <span class="number">18</span>)</div><div class="line">    ax.set_xlabel(<span class="string">'Time(Monthly)'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'Carbon Emissions in MMT'</span>)</div><div class="line">    ax.xaxis.label.set_size(<span class="number">18</span>)</div><div class="line">    ax.yaxis.label.set_size(<span class="number">18</span>)</div></pre></td></tr></table></figure><p><img src="/images/15157402388676.jpg" alt=""></p><hr><p>画柱状图</p><p><img src="/images/Screen%20Shot%202018-01-12%20at%2015.19.32.png" alt="Screen Shot 2018-01-12 at 15.19.32"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">fig = plt.figure(figsize = (<span class="number">16</span>,<span class="number">9</span>))</div><div class="line"><span class="comment"># CO2_per_source的来源与结构如上图</span></div><div class="line">x_label = map(<span class="keyword">lambda</span> x: x[:<span class="number">20</span>],CO2_per_source.index)</div><div class="line">x_tick = np.arange(len(cols))</div><div class="line">plt.bar(x_tick, CO2_per_source, align = <span class="string">'center'</span>, alpha = <span class="number">0.5</span>)</div><div class="line">fig.suptitle(<span class="string">"CO2 Emissions by Electric Power Sector"</span>, fontsize= <span class="number">25</span>)</div><div class="line">plt.xticks(x_tick, x_label, rotation = <span class="number">70</span>, fontsize = <span class="number">15</span>)</div><div class="line">plt.yticks(fontsize = <span class="number">20</span>)</div><div class="line">plt.xlabel(<span class="string">'Carbon Emissions in MMT'</span>, fontsize = <span class="number">20</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15157416530029.jpg" alt=""></p><hr><p>重叠图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statsmodels.tsa.seasonal <span class="keyword">import</span> seasonal_decompose</div><div class="line">decomposition = seasonal_decompose(mte)</div><div class="line"></div><div class="line">trend = decomposition.trend</div><div class="line">seasonal = decomposition.seasonal</div><div class="line">residual = decomposition.resid</div><div class="line"></div><div class="line">plt.subplot(<span class="number">411</span>)</div><div class="line">plt.plot(mte, label=<span class="string">'Original'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">412</span>)</div><div class="line">plt.plot(trend, label=<span class="string">'Trend'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">413</span>)</div><div class="line">plt.plot(seasonal,label=<span class="string">'Seasonality'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">414</span>)</div><div class="line">plt.plot(residual, label=<span class="string">'Residuals'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.tight_layout()</div></pre></td></tr></table></figure><p><img src="/images/15157543822442.jpg" alt=""></p><hr><p>环形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">15</span>))</div><div class="line">data=response[<span class="string">'PublicDatasetsSelect'</span>].str.split(<span class="string">','</span>)</div><div class="line">dataset=[]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.dropna():</div><div class="line">    dataset.extend(i)</div><div class="line">pd.Series(dataset).value_counts().plot.pie(autopct=<span class="string">'%1.1f%%'</span>,colors=sns.color_palette(<span class="string">'Paired'</span>,<span class="number">10</span>),startangle=<span class="number">90</span>,wedgeprops = &#123; <span class="string">'linewidth'</span> : <span class="number">2</span>, <span class="string">'edgecolor'</span> : <span class="string">'white'</span> &#125;)</div><div class="line">plt.title(<span class="string">'Dataset Source'</span>)</div><div class="line">my_circle=plt.Circle( (<span class="number">0</span>,<span class="number">0</span>), <span class="number">0.7</span>, color=<span class="string">'white'</span>)</div><div class="line">p=plt.gcf()</div><div class="line">p.gca().add_artist(my_circle)</div><div class="line">plt.ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159953413652.jpg" alt=""></p><hr><p>饼状图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">response[<span class="string">'JobSkillImportancePython'</span>].value_counts().plot.pie(ax=ax[<span class="number">0</span>],autopct=<span class="string">'%1.1f%%'</span>,explode=[<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0</span>],shadow=<span class="keyword">True</span>,colors=[<span class="string">'g'</span>,<span class="string">'lightblue'</span>,<span class="string">'r'</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Python Necessity'</span>)</div><div class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">response[<span class="string">'JobSkillImportanceR'</span>].value_counts().plot.pie(ax=ax[<span class="number">1</span>],autopct=<span class="string">'%1.1f%%'</span>,explode=[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0</span>],shadow=<span class="keyword">True</span>,colors=[<span class="string">'lightblue'</span>,<span class="string">'g'</span>,<span class="string">'r'</span>])</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'R Necessity'</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159954686370.jpg" alt=""></p><hr><p>维恩图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">pd.Series([python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]],index=[<span class="string">'Python'</span>,<span class="string">'R'</span>,<span class="string">'Both'</span>]).plot.bar(ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Number of Users'</span>)</div><div class="line">venn2(subsets = (python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]), set_labels = (<span class="string">'Python Users'</span>, <span class="string">'R Users'</span>))</div><div class="line">plt.title(<span class="string">'Venn Diagram for Users'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159955616741.jpg" alt=""></p><h2 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h2><p>count plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">22</span>,<span class="number">12</span>))</div><div class="line">sns.countplot(y=response[<span class="string">'GenderSelect'</span>],order=response[<span class="string">'GenderSelect'</span>].value_counts().index)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159941639903.jpg" alt=""></p><hr><p>利用squarify画树形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> squarify</div><div class="line">tree=response[<span class="string">'Country'</span>].value_counts().to_frame()</div><div class="line">squarify.plot(sizes=tree[<span class="string">'Country'</span>].values,label=tree.index,color=sns.color_palette(<span class="string">'RdYlGn_r'</span>,<span class="number">52</span>))</div><div class="line">plt.rcParams.update(&#123;<span class="string">'font.size'</span>:<span class="number">20</span>&#125;)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">40</span>,<span class="number">15</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159945932245.jpg" alt=""></p><hr><p>sns画分布图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">8</span>))</div><div class="line">salary=salary[salary[<span class="string">'Salary'</span>]&lt;<span class="number">1000000</span>]</div><div class="line">sns.distplot(salary[<span class="string">'Salary'</span>])</div><div class="line">plt.title(<span class="string">'Salary Distribution'</span>,size=<span class="number">15</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159947979455.jpg" alt=""></p><hr><p>sns子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">sal_coun=salary.groupby(<span class="string">'Country'</span>)[<span class="string">'Salary'</span>].median().sort_values(ascending=<span class="keyword">False</span>)[:<span class="number">15</span>].to_frame()</div><div class="line">sns.barplot(<span class="string">'Salary'</span>,sal_coun.index,data=sal_coun,palette=<span class="string">'RdYlGn'</span>,ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].axvline(salary[<span class="string">'Salary'</span>].median(),linestyle=<span class="string">'dashed'</span>)</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Highest Salary Paying Countries'</span>)</div><div class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">''</span>)</div><div class="line">max_coun=salary.groupby(<span class="string">'Country'</span>)[<span class="string">'Salary'</span>].median().to_frame()</div><div class="line">max_coun=max_coun[max_coun.index.isin(resp_coun.index)]</div><div class="line">max_coun.sort_values(by=<span class="string">'Salary'</span>,ascending=<span class="keyword">True</span>).plot.barh(width=<span class="number">0.8</span>,ax=ax[<span class="number">1</span>],color=sns.color_palette(<span class="string">'RdYlGn'</span>))</div><div class="line">ax[<span class="number">1</span>].axvline(salary[<span class="string">'Salary'</span>].median(),linestyle=<span class="string">'dashed'</span>)</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Compensation of Top 15 Respondent Countries'</span>)</div><div class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">''</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159948678550.jpg" alt=""></p><hr><p>seaborn箱型图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">10</span>,<span class="number">8</span>))</div><div class="line">sns.boxplot(y=<span class="string">'GenderSelect'</span>,x=<span class="string">'Salary'</span>,data=salary)</div><div class="line">plt.ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159949427978.jpg" alt=""></p><hr><p>seaborn count_plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">25</span>,<span class="number">15</span>))</div><div class="line">sns.countplot(y=response[<span class="string">'MajorSelect'</span>],ax=ax[<span class="number">0</span>],order=response[<span class="string">'MajorSelect'</span>].value_counts().index)</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Major'</span>)</div><div class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">sns.countplot(y=response[<span class="string">'CurrentJobTitleSelect'</span>],ax=ax[<span class="number">1</span>],order=response[<span class="string">'CurrentJobTitleSelect'</span>].value_counts().index)</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Current Job'</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159950249702.jpg" alt=""></p><hr><p>seaborn 图中添加文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sal_job=salary.groupby(<span class="string">'CurrentJobTitleSelect'</span>)[<span class="string">'Salary'</span>].median().to_frame().sort_values(by=<span class="string">'Salary'</span>,ascending=<span class="keyword">False</span>)</div><div class="line">ax=sns.barplot(sal_job.Salary,sal_job.index,palette=sns.color_palette(<span class="string">'inferno'</span>,<span class="number">20</span>))</div><div class="line">plt.title(<span class="string">'Compensation By Job Title'</span>,size=<span class="number">15</span>)</div><div class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(sal_job.Salary): </div><div class="line">    ax.text(<span class="number">.5</span>, i, v,fontsize=<span class="number">10</span>,color=<span class="string">'white'</span>,weight=<span class="string">'bold'</span>)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">8</span>,<span class="number">8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159951024672.jpg" alt=""></p><hr><p>词云</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud, STOPWORDS</div><div class="line"><span class="keyword">import</span> nltk</div><div class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line">free=pd.read_csv(<span class="string">'../input/freeformResponses.csv'</span>)</div><div class="line">stop_words=set(stopwords.words(<span class="string">'english'</span>))</div><div class="line">stop_words.update(<span class="string">','</span>,<span class="string">';'</span>,<span class="string">'!'</span>,<span class="string">'?'</span>,<span class="string">'.'</span>,<span class="string">'('</span>,<span class="string">')'</span>,<span class="string">'$'</span>,<span class="string">'#'</span>,<span class="string">'+'</span>,<span class="string">':'</span>,<span class="string">'...'</span>)</div><div class="line">motivation=free[<span class="string">'KaggleMotivationFreeForm'</span>].dropna().apply(nltk.word_tokenize)</div><div class="line">motivate=[]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> motivation:</div><div class="line">    motivate.extend(i)</div><div class="line">motivate=pd.Series(motivate)</div><div class="line">motivate=([i <span class="keyword">for</span> i <span class="keyword">in</span> motivate.str.lower() <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> stop_words])</div><div class="line">f1=open(<span class="string">"kaggle.png"</span>, <span class="string">"wb"</span>)</div><div class="line">f1.write(codecs.decode(kaggle,<span class="string">'base64'</span>))</div><div class="line">f1.close()</div><div class="line">img1 = imread(<span class="string">"kaggle.png"</span>)</div><div class="line">hcmask1 = img1</div><div class="line">wc = WordCloud(background_color=<span class="string">"black"</span>, max_words=<span class="number">4000</span>, mask=hcmask1, </div><div class="line">               stopwords=STOPWORDS, max_font_size= <span class="number">60</span>,width=<span class="number">1000</span>,height=<span class="number">1000</span>)</div><div class="line">wc.generate(<span class="string">" "</span>.join(motivate))</div><div class="line">plt.imshow(wc)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">10</span>,<span class="number">10</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159971204332.jpg" alt=""></p><hr><p>简单情况下的分类展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</div><div class="line"></div><div class="line">h = <span class="number">0.01</span></div><div class="line">x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></div><div class="line">y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></div><div class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(X, y, w, history)</span>:</span></div><div class="line">    <span class="string">"""draws classifier prediction with matplotlib magic"""</span></div><div class="line">    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)</div><div class="line">    Z = Z.reshape(xx.shape)</div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</div><div class="line">    plt.contourf(xx, yy, Z, alpha=<span class="number">0.8</span>)</div><div class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired)</div><div class="line">    plt.xlim(xx.min(), xx.max())</div><div class="line">    plt.ylim(yy.min(), yy.max())</div><div class="line">    </div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    plt.plot(history)</div><div class="line">    plt.grid()</div><div class="line">    ymin, ymax = plt.ylim()</div><div class="line">    plt.ylim(<span class="number">0</span>, ymax)</div><div class="line">    display.clear_output(wait=<span class="keyword">True</span>)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15163355887784.jpg" alt=""></p><hr><p>图中插入LaTeX公式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line">x = np.linspace(<span class="number">-3</span>, <span class="number">3</span>)</div><div class="line">x_squared, x_squared_der = s.run([scalar_squared, derivative[<span class="number">0</span>]],</div><div class="line">                                 &#123;my_scalar:x&#125;)</div><div class="line"></div><div class="line">plt.plot(x, x_squared,label=<span class="string">"$x^2$"</span>)</div><div class="line">plt.plot(x, x_squared_der, label=<span class="string">r"$\frac&#123;dx^2&#125;&#123;dx&#125;$"</span>)</div><div class="line">plt.legend();</div></pre></td></tr></table></figure><p><img src="/images/15163465540386.jpg" alt=""></p><hr><p>画多张子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># show random images from train</span></div><div class="line">cols = <span class="number">8</span></div><div class="line">rows = <span class="number">2</span></div><div class="line">fig = plt.figure(figsize=(<span class="number">2</span> * cols - <span class="number">1</span>, <span class="number">2.5</span> * rows - <span class="number">1</span>))</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(cols):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(rows):</div><div class="line">        random_index = np.random.randint(<span class="number">0</span>, len(y_train))</div><div class="line">        ax = fig.add_subplot(rows, cols, i * rows + j + <span class="number">1</span>)</div><div class="line">        ax.grid(<span class="string">'off'</span>)</div><div class="line">        ax.axis(<span class="string">'off'</span>)</div><div class="line">        ax.imshow(x_train[random_index, :])</div><div class="line">        ax.set_title(cifar10_classes[y_train[random_index, <span class="number">0</span>]])</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15167635233971.jpg" alt=""></p><h2 id="特征工程阶段"><a href="#特征工程阶段" class="headerlink" title="特征工程阶段"></a>特征工程阶段</h2><p>Numpy区间百分比切分异常值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cut off long distance trips</span></div><div class="line">lat_low, lat_hgh = np.percentile(latlong[:,<span class="number">0</span>], [<span class="number">2</span>, <span class="number">98</span>])</div><div class="line">lon_low, lon_hgh = np.percentile(latlong[:,<span class="number">1</span>], [<span class="number">2</span>, <span class="number">98</span>])</div></pre></td></tr></table></figure><hr><p>初始化同shape向量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">g2 = np.zeros_like(w)</div><div class="line">``</div><div class="line"></div><div class="line">-------</div><div class="line"></div><div class="line">累积sum</div><div class="line">``` python</div><div class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.cumsum(a,axis=<span class="number">1</span>)      <span class="comment"># sum over columns for each of the 2 rows</span></div><div class="line">array([[ <span class="number">1</span>,  <span class="number">3</span>,  <span class="number">6</span>],</div><div class="line">       [ <span class="number">4</span>,  <span class="number">9</span>, <span class="number">15</span>]])</div><div class="line">``` </div><div class="line"></div><div class="line">-------</div><div class="line">numpy array 扩展维度，很简单地将Numpy向量扩展为二维矩阵</div><div class="line">![](/images/<span class="number">15167894435840.</span>png)</div><div class="line">![Screen Shot <span class="number">2018</span><span class="number">-01</span><span class="number">-24</span> at <span class="number">19.02</span><span class="number">.32</span>](/images/Screen%<span class="number">20</span>Shot%<span class="number">202018</span><span class="number">-01</span><span class="number">-24</span>%<span class="number">20</span>at%<span class="number">2019.02</span><span class="number">.32</span>.png)</div><div class="line"></div><div class="line">-------</div><div class="line">Numpy 竖着叠放向量</div><div class="line">`np.column_stack`</div><div class="line"></div><div class="line">-------</div><div class="line"></div><div class="line">``` python</div><div class="line"><span class="comment"># 用于查看Dataframe各列数据类型</span></div><div class="line">ts.dtypes</div></pre></td></tr></table></figure></p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#skew是单变量工具，用来监测数据是否有长尾，左偏或者右偏</span></div><div class="line">print(Y_train.skew())</div><div class="line">``` </div><div class="line"></div><div class="line">``` python</div><div class="line"><span class="comment">#np.abs 是绝对值函数，用来取整个向量绝对值</span></div><div class="line"><span class="comment"># 这里对所有train里的特征求偏度并排序</span></div><div class="line">np.abs(combined[:ntrain].skew()).sort_values(ascending = <span class="keyword">False</span> ).head(<span class="number">20</span>)</div></pre></td></tr></table></figure><p>有偏度 - 需要处理。通常是用log1p </p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于将Dataframe中被读取为object的数据转换为数值型，errors='coerce'代表错误将被置为NaN</span></div><div class="line">ts[<span class="string">'Value'</span>] = pd.to_numeric(ts[<span class="string">'Value'</span>] , errors=<span class="string">'coerce'</span>)</div></pre></td></tr></table></figure><hr><p>过滤index 里面的NaN值，推广也可以过滤其他列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ts = df.loc[pd.Series(pd.to_datetime(df.index, errors=<span class="string">'coerce'</span>)).notnull().values]</div></pre></td></tr></table></figure><hr><p>按月groupby，以及unstack解构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Emissions.groupby([<span class="string">'Description'</span>, pd.TimeGrouper(<span class="string">'M'</span>)])[<span class="string">'Value'</span>].sum().unstack(level = <span class="number">0</span>)</div></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202018-01-12%20at%2016.16.30.png" alt="Screen Shot 2018-01-12 at 16.16.30"></p><hr><p>将value_counts、groupby等Series转换为Dataframe<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tree=response[<span class="string">'Country'</span>].value_counts().to_frame()</div></pre></td></tr></table></figure></p><hr><p>特征工程大杀器，<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html?highlight=pipe#tablewise-function-application" target="_blank" rel="external">Pandas Pipe</a><br>这里有个简单的例子，,每个pipes里面都有若干个特征处理函数和一个快速测试的函数，其中为了对齐美观，用bypass函数来填充空白的地方（无用但是为了强行让pipes长度相同）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">pipe_basic = [pipe_basic_fillna,pipe_bypass,\</div><div class="line">              pipe_bypass,pipe_bypass,\</div><div class="line">              pipe_bypass,pipe_bypass,\</div><div class="line">              pipe_log_getdummies,pipe_bypass, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line"></div><div class="line">pipe_ascat = [pipe_fillna_ascat,pipe_drop_cols,\</div><div class="line">              pipe_drop4cols,pipe_outliersdrop,\</div><div class="line">              pipe_extract,pipe_bypass,\</div><div class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line">pipe_ascat_unitprice = [pipe_fillna_ascat,pipe_drop_cols,\</div><div class="line">              pipe_drop4cols,pipe_outliersdrop,\</div><div class="line">              pipe_extract,pipe_unitprice,\</div><div class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line">pipes = [pipe_basic,pipe_ascat,pipe_ascat_unitprice ]</div></pre></td></tr></table></figure><p>跑的代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(pipes)):</div><div class="line">    print(<span class="string">"*"</span>*<span class="number">10</span>,<span class="string">"\n"</span>)</div><div class="line">    pipe_output=pipes[i]</div><div class="line">    output_name =<span class="string">"_"</span>.join([x.__name__[<span class="number">5</span>:] <span class="keyword">for</span> x <span class="keyword">in</span> pipe_output <span class="keyword">if</span> x.__name__ <span class="keyword">is</span> <span class="keyword">not</span> <span class="string">"pipe_bypass"</span>])</div><div class="line">    output_name = <span class="string">"PIPE_"</span> +output_name</div><div class="line">    print(output_name)</div><div class="line">    (combined.pipe(pipe_output[<span class="number">0</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">1</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">2</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">3</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">4</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">5</span>])          </div><div class="line">             .pipe(pipe_output[<span class="number">6</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">7</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">8</span>],name=output_name)</div><div class="line">             .pipe(pipe_output[<span class="number">9</span>])</div><div class="line">             ）</div></pre></td></tr></table></figure><p>在这一步，我们可以初步看到三个特征工程的性能。并且文件已经输出到hd5格式文件。后期在训练和预测时，直接取出预处理的文件就可以。各个pipe代码可见<a href="https://gist.github.com/frankchen0130/5950eaa4d98ea4f93deed707b027b517" target="_blank" rel="external">此处</a>。</p><h2 id="调参阶段"><a href="#调参阶段" class="headerlink" title="调参阶段"></a>调参阶段</h2><p>在数据准备好后训练时，最基本的就是要调整超参（Hyperparameter）耗时耗力，并且和发生错误和遗漏情况。<br>Stackoverflow上常见的算法训练错误有：</p><ul><li>算法预测的结果差异非常大。 其中一个可能就是训练时的标准化步骤，在预测时遗漏了。</li><li>算法的调参结果差异非常大。（有的是0.01,有的就是10）。其中的一个可能就是不同的训练步骤中采用的标准化算法不同（例如,一次用了StandardScaler, 另一次用了RobustScaler)</li><li>此外，繁多的超参数调整起来异常繁琐。比较容易错误或者写错。</li></ul><p><strong>解决方法：Pipeline + Gridsearch + 参数字典 + 容器。</strong><br>使用Pipeline的例子</p><p>针对线形回归问题，Sklearn提供了超过15种回归算法。利用Pipeline 大法可以综合测试所有算法，找到最合适的算法。 具体步骤如下：</p><ol><li><p>初始化所有希望调测线形回归。</p></li><li><p>建立一个字典容器。{“算法名称”:[初始算法对象，参数字典，训练好的Pipeline模型对象，CV的成绩}</p></li><li><p>在调参步骤，将初始算法用Pipeline包装起来，利用Gridsearch进行调参。调参完成后可以得到针对相应的CV而获得的最后模型对象。 例如： lasso 算法的步骤如下：</p></li></ol><ul><li>包装 pipe=Pipeline([(“scaler”:None),(“selector”:None),(“clf”:Lasso())<ul><li>Pipe就是刚刚包装好的算法。可以直接用于 训练(fit)和预测(predict)</li><li>使用Pipe来处理训练集和测试集可以避免错误和遗漏，提高效率。</li><li>但是Pipe中算法是默认的参数，直接训练出的模型RMSE不太理想。（例如：local CV, 0.12~0.14左右）。这时可以考虑调参。</li></ul></li><li>调参第一步：准备参数字典：<br>  Params_lasso ={<br>  “Scaler”:[RobustScaler(),StandardScaler()], #两个标准化算法供调模型<br>  “selector<strong>threshold”:np.logspace(-5,-4,3), #3个选择门限供选特征<br>  “clf</strong>alpha”:np.logspace(-5,-1,10) }， #10个alpha指供调参</li><li>调参第二步：暴力调参和生成模型 rsearch = GridSearchCV(pipe, param_grid=Params_lasso,scoring =’neg_mean_squared_error’,verbose=verbose,cv=10,refit =True)<ul><li>GridSearch 是暴力调参。遍历所有参数组合，另外有一个RandomedSearch 可以随机选择参数组合，缩短调参时间，并且获得近似的调参性能</li><li>Pipe就是刚刚包装好的算法。GridSearch把可选的参数和算法（放入，或者更好的组合。</li><li>调参的训练标准是“’neg_mean_squared_error”, RMSE的负数。 这种处理方法，让最大值称为最小的MSE指。只需要对结果做一次np.sqrt( 结果负数）就能获得RMSE值。</li><li>cv=10. Cross Validate 数据集为9：1。数据集小的情况，例如House Price. 3折和10折结果甚至比调参差异还大。</li><li>refit =True. 在调参完成后，再需要做一次所有数据集的fit. 生成完整的训练模型</li></ul></li></ul><hr><p>Sklearn 流程图<br><img src="/images/15161696298310.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15161698020879.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Python" scheme="http://frankchen.xyz/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>DIY远程Jupyter Notebook服务器</title>
    <link href="http://frankchen.xyz/2017/12/25/Remote-jupyter-notebook/"/>
    <id>http://frankchen.xyz/2017/12/25/Remote-jupyter-notebook/</id>
    <published>2017-12-25T11:43:17.000Z</published>
    <updated>2017-12-25T11:48:42.351Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15142020075328.jpg" alt="Screen Shot 2017-07-18 at 14.16.18"><br>构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。<br><a id="more"></a></p><h2 id="完全开放，不需密码"><a href="#完全开放，不需密码" class="headerlink" title="完全开放，不需密码"></a>完全开放，不需密码</h2><h3 id="1-登陆远程服务器"><a href="#1-登陆远程服务器" class="headerlink" title="1.  登陆远程服务器"></a>1.  登陆远程服务器</h3><h3 id="2-生成配置文件"><a href="#2-生成配置文件" class="headerlink" title="2.生成配置文件"></a>2.生成配置文件</h3><p><code>$jupyter notebook --generate-config</code></p><h3 id="3-修改默认配置文件"><a href="#3-修改默认配置文件" class="headerlink" title="3. 修改默认配置文件"></a>3. 修改默认配置文件</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py</code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.ip = <span class="string">'0.0.0.0'</span>      <span class="comment">#支持其它IP访问，关键</span></div><div class="line">c.NotebookApp.port = <span class="number">10000</span> <span class="comment">#随便指定一个端口</span></div></pre></td></tr></table></figure><h3 id="4-启动jupyter-notebook："><a href="#4-启动jupyter-notebook：" class="headerlink" title="4. 启动jupyter notebook："></a>4. 启动jupyter notebook：</h3><p><code>jupyter notebook</code></p><h3 id="5-远程访问"><a href="#5-远程访问" class="headerlink" title="5. 远程访问"></a>5. 远程访问</h3><p>此时应该可以直接从本地浏览器直接访问<code>http://address_of_remote:10000</code>就可以看到jupyter的登陆界面，输入密码即可。</p><h2 id="需要密码"><a href="#需要密码" class="headerlink" title="需要密码"></a>需要密码</h2><h3 id="1-生成密码"><a href="#1-生成密码" class="headerlink" title="1. 生成密码"></a>1. 生成密码</h3><p>打开ipython，创建一个密文的密码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</div><div class="line">In [<span class="number">2</span>]: passwd()</div><div class="line">Enter password: </div><div class="line">Verify password: </div><div class="line">Out[<span class="number">2</span>]: <span class="string">'sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274'</span></div></pre></td></tr></table></figure><h3 id="2-添加密码"><a href="#2-添加密码" class="headerlink" title="2. 添加密码"></a>2. 添加密码</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py</code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.password = <span class="string">u'sha:ce...刚才复制的那个密文'</span></div></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202017-07-18%20at%2014.16.18.png" alt="Screen Shot 2017-07-18 at 14.16.18"></p><h3 id="3-建立ssh通道"><a href="#3-建立ssh通道" class="headerlink" title="3. 建立ssh通道"></a>3. 建立ssh通道</h3><p>若还是无法登录，也可用</p><p><code>ssh username@address_of_remote -L 127.0.0.1:10000:127.0.0.1:10000</code></p><p>建立ssh通道，便可以在localhost:10000直接访问远程的jupyter了。</p><h2 id="添加system开机自启"><a href="#添加system开机自启" class="headerlink" title="添加system开机自启"></a>添加system开机自启</h2><p>将 Jupyter Notebook 设定为系统服务并且开机自动启动，这里以 systemd 下的设定为例，创建文件 <code>sudo vim /etc/systemd/system/jupyter.service</code>文件，内容是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[Unit]</div><div class="line">Description=Jupyter Notebook</div><div class="line">After=network.target</div><div class="line"></div><div class="line">[Service]</div><div class="line">Type=simple</div><div class="line">ExecStart=/home/frank/anaconda3/bin/jupyter-notebook  --config=/home/frank/.jupyter/jupyter_notebook_config.py --no-browser</div><div class="line">User=frank</div><div class="line">Group=frank</div><div class="line">WorkingDirectory=/home/frank/</div><div class="line">Restart=always</div><div class="line">RestartSec=10</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure><p>上面你需要把我的用户名frank替换掉，保存文件之后执行<br><code>systemctl enable jupyter</code><br>再执行<br><code>systemctl start jupyter</code><br>即可，需要输入几次密码，之后重启Notebook会自启。</p><p><img src="/images/Screen%20Shot%202017-12-25%20at%2019.32.28.png" alt="Screen Shot 2017-12-25 at 19.32.28"></p><h2 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h2><p>结合下文的方法，用ftp即可做到</p><ul><li><a href="http://frankchen.xyz/2017/11/12/ftp-using/">frp的内网穿透及外网访问内网jupyter-notebook的实现 | 不正经数据科学家</a></li></ul><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/23110830" target="_blank" rel="external">Jupyter (IPython notebook)用于服务器的配置方法(Windows) - 知乎专栏</a></li><li><a href="http://blog.leanote.com/post/jevonswang/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AEjupyter-notebook" target="_blank" rel="external">远程访问jupyter notebook</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15142020075328.jpg&quot; alt=&quot;Screen Shot 2017-07-18 at 14.16.18&quot;&gt;&lt;br&gt;构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
      <category term="Jupyter Notebook" scheme="http://frankchen.xyz/tags/Jupyter-Notebook/"/>
    
  </entry>
  
  <entry>
    <title>深度学习中Keras中的Embedding层的理解与使用</title>
    <link href="http://frankchen.xyz/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/"/>
    <id>http://frankchen.xyz/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/</id>
    <published>2017-12-18T07:59:41.000Z</published>
    <updated>2018-03-08T08:44:07.373Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15135840798621.jpg" alt=""><br>单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。<br><a id="more"></a></p><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>单词嵌入是使用密集的矢量表示来表示单词和文档的一类方法。</p><p>词嵌入是对传统的词袋模型编码方案的改进，传统方法使用大而稀疏的矢量来表示每个单词或者在矢量内对每个单词进行评分以表示整个词汇表，这些表示是稀疏的，因为每个词汇的表示是巨大的，给定的词或文档主要由零值组成的大向量表示。</p><p>相反，在嵌入中，单词由密集向量表示，其中向量表示将单词投影到连续向量空间中。</p><p>向量空间中的单词的位置是从文本中学习的，并且基于在使用单词时围绕单词的单词。</p><p>学习到的向量空间中的单词的位置被称为它的嵌入：Embedding。</p><p>从文本学习单词嵌入方法的两个流行例子包括：</p><ul><li>Word2Vec.</li><li>GloVe.</li></ul><p>除了这些精心设计的方法之外，还可以将词嵌入学习作为深度学习模型的一部分。这可能是一个较慢的方法，但可以通过这样为特定数据集定制模型。</p><h2 id="Keras-Embedding-Layer"><a href="#Keras-Embedding-Layer" class="headerlink" title="Keras Embedding Layer"></a>Keras Embedding Layer</h2><p>Keras提供了一个嵌入层，适用于文本数据的神经网络。</p><p>它要求输入数据是整数编码的，所以每个字都用一个唯一的整数表示。这个数据准备步骤可以使用Keras提供的Tokenizer API来执行。</p><p>嵌入层用随机权重进行初始化，并将学习训练数据集中所有单词的嵌入。</p><p>它是一个灵活的图层，可以以多种方式使用，例如：</p><ul><li>它可以单独使用来学习一个单词嵌入，以后可以保存并在另一个模型中使用。</li><li>它可以用作深度学习模型的一部分，其中嵌入与模型本身一起学习。</li><li>它可以用来加载预先训练的词嵌入模型，这是一种迁移学习。</li></ul><p>嵌入层被定义为网络的第一个隐藏层。它必须指定3个参数：</p><ul><li>input_dim：这是文本数据中词汇的取值可能数。例如，如果您的数据是整数编码为0-9之间的值，那么词汇的大小就是10个单词；</li><li>output_dim：这是嵌入单词的向量空间的大小。它为每个单词定义了这个层的输出向量的大小。例如，它可能是32或100甚至更大，可以视为具体问题的超参数；</li><li>input_length：这是输入序列的长度，就像您为Keras模型的任何输入层所定义的一样，也就是一次输入带有的词汇个数。例如，如果您的所有输入文档都由1000个字组成，那么input_length就是1000。</li></ul><p>例如，下面我们定义一个词汇表为200的嵌入层（例如从0到199的整数编码的字，包括0到199），一个32维的向量空间，其中将嵌入单词，以及输入文档，每个单词有50个单词。</p><p><code>e = Embedding(input_dim=200, output_dim=32, input_length=50)</code></p><p>嵌入层自带学习的权重，如果将模型保存到文件中，则将包含嵌入图层的权重。</p><p>嵌入层的输出是一个二维向量，每个单词在输入文本（输入文档）序列中嵌入一个。</p><p>如果您希望直接将Dense层接到Embedding层后面，则必须先使用Flatten层将Embedding层的2D输出矩阵平铺为一维矢量。</p><p>现在，让我们看看我们如何在实践中使用嵌入层。</p><h2 id="学习-Embedding的例子"><a href="#学习-Embedding的例子" class="headerlink" title="学习 Embedding的例子"></a>学习 Embedding的例子</h2><p>在本节中，我们将看看如何在文本分类问题上拟合神经网络的同时学习单词嵌入。</p><p>我们将定义一个小问题，我们有10个文本文档，每个文档都有一个学生提交的工作评论。每个文本文档被分类为正的“1”或负的“0”。这是一个简单的情感分析问题。</p><p>首先，我们将定义文档及其类别标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define documents 定义文档</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels 定义分类标签</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div></pre></td></tr></table></figure><p>接下来，我们来整数编码每个文件。这意味着把输入，嵌入层将具有整数序列。我们可以尝试其他更复杂的bag of word 模型比如计数或TF-IDF。</p><p>Keras提供<a href="https://keras.io/preprocessing/text/#one_hot" target="_blank" rel="external">one_hot()</a>函数来创建每个单词的散列作为一个有效的整数编码。我们用估计50的词汇表大小，这大大减少了hash函数的冲突概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># integer encode the documents 独热编码</span></div><div class="line">vocab_size = <span class="number">50</span></div><div class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</div><div class="line">print(encoded_docs)</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[[6, 16], [42, 24], [2, 17], [42, 24], [18], [17], [22, 17], [27, 42], [22, 24], [49, 46, 16, 34]]</div></pre></td></tr></table></figure><p>这样以后序列具有不同的长度，但是Keras更喜欢输入矢量化和所有输入具有相同的长度。我们将填充所有输入序列的长度为4，同样，我们可以使用内置的Keras函数（在这种情况下为<a href="https://keras.io/preprocessing/sequence/#pad_sequences" target="_blank" rel="external">pad_sequences()</a>函数）执行此操作,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># pad documents to a max length of 4 words 将不足长度的用0填充为长度4</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[[ 6 16  0  0]</div><div class="line"> [42 24  0  0]</div><div class="line"> [ 2 17  0  0]</div><div class="line"> [42 24  0  0]</div><div class="line"> [18  0  0  0]</div><div class="line"> [17  0  0  0]</div><div class="line"> [22 17  0  0]</div><div class="line"> [27 42  0  0]</div><div class="line"> [22 24  0  0]</div><div class="line"> [49 46 16 34]]</div></pre></td></tr></table></figure><p>我们现在准备将我们的嵌入层定义为我们的神经网络模型的一部分。</p><p>嵌入的词汇量为50，输入长度为4，我们将选择一个8维的嵌入空间。</p><p>该模型是一个简单的二元分类模型。重要的是，嵌入层的输出将是每个8维的4个矢量，每个单词一个。我们将其平铺到一个32个元素的向量上以传递到密集输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define the model 定义模型</span></div><div class="line">model = Sequential()</div><div class="line">model.add(Embedding(vocab_size, <span class="number">8</span>, input_length=max_length))</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># compile the model 编译</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model 打印模型信息</span></div><div class="line">print(model.summary())</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #</div><div class="line">=================================================================</div><div class="line">embedding_1 (Embedding)      (None, 4, 8)              400</div><div class="line">_________________________________________________________________</div><div class="line">flatten_1 (Flatten)          (None, 32)                0</div><div class="line">_________________________________________________________________</div><div class="line">dense_1 (Dense)              (None, 1)                 33</div><div class="line">=================================================================</div><div class="line">Total params: 433</div><div class="line">Trainable params: 433</div><div class="line">Non-trainable params: 0</div><div class="line">_________________________________________________________________</div></pre></td></tr></table></figure><p>最后，我们可以拟合和评估分类模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># fit the model 拟合</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model 评估</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy*<span class="number">100</span>))</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Accuracy: 100.000000</div></pre></td></tr></table></figure><p>下面是完整的代码，这里我们用函数式API改写了模型定义，不过结构和上面是完全一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Flatten, Input</div><div class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div><div class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</div><div class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> one_hot</div><div class="line"></div><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line">        <span class="string">'Good work'</span>,</div><div class="line">        <span class="string">'Great effort'</span>,</div><div class="line">        <span class="string">'nice work'</span>,</div><div class="line">        <span class="string">'Excellent!'</span>,</div><div class="line">        <span class="string">'Weak'</span>,</div><div class="line">        <span class="string">'Poor effort!'</span>,</div><div class="line">        <span class="string">'not good'</span>,</div><div class="line">        <span class="string">'poor work'</span>,</div><div class="line">        <span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">vocab_size = <span class="number">50</span></div><div class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div><div class="line"><span class="comment"># define the model</span></div><div class="line">input = Input(shape=(<span class="number">4</span>, ))</div><div class="line">x = Embedding(vocab_size, <span class="number">8</span>, input_length=max_length)(input)</div><div class="line">x = Flatten()(x)</div><div class="line">x = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</div><div class="line">model = Model(inputs=input, outputs=x)</div><div class="line"><span class="comment"># compile the model</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model</span></div><div class="line">print(model.summary())</div><div class="line"><span class="comment"># fit the model</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy * <span class="number">100</span>))</div></pre></td></tr></table></figure><p>之后，我们可以将嵌入图层中学习的权重保存到文件中，以便以后在其他模型中使用。</p><p>通常也可以使用这个模型来分类在测试数据集中看到的同类词汇的其他文档。</p><p>接下来，让我们看看在Keras中加载预先训练的词嵌入。</p><h2 id="使用预训练GloVE嵌入的示例"><a href="#使用预训练GloVE嵌入的示例" class="headerlink" title="使用预训练GloVE嵌入的示例"></a>使用预训练GloVE嵌入的示例</h2><p>Keras嵌入层也可以使用在其他地方学习的嵌入字。</p><p>在自然语言处理领域，学习，保存和分享提供词嵌入是很常见的。</p><p>例如，GloVe方法背后的研究人员提供了一套在公共领域许可下发布的预先训练的词嵌入。看到：</p><ul><li><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe: Global Vectors for Word Representation</a></li></ul><p>最小的包是822Mb，叫做“glove.6B.zip”。它训练了10亿个词汇（单词）的数据集，词汇量为40万字，有几种不同的嵌入矢量尺寸，包括50,100,200和300size。</p><p>您可以下载这个嵌入的集合，可以作为Keras嵌入层中训练数据集中的单词预先训练嵌入的权重。</p><p>这个例子受Keras项目中的一个例子的启发：<a href="https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py" target="_blank" rel="external">pretrained_word_embeddings.py</a>。</p><p>下载并解压缩后，您将看到几个文件，其中一个是“glove.6B.100d.txt”，其中包含一个100维版本的嵌入。</p><p>如果你在文件内部偷看，你会看到一个token（单词），后面是每行的权重（100个数字）。例如，下面是嵌入的ASCII文本文件的第一行，显示“the”的嵌入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062</div></pre></td></tr></table></figure><p>如前一节所述，第一步是定义这些示例，将它们编码为整数，然后将这些序列填充为相同的长度。</p><p>在这种情况下，我们需要能够将单词映射到整数以及整数到单词。</p><p>Keras提供了一个<a href="https://keras.io/preprocessing/text/#tokenizer" target="_blank" rel="external">Tokenizer</a>类，可以适应训练数据，通过调用Tokenizer类的texts_to_sequences（）方法，可以一致地将文本转换为序列，并且可以访问单词在word_index属性中的整数字典映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div><div class="line"><span class="comment"># prepare tokenizer</span></div><div class="line">t = Tokenizer()</div><div class="line">t.fit_on_texts(docs)</div><div class="line">vocab_size = len(t.word_index) + <span class="number">1</span></div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">encoded_docs = t.texts_to_sequences(docs)</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div></pre></td></tr></table></figure><p>接下来，我们需要将整个Glove字嵌入文件作为字的字典加载到内存中以嵌入数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load the whole embedding into memory</span></div><div class="line">embeddings_index = dict()</div><div class="line">f = open(<span class="string">'glove.6B.100d.txt'</span>)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">values = line.split()</div><div class="line">word = values[<span class="number">0</span>]</div><div class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</div><div class="line">embeddings_index[word] = coefs</div><div class="line">f.close()</div><div class="line">print(<span class="string">'Loaded %s word vectors.'</span> % len(embeddings_index))</div></pre></td></tr></table></figure><p>这很慢。在训练数据中过滤特殊字词的嵌入可能会更好。</p><p>接下来，我们需要为训练数据集中的每个单词创建一个嵌入矩阵。我们可以通过枚举Tokenizer.word_index中的所有唯一单词并从加载的GloVe嵌入中找到嵌入权重向量来实现这一点。</p><p>结果是一个仅用于训练期间将会看到的单词的权重矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a weight matrix for words in training docs</span></div><div class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</div><div class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</div><div class="line">embedding_vector = embeddings_index.get(word)</div><div class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">embedding_matrix[i] = embedding_vector</div></pre></td></tr></table></figure><p>现在我们可以像以前一样定义我们的模型，并进行评估。</p><p>关键的区别是嵌入层可以用GloVe字嵌入权重来播种。我们选择了100维版本，因此必须使用output_dim将其设置为100来定义嵌入层。最后，我们不希望更新此模型中的学习单词权重，因此我们将设置模型的可训练属性为False 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)</div></pre></td></tr></table></figure><p>下面列出了完整的工作示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> asarray</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</div><div class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</div><div class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</div><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div><div class="line"><span class="comment"># prepare tokenizer</span></div><div class="line">t = Tokenizer()</div><div class="line">t.fit_on_texts(docs)</div><div class="line">vocab_size = len(t.word_index) + <span class="number">1</span></div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">encoded_docs = t.texts_to_sequences(docs)</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div><div class="line"><span class="comment"># load the whole embedding into memory</span></div><div class="line">embeddings_index = dict()</div><div class="line">f = open(<span class="string">'../glove_data/glove.6B/glove.6B.100d.txt'</span>)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">values = line.split()</div><div class="line">word = values[<span class="number">0</span>]</div><div class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</div><div class="line">embeddings_index[word] = coefs</div><div class="line">f.close()</div><div class="line">print(<span class="string">'Loaded %s word vectors.'</span> % len(embeddings_index))</div><div class="line"><span class="comment"># create a weight matrix for words in training docs</span></div><div class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</div><div class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</div><div class="line">embedding_vector = embeddings_index.get(word)</div><div class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">embedding_matrix[i] = embedding_vector</div><div class="line"><span class="comment"># define model</span></div><div class="line">model = Sequential()</div><div class="line">e = Embedding(vocab_size, <span class="number">100</span>, weights=[embedding_matrix], input_length=<span class="number">4</span>, trainable=<span class="keyword">False</span>)</div><div class="line">model.add(e)</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># compile the model</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model</span></div><div class="line">print(model.summary())</div><div class="line"><span class="comment"># fit the model</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy*<span class="number">100</span>))</div></pre></td></tr></table></figure><p>运行这个例子可能需要更长的时间，但是这表明它能够适应这个简单的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]</div><div class="line"></div><div class="line">[[ 6  2  0  0]</div><div class="line"> [ 3  1  0  0]</div><div class="line"> [ 7  4  0  0]</div><div class="line"> [ 8  1  0  0]</div><div class="line"> [ 9  0  0  0]</div><div class="line"> [10  0  0  0]</div><div class="line"> [ 5  4  0  0]</div><div class="line"> [11  3  0  0]</div><div class="line"> [ 5  1  0  0]</div><div class="line"> [12 13  2 14]]</div><div class="line"></div><div class="line">Loaded 400000 word vectors.</div><div class="line"></div><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #</div><div class="line">=================================================================</div><div class="line">embedding_1 (Embedding)      (None, 4, 100)            1500</div><div class="line">_________________________________________________________________</div><div class="line">flatten_1 (Flatten)          (None, 400)               0</div><div class="line">_________________________________________________________________</div><div class="line">dense_1 (Dense)              (None, 1)                 401</div><div class="line">=================================================================</div><div class="line">Total params: 1,901</div><div class="line">Trainable params: 401</div><div class="line">Non-trainable params: 1,500</div><div class="line">_________________________________________________________________</div><div class="line"></div><div class="line"></div><div class="line">Accuracy: 100.000000</div></pre></td></tr></table></figure><p>在实践中，最好还是尝试使用预先训练好的嵌入来学习单词嵌入，因为它是固定的，并尝试在预先训练好的嵌入之上进行学习，这就类似于计算机视觉里面用预训练的VGG或者res-net迁移具体问题那样。</p><p>不过这取决于什么最适合你的具体问题。</p><h2 id="IMDB-数据集Embedding实例"><a href="#IMDB-数据集Embedding实例" class="headerlink" title="IMDB 数据集Embedding实例"></a>IMDB 数据集Embedding实例</h2><p><img src="/images/15204978301733.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential,Model</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten, Dense, Embedding, Input</div><div class="line"></div><div class="line">input_layer = Input(shape=(maxlen,)) </div><div class="line">x = Embedding(input_dim=<span class="number">10000</span>,output_dim=<span class="number">8</span>)(input_layer)</div><div class="line"><span class="comment"># 单独做一个embedding模型，利于后面观察</span></div><div class="line">embedding = Model(input_layer,x)</div><div class="line">x = Flatten()(x)</div><div class="line">x = Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>)(x)</div><div class="line">model = Model(input_layer,x)</div><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'binary_crossentropy'</span>,metrics=[<span class="string">'acc'</span>])</div><div class="line">model.summary()</div><div class="line">history = modhistory = modhistory = mod&gt; history = model.fit(x_train,y_train,epochs=<span class="number">10</span>,batch_size=<span class="number">32</span>,validation_split=<span class="number">0.2</span>)</div><div class="line"></div><div class="line"></div><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></div><div class="line">=================================================================</div><div class="line">input_4 (InputLayer)         (<span class="keyword">None</span>, <span class="number">20</span>)                <span class="number">0</span>         </div><div class="line">_________________________________________________________________</div><div class="line">embedding_5 (Embedding)      (<span class="keyword">None</span>, <span class="number">20</span>, <span class="number">8</span>)             <span class="number">80000</span>     </div><div class="line">_________________________________________________________________</div><div class="line">flatten_5 (Flatten)          (<span class="keyword">None</span>, <span class="number">160</span>)               <span class="number">0</span>         </div><div class="line">_________________________________________________________________</div><div class="line">dense_5 (Dense)              (<span class="keyword">None</span>, <span class="number">1</span>)                 <span class="number">161</span>       </div><div class="line">=================================================================</div><div class="line"></div><div class="line">Total params: <span class="number">80</span>,<span class="number">161</span></div><div class="line">Trainable params: <span class="number">80</span>,<span class="number">161</span></div><div class="line">Non-trainable params: <span class="number">0</span></div><div class="line">_________________________________________________________________</div><div class="line">Train on <span class="number">20000</span> samples, validate on <span class="number">5000</span> samples</div><div class="line">Epoch <span class="number">1</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">105</span>us/step - loss: <span class="number">0.6772</span> - acc: <span class="number">0.6006</span> - val_loss: <span class="number">0.6448</span> - val_acc: <span class="number">0.6704</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.5830</span> - acc: <span class="number">0.7188</span> - val_loss: <span class="number">0.5629</span> - val_acc: <span class="number">0.7046</span></div><div class="line">Epoch <span class="number">3</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">95</span>us/step - loss: <span class="number">0.5152</span> - acc: <span class="number">0.7464</span> - val_loss: <span class="number">0.5362</span> - val_acc: <span class="number">0.7208</span></div><div class="line">Epoch <span class="number">4</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.4879</span> - acc: <span class="number">0.7607</span> - val_loss: <span class="number">0.5299</span> - val_acc: <span class="number">0.7292</span></div><div class="line">Epoch <span class="number">5</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">97</span>us/step - loss: <span class="number">0.4731</span> - acc: <span class="number">0.7694</span> - val_loss: <span class="number">0.5290</span> - val_acc: <span class="number">0.7334</span></div><div class="line">Epoch <span class="number">6</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">98</span>us/step - loss: <span class="number">0.4633</span> - acc: <span class="number">0.7773</span> - val_loss: <span class="number">0.5317</span> - val_acc: <span class="number">0.7344</span></div><div class="line">Epoch <span class="number">7</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">96</span>us/step - loss: <span class="number">0.4548</span> - acc: <span class="number">0.7819</span> - val_loss: <span class="number">0.5333</span> - val_acc: <span class="number">0.7318</span></div><div class="line">Epoch <span class="number">8</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.4471</span> - acc: <span class="number">0.7870</span> - val_loss: <span class="number">0.5377</span> - val_acc: <span class="number">0.7288</span></div><div class="line">Epoch <span class="number">9</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">95</span>us/step - loss: <span class="number">0.4399</span> - acc: <span class="number">0.7924</span> - val_loss: <span class="number">0.5422</span> - val_acc: <span class="number">0.7278</span></div><div class="line">Epoch <span class="number">10</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">90</span>us/step - loss: <span class="number">0.4328</span> - acc: <span class="number">0.7957</span> - val_loss: <span class="number">0.5458</span> - val_acc: <span class="number">0.7290</span></div></pre></td></tr></table></figure><p>我们观察一下input的shape</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">x_train[<span class="number">1</span>].shape</div><div class="line">x_train[<span class="number">1</span>]</div><div class="line">x_train[:<span class="number">1</span>].shape</div><div class="line">x_train[:<span class="number">1</span>]</div><div class="line"></div><div class="line">(<span class="number">20</span>,)</div><div class="line">array([ <span class="number">23</span>,   <span class="number">4</span>,   <span class="number">2</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">4</span>,   <span class="number">2</span>,   <span class="number">5</span>,  <span class="number">28</span>,   <span class="number">6</span>,  <span class="number">52</span>, <span class="number">154</span>, <span class="number">462</span>,</div><div class="line">        <span class="number">33</span>,  <span class="number">89</span>,  <span class="number">78</span>, <span class="number">285</span>,  <span class="number">16</span>, <span class="number">145</span>,  <span class="number">95</span>], dtype=int32)</div><div class="line">(<span class="number">1</span>, <span class="number">20</span>)</div><div class="line">array([[ <span class="number">65</span>,  <span class="number">16</span>,  <span class="number">38</span>,   <span class="number">2</span>,  <span class="number">88</span>,  <span class="number">12</span>,  <span class="number">16</span>, <span class="number">283</span>,   <span class="number">5</span>,  <span class="number">16</span>,   <span class="number">2</span>, <span class="number">113</span>, <span class="number">103</span>,</div><div class="line">         <span class="number">32</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">2</span>,  <span class="number">19</span>, <span class="number">178</span>,  <span class="number">32</span>]], dtype=int32)</div></pre></td></tr></table></figure><p>再看看embedding的输出，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">embedding.predict(x_train[:<span class="number">1</span>]).shape</div><div class="line">embedding.predict(x_train[:<span class="number">1</span>])</div><div class="line"></div><div class="line">(<span class="number">1</span>, <span class="number">20</span>, <span class="number">8</span>)</div><div class="line">array([[[<span class="number">-0.17401133</span>, <span class="number">-0.08743777</span>,  <span class="number">0.15631911</span>, <span class="number">-0.06831486</span>, <span class="number">-0.09105065</span>,</div><div class="line">          <span class="number">0.06253908</span>, <span class="number">-0.0798945</span> ,  <span class="number">0.07671431</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [ <span class="number">0.06872956</span>, <span class="number">-0.00586612</span>,  <span class="number">0.07713806</span>, <span class="number">-0.00182899</span>,  <span class="number">0.00882899</span>,</div><div class="line">         <span class="number">-0.18892162</span>, <span class="number">-0.13580748</span>, <span class="number">-0.03166043</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [ <span class="number">0.20604047</span>,  <span class="number">0.10910885</span>,  <span class="number">0.06304865</span>, <span class="number">-0.14038748</span>,  <span class="number">0.12123005</span>,</div><div class="line">          <span class="number">0.06124007</span>,  <span class="number">0.0532628</span> ,  <span class="number">0.17591232</span>],</div><div class="line">        [<span class="number">-0.19636872</span>, <span class="number">-0.0027669</span> ,  <span class="number">0.01087157</span>, <span class="number">-0.02332311</span>, <span class="number">-0.04321857</span>,</div><div class="line">         <span class="number">-0.09228673</span>, <span class="number">-0.03061322</span>, <span class="number">-0.13376454</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.27160701</span>, <span class="number">-0.29296583</span>,  <span class="number">0.1055108</span> ,  <span class="number">0.15896739</span>, <span class="number">-0.24833643</span>,</div><div class="line">         <span class="number">-0.17791845</span>, <span class="number">-0.27316946</span>, <span class="number">-0.241273</span>  ],</div><div class="line">        [<span class="number">-0.02175452</span>, <span class="number">-0.0839383</span> ,  <span class="number">0.04338101</span>,  <span class="number">0.01062139</span>, <span class="number">-0.11473208</span>,</div><div class="line">         <span class="number">-0.18394938</span>, <span class="number">-0.05141308</span>, <span class="number">-0.10405254</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [<span class="number">-0.14751843</span>,  <span class="number">0.05572686</span>,  <span class="number">0.20332271</span>, <span class="number">-0.01759946</span>, <span class="number">-0.0946402</span> ,</div><div class="line">         <span class="number">-0.14416233</span>,  <span class="number">0.16961734</span>,  <span class="number">0.01381243</span>],</div><div class="line">        [ <span class="number">0.00282665</span>, <span class="number">-0.17532936</span>, <span class="number">-0.09342033</span>,  <span class="number">0.04514923</span>, <span class="number">-0.04684081</span>,</div><div class="line">          <span class="number">0.1748796</span> , <span class="number">-0.09669576</span>, <span class="number">-0.10699435</span>],</div><div class="line">        [ <span class="number">0.00225757</span>, <span class="number">-0.12751001</span>, <span class="number">-0.12703758</span>,  <span class="number">0.17167819</span>, <span class="number">-0.03712473</span>,</div><div class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, <span class="number">-0.02731293</span>],</div><div class="line">        [ <span class="number">0.02198115</span>,  <span class="number">0.03989581</span>,  <span class="number">0.13165356</span>,  <span class="number">0.06523556</span>,  <span class="number">0.14900513</span>,</div><div class="line">          <span class="number">0.01858517</span>, <span class="number">-0.01644249</span>, <span class="number">-0.02377043</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [<span class="number">-0.01993229</span>, <span class="number">-0.04436176</span>,  <span class="number">0.07624088</span>,  <span class="number">0.04268746</span>, <span class="number">-0.00883252</span>,</div><div class="line">          <span class="number">0.00789542</span>, <span class="number">-0.03039453</span>,  <span class="number">0.05851226</span>],</div><div class="line">        [<span class="number">-0.12873659</span>, <span class="number">-0.00083202</span>, <span class="number">-0.03246918</span>,  <span class="number">0.23910245</span>, <span class="number">-0.24635716</span>,</div><div class="line">          <span class="number">0.10966355</span>,  <span class="number">0.02079294</span>, <span class="number">-0.03829115</span>],</div><div class="line">        [ <span class="number">0.00225757</span>, <span class="number">-0.12751001</span>, <span class="number">-0.12703758</span>,  <span class="number">0.17167819</span>, <span class="number">-0.03712473</span>,</div><div class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, <span class="number">-0.02731293</span>]]], dtype=float32)</div></pre></td></tr></table></figure><p>可以看出，embedding层将(1, 20)的一个输入sample（最长为20个单词的句子，其中每个单词表示为一个int数字），嵌入为一个(1, 20, 8)的向量，即将每个单词embed为一个8维的向量，而整个embedding层的参数就由神经网络学习得到，数据经过embedding层之后就方便地转换为了可以由CNN或者RNN进一步处理的格式。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/" target="_blank" rel="external">How to Use Word Embedding Layers for Deep Learning with Keras - Machine Learning Mastery</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15135840798621.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。&lt;br&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://frankchen.xyz/tags/Deep-Learning/"/>
    
      <category term="Keras" scheme="http://frankchen.xyz/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>神经网络术语大百科：优化函数、激活函数、损失函数、正则方法的简介</title>
    <link href="http://frankchen.xyz/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/"/>
    <id>http://frankchen.xyz/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/</id>
    <published>2017-12-15T04:45:44.000Z</published>
    <updated>2017-12-16T09:21:29.262Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/neuralnetworks.png" alt="neuralnetworks"></p><p>简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。</p><a id="more"></a><h1 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h1><p>先上两张图</p><figure class="three"><br>   <img src="/images/2017/05/contours_evaluation_optimizers.gif" title="Logo" width="300"><br>   <img src="/images/2017/05/saddle_point_evaluation_optimizers.gif" title="Logo" width="300"><br></figure><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>没有激活函数，神经元就只是一个线性函数，那么无论多少层的神经元叠加是没有意义的。而主流激活函数也随着神经网络、深度学习的发展迭代进化了许多次代。</p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p><img src="/images/15134144452960.jpg" alt=""><br>Sigmoid是S形状的意思，又因为它是逻辑回归的激活函数又叫logistic函数，函数式为$<code>y = 1 / (1 + exp(-x))</code>$是很早以前最常用的激活函数，其实也是有一些优点的，比如，</p><ul><li>值域位于0-1，那么对于逻辑回归，这是对于二分类的一个很自然的表达，也就是概率</li><li>处处连续可导</li></ul><p>不过呢，我们观察它的形状，可以得出，Sigmoid函数在两端（靠近0和1的部分）梯度很小，这也意味着，如果神经元的输出落到了这个地方，那么它几乎没什么梯度可以传到后面，而随着神经网络的层层削弱，后面的层（靠近输入的层）没有多少梯度能传过来，几乎就“学不到什么”了。这叫做梯度消失问题，一度是阻碍神经网络往更深的层进化的主要困难，导致深度学习专家们绞尽脑汁想了许多方法来对抗这个问题，比如“Xavier and He Initialization”，比如我们要把weight随机初始化为如下的范围，<br><img src="/images/Screen%20Shot%202017-12-16%20at%2017.03.18.png" alt="Screen Shot 2017-12-16 at 17.03.18"></p><p>sigmoid的另一个问题是它不是0均值的，Sigmoid函数的输出值恒大于0，这会导致模型训练的收敛速度变慢。举例来讲，对，如果所有均为正数或负数，那么其对的导数总是正数或负数，这会导致如下图红色箭头所示的阶梯式更新，这显然并非一个好的优化路径。深度学习往往需要大量时间来处理大量数据，模型的收敛速度是尤为重要的。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。</p><p><img src="/images/15134157378274.jpg" alt=""></p><p>如今，sigmoid函数应用最广泛的在于其变种softmax在多元分类中，比如手写数字识别，经过卷积神经网络的处理，最后我们需要网络输出每个预测的概率值，最后预测为某一个数字，这里就需要用到softmax，<br><img src="/images/15134154076033.jpg" alt=""><br>以下是softmax的Keras代码，注意其中一个trick，<code>e = K.exp(x - K.max(x, axis=axis, keepdims=True))</code>这里每个分量减去最大值是为了减少计算量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x, axis=<span class="number">-1</span>)</span>:</span></div><div class="line">    <span class="string">"""Softmax activation function.</span></div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x : Tensor.</div><div class="line">        axis: Integer, axis along which the softmax normalization is applied.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        Tensor, output of softmax transformation.</div><div class="line"></div><div class="line">    # Raises</div><div class="line">        ValueError: In case `dim(x) == 1`.</div><div class="line">    """</div><div class="line">    ndim = K.ndim(x)</div><div class="line">    <span class="keyword">if</span> ndim == <span class="number">2</span>:</div><div class="line">        <span class="keyword">return</span> K.softmax(x)</div><div class="line">    <span class="keyword">elif</span> ndim &gt; <span class="number">2</span>:</div><div class="line">        e = K.exp(x - K.max(x, axis=axis, keepdims=<span class="keyword">True</span>))</div><div class="line">        s = K.sum(e, axis=axis, keepdims=<span class="keyword">True</span>)</div><div class="line">        <span class="keyword">return</span> e / s</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Cannot apply softmax to a tensor that is 1D'</span>)</div></pre></td></tr></table></figure></p><h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p><img src="/images/15134156685588.jpg" alt=""></p><p>tanh 是sigmoid的变形： $tanh(x)=2sigmoid(2x)-1$，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好一些，</p><p><img src="/images/15134156615077.jpg" alt=""></p><h2 id="ReLU家族"><a href="#ReLU家族" class="headerlink" title="ReLU家族"></a>ReLU家族</h2><p>然而标准ReLU不是完美的，比如因为ReLU在小于0的坐标梯度都是0，那么会造成“死亡”的神经元的问题：一旦神经元的输入与权重之乘积是负的，那么经过ReLU的激活，输出就是0，而ReLU的0梯度让“死亡”的神经元无法“复活”：没办法回到输出不是0的状态，这样就出现了许多在ReLU的变种，一般都是对标准ReLU坐标轴左边的部分做文章，比如<strong>leaky ReLU</strong>。其公式就是$LeakyReLU_ α (z) = max(\alpha z,z)$。如图，<br><img src="/images/15134123600394.jpg" alt=""></p><p>这篇文章<a href="https://arxiv.org/pdf/1505.00853.pdf" target="_blank" rel="external">Empirical Evaluation of Rectified Activations in Convolution Network</a>对比了几种leaky ReLU，比如把$\alpha$设置为0.2效果总是好过0.01，并且，对于randomized leaky ReLU (RReLU)（其中$\alpha$设置为一个在指定范围内的随机数），效果也不错，而且还具有一定的正则作用。另外，对于parametric leaky ReLU (PReLU)（其中$\alpha$作为网络的一个参数，被反向传播学习出来，之前的$\alpha$都是超参数，不能学只能调节），这种变种对于大数据集不错，但是数据量过小就有过拟合的风险。以下是Keras里面relu的代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x, alpha=<span class="number">0.</span>, max_value=None)</span>:</span></div><div class="line">    <span class="string">"""Rectified linear unit.</span></div><div class="line"></div><div class="line">    With default values, it returns element-wise `max(x, 0)`.</div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x: A tensor or variable.</div><div class="line">        alpha: A scalar, slope of negative section (default=`0.`).</div><div class="line">        max_value: Saturation threshold.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        A tensor.</div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</div><div class="line">        negative_part = tf.nn.relu(-x)</div><div class="line">    x = tf.nn.relu(x)</div><div class="line">    <span class="keyword">if</span> max_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        max_value = _to_tensor(max_value, x.dtype.base_dtype)</div><div class="line">        zero = _to_tensor(<span class="number">0.</span>, x.dtype.base_dtype)</div><div class="line">        x = tf.clip_by_value(x, zero, max_value)</div><div class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</div><div class="line">        alpha = _to_tensor(alpha, x.dtype.base_dtype)</div><div class="line">        x -= alpha * negative_part</div><div class="line">    <span class="keyword">return</span> x</div></pre></td></tr></table></figure><p>另外，在这篇文章里面<a href="https://arxiv.org/pdf/1511.07289v5.pdf" target="_blank" rel="external">FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)</a>，引入了一种新的ReLU，exponential linear unit (ELU)，公式如下，<br>$$<br>ELU_{\alpha}(z) = \alpha (\exp(z)-1) \ if \ z \lt 0 ; \ z \ if \ z \gt 0;<br>$$<br><img src="/images/15134129990682.jpg" alt=""></p><p>与标准ReLU最大的区别在于它处处连续可导，这使得梯度下降得到加速，收敛得到了加速，而使用了指数函数使得其测试阶段的计算代价更高。Keras里elu的实现，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span><span class="params">(x, alpha=<span class="number">1.</span>)</span>:</span></div><div class="line">    <span class="string">"""Exponential linear unit.</span></div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x: A tenor or variable to compute the activation function for.</div><div class="line">        alpha: A scalar, slope of positive section.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        A tensor.</div><div class="line">    """</div><div class="line">    res = tf.nn.elu(x)</div><div class="line">    <span class="keyword">if</span> alpha == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> res</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> tf.where(x &gt; <span class="number">0</span>, res, alpha * res)</div></pre></td></tr></table></figure><h2 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h2><p>一般来说，我们的选择顺序可以理解为：<br>ELU &gt; leaky ReLU (以及其变种) &gt; ReLU &gt; tanh &gt; logistic。但是，</p><ul><li>如果我们更顾虑模型运行速度，那么leaky ReLU可能比ELU更好；</li><li>如果我们不想调节超参数，那么用默认的$\alpha$就行，ReLU和ELU的分别是0.01和1； </li><li>如果算力足够可以用来调参，那么如果网络过拟合我们会选择RReLU，如果训练集数据足够多，那可以用PReLU。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/neuralnetworks.png&quot; alt=&quot;neuralnetworks&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://frankchen.xyz/tags/Deep-Learning/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Python" scheme="http://frankchen.xyz/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>如何理解Pandas 和 Numpy里的axis</title>
    <link href="http://frankchen.xyz/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/"/>
    <id>http://frankchen.xyz/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/</id>
    <published>2017-12-12T10:36:04.000Z</published>
    <updated>2018-03-09T11:12:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15130766716183.jpg" alt=""></p><p>简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。<br><a id="more"></a></p><p>Numpy 和 Pandas里的sort、mean、drop等操作，不是分行或者列分别用一个method来定义，而是一个method里面用户指定axis来操作的，举例来说：</p><p>我们先在<a href="https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/drinks.csv" target="_blank" rel="external">此处</a>下载了一份各国酒类消费的csv文件为例。<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.14.png" alt="Screen Shot 2017-12-12 at 18.46.14"><br>如下是pandas里按axis 0和1进行drop的操作示例，我们很容易看出，axis 0是按行drop，而axis 1是按列drop：<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.22.png" alt="Screen Shot 2017-12-12 at 18.46.22"></p><p>但是，mean操作呢？<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.49.18.png" alt="Screen Shot 2017-12-12 at 18.49.18"></p><p>容易看出，axis 0得出了每一列的均值，而axis 1得出了则是每一行的均值。<br>那么，在Numpy里呢？</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2019.06.17.png" alt="Screen Shot 2017-12-12 at 19.06.17"></p><p>容易看出，axis为1的时候得出的是每行的sum，axis为0的时候得出了每列的sum。</p><p>由上面的例子，我们似乎可以看出，axis为1代表水平方向上的操作，axis为0代表垂直方向上的操作，比如axis为1的sum得出的就是每一行的和。</p><p><img src="/images/15130760734631.jpg" alt=""></p><p>但是，在Pandas的Dataframe里面，为什么axis=1代表的是drop整个列呢？以下这个例子也可以说明一些情况：</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2018.56.53.png" alt="Screen Shot 2017-12-12 at 18.56.53"></p><p>联系这个视频<a href="https://www.youtube.com/watch?v=PtO3t6ynH-8" target="_blank" rel="external">How do I use the “axis” parameter in pandas? - YouTube</a>，大家也可以得到一些结论，作者说：</p><blockquote><p>0 is the row axis, and 1 is the column axis. When you drop with axis=1, that means drop a column. When you take the mean with axis=1, that means the operation should “move across” the column axis, which produces row means.<br>指的就是一种更加容易理解的方式，“0就是行的axis，1就是列的axis，当以axis=1来drop，那么就是drop一个column，而axis=1 来取mean，那么就是这个操作‘穿越’了列的axis，产生了行上的mean”。</p></blockquote><p>另外，其实我们也可以这样来操作，<br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.27.png" alt="Screen Shot 2017-12-12 at 19.01.27"><br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.45.png" alt="Screen Shot 2017-12-12 at 19.01.45"></p><p>可以看出，axis=0与axis=’rows’是一样的（在Pandas里），是不是更加容易理解了？</p><p><a href="https://distill.pub/2016/misread-tsne/" target="_blank" rel="external">How to Use t-SNE Effectively</a>这个网站给了一个非常形象的t-SNE在线实验环境，推荐大家去看一看！<br><img src="/images/15205939273866.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15130766716183.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Numpy" scheme="http://frankchen.xyz/tags/Numpy/"/>
    
      <category term="Pandas" scheme="http://frankchen.xyz/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>理解triplet loss</title>
    <link href="http://frankchen.xyz/2017/12/01/understanding-triplet-loss-and-example-code/"/>
    <id>http://frankchen.xyz/2017/12/01/understanding-triplet-loss-and-example-code/</id>
    <published>2017-12-01T09:19:05.000Z</published>
    <updated>2018-03-30T02:23:22.993Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15121200710041.jpg" alt=""><br>理解triplet loss，与给出TensorFlow和numpy两种形式的example code。<br><a id="more"></a></p><p>Triplet Loss 是当前应用的很广泛的一种损失函数，在人脸识别和聚类领域，这是一种很自然的映射与计算损失的方式，比如<a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="external">FaceNet</a>里，通过构建一种embedding 方式，将人脸图像直接映射到欧式空间，而优化这种embedding的方法可以概括为，构建许多组三元组（Anchor，Positive，Negative），其中Anchor与Positive同label，Anchor与Negative不同label（在人脸识别里面，就是Anchor与Positive是同一个个体，而与Negative是不同个体），通过学习优化这个embedding，使得欧式空间内的Anchor与Positive 的距离比与Negative的距离要近。</p><h2 id="公式表示"><a href="#公式表示" class="headerlink" title="公式表示"></a>公式表示</h2><p>用公式表示就是，我们希望：</p><p>$$<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2  +<br>\alpha \lt \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 , \<br>\forall (f(x^a_i) , f(x^p_i) , f(x^n_i))  \in \mathscr T<br>$$</p><p>其中$\alpha$ 是强制的正例和负例之间的margin，$\mathscr T$是具有基数为$N$的训练集中的三元组的集合。</p><p>那么，损失函数很自然的可以写为：</p><p>$$<br>\sum^N_i<br>\Bigl [<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2   +<br> \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 + \alpha<br> \Bigr ] _ +<br>$$</p><p>其中加号指的，如果中括号内部分大于0，则没有损失（Anchor与Positive的距离加上margin小于与Negative的距离），否则计算这个距离为损失。</p><h2 id="代码表示"><a href="#代码表示" class="headerlink" title="代码表示"></a>代码表示</h2><p>Numpy 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line"></div><div class="line"><span class="comment"># 构造batch_size * embedding_size 维度的随机矩阵</span></div><div class="line">emb = np.random.uniform(size=[])</div><div class="line"></div><div class="line"><span class="comment"># 对emb逢三取1、2、3行分别为Anchor、Positive、Negative</span></div><div class="line"><span class="comment"># 计算其2范数的距离即欧氏距离</span></div><div class="line">pos_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </div><div class="line">neg_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># 这里就是照抄公式了，注意mean和sum是一样的</span></div><div class="line">np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</div></pre></td></tr></table></figure><p>TensorFlow 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line">alpha = <span class="number">0.2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(anchor, positive, negative, alpha)</span>:</span>   </div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'triplet_loss'</span>):</div><div class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</div><div class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</div><div class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</div><div class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="keyword">None</span>)</div><div class="line">    <span class="keyword">return</span> loss</div><div class="line"></div><div class="line"><span class="comment"># 构建矩阵</span></div><div class="line">embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">'embeddings'</span>)</div><div class="line"><span class="comment"># 先将embeddings矩阵第0维resize为(?, 3)维，第1维不变，变为三维矩阵(-1, 3, embedding_size)，再在其第二维度为3上unstack为三份</span></div><div class="line">anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(<span class="number">-1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</div></pre></td></tr></table></figure><p>完整代码如下，这里测试对比了两种实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line">alpha = <span class="number">0.2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(anchor, positive, negative, alpha)</span>:</span>   </div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'triplet_loss'</span>):</div><div class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</div><div class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</div><div class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</div><div class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="keyword">None</span>)</div><div class="line">    <span class="keyword">return</span> loss</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Graph().as_default():</div><div class="line">    embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">'embeddings'</span>)</div><div class="line">    anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(<span class="number">-1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</div><div class="line">    triplet_loss = triplet_loss(anchor, positive, negative, alpha)</div><div class="line">    </div><div class="line">    sess = tf.Session()</div><div class="line">    <span class="keyword">with</span> sess.as_default():</div><div class="line">        np.random.seed(<span class="number">666</span>)</div><div class="line">        emb = np.random.uniform(size=[batch_size, embedding_size])</div><div class="line">        tf_triplet_loss = sess.run(triplet_loss, feed_dict=&#123;embeddings:emb&#125;)</div><div class="line">        </div><div class="line">        pos_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </div><div class="line">        neg_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</div><div class="line">        np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</div><div class="line">        </div><div class="line">        np.testing.assert_almost_equal(tf_triplet_loss, np_triplet_loss, decimal=<span class="number">5</span>, err_msg=<span class="string">'Triplet loss is incorrect'</span>)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15121200710041.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;理解triplet loss，与给出TensorFlow和numpy两种形式的example code。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
      <category term="TensorFlow" scheme="http://frankchen.xyz/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>数据的标准化与归一化</title>
    <link href="http://frankchen.xyz/2017/11/29/Data-Normalization-and-Standardization/"/>
    <id>http://frankchen.xyz/2017/11/29/Data-Normalization-and-Standardization/</id>
    <published>2017-11-29T03:53:57.000Z</published>
    <updated>2017-12-01T11:10:13.685Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15119359203487.png" alt=""><br>聊一聊Normalization and Standardization<br><a id="more"></a></p><h2 id="什么是"><a href="#什么是" class="headerlink" title="什么是"></a>什么是</h2><p>Normalization就是归一化，是最小-最大缩放(min-max scaling)的特例，指的是将数据缩放到指定range，这个range通常是0~1或者-1~+1，直观来讲就是下图，在数据不包含离群点时很有用，<br><img src="/images/Screen%20Shot%202017-11-29%20at%2012.35.41.png" alt="Screen Shot 2017-11-29 at 12.35.41"></p><p>公式则是</p><p>$$<br>x^{(i)}_{norm} = \frac {x^{(i)} - x_{min}} {x_{max} - x_{min}}<br>$$</p><p>若要缩放至-1~+1，则是<br>$$<br>x’ = \frac{x - min}{max - min}<br>$$</p><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#导入数据预处理库</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line"><span class="comment">#范围缩放标准化</span></div><div class="line">min_max_scaler = preprocessing.MinMaxScaler()</div><div class="line"></div><div class="line"><span class="comment">#训练集缩放标准化</span></div><div class="line">min_max_scaler.fit_transform(X_train)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试集缩放标准化</span></div><div class="line">min_max_scaler.fit_transform(X_test)</div></pre></td></tr></table></figure><p>Z-score 标准化指的是，通过缩放让数据的均值为0（移除均值），标准差为固定值（比如1）。在许多模型里，如SVM的RBF、线性模型的 L1 &amp; L2 正则项对于所有的feature都有这样的假设。<br>$$<br>x^{(i)}_{std} = \frac{x^{(i)} - \mu_x}{\sigma_x}<br>$$</p><p>以下是一个简单的例子展示了两者的区别：</p><p><img src="/images/Screen%20Shot%202017-11-29%20at%2012.41.13.png" alt="Screen Shot 2017-11-29 at 12.41.13"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#导入数据预处理库</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line"><span class="comment">#数据标准化</span></div><div class="line">scaler = preprocessing.StandardScaler().fit(X_train)</div><div class="line"></div><div class="line"><span class="comment">#训练集数据标准化</span></div><div class="line">scaler.transform(X_train)</div></pre></td></tr></table></figure><p>同时对测试集的数据进行标准化处理，以保证训练集和测试集的变换方式相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试集数据标准化</span></div><div class="line">scaler.transform(X_test)</div></pre></td></tr></table></figure><h2 id="值得注意"><a href="#值得注意" class="headerlink" title="值得注意"></a>值得注意</h2><p>从流程上讲，标准化和归一化应该在读入数据、处理缺失值，切分训练测试集之后，而且我们要做的是在切分之后，在训练集fit，再去transform测试集，而不是在整个数据上转换以后再切分，因为<strong>无论是标准化还是归一化，我们要么利用到了数据的max min值，要么利用到了数据的均值和标准差，这些数值在训练之前是不能被测试集所影响的。</strong></p><p>类似于缺失值的填充，举个例子，我们使用均值填充以下数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#使用均值填充缺失值</span></div><div class="line">imp = Imputer(missing_values=<span class="string">"NaN"</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</div><div class="line">imp.fit(X_train)</div><div class="line"></div><div class="line"><span class="comment">#填充训练集</span></div><div class="line">X_train=imp.transform(X_train)</div></pre></td></tr></table></figure><p>以同样的方式填充测试集，以保证测试集和训练集的数据填充方式保持一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#填充测试集</span></div><div class="line">X_test=imp.transform(X_test)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15119359203487.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;聊一聊Normalization and Standardization&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow on a GTX 1080</title>
    <link href="http://frankchen.xyz/2017/11/13/TensorFlow-on-a-GTX-1080/"/>
    <id>http://frankchen.xyz/2017/11/13/TensorFlow-on-a-GTX-1080/</id>
    <published>2017-11-13T10:23:28.000Z</published>
    <updated>2018-03-15T05:10:21.147Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15105686803158.jpg" alt=""><br><img src="/images/15105687114770.jpg" alt=""></p><p>Ubuntu 16.03 安装 CUDA、NVIDIA驱动，CUDNN及GPU版TensorFlow。<br><a id="more"></a><br>GPU 支持的TensorFlow让算力大幅提升，但是安装好一切支持却不那么容易！其实主要是三个东西：</p><ol><li>Nvidia 驱动：显卡驱动</li><li>CUDA Toolkit CUDA工具箱</li><li>CUDNN：CUDA Deep Neural Network library  神经网络库函数<h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install \</div><div class="line">    freeglut3-dev \</div><div class="line">    g++-4.9 \</div><div class="line">    gcc-4.9 \</div><div class="line">    libglu1-mesa-dev \</div><div class="line">    libx11-dev \</div><div class="line">    libxi-dev \</div><div class="line">    libxmu-dev \</div><div class="line">    nvidia-modprobe \</div><div class="line">    python-dev \</div><div class="line">    python-pip \</div><div class="line">    python-virtualenv</div></pre></td></tr></table></figure><h2 id="安装Nvidia驱动"><a href="#安装Nvidia驱动" class="headerlink" title="安装Nvidia驱动"></a>安装Nvidia驱动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get purge nvidia-* 删除nvidia 之前的</div><div class="line">$ sudo add-apt-repository ppa:graphics-drivers/ppa</div><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install nvidia-384</div></pre></td></tr></table></figure><p>可在<a href="https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa" target="_blank" rel="external">Proprietary GPU Drivers : “Graphics Drivers” team</a>查看当前稳定版本Nvidia驱动，如笔者当前（2017-11-13）版本是‘nvidia-384’。</p><p>接下来重启<code>$ sudo reboot</code>。<br>重启后，检测Nvidia驱动安装情况，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ cat /proc/driver/nvidia/version</div></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.98  Thu Oct 26 15:16:01 PDT 2017</div><div class="line">GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)</div></pre></td></tr></table></figure><p>显示Nvidia’s system management interface：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo nvidia-smi</div></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |</div><div class="line">|  0%   47C    P8    12W / 215W |   7992MiB /  8112MiB |      2%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line"></div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID   Type   Process name                             Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|    0       994      G   /usr/lib/xorg/Xorg                           193MiB |</div><div class="line">|    0      1889      G   compiz                                       151MiB |</div><div class="line">|    0      5068      C   /home/frank/anaconda3/bin/python            7643MiB |</div><div class="line">+-----------------------------------------------------------------------------+</div></pre></td></tr></table></figure><p>设置GCC 4.9为默认</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 10</div><div class="line">$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 20</div><div class="line"></div><div class="line">$ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 10</div><div class="line">$ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 20</div></pre></td></tr></table></figure><h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>当前虽然CUDA-9.0已经发布，但是TensorFlow默认编译版本还是基于CUDA-8.0的，我们在这里<a href="https://developer.nvidia.com/cuda-80-ga2-download-archive" target="_blank" rel="external">CUDA Toolkit 8.0 - Feb 2017 | NVIDIA Developer</a>下载runfile<br><img src="/images/Screen%20Shot%202017-11-13%20at%2018.35.28.png" alt="Screen Shot 2017-11-13 at 18.35.28"></p><p>使用如下安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo cuda_8.0.61_375.26_linux.run --override</div></pre></td></tr></table></figure></p><p>安装时记得</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">Do you accept the previously <span class="built_in">read</span> EULA? (accept/decline/quit): accept</div><div class="line">You are attempting to install on an unsupported configuration. Do you wish to <span class="built_in">continue</span>? ((y)es/(n)o) [ default is no ]: yes</div><div class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 352.39? ((y)es/(n)o/(q)uit): no</div><div class="line">Install the CUDA 8.0 Toolkit? ((y)es/(n)o/(q)uit): yes</div><div class="line">Enter Toolkit Location [ default is /usr/<span class="built_in">local</span>/cuda-8.0 ]:</div><div class="line">Do you want to install a symbolic link at /usr/<span class="built_in">local</span>/cuda? ((y)es/(n)o/(q)uit): yes</div><div class="line">Install the CUDA 8.0 Samples? ((y)es/(n)o/(q)uit): no</div><div class="line">Installing the CUDA Toolkit <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0 ...</div><div class="line"></div><div class="line">===========</div><div class="line">= Summary =8.0</div><div class="line">===========</div><div class="line"></div><div class="line">Driver:   Not Selected</div><div class="line">Toolkit:  Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</div><div class="line">Samples:  Not Selected</div><div class="line"></div><div class="line">Please make sure that</div><div class="line"> -   PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/bin</div><div class="line"> -   LD_LIBRARY_PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/lib64, or, add /usr/<span class="built_in">local</span>/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</div><div class="line"></div><div class="line">To uninstall the CUDA Toolkit, run the uninstall script <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/bin</div><div class="line">To uninstall the NVIDIA Driver, run nvidia-uninstall</div><div class="line"></div><div class="line">Please see CUDA_Installation_Guide_Linux.pdf <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/doc/pdf <span class="keyword">for</span> detailed information on setting up CUDA.</div><div class="line"></div><div class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 352.00 is required <span class="keyword">for</span> CUDA 8.0 functionality to work.</div><div class="line">To install the driver using this installer, run the following <span class="built_in">command</span>, replacing &lt;CudaInstaller&gt; with the name of this run file:</div><div class="line">    sudo &lt;CudaInstaller&gt;.run -silent -driver</div><div class="line"></div><div class="line">Logfile is /tmp/cuda_install_14557.log</div></pre></td></tr></table></figure><p>记得上面这里也有个询问你是否安装Nvidia驱动的地方，因为我们前面已经安装了最新的版本，这里当然选择no。</p><p>添加环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">echo</span> <span class="string">'export PATH=/usr/local/cuda/bin:$PATH'</span> &gt;&gt; ~/.bashrc</div><div class="line">$ <span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH'</span> &gt;&gt; ~/.bashrc</div><div class="line">$ <span class="built_in">source</span> ~/.bashrc</div></pre></td></tr></table></figure><p>查看CUDA compiler</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ nvcc -V</div></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nvcc: NVIDIA (R) Cuda compiler driver</div><div class="line">Copyright (c) 2005-2016 NVIDIA Corporation</div><div class="line">Built on Tue_Jan_10_13:22:03_CST_2017</div><div class="line">Cuda compilation tools, release 8.0, V8.0.61</div></pre></td></tr></table></figure><h2 id="安装CUDA-Deep-Neural-Network-library-：CUDNN"><a href="#安装CUDA-Deep-Neural-Network-library-：CUDNN" class="headerlink" title="安装CUDA Deep Neural Network library ：CUDNN"></a>安装CUDA Deep Neural Network library ：CUDNN</h2><p>在此处下载<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="external">cuDNN Download | NVIDIA Developer</a>，可能需要我们注册账号登录。<br>选择适配CUDA的版本，以及cuDNN v7.0 Library for Linux，这个就是个targz文件。<br><img src="/images/Screen%20Shot%202017-11-13%20at%2018.42.51.png" alt="Screen Shot 2017-11-13 at 18.42.51"></p><p>接下来操作就是把cudnn的几个库放到cuda里面：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ tar xvf cudnn-8.0-linux-x64-v7.tgz</div><div class="line">$ sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/</div><div class="line">$ sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/</div><div class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure></p><h2 id="TensorFlow安装"><a href="#TensorFlow安装" class="headerlink" title="TensorFlow安装"></a>TensorFlow安装</h2><p><code>pip  install --upgrade tfBinaryURL</code>即可，这里的<code>tfBinaryURL</code>可在<a href="https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package" target="_blank" rel="external">Installing TensorFlow on Ubuntu  |  TensorFlow</a>选取，例如我这里选取Python3.6的GPU Support：</p><p><img src="/images/Screen%20Shot%202017-11-13%20at%2018.47.45.png" alt="Screen Shot 2017-11-13 at 18.47.45"></p><h2 id="验证TensorFlow安装"><a href="#验证TensorFlow安装" class="headerlink" title="验证TensorFlow安装"></a>验证TensorFlow安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">In [1]: import tensorflow as tf</div><div class="line"></div><div class="line">In [2]: sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</div><div class="line">2017-11-13 18:54:59.081831: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</div><div class="line">2017-11-13 18:54:59.186280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node <span class="built_in">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</div><div class="line">2017-11-13 18:54:59.186604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:</div><div class="line">name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.86</div><div class="line">pciBusID: 0000:01:00.0</div><div class="line">totalMemory: 7.92GiB freeMemory: 7.46GiB</div><div class="line">2017-11-13 18:54:59.186617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)</div><div class="line">Device mapping:</div><div class="line">/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1</div><div class="line">2017-11-13 18:54:59.216573: I tensorflow/core/common_runtime/direct_session.cc:299] Device mapping:</div><div class="line">/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1</div></pre></td></tr></table></figure><p>如上，打印出这些信息就证明安装成功啦！</p><h2 id="CUDA-ToolKit-8-0-升级到9-0指南"><a href="#CUDA-ToolKit-8-0-升级到9-0指南" class="headerlink" title="CUDA ToolKit 8.0 升级到9.0指南"></a>CUDA ToolKit 8.0 升级到9.0指南</h2><p>主要就是需要下载CUDA ToolKit 9.0 的安装包，和8.0一样安装，注意下面的四步骤我们只需要第二步（ToolKit）和第四步（创建软链接，原有的是指向8.0的）</p><p><img src="/images/15210144246547.jpg" alt=""></p><p>因为CUDNN被放在CUDA ToolKit 8.0内，所有这里我们需要重新下载CUDNN并解压到CUDA ToolKit 9.0文件夹内，</p><p>再在<a href="https://www.tensorflow.org/install/install_linux#InstallingAnaconda" target="_blank" rel="external">Installing TensorFlow on Ubuntu  |  TensorFlow</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install --ignore-installed --upgrade \</div><div class="line">&lt;url&gt;</div></pre></td></tr></table></figure><p><code>url</code>选取如下的你需要的python版本的GPU网址即可。<br><img src="/images/15210146789201.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15105686803158.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15105687114770.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ubuntu 16.03 安装 CUDA、NVIDIA驱动，CUDNN及GPU版TensorFlow。&lt;br&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
      <category term="TensorFlow" scheme="http://frankchen.xyz/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>frp的内网穿透及外网访问内网jupyter-notebook的实现</title>
    <link href="http://frankchen.xyz/2017/11/12/ftp-using/"/>
    <id>http://frankchen.xyz/2017/11/12/ftp-using/</id>
    <published>2017-11-11T18:20:38.000Z</published>
    <updated>2017-11-13T08:02:04.255Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15104246654723.png" alt=""></p><a id="more"></a><p><a href="https://github.com/fatedier/frp" target="_blank" rel="external">fatedier/frp: A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.</a>是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议， 这里我们用它来搭建外网访问内网jupyter-notebook的服务。<br>我们基于Ubuntu16.04 选用amd64版本，<br><img src="/images/Screen%20Shot%202017-11-12%20at%2002.25.46.png" alt="Screen Shot 2017-11-12 at 02.25.46"></p><h3 id="server设置"><a href="#server设置" class="headerlink" title="server设置"></a>server设置</h3><p>server就是你拥有外网IP的服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[common]</div><div class="line">bind_port = 7000</div><div class="line">vhost_http_port = 8888</div></pre></td></tr></table></figure></p><p>用<code>./frps -c ./frps.ini</code>启动，注意服务端需要先启动。</p><h3 id="client设置"><a href="#client设置" class="headerlink" title="client设置"></a>client设置</h3><p>client就是没有外网IP，但是你想在外网访问的机器，</p><p>XXXXXXXXX就是上面的server的外网IP。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[common]</div><div class="line">server_addr = XXXXXXXXX</div><div class="line">server_port = 7000</div><div class="line"></div><div class="line">[web]</div><div class="line"><span class="built_in">type</span> = http</div><div class="line">local_port = 8888</div><div class="line">custom_domains = XXXXXXXXX</div></pre></td></tr></table></figure><p>以<code>./frpc -c ./frpc.ini</code>启动。</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>接下来，在client端，在8888段端口启动jupyter-notebook即可在XXXXXXXXX:8888访问内网机器上的Notebook了。</p><p><img src="/images/Screen%20Shot%202017-11-12%20at%2002.37.55.png" alt="Screen Shot 2017-11-12 at 02.37.55"></p><p>另外，由于jupyter-notebook自带终端，这也一举两得，也是一个内网穿透ssh的方案。<br>当然，必须使用一些运维工具来保证服务的稳定性，如supervisor，可参考<a href="http://frankchen.xyz/2017/07/06/Use-supervisor-support-Python3-program/">使用supervisor支持Python3程序 | 不正经数据科学家</a>。<br><img src="/images/Screen%20Shot%202017-11-12%20at%2002.39.36.png" alt="Screen Shot 2017-11-12 at 02.39.36"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15104246654723.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Pycharm Pro</title>
    <link href="http://frankchen.xyz/2017/11/08/pycharm-pro/"/>
    <id>http://frankchen.xyz/2017/11/08/pycharm-pro/</id>
    <published>2017-11-08T10:44:13.000Z</published>
    <updated>2017-11-09T08:31:53.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15101362178541.jpg" alt=""><br>Pycharm，只为提高python开发者的生产力！<br><a id="more"></a></p><h2 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h2><p><img src="/images/Screen%20Shot%202017-11-08%20at%2018.17.59.png" alt="Screen Shot 2017-11-08 at 18.17.59"><br>版本管理，主要是依靠这两个按钮，左边是pull，右边是commit。一般我们开发，打开项目，先pull下代码仓库的变更，开始开发，然后commit，再pull，合并冲突，再push。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.21.55.png" alt="Screen Shot 2017-11-08 at 18.21.55"><br>pycharm非常人性化地为我们标出了，黑色则是没有变更，蓝色是有变更，绿色是新add的文件。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.23.21.png" alt="Screen Shot 2017-11-08 at 18.23.21"><br>commit时，可以很方便地看出变更对比，对于需要回滚的零时操作文件可以用紫色的revert按钮回退变更，总之填写commit message之后就可以commit了。<br>然后，为防止在此期间，代码仓库又有人push了新变更，在push之前，我们需要再次pull，如果没有变更，push即可。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.26.24.png" alt="Screen Shot 2017-11-08 at 18.26.24"><br>如果有冲突呢，pycharm有非常human的解决冲突界面，<br><img src="/images/15101368989889.jpg" alt=""><br>总之，选择修改的、丢弃的、保留的，就可以push了，当然，这次push会有两条message，第二条是解决冲突的。</p><h2 id="远程调试"><a href="#远程调试" class="headerlink" title="远程调试"></a>远程调试</h2><p>利用pycharm我们可以在服务器直接run、debug，非常的便捷。<br>首先要设置deployment，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.31.20.png" alt="Screen Shot 2017-11-08 at 18.31.20"><br>选择SFTP，也就是ssh，这里用密码或者私钥都是ok的。设置好映射目录，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.31.56.png" alt="Screen Shot 2017-11-08 at 18.31.56"><br>接下来添加远程解释器，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.33.05.png" alt="Screen Shot 2017-11-08 at 18.33.05"><br>，并勾选auto upload，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.33.46.png" alt="Screen Shot 2017-11-08 at 18.33.46"><br>那么，每次本地的更改都会同步到服务器，直接run或者debug都是获取服务器的结果，非常方便。</p><p>## </p><h2 id="DEBUG"><a href="#DEBUG" class="headerlink" title="DEBUG"></a>DEBUG</h2><p>DEBUG可谓是开发中最最重要的技能了，也许我们在初级的开发的时候，还可以依靠各种print变量来查看，那么工程一旦变复杂，debug就必不可少了，；举个栗子，我们用TensorFlow写深度学习工程的时候，如果出现矩阵维度不匹配的情况，这个时候用debug去观察各个维度就相当高效了。<br>以下图为例，我们做debug，当然先要在我们希望观察的代码处打断点（Break Point），就是左边的红色小点，第一个断点debug停下来的地方。接下来就是debug按钮了，也就是红框内的这些箭头，依次是</p><ul><li>Step Over 直接从当前断点步进到下一个断点，也就是我们不希望看到中间的任何调用，直接跳过</li><li>Step Into，从当前断点，每一次调用都进入，如果调用比较多，可能很繁因为会一步步深入</li><li>Step Into Mycode，简单明了，一行一行的步进，不跳转到调用</li><li>Force Step Into，强制步进进入</li><li>Step Out 跳出当前调用，和Step Into结合，一个进入、一个跳出</li><li>Run to Cursor 不需打断点，直接步进到光标所在处，这个也很方便，只需把光标放在某处点击即可<br><img src="/images/Screen%20Shot%202017-11-09%20at%2015.49.12.png" alt="Screen Shot 2017-11-09 at 15.49.12"><br>此处类似堆栈，后面调用的进程在上面。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2016.19.42.png" alt="Screen Shot 2017-11-09 at 16.19.42"><br>当然，最主要的，上面这些步骤按钮的最终目的就是观察Variable的变化，通过步进观察各个变量的信息，以找出bug等等。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2016.21.15.png" alt="Screen Shot 2017-11-09 at 16.21.15"></li></ul><h2 id="Python-Console"><a href="#Python-Console" class="headerlink" title="Python Console"></a>Python Console</h2><p>相比iPython与Notebook，Pycharm自带的Python Console有其独到的优势，比如Special Variables与Code History ，如图，分别用一个两个三个下划线代表上一次上两次上三次的变量，在这里可以直接像debug一样查看各个变量的值；Code History则是使用户方便地使用之前的代码。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2015.23.52.png" alt="Screen Shot 2017-11-09 at 15.23.52"></p><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><h3 id="调整代码行次序"><a href="#调整代码行次序" class="headerlink" title="调整代码行次序"></a>调整代码行次序</h3><p>Command + Shift + ⬆️/⬇️<br>有时我们需要调整两行代码的上下次序，那么用剪切、粘贴的方法不如这个方法简洁自然。</p><h3 id="查看源码及跳转"><a href="#查看源码及跳转" class="headerlink" title="查看源码及跳转"></a>查看源码及跳转</h3><p>摁住Command键去点击即可跳转到源码处，而查看源码时我们可以通过Command + [/]来方便的前进或后退。</p><h3 id="批量展开收缩代码"><a href="#批量展开收缩代码" class="headerlink" title="批量展开收缩代码"></a>批量展开收缩代码</h3><p>Command + Shift +/-</p><p>当项目写到一定规模的时候，难免方法/函数会很多，这个时候我们可以使用此命令来收缩代码，这个主要是为了方便查看。</p><h3 id="快速插入常用代码"><a href="#快速插入常用代码" class="headerlink" title="快速插入常用代码"></a>快速插入常用代码</h3><p>Command + J 是弹出插入常用代码块的快捷键，比如Dict/List/Set 的comprehension都有，之前我只会‘main’然后跳出<code>if __name__ == &#39;__main__&#39;:</code>😜</p><p><img src="/images/2017/06/05.png" alt=""></p><h3 id="一键-PEP8"><a href="#一键-PEP8" class="headerlink" title="一键 PEP8"></a>一键 PEP8</h3><p>其实在了解这个tips之前我都是点击函数名，等待一个黄色的小灯泡再去点击灯泡。。。其实只需要<code>Command+Option+L</code>即可！</p><h3 id="cheat-sheet"><a href="#cheat-sheet" class="headerlink" title="cheat sheet"></a>cheat sheet</h3><p>顺便更新两张cheat sheet</p><p><img src="/images/2017/06/06.png" alt=""><br><img src="/images/2017/06/07.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15101362178541.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;Pycharm，只为提高python开发者的生产力！&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Pycharm" scheme="http://frankchen.xyz/tags/Pycharm/"/>
    
  </entry>
  
  <entry>
    <title>Go 语言操作与扫描 Hbase 实例</title>
    <link href="http://frankchen.xyz/2017/11/08/go-hbase/"/>
    <id>http://frankchen.xyz/2017/11/08/go-hbase/</id>
    <published>2017-11-08T03:10:21.000Z</published>
    <updated>2017-11-09T02:01:07.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15101107329028.jpg" alt=""><br><img src="/images/15101107462857.jpg" alt=""><br>记录纯go语言的gohbase客户端的扫描操作。<br><a id="more"></a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> main</div><div class="line"></div><div class="line"><span class="keyword">import</span> (</div><div class="line"><span class="string">"github.com/tsuna/gohbase"</span></div><div class="line"><span class="string">"github.com/tsuna/gohbase/hrpc"</span></div><div class="line"><span class="string">"context"</span></div><div class="line"><span class="string">"io"</span></div><div class="line"><span class="string">"fmt"</span></div><div class="line"><span class="string">"github.com/tsuna/gohbase/filter"</span></div><div class="line"><span class="string">"strconv"</span></div><div class="line"><span class="string">"time"</span></div><div class="line">)</div><div class="line"></div><div class="line"><span class="keyword">const</span> table = <span class="string">"user"</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">beforeMiniTimeStamps</span><span class="params">(beforeMini <span class="keyword">int</span>)</span> <span class="title">string</span></span> &#123;</div><div class="line"><span class="comment">//当前时刻某分钟之前的时间戳</span></div><div class="line"><span class="keyword">return</span> strconv.Itoa(<span class="keyword">int</span>(time.Now().Add(- time.Duration(beforeMini) * time.Minute).UnixNano() / <span class="number">1000000</span>))</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">fetch</span><span class="params">()</span> []*<span class="title">hrpc</span>.<span class="title">Result</span></span> &#123;</div><div class="line">client := gohbase.NewClient(<span class="string">"hmaster.shise.com,rm.shise.com,nn.shise.com"</span>)</div><div class="line"><span class="comment">//client := gohbase.NewClient("wwj.shise.com,czn.shise.com,czn.shise.com")</span></div><div class="line"><span class="comment">// 列族</span></div><div class="line">family := hrpc.Families(<span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">string</span>&#123;<span class="string">"c"</span>: <span class="literal">nil</span>&#125;)</div><div class="line"></div><div class="line"><span class="comment">// 全局hbase filter时间间隔</span></div><div class="line"><span class="comment">//timeRange := hrpc.TimeRange(time.Now().Add(- time.Duration(minute)*time.Minute), time.Now())</span></div><div class="line"></div><div class="line"><span class="comment">// 某列value的filter</span></div><div class="line">notRecommendFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">"c"</span>),</div><div class="line">[]<span class="keyword">byte</span>(<span class="string">"notRecommend"</span>),</div><div class="line">filter.NotEqual,</div><div class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(<span class="string">"true"</span>))),</div><div class="line"><span class="literal">true</span>,</div><div class="line"><span class="literal">true</span>)</div><div class="line">violationFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">"c"</span>),</div><div class="line">[]<span class="keyword">byte</span>(<span class="string">"violation"</span>),</div><div class="line">filter.NotEqual,</div><div class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(<span class="string">"true"</span>))),</div><div class="line"><span class="literal">true</span>,</div><div class="line"><span class="literal">true</span>)</div><div class="line"><span class="comment">//filter某列value的时间戳</span></div><div class="line">timeStartFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">"c"</span>),</div><div class="line">[]<span class="keyword">byte</span>(<span class="string">"createDate"</span>),</div><div class="line">filter.Greater,</div><div class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(beforeMiniTimeStamps(<span class="number">4</span>*<span class="number">60</span>)))),</div><div class="line"><span class="literal">true</span>,</div><div class="line"><span class="literal">true</span>)</div><div class="line">timeEndFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">"c"</span>),</div><div class="line">[]<span class="keyword">byte</span>(<span class="string">"createDate"</span>),</div><div class="line">filter.Less,</div><div class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(beforeMiniTimeStamps(<span class="number">2</span>*<span class="number">60</span>)))),</div><div class="line"><span class="literal">true</span>,</div><div class="line"><span class="literal">true</span>)</div><div class="line"></div><div class="line"><span class="comment">//filter 列表</span></div><div class="line">filters := filter.NewList(filter.MustPassAll, notRecommendFilter, violationFilter, timeStartFilter, timeEndFilter)</div><div class="line"><span class="comment">//创建scan对象</span></div><div class="line">scan, _ := hrpc.NewScanStr(context.Background(), table, family, hrpc.Filters(filters))</div><div class="line"></div><div class="line"><span class="keyword">var</span> rsp []*hrpc.Result</div><div class="line">scanner := client.Scan(scan)</div><div class="line"><span class="keyword">for</span> &#123;</div><div class="line">res, err := scanner.Next()</div><div class="line"><span class="keyword">if</span> err == io.EOF &#123;</div><div class="line"><span class="keyword">break</span></div><div class="line">&#125;</div><div class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</div><div class="line"><span class="built_in">print</span>(err)</div><div class="line">&#125;</div><div class="line"><span class="keyword">if</span> hasHeadImage(res) &#123;</div><div class="line">rsp = <span class="built_in">append</span>(rsp, res)</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"><span class="keyword">return</span> rsp</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">hasHeadImage</span><span class="params">(res *hrpc.Result)</span> <span class="title">bool</span></span> &#123;</div><div class="line"><span class="keyword">return</span> <span class="literal">true</span></div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">rsp := fetch()</div><div class="line"><span class="keyword">for</span> _, item := <span class="keyword">range</span> rsp &#123;</div><div class="line">fmt.Println(*item)</div><div class="line"><span class="keyword">break</span></div><div class="line">&#125;</div><div class="line">fmt.Println(<span class="built_in">len</span>(rsp))</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15101107329028.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15101107462857.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;记录纯go语言的gohbase客户端的扫描操作。&lt;br&gt;
    
    </summary>
    
    
      <category term="Go" scheme="http://frankchen.xyz/tags/Go/"/>
    
      <category term="Hbase" scheme="http://frankchen.xyz/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04 安装IKEV2 VPN 并在Mac上使用以解决Google Drive 同步问题</title>
    <link href="http://frankchen.xyz/2017/11/01/Google-Drive-Sync/"/>
    <id>http://frankchen.xyz/2017/11/01/Google-Drive-Sync/</id>
    <published>2017-11-01T01:56:43.000Z</published>
    <updated>2017-11-01T02:21:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15095018008987.jpg" alt=""><br><img src="/images/15095018930547.jpg" alt=""></p><a id="more"></a><p>Google Drive无法识别shadowsocks所用的socks5代理，故这边有需求在VPS上部署http代理的VPN。</p><h2 id="服务端安装说明"><a href="#服务端安装说明" class="headerlink" title="服务端安装说明"></a>服务端安装说明</h2><ul><li><p>下载脚本:</p><p>   <code>wget --no-check-certificate https://raw.githubusercontent.com/quericy/one-key-ikev2-vpn/master/one-key-ikev2.sh</code></p></li><li><p>运行脚本：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod +x one-key-ikev2.sh</div><div class="line">bash one-key-ikev2.sh</div></pre></td></tr></table></figure></li><li><p>等待自动配置部分内容后，选择vps类型（OpenVZ还是Xen、KVM），选错将无法成功连接，请务必核实服务器的类型。输入服务器ip或者绑定的域名(连接vpn时服务器地址将需要与此保持一致,如果是导入泛域名证书这里需要写*.域名的形式),这里推荐直接输入域名。</p></li><li>选择使用使用证书颁发机构签发的SSL证书还是生成自签名证书，这里我们选择自签名即选择no：‘’<ul><li>如果选择no,使用自签名证书（客户端如果使用IkeV2方式连接，将需要导入生成的证书并信任）则需要填写证书的相关信息(C,O,CN)，为空将使用默认值(default value)，确认无误后按任意键继续,后续安装过程中会出现输入两次pkcs12证书的密码的提示(可以设置为空)    </li></ul></li><li>接下来一直空格即可。<br>*看到install Complete字样即表示安装完成。默认用户名密码将以黄字显示，可根据提示自行修改配置文件中的用户名密码,多用户则在配置文件中按格式一行一个(多用户时用户名不能使用%any),保存并重启服务生效。</li><li>将提示信息中的证书文件ca.cert.pem拷贝到客户端，修改后缀名为.cer后导入。ios设备使用Ikev1无需导入证书，而是需要在连接时输入共享密钥，共享密钥即是提示信息中的黄字PSK.<ul><li><img src="/images/15095022245212.jpg" alt=""><h2 id="客户端配置说明"><a href="#客户端配置说明" class="headerlink" title="客户端配置说明"></a>客户端配置说明</h2></li></ul></li><li>iOS/OSX/Windows7+/WindowsPhone8.1+/Linux 均可使用IkeV2,认证方式为用户名+密码。使用SSL证书则无需导入证书；使用自签名证书则需要先导入证书才能连接,可将ca.cert.pem更改后缀名作为邮件附件发送给客户端,手机端也可通过浏览器导入,其中:<ul><li>iOS/OSX 的远程ID和服务器地址保持一致,用户鉴定选择”用户名”.如果通过浏览器导入,将证书放在可访问的远程外链上,并在系统浏览器(Safari)中访问外链地址;</li></ul></li><li>注意OSX导入后需要在钥匙串内设置信任，如：<ul><li><img src="/images/15095023464796.png" alt=""></li></ul></li><li>设置连接成功后Google Drive就会连接成功开始同步<br>😎😎😎😎😎😎<ul><li><img src="/images/Screen%20Shot%202017-11-01%20at%2010.13.03.png" alt="Screen Shot 2017-11-01 at 10.13.03"></li></ul></li></ul><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://quericy.me/blog/699/" target="_blank" rel="external">CentOS/Ubuntu一键安装IPSEC/IKEV2 VPN服务器 | Quericy Eden*</a></li><li><a href="https://github.com/quericy/one-key-ikev2-vpn/issues/58" target="_blank" rel="external">安装完成后，mac不能连接 · Issue #58 · quericy/one-key-ikev2-vpn</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15095018008987.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15095018930547.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="VPN" scheme="http://frankchen.xyz/tags/VPN/"/>
    
  </entry>
  
  <entry>
    <title>Install Opencv3.2 on Ununtu 16.04</title>
    <link href="http://frankchen.xyz/2017/10/25/Install-Opencv3-2-on-Ununtu-16-04/"/>
    <id>http://frankchen.xyz/2017/10/25/Install-Opencv3-2-on-Ununtu-16-04/</id>
    <published>2017-10-25T04:34:28.000Z</published>
    <updated>2017-11-09T02:00:24.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15101928106001.jpg" alt=""></p><p>Opencv3.2 在 Ununtu 16.04 上的编译安装<br><a id="more"></a></p><p>参考自<a href="http://blog.topspeedsnail.com/archives/4755" target="_blank" rel="external">Ubuntu 16.04编译安装OpenCV（Python） – WTF Daily Blog</a>，不过这位博主装的是3.1版本，而且有些问题。</p><h2 id="安装OpenCV依赖"><a href="#安装OpenCV依赖" class="headerlink" title="安装OpenCV依赖"></a>安装OpenCV依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get upgrade</div><div class="line">sudo apt-get install build-essential cmake pkg-config</div><div class="line"> sudo apt-get install libjpeg8-dev libtiff5-dev libjasper-dev libpng12-dev</div><div class="line"> sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</div><div class="line"> sudo apt-get install libxvidcore-dev libx264-dev</div><div class="line">sudo apt-get install libgtk-3-dev</div><div class="line">sudo apt-get install libatlas-base-dev gfortran</div><div class="line">sudo apt-get install python2.7-dev python3.5-dev</div></pre></td></tr></table></figure><h2 id="下载OpenCV源码"><a href="#下载OpenCV源码" class="headerlink" title="下载OpenCV源码"></a>下载OpenCV源码</h2><p>这里下载 3.2.0</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> ~</div><div class="line">$ wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.2.0.zip</div><div class="line">$ unzip opencv.zip</div></pre></td></tr></table></figure><p>下载和OpenCV版本对应的opencv_contrib（一些扩展功能和non-free代码）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ wget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.2.0.zip</div><div class="line">$ unzip opencv_contrib.zip</div></pre></td></tr></table></figure></p><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> ~/opencv-3.2.0/</div><div class="line">$ mkdir build</div><div class="line">$ <span class="built_in">cd</span> build</div></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE \</div><div class="line">    -D CMAKE_INSTALL_PREFIX=/usr/<span class="built_in">local</span> \</div><div class="line">    -D INSTALL_PYTHON_EXAMPLES=ON \</div><div class="line">    -D INSTALL_C_EXAMPLES=OFF \</div><div class="line">    -D OPENCV_EXTRA_MODULES_PATH=/root/Downloads/opencv_contrib-3.2.0/modules  -D PYTHON_EXECUTABLE=/root/miniconda3/bin/python  ..</div></pre></td></tr></table></figure><p>其中<code>OPENCV_EXTRA_MODULES_PATH</code>是opencv_contrib的解压后的地址，<code>PYTHON_EXECUTABLE</code>是# 你的python 解释器地址 可用<code>witch python</code> 查看。<br>若出现，需要下载<code>ippicv_linux_20151201.tgz</code>的长时间等待，可在此<a href="https://github.com/opencv/opencv_3rdparty/tree/ippicv/master_20151201/ippicv" target="_blank" rel="external">opencv_3rdparty/ippicv at ippicv/master_20151201 · opencv/opencv_3rdparty</a>手动下载对应文件，并放在对应位置如Put the ippicv_linux…tgz under<br>&lt;…&gt;/opencv-3.2.0/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e/， 参考自<a href="https://github.com/opencv/opencv/issues/5973" target="_blank" rel="external">incorrect hash in cmake ippicv when installing · Issue #5973 · opencv/opencv</a>。</p><p>编译：</p><p><code>$ make</code></p><p>安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo make install</div><div class="line">$ sudo ldconfig</div></pre></td></tr></table></figure><p>再<code>pip install opencv</code>即可😎</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15101928106001.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Opencv3.2 在 Ununtu 16.04 上的编译安装&lt;br&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
  </entry>
  
</feed>
