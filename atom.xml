<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>不正经数据科学家</title>
  
  <subtitle>Enjoy everything fun and challenging</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://frankchen.xyz/"/>
  <updated>2018-05-31T11:39:43.506Z</updated>
  <id>http://frankchen.xyz/</id>
  
  <author>
    <name>江南消夏</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mac 双开 ss 方法</title>
    <link href="http://frankchen.xyz/2018/05/31/dual-ss-on-mac/"/>
    <id>http://frankchen.xyz/2018/05/31/dual-ss-on-mac/</id>
    <published>2018-05-31T11:24:17.000Z</published>
    <updated>2018-05-31T11:39:43.506Z</updated>
    
    <content type="html"><![CDATA[<p>有时候我们需要两个代理，譬如一个用来连需要经过跳板机代理的集群服务，一个则用来科学上网，不停切换麻烦且代价比较高，那我们除了ShadowsocksX-NG客户端之外，我们可以用命令行的方式再开启一个，<br><img src="/images/15277663104280.jpg" alt=""></p><p><img src="/images/15277666370736.jpg" alt=""></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 使用Homebrew安装</span></div><div class="line">brew install shadowsocks-libev</div><div class="line"><span class="comment"># 编辑配置信息</span></div><div class="line">sudo vim /usr/<span class="built_in">local</span>/etc/shadowsocks-libev.json</div><div class="line"><span class="comment"># 格式如下，注意与ShadowsocksX-NG的local_port也就是socks5不同</span></div><div class="line">&#123;</div><div class="line">    <span class="string">"server"</span>:<span class="string">"107.167.185.234"</span>,</div><div class="line">    <span class="string">"server_port"</span>:11499,</div><div class="line">    <span class="string">"local_port"</span>:1079,</div><div class="line">    <span class="string">"password"</span>:<span class="string">"xxxxxxxx"</span>,</div><div class="line">    <span class="string">"timeout"</span>:600,</div><div class="line">    <span class="string">"method"</span>:<span class="string">"aes-256-gcm"</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># 重启 shadowsocks-libev，会自动添加开机自启</span></div><div class="line">brew services restart shadowsocks-libev</div></pre></td></tr></table></figure><p>再在SwitchyOmega里面设置两个不同的代理即可，<br><img src="/images/15277663992132.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;有时候我们需要两个代理，譬如一个用来连需要经过跳板机代理的集群服务，一个则用来科学上网，不停切换麻烦且代价比较高，那我们除了ShadowsocksX-NG客户端之外，我们可以用命令行的方式再开启一个，&lt;br&gt;&lt;img src=&quot;/images/15277663104280.
      
    
    </summary>
    
    
      <category term="Mac" scheme="http://frankchen.xyz/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>从 spark 获取 表格内容的方法 🦄</title>
    <link href="http://frankchen.xyz/2018/05/03/get-table-from-spark/"/>
    <id>http://frankchen.xyz/2018/05/03/get-table-from-spark/</id>
    <published>2018-05-03T12:51:14.000Z</published>
    <updated>2018-05-03T13:14:06.639Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"> <span class="number">1</span> <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> *</div><div class="line"> <span class="number">2</span> <span class="keyword">import</span> pyspark</div><div class="line"> <span class="number">3</span> <span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line"> <span class="number">4</span>     spark = SparkSession.builder.master(<span class="string">"yarn"</span>).appName(<span class="string">"pyspark location process"</span>).enableHiveSupport().getOrCreate()</div><div class="line"> <span class="number">5</span>     sc = spark.sparkContext</div><div class="line"> <span class="number">6</span>    <span class="comment"># spark.sql('show databases').show()</span></div><div class="line"> <span class="number">7</span>     spark.sql(<span class="string">'use annals'</span>).show()</div><div class="line"> <span class="number">8</span>    <span class="comment"># spark.sql('describe gps2').show()</span></div><div class="line"> <span class="number">9</span>     spark.sql(<span class="string">'select * from gps2 limit 1'</span>).show()</div><div class="line"><span class="number">10</span>     sql_df = spark.sql(<span class="string">'select uid, lat, lgt, app_adjust_time from gps2 limit 5'</span>)</div><div class="line"><span class="number">11</span>     <span class="comment">#sql_df.show()</span></div><div class="line"><span class="number">12</span>     print(type(sql_df))</div><div class="line"><span class="number">13</span>     sql_df.write.save(<span class="string">"data/GrMWKfDj9eIjsRuh.parquet"</span>)</div></pre></td></tr></table></figure><p>这样我们就在hdfs上得到了一份parquet格式的文件。</p><p>从hdfs 复制到跳板机<br><code>hadoop fs  -get GrMWKfDj9eIjsRuh.parquet .</code><br>再scp 之类的 复制到本地即可。🐶🐒</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/d
      
    
    </summary>
    
    
      <category term="spark" scheme="http://frankchen.xyz/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Mac 通过 socks5 代理 连接 ssh 的方法🏆</title>
    <link href="http://frankchen.xyz/2018/05/03/mac-ssh-through-socks5-proxy/"/>
    <id>http://frankchen.xyz/2018/05/03/mac-ssh-through-socks5-proxy/</id>
    <published>2018-05-03T09:08:10.000Z</published>
    <updated>2018-05-03T09:15:18.355Z</updated>
    
    <content type="html"><![CDATA[<p>经过一番痛苦的折腾，我才发现<strong>socks,http代理等使用的是TCP或UDP协议, 而ping命令则是ICMP协议, 所以proxychains4对ping命令无效.</strong>，最终又折腾过tsocks等和proxychains一样德行的以后，最终在万能的Stack Overflow找到<a href="https://serverfault.com/questions/315605/ssh-through-a-socks-proxy-client-openssh-os-x" target="_blank" rel="external">答案</a>：即通过NetCat (nc)连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">vim ~/.ssh/config</div><div class="line"><span class="comment"># 添加以下内容</span></div><div class="line">Host 52.* <span class="comment"># 这里可以通配也可以指定IP</span></div><div class="line">    ProxyCommand nc -X 5 -x 127.0.0.1:1079 %h %p</div><div class="line">    <span class="comment"># "5" 是 SOCKS 5, "1079" 是本地socks端口</span></div></pre></td></tr></table></figure><p>之后直接使用<code>ssh</code>命令连接即可😎😂</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;经过一番痛苦的折腾，我才发现&lt;strong&gt;socks,http代理等使用的是TCP或UDP协议, 而ping命令则是ICMP协议, 所以proxychains4对ping命令无效.&lt;/strong&gt;，最终又折腾过tsocks等和proxychains一样德行的以后，最终在
      
    
    </summary>
    
    
      <category term="Mac" scheme="http://frankchen.xyz/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>moving averge 滑动平均</title>
    <link href="http://frankchen.xyz/2018/04/25/moving-averge/"/>
    <id>http://frankchen.xyz/2018/04/25/moving-averge/</id>
    <published>2018-04-25T14:58:46.000Z</published>
    <updated>2018-04-26T03:49:59.376Z</updated>
    
    <content type="html"><![CDATA[<p>moving averge 即滑动平均，时间序列处理中常见的方法，简单来说，就是对于一个给定数列，设定一个窗口值N，依次取第1项~第N项，第2项~第N+1项，第3项~第N+2项的平均值，以此类推。</p><a id="more"></a><p>数据来自<a href="http://blog.topspeedsnail.com/wp-content/uploads/2016/12/%E9%93%81%E8%B7%AF%E5%AE%A2%E8%BF%90%E9%87%8F.csv" target="_blank" rel="external">铁路客运量.csv（2005-2016月度数据）</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pylab</div><div class="line">pylab.style.use(<span class="string">'bmh'</span>)</div><div class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</div><div class="line">rcParams[<span class="string">'figure.figsize'</span>] = <span class="number">10</span>, <span class="number">8</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">moving_average</span><span class="params">(l, N)</span>:</span></div><div class="line">sum = <span class="number">0</span></div><div class="line">result = list( <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> l)</div><div class="line"> </div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range( <span class="number">0</span>, N ):</div><div class="line">       <span class="comment"># 从左到右逐渐添加index在N之内的数字</span></div><div class="line">sum = sum + l[i]</div><div class="line">result[i] = sum / (i+<span class="number">1</span>)</div><div class="line"> </div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range( N, len(l) ):</div><div class="line">       <span class="comment"># 加入最右边数字减去最左边数字</span></div><div class="line">sum = sum - l[i-N] + l[i]</div><div class="line">result[i] = sum / N</div><div class="line"> </div><div class="line"><span class="keyword">return</span> result</div><div class="line"> </div><div class="line"><span class="comment"># 使用效率更高的numpy</span></div><div class="line"><span class="comment"># http://stackoverflow.com/questions/13728392/moving-average-or-running-mean</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_moving_average</span><span class="params">(x, N)</span>:</span></div><div class="line"><span class="keyword">return</span> np.convolve(x, np.ones((N,))/N)[(N<span class="number">-1</span>):]</div><div class="line"> </div><div class="line">url = <span class="string">'铁路客运量.csv'</span></div><div class="line"></div><div class="line"> </div><div class="line">df = pd.read_csv(url)  <span class="comment"># python2使用StringIO.StringIO</span></div><div class="line"> </div><div class="line">data = np.array(df[<span class="string">'铁路客运量_当期值(万人)'</span>])</div><div class="line"> </div><div class="line">dic = &#123;&#125;</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">3</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>]:</div><div class="line">    ma_data = moving_average(data, i)</div><div class="line">    dic[i] = ma_data</div><div class="line">ma_data_df = pd.DataFrame(dic)</div><div class="line"></div><div class="line">ma_data_df.plot()</div></pre></td></tr></table></figure></p><p>可以看到，趋势逐渐变得平滑，即对局部震荡不敏感。</p><p><img src="/images/download.png" alt="download"></p><p>使用numpy.convolve是一种更方便的方法，值得注意的是其有三种mode，分别是’full’（单个重叠也计算）, ‘same’（强制等长）, ‘valid’（完全重叠），</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_moving_average</span><span class="params">(x, N, mode)</span>:</span></div><div class="line"><span class="comment"># return np.convolve(x, np.ones((N,))/N, mode='valid')[(N-1):]</span></div><div class="line"><span class="keyword">return</span> np.convolve(x, np.ones((N,))/N, mode=mode)</div><div class="line">dic = &#123;&#125;</div><div class="line">modes = [<span class="string">'full'</span>, <span class="string">'same'</span>, <span class="string">'valid'</span>]</div><div class="line">i = <span class="number">10</span></div><div class="line"><span class="keyword">for</span> mode <span class="keyword">in</span> modes:</div><div class="line">    ma_data = fast_moving_average(data, i, mode)</div><div class="line">    pylab.plot(ma_data)</div><div class="line">pylab.legend(modes)</div></pre></td></tr></table></figure><p><img src="/images/download%20-1-.png" alt="download -1-"></p><p>参考自斗大熊的博客<a href="http://blog.topspeedsnail.com/archives/11022" target="_blank" rel="external">MovingAverage-滑动平均 – WTF Daily Blog</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;moving averge 即滑动平均，时间序列处理中常见的方法，简单来说，就是对于一个给定数列，设定一个窗口值N，依次取第1项~第N项，第2项~第N+1项，第3项~第N+2项的平均值，以此类推。&lt;/p&gt;
    
    </summary>
    
    
      <category term="time series" scheme="http://frankchen.xyz/tags/time-series/"/>
    
  </entry>
  
  <entry>
    <title>keras 中模型的保存及重用</title>
    <link href="http://frankchen.xyz/2018/04/19/keras-reuse-model/"/>
    <id>http://frankchen.xyz/2018/04/19/keras-reuse-model/</id>
    <published>2018-04-19T08:50:00.000Z</published>
    <updated>2018-04-25T11:57:18.773Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15135840798621.jpg" alt=""><br>深度学习中如何保存最佳模型，如何重用已经保存的模型？本文主要介绍Keras 保存及重用模型的方法<br><a id="more"></a></p><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>如下，我们预定义保存的<code>hdf5</code>文件名，再初始化<code>ModelCheckpoint</code>，将其加入Keras的callback里（即每个batch结束后做的事情），那么模型就会在每次batch结束后对比，保存最好的模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div><div class="line"></div><div class="line"><span class="comment"># create model</span></div><div class="line">model = Sequential()</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line"><span class="comment"># Compile model</span></div><div class="line">model.compile(...)</div><div class="line"><span class="comment"># checkpoint</span></div><div class="line">filepath=<span class="string">"weights-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5"</span></div><div class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">'val_acc'</span>, verbose=<span class="number">1</span>, save_best_only=<span class="keyword">True</span>, mode=<span class="string">'max'</span>)</div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=[checkpoint], verbose=<span class="number">0</span>)</div></pre></td></tr></table></figure><p>结束后，我们会得到如下的结果，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">weights-53-0.76.hdf5</div><div class="line">weights-71-0.76.hdf5</div><div class="line">weights-77-0.78.hdf5</div><div class="line">weights-99-0.78.hdf5</div></pre></td></tr></table></figure><p>如果我们只想保存一个最好的模型，那么把保存文件名字固定为<code>filepath=&quot;weights.best.hdf5&quot;</code>即可。</p><h2 id="load模型"><a href="#load模型" class="headerlink" title="load模型"></a>load模型</h2><p>注意，之前保存的只是模型的weights，重新load需要再次定义模型结构再load weights并再次combine，例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = Sequential()</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line"><span class="comment"># load weights</span></div><div class="line">model.load_weights(<span class="string">"weights.best.hdf5"</span>)</div><div class="line"><span class="comment"># Compile model </span></div><div class="line">model.compile(...)</div><div class="line"><span class="comment"># estimate accuracy </span></div><div class="line">scores = model.evaluate(X, Y, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'&#123;&#125;: &#123;:.2%&#125;'</span>.format(model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]))</div></pre></td></tr></table></figure><p>如果之前选择了连模型结构也一起保存（即在<code>ModelCheckpoint</code>中选择<code>save_weights_only=False</code>），那么load就很简单，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div><div class="line"></div><div class="line"><span class="comment"># create model</span></div><div class="line">model = Sequential()</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line">model.add(...)</div><div class="line"><span class="comment"># Compile model</span></div><div class="line">model.compile(...)</div><div class="line"><span class="comment"># checkpoint</span></div><div class="line">filepath=<span class="string">"weights-best.hdf5"</span></div><div class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">'val_acc'</span>, verbose=<span class="number">1</span>, save_best_only=<span class="keyword">True</span>, mode=<span class="string">'max'</span>, save_weights_only=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=[checkpoint], verbose=<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="comment"># Load the model</span></div><div class="line">model= load_model(filepath)</div><div class="line">scores=model.evaluate(X, Y,verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'&#123;&#125;: &#123;:.2%&#125;'</span>.format(model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]))</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15135840798621.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;深度学习中如何保存最佳模型，如何重用已经保存的模型？本文主要介绍Keras 保存及重用模型的方法&lt;br&gt;
    
    </summary>
    
    
      <category term="Keras" scheme="http://frankchen.xyz/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>理解一维卷积</title>
    <link href="http://frankchen.xyz/2018/04/17/conv1d-in-keras/"/>
    <id>http://frankchen.xyz/2018/04/17/conv1d-in-keras/</id>
    <published>2018-04-17T07:46:36.000Z</published>
    <updated>2018-04-19T08:50:30.253Z</updated>
    
    <content type="html"><![CDATA[<p>理解一维卷积<br><a id="more"></a><br>下面是一个利用CNN进行NLP中的情感分类的例子，<br><img src="/images/15240224514694.png" alt=""></p><p>上图中，输入为表示为词表为d=5，长度为7的矩阵的句子，1D卷积核为长度分别为(2,3,4)的各两个，经过卷积并激活函数后，各自产生了(4x1, 5x1, 6x1)的各两个feature map，每个feature map经过一次1D max pooling后（即取每个feature map的最大值）再concatenate为一个6x1的1D向量，经过一个全连接层再softmax激活即可进行情感分类预测。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;理解一维卷积&lt;br&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://frankchen.xyz/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>处理大数据集的建议</title>
    <link href="http://frankchen.xyz/2018/04/10/handle-big-datasets/"/>
    <id>http://frankchen.xyz/2018/04/10/handle-big-datasets/</id>
    <published>2018-04-10T07:07:34.000Z</published>
    <updated>2018-04-10T08:15:51.972Z</updated>
    
    <content type="html"><![CDATA[<p>最近的一些比赛如<a href="https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection" target="_blank" rel="external">TalkingData AdTracking Fraud Detection Challenge | Kaggle</a>提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。<br><a id="more"></a></p><h2 id="1-及时删除无用变量并垃圾回收"><a href="#1-及时删除无用变量并垃圾回收" class="headerlink" title="1.及时删除无用变量并垃圾回收"></a>1.及时删除无用变量并垃圾回收</h2><p>通常我们在特征工程中会涉及大量的转换操作，产生很多的中间变量等，除了使用<code>del</code>以外，使用<code>gc.collect()</code>也是个不错的选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">temp = pd.read_csv(<span class="string">'../input/train_sample.csv'</span>)</div><div class="line"></div><div class="line"><span class="comment">#do something to the file</span></div><div class="line">temp[<span class="string">'os'</span>] = temp[<span class="string">'os'</span>].astype(<span class="string">'str'</span>)</div><div class="line"><span class="comment">#delete when no longer needed</span></div><div class="line"><span class="keyword">del</span> temp</div><div class="line"><span class="comment">#collect residual garbage</span></div><div class="line">gc.collect()</div></pre></td></tr></table></figure><h2 id="2-预定义数据类型"><a href="#2-预定义数据类型" class="headerlink" title="2.预定义数据类型"></a>2.预定义数据类型</h2><p>pandas一般会自己推断数据类型，不过倾向于使用耗费空间大的，如下面例子所示，预定义数据类型节省了超过一半的空间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line">dtypes = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'uint32'</span>,</div><div class="line">        <span class="string">'app'</span>           : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'device'</span>        : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'os'</span>            : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'channel'</span>       : <span class="string">'uint16'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'uint8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">dtypes2 = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'int32'</span>,</div><div class="line">        <span class="string">'app'</span>           : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'device'</span>        : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'os'</span>            : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'channel'</span>       : <span class="string">'int16'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'int8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,dtype=dtypes,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line"></div><div class="line">train = pd.read_csv(train_sample_file,dtype=dtypes2,parse_dates=[<span class="string">'click_time'</span>])</div><div class="line"></div><div class="line"><span class="comment">#check datatypes:</span></div><div class="line">train.info()</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null int64</div><div class="line">app                100000 non-null int64</div><div class="line">device             100000 non-null int64</div><div class="line">os                 100000 non-null int64</div><div class="line">channel            100000 non-null int64</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null int64</div><div class="line">dtypes: datetime64[ns](1), int64(6), object(1)</div><div class="line">memory usage: 6.1+ MB</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null uint32</div><div class="line">app                100000 non-null uint16</div><div class="line">device             100000 non-null uint16</div><div class="line">os                 100000 non-null uint16</div><div class="line">channel            100000 non-null uint16</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null uint8</div><div class="line">dtypes: datetime64[ns](1), object(1), uint16(4), uint32(1), uint8(1)</div><div class="line">memory usage: 2.8+ MB</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 100000 entries, 0 to 99999</div><div class="line">Data columns (total 8 columns):</div><div class="line">ip                 100000 non-null int32</div><div class="line">app                100000 non-null int16</div><div class="line">device             100000 non-null int16</div><div class="line">os                 100000 non-null int16</div><div class="line">channel            100000 non-null int16</div><div class="line">click_time         100000 non-null datetime64[ns]</div><div class="line">attributed_time    227 non-null object</div><div class="line">is_attributed      100000 non-null int8</div><div class="line">dtypes: datetime64[ns](1), int16(4), int32(1), int8(1), object(1)</div><div class="line">memory usage: 2.8+ MB</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="3-只使用csv文件内的指定行"><a href="#3-只使用csv文件内的指定行" class="headerlink" title="3.只使用csv文件内的指定行"></a>3.只使用csv文件内的指定行</h2><h3 id="a-指定行数"><a href="#a-指定行数" class="headerlink" title="a) 指定行数"></a>a) 指定行数</h3><p>直接使用nrows指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, nrows=<span class="number">1e5</span>, dtype=dtypes)</div></pre></td></tr></table></figure><h3 id="b-跳过行数"><a href="#b-跳过行数" class="headerlink" title="b) 跳过行数"></a>b) 跳过行数</h3><p>比如我们跳过前500w取100w下面保留了head，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, skiprows=range(<span class="number">1</span>, <span class="number">5000000</span>), nrows=<span class="number">1000000</span>, dtype=dtypes)</div></pre></td></tr></table></figure><h3 id="c-sampling"><a href="#c-sampling" class="headerlink" title="c) sampling"></a>c) sampling</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> subprocess</div><div class="line">print(<span class="string">'# Line count:'</span>)</div><div class="line"><span class="keyword">for</span> file <span class="keyword">in</span> [<span class="string">'train.csv'</span>, <span class="string">'test.csv'</span>, <span class="string">'train_sample.csv'</span>]:</div><div class="line">    lines = subprocess.run([<span class="string">'wc'</span>, <span class="string">'-l'</span>, <span class="string">'../input/&#123;&#125;'</span>.format(file)], stdout=subprocess.PIPE).stdout.decode(<span class="string">'utf-8'</span>)</div><div class="line">    print(lines, end=<span class="string">''</span>, flush=<span class="keyword">True</span>)</div><div class="line"><span class="string">'''</span></div><div class="line"># Line count:</div><div class="line">184903891 ../input/train.csv</div><div class="line">18790470 ../input/test.csv</div><div class="line">100001 ../input/train_sample.csv</div><div class="line">'''</div></pre></td></tr></table></figure><p>train一共有<code>lines=184903891</code> 行，那么假设我们需要采样出100w行，那么我们需要跳过<code>lines - 1 - 1000000</code>行，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#generate list of lines to skip</span></div><div class="line">skiplines = np.random.choice(np.arange(<span class="number">1</span>, lines), size=lines<span class="number">-1</span><span class="number">-1000000</span>, replace=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="comment">#sort the list</span></div><div class="line">skiplines=np.sort(skiplines)</div><div class="line"><span class="comment">#check our list</span></div><div class="line">print(<span class="string">'lines to skip:'</span>, len(skiplines))</div><div class="line">print(<span class="string">'remaining lines in sample:'</span>, lines-len(skiplines), <span class="string">'(remember that it includes the heading!)'</span>)</div><div class="line"></div><div class="line"><span class="comment">###################SANITY CHECK###################</span></div><div class="line"><span class="comment">#find lines that weren't skipped by checking difference between each consecutive line</span></div><div class="line"><span class="comment">#how many out of first 100000 will be imported into the csv?</span></div><div class="line">diff = skiplines[<span class="number">1</span>:<span class="number">100000</span>]-skiplines[<span class="number">2</span>:<span class="number">100001</span>]</div><div class="line">remain = sum(diff!=<span class="number">-1</span>)</div><div class="line">print(<span class="string">'Ratio of lines from first 100000 lines:'</span>,  <span class="string">'&#123;0:.5f&#125;'</span>.format(remain/<span class="number">100000</span>) ) </div><div class="line">print(<span class="string">'Ratio imported from all lines:'</span>, <span class="string">'&#123;0:.5f&#125;'</span>.format((lines-len(skiplines))/lines) )</div><div class="line">train = pd.read_csv(<span class="string">'../input/train.csv'</span>, skiprows=skiplines, dtype=dtypes)</div><div class="line">train.head()</div><div class="line"><span class="keyword">del</span> skiplines</div><div class="line">gc.collect()</div></pre></td></tr></table></figure><h2 id="4-使用pandas-的生成器，用chunk处理"><a href="#4-使用pandas-的生成器，用chunk处理" class="headerlink" title="4.使用pandas 的生成器，用chunk处理"></a>4.使用pandas 的生成器，用chunk处理</h2><p>这里我们使用np.where过滤掉‘is_attributed’为0的部分（例如<code>[xv if c else yv for (c,xv,yv) in zip(condition,x,y)]</code>）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#set up an empty dataframe</span></div><div class="line">df_converted = pd.DataFrame()</div><div class="line"></div><div class="line"><span class="comment">#we are going to work with chunks of size 1 million rows</span></div><div class="line">chunksize = <span class="number">10</span> ** <span class="number">6</span></div><div class="line"></div><div class="line"><span class="comment">#in each chunk, filter for values that have 'is_attributed'==1, and merge these values into one dataframe</span></div><div class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> pd.read_csv(<span class="string">'../input/train.csv'</span>, chunksize=chunksize, dtype=dtypes):</div><div class="line">    filtered = (chunk[(np.where(chunk[<span class="string">'is_attributed'</span>]==<span class="number">1</span>, <span class="keyword">True</span>, <span class="keyword">False</span>))])</div><div class="line">    df_converted = pd.concat([df_converted, filtered], ignore_index=<span class="keyword">True</span>, )</div></pre></td></tr></table></figure></p><h2 id="5-只载入若干列"><a href="#5-只载入若干列" class="headerlink" title="5.只载入若干列"></a>5.只载入若干列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#wanted columns</span></div><div class="line">columns = [<span class="string">'ip'</span>, <span class="string">'click_time'</span>, <span class="string">'is_attributed'</span>]</div><div class="line">dtypes = &#123;</div><div class="line">        <span class="string">'ip'</span>            : <span class="string">'uint32'</span>,</div><div class="line">        <span class="string">'is_attributed'</span> : <span class="string">'uint8'</span>,</div><div class="line">        &#125;</div><div class="line"></div><div class="line">ips_df = pd.read_csv(<span class="string">'../input/train.csv'</span>, usecols=columns, dtype=dtypes)</div><div class="line">print(ips_df.info())</div><div class="line">ips_df.head()</div><div class="line"><span class="string">'''</span></div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 184903890 entries, 0 to 184903889</div><div class="line">Data columns (total 3 columns):</div><div class="line">ip               uint32</div><div class="line">click_time       object</div><div class="line">is_attributed    uint8</div><div class="line">dtypes: object(1), uint32(1), uint8(1)</div><div class="line">memory usage: 2.2+ GB</div><div class="line">None'''</div></pre></td></tr></table></figure><h2 id="6-结合多种方法创意性的处理数据"><a href="#6-结合多种方法创意性的处理数据" class="headerlink" title="6.结合多种方法创意性的处理数据"></a>6.结合多种方法创意性的处理数据</h2><p>例如无法使用整个数据来groupby那么可以分块来做，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">size=<span class="number">100000</span></div><div class="line">all_rows = len(ips_df)</div><div class="line">num_parts = all_rows//size</div><div class="line"></div><div class="line"><span class="comment">#generate the first batch</span></div><div class="line">ip_sums = ips_df[<span class="number">0</span>:size][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line"></div><div class="line"><span class="comment">#add remaining batches</span></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> range(<span class="number">1</span>,num_parts):</div><div class="line">    start = p*size</div><div class="line">    end = p*size + size</div><div class="line">    <span class="keyword">if</span> end &lt; all_rows:</div><div class="line">        group = ips_df[start:end][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        group = ips_df[start:][[<span class="string">'ip'</span>, <span class="string">'is_attributed'</span>]].groupby(<span class="string">'ip'</span>, as_index=<span class="keyword">False</span>).sum()</div><div class="line">    ip_sums = ip_sums.merge(group, on=<span class="string">'ip'</span>, how=<span class="string">'outer'</span>)</div><div class="line">    ip_sums.columns = [<span class="string">'ip'</span>, <span class="string">'sum1'</span>,<span class="string">'sum2'</span>]</div><div class="line">    ip_sums[<span class="string">'conversions_per_ip'</span>] = np.nansum((ip_sums[<span class="string">'sum1'</span>], ip_sums[<span class="string">'sum2'</span>]), axis = <span class="number">0</span>)</div><div class="line">    ip_sums.drop(columns=[<span class="string">'sum1'</span>, <span class="string">'sum2'</span>], axis = <span class="number">0</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><h2 id="7-使用dask代替pandas"><a href="#7-使用dask代替pandas" class="headerlink" title="7.使用dask代替pandas"></a>7.使用dask代替pandas</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import dask</div><div class="line">import dask.dataframe as dd</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近的一些比赛如&lt;a href=&quot;https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection&quot;&gt;TalkingData AdTracking Fraud Detection Challenge | Kaggle&lt;/a&gt;提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Kaggle" scheme="http://frankchen.xyz/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之 sklearn中的pipeline</title>
    <link href="http://frankchen.xyz/2018/04/08/pipeline-in-machine-learning/"/>
    <id>http://frankchen.xyz/2018/04/08/pipeline-in-machine-learning/</id>
    <published>2018-04-08T08:13:42.000Z</published>
    <updated>2018-04-11T07:25:07.449Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15231874915799.jpg" alt=""><br><a id="more"></a><br>如图所示，利用pipeline我们可以方便的减少代码量同时让机器学习的流程变得直观，<br><img src="/images/15231783974167.jpg" alt=""></p><p>例如我们需要做如下操作，容易看出，训练测试集重复了代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">vect = CountVectorizer()</div><div class="line">tfidf = TfidfTransformer()</div><div class="line">clf = SGDClassifier()</div><div class="line"></div><div class="line">vX = vect.fit_transform(Xtrain)</div><div class="line">tfidfX = tfidf.fit_transform(vX)</div><div class="line">predicted = clf.fit_predict(tfidfX)</div><div class="line"></div><div class="line"><span class="comment"># Now evaluate all steps on test set</span></div><div class="line">vX = vect.fit_transform(Xtest)</div><div class="line">tfidfX = tfidf.fit_transform(vX)</div><div class="line">predicted = clf.fit_predict(tfidfX)</div></pre></td></tr></table></figure><p>利用pipeline，上面代码可以抽象为，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">pipeline = Pipeline([</div><div class="line">    (<span class="string">'vect'</span>, CountVectorizer()),</div><div class="line">    (<span class="string">'tfidf'</span>, TfidfTransformer()),</div><div class="line">    (<span class="string">'clf'</span>, SGDClassifier()),</div><div class="line">])</div><div class="line">predicted = pipeline.fit(Xtrain).predict(Xtrain)</div><div class="line"><span class="comment"># Now evaluate all steps on test set</span></div><div class="line">predicted = pipeline.predict(Xtest)</div></pre></td></tr></table></figure><p>注意，pipeline最后一步如果有predict()方法我们才可以对pipeline使用fit_predict()，同理，最后一步如果有transform()方法我们才可以对pipeline使用fit_transform()方法。</p><h2 id="使用pipeline做cross-validation"><a href="#使用pipeline做cross-validation" class="headerlink" title="使用pipeline做cross validation"></a>使用pipeline做cross validation</h2><p>看如下案例，即先对输入手写数字的数据进行PCA降维，再通过逻辑回归预测标签。其中我们通过pipeline对<br>PCA的降维维数n_components和逻辑回归的正则项C大小做交叉验证，主要步骤有：</p><ol><li>依次实例化各成分对象如<code>pca = decomposition.PCA()</code></li><li>以(name, object)的tuble为元素组装pipeline如<code>Pipeline(steps=[(&#39;pca&#39;, pca), (&#39;logistic&#39;, logistic)])</code></li><li>初始化CV参数如<code>n_components = [20, 40, 64]</code></li><li>实例化CV对象如<code>estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, logistic__C=Cs))</code>，其中注意参数的传递方式，即key为pipeline元素名+函数参数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, decomposition, datasets</div><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line">logistic = linear_model.LogisticRegression()</div><div class="line"></div><div class="line">pca = decomposition.PCA()</div><div class="line">pipe = Pipeline(steps=[(<span class="string">'pca'</span>, pca), (<span class="string">'logistic'</span>, logistic)])</div><div class="line"></div><div class="line">digits = datasets.load_digits()</div><div class="line">X_digits = digits.data</div><div class="line">y_digits = digits.target</div><div class="line"></div><div class="line"><span class="comment"># Prediction</span></div><div class="line">n_components = [<span class="number">20</span>, <span class="number">40</span>, <span class="number">64</span>]</div><div class="line">Cs = np.logspace(<span class="number">-4</span>, <span class="number">4</span>, <span class="number">3</span>)</div><div class="line"></div><div class="line">pca.fit(X_digits)</div><div class="line">estimator = GridSearchCV(pipe,</div><div class="line">                         dict(pca__n_components=n_components, logistic__C=Cs))</div><div class="line">estimator.fit(X_digits, y_digits)</div><div class="line"></div><div class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">4</span>, <span class="number">3</span>))</div><div class="line">plt.clf()</div><div class="line">plt.axes([<span class="number">.2</span>, <span class="number">.2</span>, <span class="number">.7</span>, <span class="number">.7</span>])</div><div class="line">plt.plot(pca.explained_variance_, linewidth=<span class="number">2</span>)</div><div class="line">plt.axis(<span class="string">'tight'</span>)</div><div class="line">plt.xlabel(<span class="string">'n_components'</span>)</div><div class="line">plt.ylabel(<span class="string">'explained_variance_'</span>)</div><div class="line">plt.axvline(</div><div class="line">    estimator.best_estimator_.named_steps[<span class="string">'pca'</span>].n_components,</div><div class="line">    linestyle=<span class="string">':'</span>,</div><div class="line">    label=<span class="string">'n_components chosen'</span>)</div><div class="line">plt.legend(prop=dict(size=<span class="number">12</span>))</div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="自定义transformer"><a href="#自定义transformer" class="headerlink" title="自定义transformer"></a>自定义transformer</h2><p>我们可以如下自定义transformer（来自<a href="http://michelleful.github.io/code-blog/2015/06/20/pipelines/" target="_blank" rel="external">Using Pipelines and FeatureUnions in scikit-learn - Michelle Fullwood</a>）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SampleExtractor</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vars)</span>:</span></div><div class="line">        self.vars = vars  <span class="comment"># e.g. pass in a column name to extract</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></div><div class="line">        <span class="keyword">return</span> do_something_to(X, self.vars)  <span class="comment"># where the actual feature extraction happens</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></div><div class="line">        <span class="keyword">return</span> self  <span class="comment"># generally does nothing</span></div></pre></td></tr></table></figure><p>另外，我们也可以对每个feature单独处理，例如下面的这个比较大的流水线（来自<a href="http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html" target="_blank" rel="external">Using scikit-learn Pipelines and FeatureUnions | zacstewart.com</a>），我们可以发现作者的pipeline中，首先是一个叫做<code>features</code>的FeatureUnion，其中，每个特征分别以一个pipeline来处理，这个pipeline首先是一个<code>ColumnExtractor</code>提取出这个特征，后续进行一系列处理转换，最终这些pipeline组合为特征组合，再喂给一系列<code>ModelTransformer</code>包装的模型来predict，最终使用<code>KNeighborsRegressor</code>预测（相当于两层stacking）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">pipeline = Pipeline([</div><div class="line">    (<span class="string">'features'</span>, FeatureUnion([</div><div class="line">        (<span class="string">'continuous'</span>, Pipeline([</div><div class="line">            (<span class="string">'extract'</span>, ColumnExtractor(CONTINUOUS_FIELDS)),</div><div class="line">            (<span class="string">'scale'</span>, Normalizer())</div><div class="line">        ])),</div><div class="line">        (<span class="string">'factors'</span>, Pipeline([</div><div class="line">            (<span class="string">'extract'</span>, ColumnExtractor(FACTOR_FIELDS)),</div><div class="line">            (<span class="string">'one_hot'</span>, OneHotEncoder(n_values=<span class="number">5</span>)),</div><div class="line">            (<span class="string">'to_dense'</span>, DenseTransformer())</div><div class="line">        ])),</div><div class="line">        (<span class="string">'weekday'</span>, Pipeline([</div><div class="line">            (<span class="string">'extract'</span>, DayOfWeekTransformer()),</div><div class="line">            (<span class="string">'one_hot'</span>, OneHotEncoder()),</div><div class="line">            (<span class="string">'to_dense'</span>, DenseTransformer())</div><div class="line">        ])),</div><div class="line">        (<span class="string">'hour_of_day'</span>, HourOfDayTransformer()),</div><div class="line">        (<span class="string">'month'</span>, Pipeline([</div><div class="line">            (<span class="string">'extract'</span>, ColumnExtractor([<span class="string">'datetime'</span>])),</div><div class="line">            (<span class="string">'to_month'</span>, DateTransformer()),</div><div class="line">            (<span class="string">'one_hot'</span>, OneHotEncoder()),</div><div class="line">            (<span class="string">'to_dense'</span>, DenseTransformer())</div><div class="line">        ])),</div><div class="line">        (<span class="string">'growth'</span>, Pipeline([</div><div class="line">            (<span class="string">'datetime'</span>, ColumnExtractor([<span class="string">'datetime'</span>])),</div><div class="line">            (<span class="string">'to_numeric'</span>, MatrixConversion(int)),</div><div class="line">            (<span class="string">'regression'</span>, ModelTransformer(LinearRegression()))</div><div class="line">        ]))</div><div class="line">    ])),</div><div class="line">    (<span class="string">'estimators'</span>, FeatureUnion([</div><div class="line">        (<span class="string">'knn'</span>, ModelTransformer(KNeighborsRegressor(n_neighbors=<span class="number">5</span>))),</div><div class="line">        (<span class="string">'gbr'</span>, ModelTransformer(GradientBoostingRegressor())),</div><div class="line">        (<span class="string">'dtr'</span>, ModelTransformer(DecisionTreeRegressor())),</div><div class="line">        (<span class="string">'etr'</span>, ModelTransformer(ExtraTreesRegressor())),</div><div class="line">        (<span class="string">'rfr'</span>, ModelTransformer(RandomForestRegressor())),</div><div class="line">        (<span class="string">'par'</span>, ModelTransformer(PassiveAggressiveRegressor())),</div><div class="line">        (<span class="string">'en'</span>, ModelTransformer(ElasticNet())),</div><div class="line">        (<span class="string">'cluster'</span>, ModelTransformer(KMeans(n_clusters=<span class="number">2</span>)))</div><div class="line">    ])),</div><div class="line">    (<span class="string">'estimator'</span>, KNeighborsRegressor())</div><div class="line">])</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HourOfDayTransformer</span><span class="params">(TransformerMixin)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, **transform_params)</span>:</span></div><div class="line">        hours = DataFrame(X[<span class="string">'datetime'</span>].apply(<span class="keyword">lambda</span> x: x.hour))</div><div class="line">        <span class="keyword">return</span> hours</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None, **fit_params)</span>:</span></div><div class="line">        <span class="keyword">return</span> self</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelTransformer</span><span class="params">(TransformerMixin)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model)</span>:</span></div><div class="line">        self.model = model</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, *args, **kwargs)</span>:</span></div><div class="line">        self.model.fit(*args, **kwargs)</div><div class="line">        <span class="keyword">return</span> self</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, **transform_params)</span>:</span></div><div class="line">        <span class="keyword">return</span> DataFrame(self.model.predict(X))</div></pre></td></tr></table></figure><h2 id="FeatureUnion"><a href="#FeatureUnion" class="headerlink" title="FeatureUnion"></a>FeatureUnion</h2><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html" target="_blank" rel="external">sklearn.pipeline.FeatureUnion — scikit-learn 0.19.1 documentation</a> 和pipeline的序列执行不同，FeatureUnion指的是并行地应用许多transformer在input上，再将结果合并，所以自然地适合特征工程中的增加特征，而FeatureUnion与pipeline组合可以方便的完成许多复杂的操作，例如如下的例子，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">pipeline = Pipeline([</div><div class="line">  (<span class="string">'extract_essays'</span>, EssayExractor()),</div><div class="line">  (<span class="string">'features'</span>, FeatureUnion([</div><div class="line">    (<span class="string">'ngram_tf_idf'</span>, Pipeline([</div><div class="line">      (<span class="string">'counts'</span>, CountVectorizer()),</div><div class="line">      (<span class="string">'tf_idf'</span>, TfidfTransformer())</div><div class="line">    ])),</div><div class="line">    (<span class="string">'essay_length'</span>, LengthTransformer()),</div><div class="line">    (<span class="string">'misspellings'</span>, MispellingCountTransformer())</div><div class="line">  ])),</div><div class="line">  (<span class="string">'classifier'</span>, MultinomialNB())</div><div class="line">])</div></pre></td></tr></table></figure><p>整个<code>features</code>是一个FeatureUnion，而其中的ngram_tf_idf又是一个包括两步的pipeline。<br><img src="/images/15233302459256.jpg" alt=""></p><p>下面的例子中，使用FeatureUnion结合PCA降维后特征以及选择原特征中的几个作为特征组合再喂给SVM分类，最后用grid_search 做了 pca的<code>n_components</code>、SelectKBest的<code>k</code>以及SVM的<code>C</code>的CV。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline, FeatureUnion</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</div><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</div><div class="line"></div><div class="line">iris = load_iris()</div><div class="line"></div><div class="line">X, y = iris.data, iris.target</div><div class="line"></div><div class="line">print(X.shape, y.shape)</div><div class="line"></div><div class="line"><span class="comment"># This dataset is way too high-dimensional. Better do PCA:</span></div><div class="line">pca = PCA()</div><div class="line"></div><div class="line"><span class="comment"># Maybe some original features where good, too?</span></div><div class="line">selection = SelectKBest()</div><div class="line"></div><div class="line"><span class="comment"># Build estimator from PCA and Univariate selection:</span></div><div class="line"></div><div class="line">svm = SVC(kernel=<span class="string">"linear"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Do grid search over k, n_components and C:</span></div><div class="line"></div><div class="line">pipeline = Pipeline([(<span class="string">"features"</span>,</div><div class="line">                      FeatureUnion([(<span class="string">"pca"</span>, pca), (<span class="string">"univ_select"</span>,</div><div class="line">                                                   selection)])), (<span class="string">"svm"</span>,</div><div class="line">                                                                   svm)])</div><div class="line"></div><div class="line">param_grid = dict(</div><div class="line">    features__pca__n_components=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</div><div class="line">    features__univ_select__k=[<span class="number">1</span>, <span class="number">2</span>],</div><div class="line">    svm__C=[<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>])</div><div class="line"></div><div class="line">grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=<span class="number">10</span>)</div><div class="line">grid_search.fit(X, y)</div><div class="line"></div><div class="line">grid_search.best_estimator_</div><div class="line">grid_search.best_params_</div><div class="line">grid_search.best_score_</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15231874915799.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>VPS搭建私人BT离线服务器</title>
    <link href="http://frankchen.xyz/2018/04/08/private-BT-server/"/>
    <id>http://frankchen.xyz/2018/04/08/private-BT-server/</id>
    <published>2018-04-08T03:13:51.000Z</published>
    <updated>2018-04-08T03:47:02.802Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15231584798585.jpg" alt=""><br>使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。<br><a id="more"></a> </p><h2 id="安装及配置-Transmission"><a href="#安装及配置-Transmission" class="headerlink" title="安装及配置 Transmission"></a>安装及配置 Transmission</h2><ul><li>安装 <code>sudo apt-get install transmission-daemon</code></li><li>配置 停止服务（否则配置文件锁定，无法修改）<code>sudo service transmission-daemon stop</code></li><li>编辑配置文件</li></ul><p><code>sudo vim /etc/transmission-daemon/settings.json</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="string">"ratio-limit"</span>: 0.0100, </div><div class="line">    <span class="string">"ratio-limit-enabled"</span>: <span class="literal">true</span>,  </div><div class="line">    <span class="string">"rpc-password"</span>: <span class="string">"*******"</span>,   </div><div class="line">    <span class="string">"rpc-username"</span>: <span class="string">"frank"</span>,</div><div class="line">    <span class="string">"download-dir"</span>: <span class="string">"/var/www/html/Downloads"</span>, </div><div class="line">&#125;</div></pre></td></tr></table></figure><p> 我只列出了我修改过且无法在 Transmission Web-GUI 中无法完成修改的几项，四项依次是下载完成做种率，开启限制做种率，Web-GUI 密码，Web-GUI 用户名。像保存路径，下载/ 上传速度限制，都可以在 Web-GUI 中直接设定，为了方便之后对下载文件的 Web 管理，我直接将保存路径改到了 Web 发布路径下的一个子目录。</p><p> 重启服务</p><p> <code>sudo service transmission-daemon start</code></p><p> 此时在浏览器打开<code>VPS的IP地址/域名:9091</code>并输入刚刚设置的用户名及密码应该就可以访问 Transmission 的 Web-GUI了。<br> <img src="/images/Screen%20Shot%202018-04-08%20at%2011.25.35.png" alt="Screen Shot 2018-04-08 at 11.25.35"></p><p> 可是在添加了第一个任务后出现保存路径写入权限的问题。<br>解决办法如<a href="https://askubuntu.com/questions/221081/permission-denied-when-downloading-with-transmission-deamon" target="_blank" rel="external">Permission denied when downloading with transmission deamon - Ask Ubuntu</a>所示：</p><p>我们的下载地址是 <code>/var/www/html/Downloads</code> 用户名是<code>znwindy</code>:<br>那么 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将本用户加入 `debian-transmission`组</span></div><div class="line">sudo usermod <span class="_">-a</span> -G debian-transmission znwindy</div><div class="line"><span class="comment"># 文件夹所有者</span></div><div class="line">sudo chgrp debian-transmission /var/www/html/Downloads</div><div class="line"><span class="comment"># 组添加写权限</span></div><div class="line">sudo chmod -R 755 /var/www</div><div class="line"><span class="comment"># 停止后台deamon </span></div><div class="line"></div><div class="line">sudo service transmission-daemon stop</div><div class="line"><span class="comment"># 更改 file creation mask</span></div><div class="line">sudo vim /etc/transmission-daemon/settings.json</div><div class="line"><span class="comment"># 把"umask": 18 改为 "umask": 2</span></div><div class="line"><span class="comment"># 重启服务</span></div><div class="line">sudo service transmission-daemon start</div></pre></td></tr></table></figure><p>即可解决写的问题。</p><h2 id="配置-Apache-加密区域"><a href="#配置-Apache-加密区域" class="headerlink" title="配置 Apache 加密区域"></a>配置 Apache 加密区域</h2><p>安装apache2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install apache2</div></pre></td></tr></table></figure><p>Adjust the Firewall</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo ufw app list</div><div class="line">sudo ufw allow <span class="string">'Apache Full'</span></div><div class="line">sudo ufw status</div><div class="line">sudo systemctl status apache2</div></pre></td></tr></table></figure><p>密码生成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo htpasswd -c /etc/apache2/.htpasswd 用户名</div></pre></td></tr></table></figure><p>然后会被提示输入两次该 “用户名” 的密码。</p><p>修改虚拟 host 的配置文件<br><code>sudo vim /etc/apache2/sites-enabled/000-default.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;Directory <span class="string">"/var/www/html"</span>&gt;</div><div class="line">        AuthType Basic</div><div class="line">        AuthName <span class="string">"Restricted Content"</span></div><div class="line">        AuthUserFile /etc/apache2/.htpasswd</div><div class="line">        Require valid-user</div><div class="line">&lt;/Directory&gt;</div></pre></td></tr></table></figure><p>保存后重启</p><p><code>sudo service apache2 restart</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过 HTTP 将下载的任务取回本地，速度也很快！这样，通过访问 Transmission Web-GUI “投喂” 种子，磁力链，然后在下载完成后通过 HTTP 方式从 VPS 将资源取回本地，甚至直接对 .mp3、.mp4 等文件格式进行在线播放，实现了一个简化版的迅雷离线下载，可是它却在下载某些特定资源时远比迅雷离线管用。</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/24478342" target="_blank" rel="external">在 VPS 上搭建私人离线下载</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15231584798585.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。&lt;br&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
      <category term="Old Driver" scheme="http://frankchen.xyz/tags/Old-Driver/"/>
    
  </entry>
  
  <entry>
    <title>numpy 中增加channel的方法</title>
    <link href="http://frankchen.xyz/2018/03/29/numpy-add-channel/"/>
    <id>http://frankchen.xyz/2018/03/29/numpy-add-channel/</id>
    <published>2018-03-29T12:15:30.000Z</published>
    <updated>2018-03-29T12:48:49.127Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15223277046847.jpg" alt=""><br>numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。</p><a id="more"></a><p>在机器学习中，所有的数据都是向量和矩阵，而怎么根据我们所要解决的问题来调整模型以及数据的格式，也就是矩阵的维度和大小是一项重要的基本功，那么本文就具体介绍下numpy中数组的转换，也就是增加channel的方法。</p><h2 id="一维转二维"><a href="#一维转二维" class="headerlink" title="一维转二维"></a>一维转二维</h2><p>例如我们有一个一维的numpy array，有如下方法可以转为二维</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">a = np.arange(<span class="number">10</span>)</div><div class="line">a</div><div class="line">a.shape</div><div class="line">b = a[:,<span class="keyword">None</span>]</div><div class="line">b</div><div class="line">b.shape</div><div class="line"><span class="string">'''</span></div><div class="line">array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</div><div class="line">(10,)</div><div class="line">array([[0],</div><div class="line">       [1],</div><div class="line">       [2],</div><div class="line">       [3],</div><div class="line">       [4],</div><div class="line">       [5],</div><div class="line">       [6],</div><div class="line">       [7],</div><div class="line">       [8],</div><div class="line">       [9]])</div><div class="line">(10, 1)</div><div class="line">'''</div></pre></td></tr></table></figure><p> 可以看到，<code>a</code>确实被转为了二维，以下方法是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">c = a[:,np.newaxis]</div><div class="line">c</div><div class="line">(c == b).all()</div><div class="line">np.newaxis == <span class="keyword">None</span></div><div class="line"><span class="string">'''</span></div><div class="line">array([[0],</div><div class="line">       [1],</div><div class="line">       [2],</div><div class="line">       [3],</div><div class="line">       [4],</div><div class="line">       [5],</div><div class="line">       [6],</div><div class="line">       [7],</div><div class="line">       [8],</div><div class="line">       [9]])</div><div class="line">True</div><div class="line">True</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="转为多维"><a href="#转为多维" class="headerlink" title="转为多维"></a>转为多维</h2><p>时间序列预测中，我们一般需要的是(sample，time_stamp，feature)的3 个channel的数据，即一个三维矩阵，包含若干个sample，每个sample包含若干个时间序列点，而每个时间序列点有包括若干个feature，哪怕我们只是做单变量的时间序列预测，输入RNN网络例如LSTM的时候，数据也必须是三维的格式，下面我们讲一讲这么做的方法。</p><p>例如我们有一个若干个时间点每个时间点有两个特征的数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">a = np.arange(<span class="number">24</span>).reshape((<span class="number">-1</span>,<span class="number">2</span>))</div><div class="line">a.shape</div><div class="line">a</div><div class="line"><span class="string">'''</span></div><div class="line">(12, 2)</div><div class="line">array([[ 0,  1],</div><div class="line">       [ 2,  3],</div><div class="line">       [ 4,  5],</div><div class="line">       [ 6,  7],</div><div class="line">       [ 8,  9],</div><div class="line">       [10, 11],</div><div class="line">       [12, 13],</div><div class="line">       [14, 15],</div><div class="line">       [16, 17],</div><div class="line">       [18, 19],</div><div class="line">       [20, 21],</div><div class="line">       [22, 23]])</div><div class="line">'''</div></pre></td></tr></table></figure><p>我们将a转化为三个channel，即可以</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">b = a[:,<span class="keyword">None</span>,:]</div><div class="line">b.shape</div><div class="line">b</div><div class="line"><span class="string">'''</span></div><div class="line">(12, 1, 2)</div><div class="line">array([[[ 0,  1]],</div><div class="line"></div><div class="line">       [[ 2,  3]],</div><div class="line"></div><div class="line">       [[ 4,  5]],</div><div class="line"></div><div class="line">       [[ 6,  7]],</div><div class="line"></div><div class="line">       [[ 8,  9]],</div><div class="line"></div><div class="line">       [[10, 11]],</div><div class="line"></div><div class="line">       [[12, 13]],</div><div class="line"></div><div class="line">       [[14, 15]],</div><div class="line"></div><div class="line">       [[16, 17]],</div><div class="line"></div><div class="line">       [[18, 19]],</div><div class="line"></div><div class="line">       [[20, 21]],</div><div class="line"></div><div class="line">       [[22, 23]]])</div><div class="line">       '''</div></pre></td></tr></table></figure><p>以上对应着pandas的Dataframe，及我们对Dataframe取values属性，会得到一个二维矩阵，做法就如同上面一样，但是如果是Series的话，取values属性得到的是一个一维的，这时候我们的做法则是，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">c = np.arange(<span class="number">12</span>)</div><div class="line">c</div><div class="line">d = c[:,<span class="keyword">None</span>,<span class="keyword">None</span>]</div><div class="line">d.shape</div><div class="line">d</div><div class="line"><span class="string">'''</span></div><div class="line">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</div><div class="line">(12, 1, 1)</div><div class="line">array([[[ 0]],</div><div class="line"></div><div class="line">       [[ 1]],</div><div class="line"></div><div class="line">       [[ 2]],</div><div class="line"></div><div class="line">       [[ 3]],</div><div class="line"></div><div class="line">       [[ 4]],</div><div class="line"></div><div class="line">       [[ 5]],</div><div class="line"></div><div class="line">       [[ 6]],</div><div class="line"></div><div class="line">       [[ 7]],</div><div class="line"></div><div class="line">       [[ 8]],</div><div class="line"></div><div class="line">       [[ 9]],</div><div class="line"></div><div class="line">       [[10]],</div><div class="line"></div><div class="line">       [[11]]])</div><div class="line">'''</div></pre></td></tr></table></figure><h2 id="减少维度"><a href="#减少维度" class="headerlink" title="减少维度"></a>减少维度</h2><p>若要减少数据的维度，我们可以用的方法如下，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">d = np.arange(<span class="number">12</span>)[:,<span class="keyword">None</span>,<span class="keyword">None</span>]</div><div class="line">d.shape</div><div class="line">d</div><div class="line">e = np.squeeze(d)</div><div class="line">e.shape</div><div class="line">e</div><div class="line"><span class="string">'''(12, 1, 1)</span></div><div class="line">array([[[ 0]],</div><div class="line"></div><div class="line">       [[ 1]],</div><div class="line"></div><div class="line">       [[ 2]],</div><div class="line"></div><div class="line">       [[ 3]],</div><div class="line"></div><div class="line">       [[ 4]],</div><div class="line"></div><div class="line">       [[ 5]],</div><div class="line"></div><div class="line">       [[ 6]],</div><div class="line"></div><div class="line">       [[ 7]],</div><div class="line"></div><div class="line">       [[ 8]],</div><div class="line"></div><div class="line">       [[ 9]],</div><div class="line"></div><div class="line">       [[10]],</div><div class="line"></div><div class="line">       [[11]]])</div><div class="line">(12,)</div><div class="line">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])'''</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15223277046847.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python 正则实用例子</title>
    <link href="http://frankchen.xyz/2018/02/24/re-basic-of-python/"/>
    <id>http://frankchen.xyz/2018/02/24/re-basic-of-python/</id>
    <published>2018-02-24T10:52:00.000Z</published>
    <updated>2018-02-24T11:09:45.871Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15194705842254.png" alt=""></p><p>本文主要关于python的正则表达式的符号与方法。</p><a id="more"></a><ul><li>findall: 找寻所有匹配，返回所有组合的列表</li><li>search: 找寻第一个匹配并返回</li><li>sub: 替换符合规律的内容，并返回替换后的内容</li></ul><p><strong>.</strong>：匹配除了换行符以外的任意字符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xy123'</span></div><div class="line">b = re.findall(<span class="string">'x...'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['xy12']</span></div></pre></td></tr></table></figure><p><strong>*</strong>：匹配前一个字符0次或者无限次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xyxy123'</span></div><div class="line">b = re.findall(<span class="string">'x*'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['x', '', 'x', '', '', '', '', '']</span></div></pre></td></tr></table></figure><p><strong>?</strong>：匹配前一个字符0次或者1次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = <span class="string">'xy123'</span></div><div class="line">b = re.findall(<span class="string">'x?'</span>,a)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['x', '', '', '', '', '']</span></div></pre></td></tr></table></figure><p><strong>.*</strong>：贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">b = re.findall(<span class="string">'xx.*xx'</span>,secret_code)</div><div class="line">print(b)</div><div class="line"><span class="comment"># ['xxIxxfasdjifja134xxlovexx23345sdfxxyouxx']</span></div></pre></td></tr></table></figure><p><strong>.*?</strong>：非贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">c = re.findall(<span class="string">'xx.*?xx'</span>,secret_code)</div><div class="line">print(c)</div><div class="line"><span class="comment"># ['xxIxx', 'xxlovexx', 'xxyouxx']</span></div></pre></td></tr></table></figure><p><strong>()</strong>：括号内结果返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">d = re.findall(<span class="string">'xx(.*?)xx'</span>,secret_code)</div><div class="line">print(d)</div><div class="line"><span class="keyword">for</span> each <span class="keyword">in</span> d:</div><div class="line">    print(each)</div><div class="line"><span class="comment"># ['I', 'love', 'you']</span></div><div class="line"><span class="comment"># I</span></div><div class="line"><span class="comment"># love</span></div><div class="line"><span class="comment"># you</span></div></pre></td></tr></table></figure><p><strong>re.S</strong>使得.的作用域包括换行符”\n”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">s = <span class="string">'''sdfxxhello</span></div><div class="line">xxfsdfxxworldxxasdf'''</div><div class="line"></div><div class="line">d = re.findall(<span class="string">'xx(.*?)xx'</span>,s,re.S)</div><div class="line">print(d)</div><div class="line"><span class="comment">#  ['hello\n', 'world']</span></div></pre></td></tr></table></figure><p>对比findall与search的区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">s2 = <span class="string">'asdfxxIxx123xxlovexxdfd'</span></div><div class="line">f = re.search(<span class="string">'xx(.*?)xx123xx(.*?)xx'</span>,s2).group(<span class="number">2</span>)</div><div class="line">print(f)</div><div class="line">f2 = re.findall(<span class="string">'xx(.*?)xx123xx(.*?)xx'</span>,s2)</div><div class="line">print(f2[<span class="number">0</span>][<span class="number">1</span>])</div><div class="line"><span class="comment"># love</span></div><div class="line"><span class="comment"># love</span></div></pre></td></tr></table></figure><p>虽然两者结果相同，但是search是搭配group来得到第二个匹配，而findall的结果是[(‘I’, ‘love’)]，包含元组的列表，所以需要f2[0][1]来引入。</p><p><strong>sub</strong>的使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">s = <span class="string">'123rrrrr123'</span></div><div class="line">output = re.sub(<span class="string">'123(.*?)123'</span>,<span class="string">'123%d123'</span>%<span class="number">789</span>,s)</div><div class="line">print(output)</div><div class="line"><span class="comment"># 123789123</span></div></pre></td></tr></table></figure><p>例如我们需要将文档中的所有的png图片改变路径，即需要找到所有的<code>.png</code>结尾，再将其都加上路径，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiply</span><span class="params">(m)</span>:</span></div><div class="line">    <span class="comment"># Convert group 0 to an integer.</span></div><div class="line">    v = m.group(<span class="number">0</span>)</div><div class="line">    print(v)</div><div class="line">    <span class="comment"># Multiply integer by 2.</span></div><div class="line">    <span class="comment"># ... Convert back into string and return it.</span></div><div class="line">    print(<span class="string">'basic/'</span>+v)</div><div class="line">    <span class="keyword">return</span> <span class="string">'basic/'</span>+v</div></pre></td></tr></table></figure><p>结果如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>autoencoder.png</div><div class="line">    basic/autoencoder.png</div><div class="line">    RNN.png</div><div class="line">    basic/RNN.png</div><div class="line">    rnn_step_forward.png</div><div class="line">    basic/rnn_step_forward.png</div><div class="line">    rnns.png</div><div class="line">    basic/rnns.png</div><div class="line">    rnn_cell_backprop.png</div><div class="line">    basic/rnn_cell_backprop.png</div><div class="line">    LSTM.png</div><div class="line">    basic/LSTM.png</div><div class="line">    LSTM_rnn.png</div><div class="line">    basic/LSTM_rnn.png</div><div class="line">    attn_mechanism.png</div><div class="line">    basic/attn_mechanism.png</div><div class="line">    attn_model.png</div><div class="line">    basic/attn_model.png</div></pre></td></tr></table></figure><p>仿照上面案例，我们可以方便的对我们的任务进行定制。</p><p><strong>subn</strong> 相比sub，subn返回元组，第二个元素表示替换发生的次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(m)</span>:</span></div><div class="line">    <span class="comment"># Convert.</span></div><div class="line">    v = int(m.group(<span class="number">0</span>))</div><div class="line">    <span class="comment"># Add 2.</span></div><div class="line">    <span class="keyword">return</span> str(v + <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># Call re.subn.</span></div><div class="line">result = re.subn(<span class="string">"\d+"</span>, add, <span class="string">"1 2 3 4 5"</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Result string:"</span>, result[<span class="number">0</span>])</div><div class="line">print(<span class="string">"Number of substitutions:"</span>, result[<span class="number">1</span>])</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span></div><div class="line">Result string: <span class="number">11</span> <span class="number">21</span> <span class="number">31</span> <span class="number">41</span> <span class="number">51</span></div><div class="line">Number of substitutions: <span class="number">5</span></div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15194705842254.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文主要关于python的正则表达式的符号与方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="re" scheme="http://frankchen.xyz/tags/re/"/>
    
  </entry>
  
  <entry>
    <title>Tex 写（中文）毕业论文全攻略</title>
    <link href="http://frankchen.xyz/2018/02/08/Writing-Graduation-Thesis-in-Tex/"/>
    <id>http://frankchen.xyz/2018/02/08/Writing-Graduation-Thesis-in-Tex/</id>
    <published>2018-02-07T17:36:41.000Z</published>
    <updated>2018-02-07T18:11:41.628Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15180252634406.png" alt=""></p><p>用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！</p><a id="more"></a><p>这里我们并不存在鄙视链，说什么Tex 优于 Word之类的，其实Word作为极其复杂的文本处理软件，我相信Tex能做到的，Word一定有其实现方式，只不过大部分人都只会用到Word的一小部分功能，相比Word，Tex解决方案更加便捷优雅，比如自动排号（章节、表格、参考文献的编号），全局设置的字体、间距格式等等。相比Word事无巨细的维护修改成本，Tex 的解决方案更加programmer，即软件开发，后期主要工作是迭代维护，若能在前期即考虑这点，后期能省下极多的脑细胞和精力。好了不说多，发车吧~</p><h2 id="总论"><a href="#总论" class="headerlink" title="总论"></a>总论</h2><p> 总体来说，是用上交Tex模板结合Atom编辑器在本地编辑<a href="https://atom.io/" target="_blank" rel="external">Atom</a>（这个用什么编辑器随意）以及Dropbox同步到云端<a href="https://www.dropbox.com/h" target="_blank" rel="external">Dropbox</a>以及云端上在sharelatex服务器上即时编译所见即所得。</p><h2 id="工具使用方法"><a href="#工具使用方法" class="headerlink" title="工具使用方法"></a>工具使用方法</h2><p>首先我们在sharelatex官网<a href="https://www.sharelatex.com/project" target="_blank" rel="external">Your Projects - ShareLaTeX, Online LaTeX Editor</a>注册账号，免费账号即可，如果需要多人协作可以用邀请小号的方式让自己增加权限（sharelatex新建账号不验证邮箱。。所以你懂的），接下来在上交模板<a href="https://github.com/sjtug/SJTUThesis" target="_blank" rel="external">sjtug/SJTUThesis: 上海交通大学 XeLaTeX 学位论文模板 A XeLaTeX template for Shanghai Jiao Tong University (SJTU) thesis.</a>处点击此处添加最新版模板到我们的sharelatex项目，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.25.png" alt="Screen Shot 2018-02-08 at 01.58.25"></p><p><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.56.png" alt="Screen Shot 2018-02-08 at 01.58.56"></p><p>如图，再点进去，先别急着修改，我们先设置个网盘同步，Dropbox需要梯子，在sharelatex的账号设置处链接到Dropbox，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.00.57.png" alt="Screen Shot 2018-02-08 at 02.00.57"></p><p>同时Dropbox安装一个桌面版，需要设置代理，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.02.29.png" alt="Screen Shot 2018-02-08 at 02.02.29"><br>如图，我们使用ss作为代理。</p><p>接下来安装Atom编辑器，在插件里装一个如下插件，这里我们需要它只是为了注释这一个功能，因为我们不需要本地编译。<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.03.38.png" alt="Screen Shot 2018-02-08 at 02.03.38"></p><p>接下来我们就可以在本地用Atom编辑Dropbox网盘在本地的Tex项目，只要我们保存，Dropbox就会同步到sharelatex，如果开启自动编译云端就会展示当下编译的PDF效果，如图<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.07.11.png" alt="Screen Shot 2018-02-08 at 02.07.11"></p><h2 id="Tex模板使用说明"><a href="#Tex模板使用说明" class="headerlink" title="Tex模板使用说明"></a>Tex模板使用说明</h2><p>详见此处<a href="http://sjtug.org/SJTUThesis/README.pdf" target="_blank" rel="external">README.pdf</a>，主要思路就是把各章、摘要、参考文献等分为不同的tex文件，图表等资源放在一处文件夹内，逐个引用，有全局的的设置文件，编译时将这些零件拼接为pdf，后续会添加更多心得。</p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ol><li><a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="external">MathJax basic tutorial and quick reference - Mathematics Meta Stack Exchange</a>：一个常用Latex公式符号的全集</li><li>如果上面没找到，可以试试这里，手写识别latex字符<a href="http://detexify.kirelabs.org/classify.html" target="_blank" rel="external">Detexify LaTeX handwritten symbol recognition</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15180252634406.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tex" scheme="http://frankchen.xyz/tags/Tex/"/>
    
  </entry>
  
  <entry>
    <title>理解TSNE算法</title>
    <link href="http://frankchen.xyz/2018/01/30/Understanding-TSNE/"/>
    <id>http://frankchen.xyz/2018/01/30/Understanding-TSNE/</id>
    <published>2018-01-30T03:39:39.000Z</published>
    <updated>2018-01-30T08:17:42.455Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15172836269060.jpg" alt=""></p><p>结合<a href="http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf" target="_blank" rel="external">论文</a>公式与几个python实现理解t-SNE算法。<br><a id="more"></a></p><p>t-SNE 是一种数据可视化工具，它可以将高维数据降维到2-3维以用于画图，局部相似性被这种embedding所保留。</p><p>t-SNE把原空间的数据点之间的距离转换为高斯分布概率，如果两点在高维空间距离越近，那么这个概率值越大。注意到高斯分布的这个标准差$\sigma_i$ 对每个点都是不同的，这也是算法的创新点之一，因为理论上空间不同位置的点的密度是不同的，条件概率如此计算，</p><p>$$p_{j|i} = \frac{\exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}_j) / (2 \sigma_i^2)})}{\sum_{i \neq k} \exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}_k) / (2 \sigma_i^2)})}, \quad p_{i|i} = 0,$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.18.45.png" alt="Screen Shot 2018-01-30 at 15.18.45"></p><p>图中公式是理论方式，实际是先计算条件概率再用下面公式来产生联合分布，</p><p>$$p_{ij} = \frac{p_{j|i} + p_{i|j}}{2N}.$$</p><p>其中 $\sigma_i$ 将自动确定。这个过程可以通过设置算法的困惑性来影响。</p><p>用一个长尾分布(Student-t Distribution，简称为t分布)来表示 embed空间的相似性<br>$$q_{ij} = \frac{(1 + ||\boldsymbol{y}_i - \boldsymbol{y}_j)||^2)^{-1}}{\sum_{k \neq l} (1 + ||\boldsymbol{y}_k - \boldsymbol{y}_l)||^2)^{-1}},$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.28.56.png" alt="Screen Shot 2018-01-30 at 15.28.56"></p><p>损失函数是两个分布之间的 Kullback-Leibler divergence（KL散度）</p><p>$$KL(P|Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$</p><p>而为什么说tsne保留的是局部相似性呢？我们从KL散度的公式出发来解释，<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.33.19.png" alt="Screen Shot 2018-01-30 at 15.33.19"><br>可以看到，当$p_{ij}$很大而$q_{ij}$很小（高维空间距离近，低维空间距离远）惩罚很大，反之惩罚小（高维空间距离远，低维空间距离近）。</p><p>而为什么高维空间用高斯分布，低维空间用Student-t Distribution呢？</p><p><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.32.png" alt="Screen Shot 2018-01-30 at 15.41.32"><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.43.png" alt="Screen Shot 2018-01-30 at 15.41.43"><br>原因就是因为降维是必然要带来信息损失，我们要保存局部信息那么必然要损失全局信息，比如我们要把上面的这个2维空间的三个成直角边的点降维到1维，那么把它们放平就保存了局部信息（左中和中右之间的距离保持不变），但是牺牲了全局信息（左右之间的距离变大了）。而Student-t Distribution就能放大这种密度，如下图（tsne默认t分布自由度为1），t分布相比高斯分布更加长尾。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.48.47.png" alt="Screen Shot 2018-01-30 at 15.48.47"><br>梯度计算时有优化技巧，如果按下图中的原公式计算，复杂度为$O(N^2)$ Barnes-Hut 树方法就可以优化到$ O(NlogN)$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.59.02.png" alt="Screen Shot 2018-01-30 at 15.59.02"><br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.17.png" alt="Screen Shot 2018-01-30 at 16.01.17"><br>原理类似于用上图中ABC三点中心的距离乘以三来代替计算三者各自的距离。<br>那么把用barnes树结构来进行深度优先搜索，分别判断其距离是否大于阈值，分块计算距离，这样复杂度就降低了。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.38.png" alt="Screen Shot 2018-01-30 at 16.01.38"></p><p>以下是计算损失KL散度的公式，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence</span><span class="params">(params, P, degrees_of_freedom, n_samples, n_components,</span></span></div><div class="line">                   skip_num_points=<span class="number">0</span>):</div><div class="line">    <span class="string">"""t-SNE objective function: gradient of the KL divergence</span></div><div class="line">    of p_ijs and q_ijs and the absolute error."""</div><div class="line">    X_embedded = params.reshape(n_samples, n_components)</div><div class="line"></div><div class="line">    <span class="comment"># Q is a heavy-tailed distribution: Student's t-distribution</span></div><div class="line">    n = pdist(X_embedded, <span class="string">"sqeuclidean"</span>)</div><div class="line">    n += <span class="number">1.</span></div><div class="line">    n /= degrees_of_freedom</div><div class="line">    n **= (degrees_of_freedom + <span class="number">1.0</span>) / <span class="number">-2.0</span></div><div class="line">    Q = np.maximum(n / (<span class="number">2.0</span> * np.sum(n)), MACHINE_EPSILON)</div><div class="line"></div><div class="line">    <span class="comment"># Optimization trick below: np.dot(x, y) is faster than</span></div><div class="line">    <span class="comment"># np.sum(x * y) because it calls BLAS</span></div><div class="line"></div><div class="line">    <span class="comment"># Objective: C (Kullback-Leibler divergence of P and Q)</span></div><div class="line">    kl_divergence = <span class="number">2.0</span> * np.dot(P, np.log(P / Q))</div><div class="line"></div><div class="line">    <span class="comment"># Gradient: dC/dY</span></div><div class="line">    grad = np.ndarray((n_samples, n_components))</div><div class="line">    PQd = squareform((P - Q) * n)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(skip_num_points, n_samples):</div><div class="line">        np.dot(_ravel(PQd[i]), X_embedded[i] - X_embedded, out=grad[i])</div><div class="line">    grad = grad.ravel()</div><div class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</div><div class="line">    grad *= c</div></pre></td></tr></table></figure><p>用梯度下降（和一些tricks）优化，值得注意的是损失函数非对称，并且不同的训练会导致结果的不同。</p><p>sklearn里对于binary search计算 联合分布下面的(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_utils.pyx" target="_blank" rel="external">_utils._binary_search_perplexity</a>)和Barnes-Hut 树计算梯度(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_barnes_hut_tsne.pyx" target="_blank" rel="external">_barnes_hut_tsne.gradient</a>)都是C实现，有空再来研究。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_joint_probabilities</span><span class="params">(distances, desired_perplexity, verbose)</span>:</span></div><div class="line">    <span class="string">"""Compute joint probabilities p_ij from distances."""</span></div><div class="line">    <span class="comment"># Compute conditional probabilities such that they approximately match</span></div><div class="line">    <span class="comment"># the desired perplexity</span></div><div class="line">    distances = astype(distances, np.float32, copy=<span class="keyword">False</span>)</div><div class="line">    </div><div class="line">    conditional_P = _utils._binary_search_perplexity(</div><div class="line">        distances, <span class="keyword">None</span>, desired_perplexity, verbose)</div><div class="line">    P = conditional_P + conditional_P.T</div><div class="line">    sum_P = np.maximum(np.sum(P), MACHINE_EPSILON)</div><div class="line">    P = np.maximum(squareform(P) / sum_P, MACHINE_EPSILON)</div><div class="line">    <span class="keyword">return</span> P</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence_bh</span><span class="params">(params, P, neighbors, degrees_of_freedom, n_samples,</span></span></div><div class="line">                      n_components, angle=<span class="number">0.5</span>, skip_num_points=<span class="number">0</span>,</div><div class="line">                      verbose=False):</div><div class="line">    <span class="string">"""t-SNE objective function: KL divergence of p_ijs and q_ijs."""</span></div><div class="line">    params = astype(params, np.float32, copy=<span class="keyword">False</span>)</div><div class="line">    X_embedded = params.reshape(n_samples, n_components)</div><div class="line">    neighbors = astype(neighbors, np.int64, copy=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">if</span> len(P.shape) == <span class="number">1</span>:</div><div class="line">        sP = squareform(P).astype(np.float32)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        sP = P.astype(np.float32)</div><div class="line"></div><div class="line">    grad = np.zeros(X_embedded.shape, dtype=np.float32)</div><div class="line">    error = _barnes_hut_tsne.gradient(sP, X_embedded, neighbors,</div><div class="line">                                      grad, angle, n_components, verbose,</div><div class="line">                                      dof=degrees_of_freedom)</div><div class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</div><div class="line">    grad = grad.ravel()</div><div class="line">    grad *= c</div><div class="line"></div><div class="line">    <span class="keyword">return</span> error, grad</div></pre></td></tr></table></figure><p><a href="http://lvdmaaten.github.io/tsne/" target="_blank" rel="external">t-SNE – Laurens van der Maaten</a>这个链接是作者收集的各种tsne变种及相关实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15172836269060.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;结合&lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&quot;&gt;论文&lt;/a&gt;公式与几个python实现理解t-SNE算法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Data Science Pipelines |  特征工程中的管道</title>
    <link href="http://frankchen.xyz/2018/01/12/Data-Science-Notes/"/>
    <id>http://frankchen.xyz/2018/01/12/Data-Science-Notes/</id>
    <published>2018-01-12T06:22:50.000Z</published>
    <updated>2018-04-08T08:13:01.013Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15161698020879.png" alt=""></p><p>暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。</p><a id="more"></a><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><ol><li><p>以一个Kaggle上的House Price为案例，机器学习流程分成两个大步骤 ：即<br>EDA与特征工程（只使用Pandas, StatsModel，scipy,numpy, seaborn等库）</p><ul><li><p>输入： 原始Train, Test 数据集，将原始Train和Test 合并成一个数据集combined</p></li><li><p>处理： Pandas Pipe</p><p>  根据各种可能和各种特征工程方法定义各种函数（输入combined, 输入pre_combined)<br>  用PandasPipe 将这个函数像搭积木一样连在一起。用列表按序存放这些函数）<br>  这个列表就是，1. 基本的填充空值, 2. 转换数据类型， 3. 空白函数（为了对齐美观而以，啥事不做），4. log 转换，类别数据哑元处理， 5. 导出到hdf5文件， 6.检查R2值<br>  利用各种排列组合，或者各种参数组合，可以产生丰富的pipes，每一个pipes都可以产生一个预处理过的文件。</p></li><li><p>输出：某文件夹下 的N个预处理过的hdf5文件。 针对各种特征工程的排列组合，或者是Kaggle上面的各种新奇的特征工程方法。</p></li></ul></li><li><p>机器学习阶段（训练和产生模型，目标是尽可能获得尽可能低的RMSE值（针对训练数据），同时要具有范化的能力（针对测试数据））</p><ul><li>第一步，建立基准，筛选出最好的一个（几个）预处理文件（随机数设成固定值）</li><li>第二步，针对筛选出来的预处理文件，进行调参。找到最合适的几个算法（通常是RMSE值最低，且不同Kernel）（随机数设成固定值）    </li><li>第三步，用调好的参数来预处理文件中的Traing数据的做average 和stacking</li><li>第四部，生成csv文件，提交到Kaggle 看看得分如何。</li></ul></li></ol><h2 id="准备阶段-与-NoteBook-Head"><a href="#准备阶段-与-NoteBook-Head" class="headerlink" title="准备阶段 与 NoteBook Head"></a>准备阶段 与 NoteBook Head</h2><p>过滤warning：有句话说的好，在计算机科学里，我们只在意错误不在意warning</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> warnings</div><div class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</div></pre></td></tr></table></figure><hr><p>工作目录切换到当前python文件所在目录<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line">os.chdir(os.path.dirname(os.path.abspath(__file__)))</div></pre></td></tr></table></figure></p><hr><p>Notebook交互输出所有结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</div><div class="line">InteractiveShell.ast_node_interactivity=<span class="string">'all'</span></div></pre></td></tr></table></figure><p>结果如下<br><img src="/images/Screen%20Shot%202018-01-12%20at%2015.27.58.png" alt="Screen Shot 2018-01-12 at 15.27.58"></p><p>以上可以通过设置固定下来，方法如下：</p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.51.01.png" alt="Screen Shot 2018-02-05 at 14.51.01"></p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.50.29.png" alt="Screen Shot 2018-02-05 at 14.50.29"></p><hr><p>一般对train以及test做一个concat，并记录train的条数ntrain<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">"train.csv.gz"</span>)</div><div class="line">test = pd.read_csv(<span class="string">"test.csv.gz"</span>)</div><div class="line"></div><div class="line">combined = pd.concat([train,test],axis =<span class="number">0</span>, ignore_index =<span class="keyword">True</span>)</div><div class="line">ntrain = train.shape[<span class="number">0</span>]</div><div class="line">Y_train = train[<span class="string">"SalePrice"</span>]</div><div class="line">X_train = train.drop([<span class="string">"Id"</span>,<span class="string">"SalePrice"</span>],axis=<span class="number">1</span>)</div><div class="line">print(<span class="string">"train data shape:\t "</span>,train.shape)</div><div class="line">print(<span class="string">"test data shape:\t "</span>,test.shape)</div><div class="line">print(<span class="string">"combined data shape:\t"</span>,combined.shape)</div></pre></td></tr></table></figure></p><h2 id="EDA相关"><a href="#EDA相关" class="headerlink" title="EDA相关"></a>EDA相关</h2><p>1D Scatter</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">nca = NCA(num_dims=<span class="number">1</span>)</div><div class="line">nca.fit(xx_t, yy)</div><div class="line">xxxxx = nca.transform(xx)</div><div class="line">zeros=np.zeros_like(xxxxx)</div><div class="line">plt.scatter(xxxxx, zeros+<span class="number">1</span>,c=yy[:,np.newaxis])</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/myplot.png" alt="myplot"></p><hr><p>缺失值分析</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cols_missing_value = combined.isnull().sum()/combined.shape[<span class="number">0</span>]</div><div class="line">cols_missing_value = cols_missing_value[cols_missing_value&gt;<span class="number">0</span>]</div><div class="line">print(<span class="string">"How many features is bad/missing value? The answer is:"</span>,cols_missing_value.shape[<span class="number">0</span>])</div><div class="line">cols_missing_value.sort_values(ascending=<span class="keyword">False</span>).head(<span class="number">10</span>).plot.barh()</div></pre></td></tr></table></figure><p><img src="/images/15161679439549.jpg" alt=""></p><p>有缺失 - 需要填充或者删除，通常用均值或者中指，或者用人工分析（人工分析是提分关键）</p><hr><p>将若干个Dataframe画在同一个图里面相同坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">fig, ax = plt.subplots()</div><div class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果</span></div><div class="line"><span class="keyword">for</span> desc, group <span class="keyword">in</span> Energy_sources:</div><div class="line">    group.plot(x = group.index, y=<span class="string">'Value'</span>, label=desc,ax = ax, title=<span class="string">'Carbon Emissions per Energy Source'</span>, fontsize = <span class="number">20</span>)</div><div class="line">    ax.set_xlabel(<span class="string">'Time(Monthly)'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'Carbon Emissions in MMT'</span>)</div><div class="line">    ax.xaxis.label.set_size(<span class="number">20</span>)</div><div class="line">    ax.yaxis.label.set_size(<span class="number">20</span>)</div><div class="line">    ax.legend(fontsize = <span class="number">16</span>)</div></pre></td></tr></table></figure><p>结果如下图，<br><img src="/images/15157398435931.jpg" alt=""></p><hr><p>画a*b的子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fig, axes = plt.subplots(<span class="number">3</span>,<span class="number">3</span>, figsize = (<span class="number">30</span>, <span class="number">20</span>))</div><div class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果 也就是下面的Energy_sources</span></div><div class="line"><span class="keyword">for</span> (desc, group), ax <span class="keyword">in</span> zip(Energy_sources, axes.flatten()):</div><div class="line">    group.plot(x = group.index, y=<span class="string">'Value'</span>,ax = ax, title=desc, fontsize = <span class="number">18</span>)</div><div class="line">    ax.set_xlabel(<span class="string">'Time(Monthly)'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'Carbon Emissions in MMT'</span>)</div><div class="line">    ax.xaxis.label.set_size(<span class="number">18</span>)</div><div class="line">    ax.yaxis.label.set_size(<span class="number">18</span>)</div></pre></td></tr></table></figure><p><img src="/images/15157402388676.jpg" alt=""></p><hr><p>画柱状图</p><p><img src="/images/Screen%20Shot%202018-01-12%20at%2015.19.32.png" alt="Screen Shot 2018-01-12 at 15.19.32"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">fig = plt.figure(figsize = (<span class="number">16</span>,<span class="number">9</span>))</div><div class="line"><span class="comment"># CO2_per_source的来源与结构如上图</span></div><div class="line">x_label = map(<span class="keyword">lambda</span> x: x[:<span class="number">20</span>],CO2_per_source.index)</div><div class="line">x_tick = np.arange(len(cols))</div><div class="line">plt.bar(x_tick, CO2_per_source, align = <span class="string">'center'</span>, alpha = <span class="number">0.5</span>)</div><div class="line">fig.suptitle(<span class="string">"CO2 Emissions by Electric Power Sector"</span>, fontsize= <span class="number">25</span>)</div><div class="line">plt.xticks(x_tick, x_label, rotation = <span class="number">70</span>, fontsize = <span class="number">15</span>)</div><div class="line">plt.yticks(fontsize = <span class="number">20</span>)</div><div class="line">plt.xlabel(<span class="string">'Carbon Emissions in MMT'</span>, fontsize = <span class="number">20</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15157416530029.jpg" alt=""></p><hr><p>重叠图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statsmodels.tsa.seasonal <span class="keyword">import</span> seasonal_decompose</div><div class="line">decomposition = seasonal_decompose(mte)</div><div class="line"></div><div class="line">trend = decomposition.trend</div><div class="line">seasonal = decomposition.seasonal</div><div class="line">residual = decomposition.resid</div><div class="line"></div><div class="line">plt.subplot(<span class="number">411</span>)</div><div class="line">plt.plot(mte, label=<span class="string">'Original'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">412</span>)</div><div class="line">plt.plot(trend, label=<span class="string">'Trend'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">413</span>)</div><div class="line">plt.plot(seasonal,label=<span class="string">'Seasonality'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.subplot(<span class="number">414</span>)</div><div class="line">plt.plot(residual, label=<span class="string">'Residuals'</span>)</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.tight_layout()</div></pre></td></tr></table></figure><p><img src="/images/15157543822442.jpg" alt=""></p><hr><p>环形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">15</span>))</div><div class="line">data=response[<span class="string">'PublicDatasetsSelect'</span>].str.split(<span class="string">','</span>)</div><div class="line">dataset=[]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.dropna():</div><div class="line">    dataset.extend(i)</div><div class="line">pd.Series(dataset).value_counts().plot.pie(autopct=<span class="string">'%1.1f%%'</span>,colors=sns.color_palette(<span class="string">'Paired'</span>,<span class="number">10</span>),startangle=<span class="number">90</span>,wedgeprops = &#123; <span class="string">'linewidth'</span> : <span class="number">2</span>, <span class="string">'edgecolor'</span> : <span class="string">'white'</span> &#125;)</div><div class="line">plt.title(<span class="string">'Dataset Source'</span>)</div><div class="line">my_circle=plt.Circle( (<span class="number">0</span>,<span class="number">0</span>), <span class="number">0.7</span>, color=<span class="string">'white'</span>)</div><div class="line">p=plt.gcf()</div><div class="line">p.gca().add_artist(my_circle)</div><div class="line">plt.ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159953413652.jpg" alt=""></p><hr><p>饼状图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">response[<span class="string">'JobSkillImportancePython'</span>].value_counts().plot.pie(ax=ax[<span class="number">0</span>],autopct=<span class="string">'%1.1f%%'</span>,explode=[<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0</span>],shadow=<span class="keyword">True</span>,colors=[<span class="string">'g'</span>,<span class="string">'lightblue'</span>,<span class="string">'r'</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Python Necessity'</span>)</div><div class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">response[<span class="string">'JobSkillImportanceR'</span>].value_counts().plot.pie(ax=ax[<span class="number">1</span>],autopct=<span class="string">'%1.1f%%'</span>,explode=[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0</span>],shadow=<span class="keyword">True</span>,colors=[<span class="string">'lightblue'</span>,<span class="string">'g'</span>,<span class="string">'r'</span>])</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'R Necessity'</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159954686370.jpg" alt=""></p><hr><p>维恩图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">pd.Series([python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]],index=[<span class="string">'Python'</span>,<span class="string">'R'</span>,<span class="string">'Both'</span>]).plot.bar(ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Number of Users'</span>)</div><div class="line">venn2(subsets = (python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]), set_labels = (<span class="string">'Python Users'</span>, <span class="string">'R Users'</span>))</div><div class="line">plt.title(<span class="string">'Venn Diagram for Users'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159955616741.jpg" alt=""></p><h2 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h2><p>count plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">22</span>,<span class="number">12</span>))</div><div class="line">sns.countplot(y=response[<span class="string">'GenderSelect'</span>],order=response[<span class="string">'GenderSelect'</span>].value_counts().index)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159941639903.jpg" alt=""></p><hr><p>利用squarify画树形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> squarify</div><div class="line">tree=response[<span class="string">'Country'</span>].value_counts().to_frame()</div><div class="line">squarify.plot(sizes=tree[<span class="string">'Country'</span>].values,label=tree.index,color=sns.color_palette(<span class="string">'RdYlGn_r'</span>,<span class="number">52</span>))</div><div class="line">plt.rcParams.update(&#123;<span class="string">'font.size'</span>:<span class="number">20</span>&#125;)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">40</span>,<span class="number">15</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159945932245.jpg" alt=""></p><hr><p>sns画分布图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">8</span>))</div><div class="line">salary=salary[salary[<span class="string">'Salary'</span>]&lt;<span class="number">1000000</span>]</div><div class="line">sns.distplot(salary[<span class="string">'Salary'</span>])</div><div class="line">plt.title(<span class="string">'Salary Distribution'</span>,size=<span class="number">15</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159947979455.jpg" alt=""></p><hr><p>sns子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</div><div class="line">sal_coun=salary.groupby(<span class="string">'Country'</span>)[<span class="string">'Salary'</span>].median().sort_values(ascending=<span class="keyword">False</span>)[:<span class="number">15</span>].to_frame()</div><div class="line">sns.barplot(<span class="string">'Salary'</span>,sal_coun.index,data=sal_coun,palette=<span class="string">'RdYlGn'</span>,ax=ax[<span class="number">0</span>])</div><div class="line">ax[<span class="number">0</span>].axvline(salary[<span class="string">'Salary'</span>].median(),linestyle=<span class="string">'dashed'</span>)</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Highest Salary Paying Countries'</span>)</div><div class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">''</span>)</div><div class="line">max_coun=salary.groupby(<span class="string">'Country'</span>)[<span class="string">'Salary'</span>].median().to_frame()</div><div class="line">max_coun=max_coun[max_coun.index.isin(resp_coun.index)]</div><div class="line">max_coun.sort_values(by=<span class="string">'Salary'</span>,ascending=<span class="keyword">True</span>).plot.barh(width=<span class="number">0.8</span>,ax=ax[<span class="number">1</span>],color=sns.color_palette(<span class="string">'RdYlGn'</span>))</div><div class="line">ax[<span class="number">1</span>].axvline(salary[<span class="string">'Salary'</span>].median(),linestyle=<span class="string">'dashed'</span>)</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Compensation of Top 15 Respondent Countries'</span>)</div><div class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">''</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159948678550.jpg" alt=""></p><hr><p>seaborn箱型图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">plt.subplots(figsize=(<span class="number">10</span>,<span class="number">8</span>))</div><div class="line">sns.boxplot(y=<span class="string">'GenderSelect'</span>,x=<span class="string">'Salary'</span>,data=salary)</div><div class="line">plt.ylabel(<span class="string">''</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159949427978.jpg" alt=""></p><hr><p>seaborn count_plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">25</span>,<span class="number">15</span>))</div><div class="line">sns.countplot(y=response[<span class="string">'MajorSelect'</span>],ax=ax[<span class="number">0</span>],order=response[<span class="string">'MajorSelect'</span>].value_counts().index)</div><div class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Major'</span>)</div><div class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">sns.countplot(y=response[<span class="string">'CurrentJobTitleSelect'</span>],ax=ax[<span class="number">1</span>],order=response[<span class="string">'CurrentJobTitleSelect'</span>].value_counts().index)</div><div class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Current Job'</span>)</div><div class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">''</span>)</div><div class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159950249702.jpg" alt=""></p><hr><p>seaborn 图中添加文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sal_job=salary.groupby(<span class="string">'CurrentJobTitleSelect'</span>)[<span class="string">'Salary'</span>].median().to_frame().sort_values(by=<span class="string">'Salary'</span>,ascending=<span class="keyword">False</span>)</div><div class="line">ax=sns.barplot(sal_job.Salary,sal_job.index,palette=sns.color_palette(<span class="string">'inferno'</span>,<span class="number">20</span>))</div><div class="line">plt.title(<span class="string">'Compensation By Job Title'</span>,size=<span class="number">15</span>)</div><div class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(sal_job.Salary): </div><div class="line">    ax.text(<span class="number">.5</span>, i, v,fontsize=<span class="number">10</span>,color=<span class="string">'white'</span>,weight=<span class="string">'bold'</span>)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">8</span>,<span class="number">8</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159951024672.jpg" alt=""></p><hr><p>词云</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud, STOPWORDS</div><div class="line"><span class="keyword">import</span> nltk</div><div class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line">free=pd.read_csv(<span class="string">'../input/freeformResponses.csv'</span>)</div><div class="line">stop_words=set(stopwords.words(<span class="string">'english'</span>))</div><div class="line">stop_words.update(<span class="string">','</span>,<span class="string">';'</span>,<span class="string">'!'</span>,<span class="string">'?'</span>,<span class="string">'.'</span>,<span class="string">'('</span>,<span class="string">')'</span>,<span class="string">'$'</span>,<span class="string">'#'</span>,<span class="string">'+'</span>,<span class="string">':'</span>,<span class="string">'...'</span>)</div><div class="line">motivation=free[<span class="string">'KaggleMotivationFreeForm'</span>].dropna().apply(nltk.word_tokenize)</div><div class="line">motivate=[]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> motivation:</div><div class="line">    motivate.extend(i)</div><div class="line">motivate=pd.Series(motivate)</div><div class="line">motivate=([i <span class="keyword">for</span> i <span class="keyword">in</span> motivate.str.lower() <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> stop_words])</div><div class="line">f1=open(<span class="string">"kaggle.png"</span>, <span class="string">"wb"</span>)</div><div class="line">f1.write(codecs.decode(kaggle,<span class="string">'base64'</span>))</div><div class="line">f1.close()</div><div class="line">img1 = imread(<span class="string">"kaggle.png"</span>)</div><div class="line">hcmask1 = img1</div><div class="line">wc = WordCloud(background_color=<span class="string">"black"</span>, max_words=<span class="number">4000</span>, mask=hcmask1, </div><div class="line">               stopwords=STOPWORDS, max_font_size= <span class="number">60</span>,width=<span class="number">1000</span>,height=<span class="number">1000</span>)</div><div class="line">wc.generate(<span class="string">" "</span>.join(motivate))</div><div class="line">plt.imshow(wc)</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">fig=plt.gcf()</div><div class="line">fig.set_size_inches(<span class="number">10</span>,<span class="number">10</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15159971204332.jpg" alt=""></p><hr><p>简单情况下的分类展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</div><div class="line"></div><div class="line">h = <span class="number">0.01</span></div><div class="line">x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></div><div class="line">y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></div><div class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(X, y, w, history)</span>:</span></div><div class="line">    <span class="string">"""draws classifier prediction with matplotlib magic"""</span></div><div class="line">    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)</div><div class="line">    Z = Z.reshape(xx.shape)</div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</div><div class="line">    plt.contourf(xx, yy, Z, alpha=<span class="number">0.8</span>)</div><div class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired)</div><div class="line">    plt.xlim(xx.min(), xx.max())</div><div class="line">    plt.ylim(yy.min(), yy.max())</div><div class="line">    </div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    plt.plot(history)</div><div class="line">    plt.grid()</div><div class="line">    ymin, ymax = plt.ylim()</div><div class="line">    plt.ylim(<span class="number">0</span>, ymax)</div><div class="line">    display.clear_output(wait=<span class="keyword">True</span>)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15163355887784.jpg" alt=""></p><hr><p>图中插入LaTeX公式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line">x = np.linspace(<span class="number">-3</span>, <span class="number">3</span>)</div><div class="line">x_squared, x_squared_der = s.run([scalar_squared, derivative[<span class="number">0</span>]],</div><div class="line">                                 &#123;my_scalar:x&#125;)</div><div class="line"></div><div class="line">plt.plot(x, x_squared,label=<span class="string">"$x^2$"</span>)</div><div class="line">plt.plot(x, x_squared_der, label=<span class="string">r"$\frac&#123;dx^2&#125;&#123;dx&#125;$"</span>)</div><div class="line">plt.legend();</div></pre></td></tr></table></figure><p><img src="/images/15163465540386.jpg" alt=""></p><hr><p>画多张子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># show random images from train</span></div><div class="line">cols = <span class="number">8</span></div><div class="line">rows = <span class="number">2</span></div><div class="line">fig = plt.figure(figsize=(<span class="number">2</span> * cols - <span class="number">1</span>, <span class="number">2.5</span> * rows - <span class="number">1</span>))</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(cols):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(rows):</div><div class="line">        random_index = np.random.randint(<span class="number">0</span>, len(y_train))</div><div class="line">        ax = fig.add_subplot(rows, cols, i * rows + j + <span class="number">1</span>)</div><div class="line">        ax.grid(<span class="string">'off'</span>)</div><div class="line">        ax.axis(<span class="string">'off'</span>)</div><div class="line">        ax.imshow(x_train[random_index, :])</div><div class="line">        ax.set_title(cifar10_classes[y_train[random_index, <span class="number">0</span>]])</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="/images/15167635233971.jpg" alt=""></p><h2 id="特征工程阶段"><a href="#特征工程阶段" class="headerlink" title="特征工程阶段"></a>特征工程阶段</h2><p>Numpy区间百分比切分异常值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cut off long distance trips</span></div><div class="line">lat_low, lat_hgh = np.percentile(latlong[:,<span class="number">0</span>], [<span class="number">2</span>, <span class="number">98</span>])</div><div class="line">lon_low, lon_hgh = np.percentile(latlong[:,<span class="number">1</span>], [<span class="number">2</span>, <span class="number">98</span>])</div></pre></td></tr></table></figure><hr><p>初始化同shape向量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">g2 = np.zeros_like(w)</div><div class="line">``</div><div class="line"></div><div class="line">-------</div><div class="line"></div><div class="line">累积sum</div><div class="line">``` python</div><div class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.cumsum(a,axis=<span class="number">1</span>)      <span class="comment"># sum over columns for each of the 2 rows</span></div><div class="line">array([[ <span class="number">1</span>,  <span class="number">3</span>,  <span class="number">6</span>],</div><div class="line">       [ <span class="number">4</span>,  <span class="number">9</span>, <span class="number">15</span>]])</div><div class="line">``` </div><div class="line"></div><div class="line">-------</div><div class="line">numpy array 扩展维度，很简单地将Numpy向量扩展为二维矩阵</div><div class="line">![](/images/<span class="number">15167894435840.</span>png)</div><div class="line">![Screen Shot <span class="number">2018</span><span class="number">-01</span><span class="number">-24</span> at <span class="number">19.02</span><span class="number">.32</span>](/images/Screen%<span class="number">20</span>Shot%<span class="number">202018</span><span class="number">-01</span><span class="number">-24</span>%<span class="number">20</span>at%<span class="number">2019.02</span><span class="number">.32</span>.png)</div><div class="line"></div><div class="line">-------</div><div class="line">Numpy 竖着叠放向量</div><div class="line">`np.column_stack`</div><div class="line"></div><div class="line">-------</div><div class="line"></div><div class="line">``` python</div><div class="line"><span class="comment"># 用于查看Dataframe各列数据类型</span></div><div class="line">ts.dtypes</div></pre></td></tr></table></figure></p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#skew是单变量工具，用来监测数据是否有长尾，左偏或者右偏</span></div><div class="line">print(Y_train.skew())</div><div class="line">``` </div><div class="line"></div><div class="line">``` python</div><div class="line"><span class="comment">#np.abs 是绝对值函数，用来取整个向量绝对值</span></div><div class="line"><span class="comment"># 这里对所有train里的特征求偏度并排序</span></div><div class="line">np.abs(combined[:ntrain].skew()).sort_values(ascending = <span class="keyword">False</span> ).head(<span class="number">20</span>)</div></pre></td></tr></table></figure><p>有偏度 - 需要处理。通常是用log1p </p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于将Dataframe中被读取为object的数据转换为数值型，errors='coerce'代表错误将被置为NaN</span></div><div class="line">ts[<span class="string">'Value'</span>] = pd.to_numeric(ts[<span class="string">'Value'</span>] , errors=<span class="string">'coerce'</span>)</div></pre></td></tr></table></figure><hr><p>过滤index 里面的NaN值，推广也可以过滤其他列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ts = df.loc[pd.Series(pd.to_datetime(df.index, errors=<span class="string">'coerce'</span>)).notnull().values]</div></pre></td></tr></table></figure><hr><p>按月groupby，以及unstack解构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Emissions.groupby([<span class="string">'Description'</span>, pd.TimeGrouper(<span class="string">'M'</span>)])[<span class="string">'Value'</span>].sum().unstack(level = <span class="number">0</span>)</div></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202018-01-12%20at%2016.16.30.png" alt="Screen Shot 2018-01-12 at 16.16.30"></p><hr><p>将value_counts、groupby等Series转换为Dataframe<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tree=response[<span class="string">'Country'</span>].value_counts().to_frame()</div></pre></td></tr></table></figure></p><hr><p>特征工程大杀器，<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html?highlight=pipe#tablewise-function-application" target="_blank" rel="external">Pandas Pipe</a><br>这里有个简单的例子，,每个pipes里面都有若干个特征处理函数和一个快速测试的函数，其中为了对齐美观，用bypass函数来填充空白的地方（无用但是为了强行让pipes长度相同）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">pipe_basic = [pipe_basic_fillna,pipe_bypass,\</div><div class="line">              pipe_bypass,pipe_bypass,\</div><div class="line">              pipe_bypass,pipe_bypass,\</div><div class="line">              pipe_log_getdummies,pipe_bypass, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line"></div><div class="line">pipe_ascat = [pipe_fillna_ascat,pipe_drop_cols,\</div><div class="line">              pipe_drop4cols,pipe_outliersdrop,\</div><div class="line">              pipe_extract,pipe_bypass,\</div><div class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line">pipe_ascat_unitprice = [pipe_fillna_ascat,pipe_drop_cols,\</div><div class="line">              pipe_drop4cols,pipe_outliersdrop,\</div><div class="line">              pipe_extract,pipe_unitprice,\</div><div class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</div><div class="line">              pipe_export,pipe_r2test]</div><div class="line"></div><div class="line">pipes = [pipe_basic,pipe_ascat,pipe_ascat_unitprice ]</div></pre></td></tr></table></figure><p>跑的代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(pipes)):</div><div class="line">    print(<span class="string">"*"</span>*<span class="number">10</span>,<span class="string">"\n"</span>)</div><div class="line">    pipe_output=pipes[i]</div><div class="line">    output_name =<span class="string">"_"</span>.join([x.__name__[<span class="number">5</span>:] <span class="keyword">for</span> x <span class="keyword">in</span> pipe_output <span class="keyword">if</span> x.__name__ <span class="keyword">is</span> <span class="keyword">not</span> <span class="string">"pipe_bypass"</span>])</div><div class="line">    output_name = <span class="string">"PIPE_"</span> +output_name</div><div class="line">    print(output_name)</div><div class="line">    (combined.pipe(pipe_output[<span class="number">0</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">1</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">2</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">3</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">4</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">5</span>])          </div><div class="line">             .pipe(pipe_output[<span class="number">6</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">7</span>])</div><div class="line">             .pipe(pipe_output[<span class="number">8</span>],name=output_name)</div><div class="line">             .pipe(pipe_output[<span class="number">9</span>])</div><div class="line">             ）</div></pre></td></tr></table></figure><p>在这一步，我们可以初步看到三个特征工程的性能。并且文件已经输出到hd5格式文件。后期在训练和预测时，直接取出预处理的文件就可以。各个pipe代码可见<a href="https://gist.github.com/frankchen0130/5950eaa4d98ea4f93deed707b027b517" target="_blank" rel="external">此处</a>。</p><h2 id="调参阶段"><a href="#调参阶段" class="headerlink" title="调参阶段"></a>调参阶段</h2><p>在数据准备好后训练时，最基本的就是要调整超参（Hyperparameter）耗时耗力，并且和发生错误和遗漏情况。<br>Stackoverflow上常见的算法训练错误有：</p><ul><li>算法预测的结果差异非常大。 其中一个可能就是训练时的标准化步骤，在预测时遗漏了。</li><li>算法的调参结果差异非常大。（有的是0.01,有的就是10）。其中的一个可能就是不同的训练步骤中采用的标准化算法不同（例如,一次用了StandardScaler, 另一次用了RobustScaler)</li><li>此外，繁多的超参数调整起来异常繁琐。比较容易错误或者写错。</li></ul><p><strong>解决方法：Pipeline + Gridsearch + 参数字典 + 容器。</strong><br>使用Pipeline的例子</p><p>针对线形回归问题，Sklearn提供了超过15种回归算法。利用Pipeline 大法可以综合测试所有算法，找到最合适的算法。 具体步骤如下：</p><ol><li><p>初始化所有希望调测线形回归。</p></li><li><p>建立一个字典容器。{“算法名称”:[初始算法对象，参数字典，训练好的Pipeline模型对象，CV的成绩}</p></li><li><p>在调参步骤，将初始算法用Pipeline包装起来，利用Gridsearch进行调参。调参完成后可以得到针对相应的CV而获得的最后模型对象。 例如： lasso 算法的步骤如下：</p></li></ol><ul><li>包装 pipe=Pipeline([(“scaler”:None),(“selector”:None),(“clf”:Lasso())<ul><li>Pipe就是刚刚包装好的算法。可以直接用于 训练(fit)和预测(predict)</li><li>使用Pipe来处理训练集和测试集可以避免错误和遗漏，提高效率。</li><li>但是Pipe中算法是默认的参数，直接训练出的模型RMSE不太理想。（例如：local CV, 0.12~0.14左右）。这时可以考虑调参。</li></ul></li><li>调参第一步：准备参数字典：<br>  Params_lasso ={<br>  “Scaler”:[RobustScaler(),StandardScaler()], #两个标准化算法供调模型<br>  “selector<strong>threshold”:np.logspace(-5,-4,3), #3个选择门限供选特征<br>  “clf</strong>alpha”:np.logspace(-5,-1,10) }， #10个alpha指供调参</li><li>调参第二步：暴力调参和生成模型 rsearch = GridSearchCV(pipe, param_grid=Params_lasso,scoring =’neg_mean_squared_error’,verbose=verbose,cv=10,refit =True)<ul><li>GridSearch 是暴力调参。遍历所有参数组合，另外有一个RandomedSearch 可以随机选择参数组合，缩短调参时间，并且获得近似的调参性能</li><li>Pipe就是刚刚包装好的算法。GridSearch把可选的参数和算法（放入，或者更好的组合。</li><li>调参的训练标准是“’neg_mean_squared_error”, RMSE的负数。 这种处理方法，让最大值称为最小的MSE指。只需要对结果做一次np.sqrt( 结果负数）就能获得RMSE值。</li><li>cv=10. Cross Validate 数据集为9：1。数据集小的情况，例如House Price. 3折和10折结果甚至比调参差异还大。</li><li>refit =True. 在调参完成后，再需要做一次所有数据集的fit. 生成完整的训练模型</li></ul></li></ul><hr><p>Sklearn 流程图<br><img src="/images/15161696298310.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15161698020879.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Python" scheme="http://frankchen.xyz/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>DIY远程Jupyter Notebook服务器</title>
    <link href="http://frankchen.xyz/2017/12/25/Remote-jupyter-notebook/"/>
    <id>http://frankchen.xyz/2017/12/25/Remote-jupyter-notebook/</id>
    <published>2017-12-25T11:43:17.000Z</published>
    <updated>2017-12-25T11:48:42.351Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15142020075328.jpg" alt="Screen Shot 2017-07-18 at 14.16.18"><br>构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。<br><a id="more"></a></p><h2 id="完全开放，不需密码"><a href="#完全开放，不需密码" class="headerlink" title="完全开放，不需密码"></a>完全开放，不需密码</h2><h3 id="1-登陆远程服务器"><a href="#1-登陆远程服务器" class="headerlink" title="1.  登陆远程服务器"></a>1.  登陆远程服务器</h3><h3 id="2-生成配置文件"><a href="#2-生成配置文件" class="headerlink" title="2.生成配置文件"></a>2.生成配置文件</h3><p><code>$jupyter notebook --generate-config</code></p><h3 id="3-修改默认配置文件"><a href="#3-修改默认配置文件" class="headerlink" title="3. 修改默认配置文件"></a>3. 修改默认配置文件</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py</code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.ip = <span class="string">'0.0.0.0'</span>      <span class="comment">#支持其它IP访问，关键</span></div><div class="line">c.NotebookApp.port = <span class="number">10000</span> <span class="comment">#随便指定一个端口</span></div></pre></td></tr></table></figure><h3 id="4-启动jupyter-notebook："><a href="#4-启动jupyter-notebook：" class="headerlink" title="4. 启动jupyter notebook："></a>4. 启动jupyter notebook：</h3><p><code>jupyter notebook</code></p><h3 id="5-远程访问"><a href="#5-远程访问" class="headerlink" title="5. 远程访问"></a>5. 远程访问</h3><p>此时应该可以直接从本地浏览器直接访问<code>http://address_of_remote:10000</code>就可以看到jupyter的登陆界面，输入密码即可。</p><h2 id="需要密码"><a href="#需要密码" class="headerlink" title="需要密码"></a>需要密码</h2><h3 id="1-生成密码"><a href="#1-生成密码" class="headerlink" title="1. 生成密码"></a>1. 生成密码</h3><p>打开ipython，创建一个密文的密码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</div><div class="line">In [<span class="number">2</span>]: passwd()</div><div class="line">Enter password: </div><div class="line">Verify password: </div><div class="line">Out[<span class="number">2</span>]: <span class="string">'sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274'</span></div></pre></td></tr></table></figure><h3 id="2-添加密码"><a href="#2-添加密码" class="headerlink" title="2. 添加密码"></a>2. 添加密码</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py</code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.password = <span class="string">u'sha:ce...刚才复制的那个密文'</span></div></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202017-07-18%20at%2014.16.18.png" alt="Screen Shot 2017-07-18 at 14.16.18"></p><h3 id="3-建立ssh通道"><a href="#3-建立ssh通道" class="headerlink" title="3. 建立ssh通道"></a>3. 建立ssh通道</h3><p>若还是无法登录，也可用</p><p><code>ssh username@address_of_remote -L 127.0.0.1:10000:127.0.0.1:10000</code></p><p>建立ssh通道，便可以在localhost:10000直接访问远程的jupyter了。</p><h2 id="添加system开机自启"><a href="#添加system开机自启" class="headerlink" title="添加system开机自启"></a>添加system开机自启</h2><p>将 Jupyter Notebook 设定为系统服务并且开机自动启动，这里以 systemd 下的设定为例，创建文件 <code>sudo vim /etc/systemd/system/jupyter.service</code>文件，内容是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[Unit]</div><div class="line">Description=Jupyter Notebook</div><div class="line">After=network.target</div><div class="line"></div><div class="line">[Service]</div><div class="line">Type=simple</div><div class="line">ExecStart=/home/frank/anaconda3/bin/jupyter-notebook  --config=/home/frank/.jupyter/jupyter_notebook_config.py --no-browser</div><div class="line">User=frank</div><div class="line">Group=frank</div><div class="line">WorkingDirectory=/home/frank/</div><div class="line">Restart=always</div><div class="line">RestartSec=10</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure><p>上面你需要把我的用户名frank替换掉，保存文件之后执行<br><code>systemctl enable jupyter</code><br>再执行<br><code>systemctl start jupyter</code><br>即可，需要输入几次密码，之后重启Notebook会自启。</p><p><img src="/images/Screen%20Shot%202017-12-25%20at%2019.32.28.png" alt="Screen Shot 2017-12-25 at 19.32.28"></p><h2 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h2><p>结合下文的方法，用ftp即可做到</p><ul><li><a href="http://frankchen.xyz/2017/11/12/ftp-using/">frp的内网穿透及外网访问内网jupyter-notebook的实现 | 不正经数据科学家</a></li></ul><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/23110830" target="_blank" rel="external">Jupyter (IPython notebook)用于服务器的配置方法(Windows) - 知乎专栏</a></li><li><a href="http://blog.leanote.com/post/jevonswang/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AEjupyter-notebook" target="_blank" rel="external">远程访问jupyter notebook</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15142020075328.jpg&quot; alt=&quot;Screen Shot 2017-07-18 at 14.16.18&quot;&gt;&lt;br&gt;构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Linux" scheme="http://frankchen.xyz/tags/Linux/"/>
    
      <category term="Jupyter Notebook" scheme="http://frankchen.xyz/tags/Jupyter-Notebook/"/>
    
  </entry>
  
  <entry>
    <title>深度学习中Keras中的Embedding层的理解与使用</title>
    <link href="http://frankchen.xyz/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/"/>
    <id>http://frankchen.xyz/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/</id>
    <published>2017-12-18T07:59:41.000Z</published>
    <updated>2018-03-08T08:44:07.373Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15135840798621.jpg" alt=""><br>单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。<br><a id="more"></a></p><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>单词嵌入是使用密集的矢量表示来表示单词和文档的一类方法。</p><p>词嵌入是对传统的词袋模型编码方案的改进，传统方法使用大而稀疏的矢量来表示每个单词或者在矢量内对每个单词进行评分以表示整个词汇表，这些表示是稀疏的，因为每个词汇的表示是巨大的，给定的词或文档主要由零值组成的大向量表示。</p><p>相反，在嵌入中，单词由密集向量表示，其中向量表示将单词投影到连续向量空间中。</p><p>向量空间中的单词的位置是从文本中学习的，并且基于在使用单词时围绕单词的单词。</p><p>学习到的向量空间中的单词的位置被称为它的嵌入：Embedding。</p><p>从文本学习单词嵌入方法的两个流行例子包括：</p><ul><li>Word2Vec.</li><li>GloVe.</li></ul><p>除了这些精心设计的方法之外，还可以将词嵌入学习作为深度学习模型的一部分。这可能是一个较慢的方法，但可以通过这样为特定数据集定制模型。</p><h2 id="Keras-Embedding-Layer"><a href="#Keras-Embedding-Layer" class="headerlink" title="Keras Embedding Layer"></a>Keras Embedding Layer</h2><p>Keras提供了一个嵌入层，适用于文本数据的神经网络。</p><p>它要求输入数据是整数编码的，所以每个字都用一个唯一的整数表示。这个数据准备步骤可以使用Keras提供的Tokenizer API来执行。</p><p>嵌入层用随机权重进行初始化，并将学习训练数据集中所有单词的嵌入。</p><p>它是一个灵活的图层，可以以多种方式使用，例如：</p><ul><li>它可以单独使用来学习一个单词嵌入，以后可以保存并在另一个模型中使用。</li><li>它可以用作深度学习模型的一部分，其中嵌入与模型本身一起学习。</li><li>它可以用来加载预先训练的词嵌入模型，这是一种迁移学习。</li></ul><p>嵌入层被定义为网络的第一个隐藏层。它必须指定3个参数：</p><ul><li>input_dim：这是文本数据中词汇的取值可能数。例如，如果您的数据是整数编码为0-9之间的值，那么词汇的大小就是10个单词；</li><li>output_dim：这是嵌入单词的向量空间的大小。它为每个单词定义了这个层的输出向量的大小。例如，它可能是32或100甚至更大，可以视为具体问题的超参数；</li><li>input_length：这是输入序列的长度，就像您为Keras模型的任何输入层所定义的一样，也就是一次输入带有的词汇个数。例如，如果您的所有输入文档都由1000个字组成，那么input_length就是1000。</li></ul><p>例如，下面我们定义一个词汇表为200的嵌入层（例如从0到199的整数编码的字，包括0到199），一个32维的向量空间，其中将嵌入单词，以及输入文档，每个单词有50个单词。</p><p><code>e = Embedding(input_dim=200, output_dim=32, input_length=50)</code></p><p>嵌入层自带学习的权重，如果将模型保存到文件中，则将包含嵌入图层的权重。</p><p>嵌入层的输出是一个二维向量，每个单词在输入文本（输入文档）序列中嵌入一个。</p><p>如果您希望直接将Dense层接到Embedding层后面，则必须先使用Flatten层将Embedding层的2D输出矩阵平铺为一维矢量。</p><p>现在，让我们看看我们如何在实践中使用嵌入层。</p><h2 id="学习-Embedding的例子"><a href="#学习-Embedding的例子" class="headerlink" title="学习 Embedding的例子"></a>学习 Embedding的例子</h2><p>在本节中，我们将看看如何在文本分类问题上拟合神经网络的同时学习单词嵌入。</p><p>我们将定义一个小问题，我们有10个文本文档，每个文档都有一个学生提交的工作评论。每个文本文档被分类为正的“1”或负的“0”。这是一个简单的情感分析问题。</p><p>首先，我们将定义文档及其类别标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define documents 定义文档</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels 定义分类标签</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div></pre></td></tr></table></figure><p>接下来，我们来整数编码每个文件。这意味着把输入，嵌入层将具有整数序列。我们可以尝试其他更复杂的bag of word 模型比如计数或TF-IDF。</p><p>Keras提供<a href="https://keras.io/preprocessing/text/#one_hot" target="_blank" rel="external">one_hot()</a>函数来创建每个单词的散列作为一个有效的整数编码。我们用估计50的词汇表大小，这大大减少了hash函数的冲突概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># integer encode the documents 独热编码</span></div><div class="line">vocab_size = <span class="number">50</span></div><div class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</div><div class="line">print(encoded_docs)</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[[6, 16], [42, 24], [2, 17], [42, 24], [18], [17], [22, 17], [27, 42], [22, 24], [49, 46, 16, 34]]</div></pre></td></tr></table></figure><p>这样以后序列具有不同的长度，但是Keras更喜欢输入矢量化和所有输入具有相同的长度。我们将填充所有输入序列的长度为4，同样，我们可以使用内置的Keras函数（在这种情况下为<a href="https://keras.io/preprocessing/sequence/#pad_sequences" target="_blank" rel="external">pad_sequences()</a>函数）执行此操作,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># pad documents to a max length of 4 words 将不足长度的用0填充为长度4</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[[ 6 16  0  0]</div><div class="line"> [42 24  0  0]</div><div class="line"> [ 2 17  0  0]</div><div class="line"> [42 24  0  0]</div><div class="line"> [18  0  0  0]</div><div class="line"> [17  0  0  0]</div><div class="line"> [22 17  0  0]</div><div class="line"> [27 42  0  0]</div><div class="line"> [22 24  0  0]</div><div class="line"> [49 46 16 34]]</div></pre></td></tr></table></figure><p>我们现在准备将我们的嵌入层定义为我们的神经网络模型的一部分。</p><p>嵌入的词汇量为50，输入长度为4，我们将选择一个8维的嵌入空间。</p><p>该模型是一个简单的二元分类模型。重要的是，嵌入层的输出将是每个8维的4个矢量，每个单词一个。我们将其平铺到一个32个元素的向量上以传递到密集输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define the model 定义模型</span></div><div class="line">model = Sequential()</div><div class="line">model.add(Embedding(vocab_size, <span class="number">8</span>, input_length=max_length))</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># compile the model 编译</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model 打印模型信息</span></div><div class="line">print(model.summary())</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #</div><div class="line">=================================================================</div><div class="line">embedding_1 (Embedding)      (None, 4, 8)              400</div><div class="line">_________________________________________________________________</div><div class="line">flatten_1 (Flatten)          (None, 32)                0</div><div class="line">_________________________________________________________________</div><div class="line">dense_1 (Dense)              (None, 1)                 33</div><div class="line">=================================================================</div><div class="line">Total params: 433</div><div class="line">Trainable params: 433</div><div class="line">Non-trainable params: 0</div><div class="line">_________________________________________________________________</div></pre></td></tr></table></figure><p>最后，我们可以拟合和评估分类模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># fit the model 拟合</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model 评估</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy*<span class="number">100</span>))</div></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Accuracy: 100.000000</div></pre></td></tr></table></figure><p>下面是完整的代码，这里我们用函数式API改写了模型定义，不过结构和上面是完全一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Flatten, Input</div><div class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</div><div class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</div><div class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> one_hot</div><div class="line"></div><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line">        <span class="string">'Good work'</span>,</div><div class="line">        <span class="string">'Great effort'</span>,</div><div class="line">        <span class="string">'nice work'</span>,</div><div class="line">        <span class="string">'Excellent!'</span>,</div><div class="line">        <span class="string">'Weak'</span>,</div><div class="line">        <span class="string">'Poor effort!'</span>,</div><div class="line">        <span class="string">'not good'</span>,</div><div class="line">        <span class="string">'poor work'</span>,</div><div class="line">        <span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">vocab_size = <span class="number">50</span></div><div class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div><div class="line"><span class="comment"># define the model</span></div><div class="line">input = Input(shape=(<span class="number">4</span>, ))</div><div class="line">x = Embedding(vocab_size, <span class="number">8</span>, input_length=max_length)(input)</div><div class="line">x = Flatten()(x)</div><div class="line">x = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</div><div class="line">model = Model(inputs=input, outputs=x)</div><div class="line"><span class="comment"># compile the model</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model</span></div><div class="line">print(model.summary())</div><div class="line"><span class="comment"># fit the model</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy * <span class="number">100</span>))</div></pre></td></tr></table></figure><p>之后，我们可以将嵌入图层中学习的权重保存到文件中，以便以后在其他模型中使用。</p><p>通常也可以使用这个模型来分类在测试数据集中看到的同类词汇的其他文档。</p><p>接下来，让我们看看在Keras中加载预先训练的词嵌入。</p><h2 id="使用预训练GloVE嵌入的示例"><a href="#使用预训练GloVE嵌入的示例" class="headerlink" title="使用预训练GloVE嵌入的示例"></a>使用预训练GloVE嵌入的示例</h2><p>Keras嵌入层也可以使用在其他地方学习的嵌入字。</p><p>在自然语言处理领域，学习，保存和分享提供词嵌入是很常见的。</p><p>例如，GloVe方法背后的研究人员提供了一套在公共领域许可下发布的预先训练的词嵌入。看到：</p><ul><li><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe: Global Vectors for Word Representation</a></li></ul><p>最小的包是822Mb，叫做“glove.6B.zip”。它训练了10亿个词汇（单词）的数据集，词汇量为40万字，有几种不同的嵌入矢量尺寸，包括50,100,200和300size。</p><p>您可以下载这个嵌入的集合，可以作为Keras嵌入层中训练数据集中的单词预先训练嵌入的权重。</p><p>这个例子受Keras项目中的一个例子的启发：<a href="https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py" target="_blank" rel="external">pretrained_word_embeddings.py</a>。</p><p>下载并解压缩后，您将看到几个文件，其中一个是“glove.6B.100d.txt”，其中包含一个100维版本的嵌入。</p><p>如果你在文件内部偷看，你会看到一个token（单词），后面是每行的权重（100个数字）。例如，下面是嵌入的ASCII文本文件的第一行，显示“the”的嵌入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062</div></pre></td></tr></table></figure><p>如前一节所述，第一步是定义这些示例，将它们编码为整数，然后将这些序列填充为相同的长度。</p><p>在这种情况下，我们需要能够将单词映射到整数以及整数到单词。</p><p>Keras提供了一个<a href="https://keras.io/preprocessing/text/#tokenizer" target="_blank" rel="external">Tokenizer</a>类，可以适应训练数据，通过调用Tokenizer类的texts_to_sequences（）方法，可以一致地将文本转换为序列，并且可以访问单词在word_index属性中的整数字典映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div><div class="line"><span class="comment"># prepare tokenizer</span></div><div class="line">t = Tokenizer()</div><div class="line">t.fit_on_texts(docs)</div><div class="line">vocab_size = len(t.word_index) + <span class="number">1</span></div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">encoded_docs = t.texts_to_sequences(docs)</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div></pre></td></tr></table></figure><p>接下来，我们需要将整个Glove字嵌入文件作为字的字典加载到内存中以嵌入数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load the whole embedding into memory</span></div><div class="line">embeddings_index = dict()</div><div class="line">f = open(<span class="string">'glove.6B.100d.txt'</span>)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">values = line.split()</div><div class="line">word = values[<span class="number">0</span>]</div><div class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</div><div class="line">embeddings_index[word] = coefs</div><div class="line">f.close()</div><div class="line">print(<span class="string">'Loaded %s word vectors.'</span> % len(embeddings_index))</div></pre></td></tr></table></figure><p>这很慢。在训练数据中过滤特殊字词的嵌入可能会更好。</p><p>接下来，我们需要为训练数据集中的每个单词创建一个嵌入矩阵。我们可以通过枚举Tokenizer.word_index中的所有唯一单词并从加载的GloVe嵌入中找到嵌入权重向量来实现这一点。</p><p>结果是一个仅用于训练期间将会看到的单词的权重矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a weight matrix for words in training docs</span></div><div class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</div><div class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</div><div class="line">embedding_vector = embeddings_index.get(word)</div><div class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">embedding_matrix[i] = embedding_vector</div></pre></td></tr></table></figure><p>现在我们可以像以前一样定义我们的模型，并进行评估。</p><p>关键的区别是嵌入层可以用GloVe字嵌入权重来播种。我们选择了100维版本，因此必须使用output_dim将其设置为100来定义嵌入层。最后，我们不希望更新此模型中的学习单词权重，因此我们将设置模型的可训练属性为False 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)</div></pre></td></tr></table></figure><p>下面列出了完整的工作示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> asarray</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</div><div class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</div><div class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</div><div class="line"><span class="comment"># define documents</span></div><div class="line">docs = [<span class="string">'Well done!'</span>,</div><div class="line"><span class="string">'Good work'</span>,</div><div class="line"><span class="string">'Great effort'</span>,</div><div class="line"><span class="string">'nice work'</span>,</div><div class="line"><span class="string">'Excellent!'</span>,</div><div class="line"><span class="string">'Weak'</span>,</div><div class="line"><span class="string">'Poor effort!'</span>,</div><div class="line"><span class="string">'not good'</span>,</div><div class="line"><span class="string">'poor work'</span>,</div><div class="line"><span class="string">'Could have done better.'</span>]</div><div class="line"><span class="comment"># define class labels</span></div><div class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</div><div class="line"><span class="comment"># prepare tokenizer</span></div><div class="line">t = Tokenizer()</div><div class="line">t.fit_on_texts(docs)</div><div class="line">vocab_size = len(t.word_index) + <span class="number">1</span></div><div class="line"><span class="comment"># integer encode the documents</span></div><div class="line">encoded_docs = t.texts_to_sequences(docs)</div><div class="line">print(encoded_docs)</div><div class="line"><span class="comment"># pad documents to a max length of 4 words</span></div><div class="line">max_length = <span class="number">4</span></div><div class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">'post'</span>)</div><div class="line">print(padded_docs)</div><div class="line"><span class="comment"># load the whole embedding into memory</span></div><div class="line">embeddings_index = dict()</div><div class="line">f = open(<span class="string">'../glove_data/glove.6B/glove.6B.100d.txt'</span>)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">values = line.split()</div><div class="line">word = values[<span class="number">0</span>]</div><div class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>)</div><div class="line">embeddings_index[word] = coefs</div><div class="line">f.close()</div><div class="line">print(<span class="string">'Loaded %s word vectors.'</span> % len(embeddings_index))</div><div class="line"><span class="comment"># create a weight matrix for words in training docs</span></div><div class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</div><div class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</div><div class="line">embedding_vector = embeddings_index.get(word)</div><div class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">embedding_matrix[i] = embedding_vector</div><div class="line"><span class="comment"># define model</span></div><div class="line">model = Sequential()</div><div class="line">e = Embedding(vocab_size, <span class="number">100</span>, weights=[embedding_matrix], input_length=<span class="number">4</span>, trainable=<span class="keyword">False</span>)</div><div class="line">model.add(e)</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># compile the model</span></div><div class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</div><div class="line"><span class="comment"># summarize the model</span></div><div class="line">print(model.summary())</div><div class="line"><span class="comment"># fit the model</span></div><div class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model</span></div><div class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Accuracy: %f'</span> % (accuracy*<span class="number">100</span>))</div></pre></td></tr></table></figure><p>运行这个例子可能需要更长的时间，但是这表明它能够适应这个简单的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]</div><div class="line"></div><div class="line">[[ 6  2  0  0]</div><div class="line"> [ 3  1  0  0]</div><div class="line"> [ 7  4  0  0]</div><div class="line"> [ 8  1  0  0]</div><div class="line"> [ 9  0  0  0]</div><div class="line"> [10  0  0  0]</div><div class="line"> [ 5  4  0  0]</div><div class="line"> [11  3  0  0]</div><div class="line"> [ 5  1  0  0]</div><div class="line"> [12 13  2 14]]</div><div class="line"></div><div class="line">Loaded 400000 word vectors.</div><div class="line"></div><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param #</div><div class="line">=================================================================</div><div class="line">embedding_1 (Embedding)      (None, 4, 100)            1500</div><div class="line">_________________________________________________________________</div><div class="line">flatten_1 (Flatten)          (None, 400)               0</div><div class="line">_________________________________________________________________</div><div class="line">dense_1 (Dense)              (None, 1)                 401</div><div class="line">=================================================================</div><div class="line">Total params: 1,901</div><div class="line">Trainable params: 401</div><div class="line">Non-trainable params: 1,500</div><div class="line">_________________________________________________________________</div><div class="line"></div><div class="line"></div><div class="line">Accuracy: 100.000000</div></pre></td></tr></table></figure><p>在实践中，最好还是尝试使用预先训练好的嵌入来学习单词嵌入，因为它是固定的，并尝试在预先训练好的嵌入之上进行学习，这就类似于计算机视觉里面用预训练的VGG或者res-net迁移具体问题那样。</p><p>不过这取决于什么最适合你的具体问题。</p><h2 id="IMDB-数据集Embedding实例"><a href="#IMDB-数据集Embedding实例" class="headerlink" title="IMDB 数据集Embedding实例"></a>IMDB 数据集Embedding实例</h2><p><img src="/images/15204978301733.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential,Model</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten, Dense, Embedding, Input</div><div class="line"></div><div class="line">input_layer = Input(shape=(maxlen,)) </div><div class="line">x = Embedding(input_dim=<span class="number">10000</span>,output_dim=<span class="number">8</span>)(input_layer)</div><div class="line"><span class="comment"># 单独做一个embedding模型，利于后面观察</span></div><div class="line">embedding = Model(input_layer,x)</div><div class="line">x = Flatten()(x)</div><div class="line">x = Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>)(x)</div><div class="line">model = Model(input_layer,x)</div><div class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'binary_crossentropy'</span>,metrics=[<span class="string">'acc'</span>])</div><div class="line">model.summary()</div><div class="line">history = modhistory = modhistory = mod&gt; history = model.fit(x_train,y_train,epochs=<span class="number">10</span>,batch_size=<span class="number">32</span>,validation_split=<span class="number">0.2</span>)</div><div class="line"></div><div class="line"></div><div class="line">_________________________________________________________________</div><div class="line">Layer (type)                 Output Shape              Param <span class="comment">#   </span></div><div class="line">=================================================================</div><div class="line">input_4 (InputLayer)         (<span class="keyword">None</span>, <span class="number">20</span>)                <span class="number">0</span>         </div><div class="line">_________________________________________________________________</div><div class="line">embedding_5 (Embedding)      (<span class="keyword">None</span>, <span class="number">20</span>, <span class="number">8</span>)             <span class="number">80000</span>     </div><div class="line">_________________________________________________________________</div><div class="line">flatten_5 (Flatten)          (<span class="keyword">None</span>, <span class="number">160</span>)               <span class="number">0</span>         </div><div class="line">_________________________________________________________________</div><div class="line">dense_5 (Dense)              (<span class="keyword">None</span>, <span class="number">1</span>)                 <span class="number">161</span>       </div><div class="line">=================================================================</div><div class="line"></div><div class="line">Total params: <span class="number">80</span>,<span class="number">161</span></div><div class="line">Trainable params: <span class="number">80</span>,<span class="number">161</span></div><div class="line">Non-trainable params: <span class="number">0</span></div><div class="line">_________________________________________________________________</div><div class="line">Train on <span class="number">20000</span> samples, validate on <span class="number">5000</span> samples</div><div class="line">Epoch <span class="number">1</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">105</span>us/step - loss: <span class="number">0.6772</span> - acc: <span class="number">0.6006</span> - val_loss: <span class="number">0.6448</span> - val_acc: <span class="number">0.6704</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.5830</span> - acc: <span class="number">0.7188</span> - val_loss: <span class="number">0.5629</span> - val_acc: <span class="number">0.7046</span></div><div class="line">Epoch <span class="number">3</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">95</span>us/step - loss: <span class="number">0.5152</span> - acc: <span class="number">0.7464</span> - val_loss: <span class="number">0.5362</span> - val_acc: <span class="number">0.7208</span></div><div class="line">Epoch <span class="number">4</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.4879</span> - acc: <span class="number">0.7607</span> - val_loss: <span class="number">0.5299</span> - val_acc: <span class="number">0.7292</span></div><div class="line">Epoch <span class="number">5</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">97</span>us/step - loss: <span class="number">0.4731</span> - acc: <span class="number">0.7694</span> - val_loss: <span class="number">0.5290</span> - val_acc: <span class="number">0.7334</span></div><div class="line">Epoch <span class="number">6</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">98</span>us/step - loss: <span class="number">0.4633</span> - acc: <span class="number">0.7773</span> - val_loss: <span class="number">0.5317</span> - val_acc: <span class="number">0.7344</span></div><div class="line">Epoch <span class="number">7</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">96</span>us/step - loss: <span class="number">0.4548</span> - acc: <span class="number">0.7819</span> - val_loss: <span class="number">0.5333</span> - val_acc: <span class="number">0.7318</span></div><div class="line">Epoch <span class="number">8</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">93</span>us/step - loss: <span class="number">0.4471</span> - acc: <span class="number">0.7870</span> - val_loss: <span class="number">0.5377</span> - val_acc: <span class="number">0.7288</span></div><div class="line">Epoch <span class="number">9</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">95</span>us/step - loss: <span class="number">0.4399</span> - acc: <span class="number">0.7924</span> - val_loss: <span class="number">0.5422</span> - val_acc: <span class="number">0.7278</span></div><div class="line">Epoch <span class="number">10</span>/<span class="number">10</span></div><div class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - <span class="number">2</span>s <span class="number">90</span>us/step - loss: <span class="number">0.4328</span> - acc: <span class="number">0.7957</span> - val_loss: <span class="number">0.5458</span> - val_acc: <span class="number">0.7290</span></div></pre></td></tr></table></figure><p>我们观察一下input的shape</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">x_train[<span class="number">1</span>].shape</div><div class="line">x_train[<span class="number">1</span>]</div><div class="line">x_train[:<span class="number">1</span>].shape</div><div class="line">x_train[:<span class="number">1</span>]</div><div class="line"></div><div class="line">(<span class="number">20</span>,)</div><div class="line">array([ <span class="number">23</span>,   <span class="number">4</span>,   <span class="number">2</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">4</span>,   <span class="number">2</span>,   <span class="number">5</span>,  <span class="number">28</span>,   <span class="number">6</span>,  <span class="number">52</span>, <span class="number">154</span>, <span class="number">462</span>,</div><div class="line">        <span class="number">33</span>,  <span class="number">89</span>,  <span class="number">78</span>, <span class="number">285</span>,  <span class="number">16</span>, <span class="number">145</span>,  <span class="number">95</span>], dtype=int32)</div><div class="line">(<span class="number">1</span>, <span class="number">20</span>)</div><div class="line">array([[ <span class="number">65</span>,  <span class="number">16</span>,  <span class="number">38</span>,   <span class="number">2</span>,  <span class="number">88</span>,  <span class="number">12</span>,  <span class="number">16</span>, <span class="number">283</span>,   <span class="number">5</span>,  <span class="number">16</span>,   <span class="number">2</span>, <span class="number">113</span>, <span class="number">103</span>,</div><div class="line">         <span class="number">32</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">2</span>,  <span class="number">19</span>, <span class="number">178</span>,  <span class="number">32</span>]], dtype=int32)</div></pre></td></tr></table></figure><p>再看看embedding的输出，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">embedding.predict(x_train[:<span class="number">1</span>]).shape</div><div class="line">embedding.predict(x_train[:<span class="number">1</span>])</div><div class="line"></div><div class="line">(<span class="number">1</span>, <span class="number">20</span>, <span class="number">8</span>)</div><div class="line">array([[[<span class="number">-0.17401133</span>, <span class="number">-0.08743777</span>,  <span class="number">0.15631911</span>, <span class="number">-0.06831486</span>, <span class="number">-0.09105065</span>,</div><div class="line">          <span class="number">0.06253908</span>, <span class="number">-0.0798945</span> ,  <span class="number">0.07671431</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [ <span class="number">0.06872956</span>, <span class="number">-0.00586612</span>,  <span class="number">0.07713806</span>, <span class="number">-0.00182899</span>,  <span class="number">0.00882899</span>,</div><div class="line">         <span class="number">-0.18892162</span>, <span class="number">-0.13580748</span>, <span class="number">-0.03166043</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [ <span class="number">0.20604047</span>,  <span class="number">0.10910885</span>,  <span class="number">0.06304865</span>, <span class="number">-0.14038748</span>,  <span class="number">0.12123005</span>,</div><div class="line">          <span class="number">0.06124007</span>,  <span class="number">0.0532628</span> ,  <span class="number">0.17591232</span>],</div><div class="line">        [<span class="number">-0.19636872</span>, <span class="number">-0.0027669</span> ,  <span class="number">0.01087157</span>, <span class="number">-0.02332311</span>, <span class="number">-0.04321857</span>,</div><div class="line">         <span class="number">-0.09228673</span>, <span class="number">-0.03061322</span>, <span class="number">-0.13376454</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.27160701</span>, <span class="number">-0.29296583</span>,  <span class="number">0.1055108</span> ,  <span class="number">0.15896739</span>, <span class="number">-0.24833643</span>,</div><div class="line">         <span class="number">-0.17791845</span>, <span class="number">-0.27316946</span>, <span class="number">-0.241273</span>  ],</div><div class="line">        [<span class="number">-0.02175452</span>, <span class="number">-0.0839383</span> ,  <span class="number">0.04338101</span>,  <span class="number">0.01062139</span>, <span class="number">-0.11473208</span>,</div><div class="line">         <span class="number">-0.18394938</span>, <span class="number">-0.05141308</span>, <span class="number">-0.10405254</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [<span class="number">-0.14751843</span>,  <span class="number">0.05572686</span>,  <span class="number">0.20332271</span>, <span class="number">-0.01759946</span>, <span class="number">-0.0946402</span> ,</div><div class="line">         <span class="number">-0.14416233</span>,  <span class="number">0.16961734</span>,  <span class="number">0.01381243</span>],</div><div class="line">        [ <span class="number">0.00282665</span>, <span class="number">-0.17532936</span>, <span class="number">-0.09342033</span>,  <span class="number">0.04514923</span>, <span class="number">-0.04684081</span>,</div><div class="line">          <span class="number">0.1748796</span> , <span class="number">-0.09669576</span>, <span class="number">-0.10699435</span>],</div><div class="line">        [ <span class="number">0.00225757</span>, <span class="number">-0.12751001</span>, <span class="number">-0.12703758</span>,  <span class="number">0.17167819</span>, <span class="number">-0.03712473</span>,</div><div class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, <span class="number">-0.02731293</span>],</div><div class="line">        [ <span class="number">0.02198115</span>,  <span class="number">0.03989581</span>,  <span class="number">0.13165356</span>,  <span class="number">0.06523556</span>,  <span class="number">0.14900513</span>,</div><div class="line">          <span class="number">0.01858517</span>, <span class="number">-0.01644249</span>, <span class="number">-0.02377043</span>],</div><div class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, <span class="number">-0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</div><div class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</div><div class="line">        [<span class="number">-0.01912907</span>, <span class="number">-0.01732869</span>,  <span class="number">0.00391375</span>, <span class="number">-0.02338142</span>,  <span class="number">0.02787969</span>,</div><div class="line">         <span class="number">-0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</div><div class="line">        [<span class="number">-0.01993229</span>, <span class="number">-0.04436176</span>,  <span class="number">0.07624088</span>,  <span class="number">0.04268746</span>, <span class="number">-0.00883252</span>,</div><div class="line">          <span class="number">0.00789542</span>, <span class="number">-0.03039453</span>,  <span class="number">0.05851226</span>],</div><div class="line">        [<span class="number">-0.12873659</span>, <span class="number">-0.00083202</span>, <span class="number">-0.03246918</span>,  <span class="number">0.23910245</span>, <span class="number">-0.24635716</span>,</div><div class="line">          <span class="number">0.10966355</span>,  <span class="number">0.02079294</span>, <span class="number">-0.03829115</span>],</div><div class="line">        [ <span class="number">0.00225757</span>, <span class="number">-0.12751001</span>, <span class="number">-0.12703758</span>,  <span class="number">0.17167819</span>, <span class="number">-0.03712473</span>,</div><div class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, <span class="number">-0.02731293</span>]]], dtype=float32)</div></pre></td></tr></table></figure><p>可以看出，embedding层将(1, 20)的一个输入sample（最长为20个单词的句子，其中每个单词表示为一个int数字），嵌入为一个(1, 20, 8)的向量，即将每个单词embed为一个8维的向量，而整个embedding层的参数就由神经网络学习得到，数据经过embedding层之后就方便地转换为了可以由CNN或者RNN进一步处理的格式。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/" target="_blank" rel="external">How to Use Word Embedding Layers for Deep Learning with Keras - Machine Learning Mastery</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15135840798621.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。&lt;br&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://frankchen.xyz/tags/Deep-Learning/"/>
    
      <category term="Keras" scheme="http://frankchen.xyz/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>神经网络术语大百科：优化函数、激活函数、损失函数、正则方法的简介</title>
    <link href="http://frankchen.xyz/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/"/>
    <id>http://frankchen.xyz/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/</id>
    <published>2017-12-15T04:45:44.000Z</published>
    <updated>2017-12-16T09:21:29.262Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/neuralnetworks.png" alt="neuralnetworks"></p><p>简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。</p><a id="more"></a><h1 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h1><p>先上两张图</p><figure class="three"><br>   <img src="/images/2017/05/contours_evaluation_optimizers.gif" title="Logo" width="300"><br>   <img src="/images/2017/05/saddle_point_evaluation_optimizers.gif" title="Logo" width="300"><br></figure><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>没有激活函数，神经元就只是一个线性函数，那么无论多少层的神经元叠加是没有意义的。而主流激活函数也随着神经网络、深度学习的发展迭代进化了许多次代。</p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p><img src="/images/15134144452960.jpg" alt=""><br>Sigmoid是S形状的意思，又因为它是逻辑回归的激活函数又叫logistic函数，函数式为$<code>y = 1 / (1 + exp(-x))</code>$是很早以前最常用的激活函数，其实也是有一些优点的，比如，</p><ul><li>值域位于0-1，那么对于逻辑回归，这是对于二分类的一个很自然的表达，也就是概率</li><li>处处连续可导</li></ul><p>不过呢，我们观察它的形状，可以得出，Sigmoid函数在两端（靠近0和1的部分）梯度很小，这也意味着，如果神经元的输出落到了这个地方，那么它几乎没什么梯度可以传到后面，而随着神经网络的层层削弱，后面的层（靠近输入的层）没有多少梯度能传过来，几乎就“学不到什么”了。这叫做梯度消失问题，一度是阻碍神经网络往更深的层进化的主要困难，导致深度学习专家们绞尽脑汁想了许多方法来对抗这个问题，比如“Xavier and He Initialization”，比如我们要把weight随机初始化为如下的范围，<br><img src="/images/Screen%20Shot%202017-12-16%20at%2017.03.18.png" alt="Screen Shot 2017-12-16 at 17.03.18"></p><p>sigmoid的另一个问题是它不是0均值的，Sigmoid函数的输出值恒大于0，这会导致模型训练的收敛速度变慢。举例来讲，对，如果所有均为正数或负数，那么其对的导数总是正数或负数，这会导致如下图红色箭头所示的阶梯式更新，这显然并非一个好的优化路径。深度学习往往需要大量时间来处理大量数据，模型的收敛速度是尤为重要的。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。</p><p><img src="/images/15134157378274.jpg" alt=""></p><p>如今，sigmoid函数应用最广泛的在于其变种softmax在多元分类中，比如手写数字识别，经过卷积神经网络的处理，最后我们需要网络输出每个预测的概率值，最后预测为某一个数字，这里就需要用到softmax，<br><img src="/images/15134154076033.jpg" alt=""><br>以下是softmax的Keras代码，注意其中一个trick，<code>e = K.exp(x - K.max(x, axis=axis, keepdims=True))</code>这里每个分量减去最大值是为了减少计算量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x, axis=<span class="number">-1</span>)</span>:</span></div><div class="line">    <span class="string">"""Softmax activation function.</span></div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x : Tensor.</div><div class="line">        axis: Integer, axis along which the softmax normalization is applied.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        Tensor, output of softmax transformation.</div><div class="line"></div><div class="line">    # Raises</div><div class="line">        ValueError: In case `dim(x) == 1`.</div><div class="line">    """</div><div class="line">    ndim = K.ndim(x)</div><div class="line">    <span class="keyword">if</span> ndim == <span class="number">2</span>:</div><div class="line">        <span class="keyword">return</span> K.softmax(x)</div><div class="line">    <span class="keyword">elif</span> ndim &gt; <span class="number">2</span>:</div><div class="line">        e = K.exp(x - K.max(x, axis=axis, keepdims=<span class="keyword">True</span>))</div><div class="line">        s = K.sum(e, axis=axis, keepdims=<span class="keyword">True</span>)</div><div class="line">        <span class="keyword">return</span> e / s</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Cannot apply softmax to a tensor that is 1D'</span>)</div></pre></td></tr></table></figure></p><h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p><img src="/images/15134156685588.jpg" alt=""></p><p>tanh 是sigmoid的变形： $tanh(x)=2sigmoid(2x)-1$，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好一些，</p><p><img src="/images/15134156615077.jpg" alt=""></p><h2 id="ReLU家族"><a href="#ReLU家族" class="headerlink" title="ReLU家族"></a>ReLU家族</h2><p>然而标准ReLU不是完美的，比如因为ReLU在小于0的坐标梯度都是0，那么会造成“死亡”的神经元的问题：一旦神经元的输入与权重之乘积是负的，那么经过ReLU的激活，输出就是0，而ReLU的0梯度让“死亡”的神经元无法“复活”：没办法回到输出不是0的状态，这样就出现了许多在ReLU的变种，一般都是对标准ReLU坐标轴左边的部分做文章，比如<strong>leaky ReLU</strong>。其公式就是$LeakyReLU_ α (z) = max(\alpha z,z)$。如图，<br><img src="/images/15134123600394.jpg" alt=""></p><p>这篇文章<a href="https://arxiv.org/pdf/1505.00853.pdf" target="_blank" rel="external">Empirical Evaluation of Rectified Activations in Convolution Network</a>对比了几种leaky ReLU，比如把$\alpha$设置为0.2效果总是好过0.01，并且，对于randomized leaky ReLU (RReLU)（其中$\alpha$设置为一个在指定范围内的随机数），效果也不错，而且还具有一定的正则作用。另外，对于parametric leaky ReLU (PReLU)（其中$\alpha$作为网络的一个参数，被反向传播学习出来，之前的$\alpha$都是超参数，不能学只能调节），这种变种对于大数据集不错，但是数据量过小就有过拟合的风险。以下是Keras里面relu的代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x, alpha=<span class="number">0.</span>, max_value=None)</span>:</span></div><div class="line">    <span class="string">"""Rectified linear unit.</span></div><div class="line"></div><div class="line">    With default values, it returns element-wise `max(x, 0)`.</div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x: A tensor or variable.</div><div class="line">        alpha: A scalar, slope of negative section (default=`0.`).</div><div class="line">        max_value: Saturation threshold.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        A tensor.</div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</div><div class="line">        negative_part = tf.nn.relu(-x)</div><div class="line">    x = tf.nn.relu(x)</div><div class="line">    <span class="keyword">if</span> max_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        max_value = _to_tensor(max_value, x.dtype.base_dtype)</div><div class="line">        zero = _to_tensor(<span class="number">0.</span>, x.dtype.base_dtype)</div><div class="line">        x = tf.clip_by_value(x, zero, max_value)</div><div class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</div><div class="line">        alpha = _to_tensor(alpha, x.dtype.base_dtype)</div><div class="line">        x -= alpha * negative_part</div><div class="line">    <span class="keyword">return</span> x</div></pre></td></tr></table></figure><p>另外，在这篇文章里面<a href="https://arxiv.org/pdf/1511.07289v5.pdf" target="_blank" rel="external">FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)</a>，引入了一种新的ReLU，exponential linear unit (ELU)，公式如下，<br>$$<br>ELU_{\alpha}(z) = \alpha (\exp(z)-1) \ if \ z \lt 0 ; \ z \ if \ z \gt 0;<br>$$<br><img src="/images/15134129990682.jpg" alt=""></p><p>与标准ReLU最大的区别在于它处处连续可导，这使得梯度下降得到加速，收敛得到了加速，而使用了指数函数使得其测试阶段的计算代价更高。Keras里elu的实现，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span><span class="params">(x, alpha=<span class="number">1.</span>)</span>:</span></div><div class="line">    <span class="string">"""Exponential linear unit.</span></div><div class="line"></div><div class="line">    # Arguments</div><div class="line">        x: A tenor or variable to compute the activation function for.</div><div class="line">        alpha: A scalar, slope of positive section.</div><div class="line"></div><div class="line">    # Returns</div><div class="line">        A tensor.</div><div class="line">    """</div><div class="line">    res = tf.nn.elu(x)</div><div class="line">    <span class="keyword">if</span> alpha == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> res</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> tf.where(x &gt; <span class="number">0</span>, res, alpha * res)</div></pre></td></tr></table></figure><h2 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h2><p>一般来说，我们的选择顺序可以理解为：<br>ELU &gt; leaky ReLU (以及其变种) &gt; ReLU &gt; tanh &gt; logistic。但是，</p><ul><li>如果我们更顾虑模型运行速度，那么leaky ReLU可能比ELU更好；</li><li>如果我们不想调节超参数，那么用默认的$\alpha$就行，ReLU和ELU的分别是0.01和1； </li><li>如果算力足够可以用来调参，那么如果网络过拟合我们会选择RReLU，如果训练集数据足够多，那可以用PReLU。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/neuralnetworks.png&quot; alt=&quot;neuralnetworks&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://frankchen.xyz/tags/Deep-Learning/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Python" scheme="http://frankchen.xyz/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>如何理解Pandas 和 Numpy里的axis</title>
    <link href="http://frankchen.xyz/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/"/>
    <id>http://frankchen.xyz/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/</id>
    <published>2017-12-12T10:36:04.000Z</published>
    <updated>2018-03-09T11:12:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15130766716183.jpg" alt=""></p><p>简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。<br><a id="more"></a></p><p>Numpy 和 Pandas里的sort、mean、drop等操作，不是分行或者列分别用一个method来定义，而是一个method里面用户指定axis来操作的，举例来说：</p><p>我们先在<a href="https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/drinks.csv" target="_blank" rel="external">此处</a>下载了一份各国酒类消费的csv文件为例。<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.14.png" alt="Screen Shot 2017-12-12 at 18.46.14"><br>如下是pandas里按axis 0和1进行drop的操作示例，我们很容易看出，axis 0是按行drop，而axis 1是按列drop：<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.22.png" alt="Screen Shot 2017-12-12 at 18.46.22"></p><p>但是，mean操作呢？<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.49.18.png" alt="Screen Shot 2017-12-12 at 18.49.18"></p><p>容易看出，axis 0得出了每一列的均值，而axis 1得出了则是每一行的均值。<br>那么，在Numpy里呢？</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2019.06.17.png" alt="Screen Shot 2017-12-12 at 19.06.17"></p><p>容易看出，axis为1的时候得出的是每行的sum，axis为0的时候得出了每列的sum。</p><p>由上面的例子，我们似乎可以看出，axis为1代表水平方向上的操作，axis为0代表垂直方向上的操作，比如axis为1的sum得出的就是每一行的和。</p><p><img src="/images/15130760734631.jpg" alt=""></p><p>但是，在Pandas的Dataframe里面，为什么axis=1代表的是drop整个列呢？以下这个例子也可以说明一些情况：</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2018.56.53.png" alt="Screen Shot 2017-12-12 at 18.56.53"></p><p>联系这个视频<a href="https://www.youtube.com/watch?v=PtO3t6ynH-8" target="_blank" rel="external">How do I use the “axis” parameter in pandas? - YouTube</a>，大家也可以得到一些结论，作者说：</p><blockquote><p>0 is the row axis, and 1 is the column axis. When you drop with axis=1, that means drop a column. When you take the mean with axis=1, that means the operation should “move across” the column axis, which produces row means.<br>指的就是一种更加容易理解的方式，“0就是行的axis，1就是列的axis，当以axis=1来drop，那么就是drop一个column，而axis=1 来取mean，那么就是这个操作‘穿越’了列的axis，产生了行上的mean”。</p></blockquote><p>另外，其实我们也可以这样来操作，<br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.27.png" alt="Screen Shot 2017-12-12 at 19.01.27"><br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.45.png" alt="Screen Shot 2017-12-12 at 19.01.45"></p><p>可以看出，axis=0与axis=’rows’是一样的（在Pandas里），是不是更加容易理解了？</p><p><a href="https://distill.pub/2016/misread-tsne/" target="_blank" rel="external">How to Use t-SNE Effectively</a>这个网站给了一个非常形象的t-SNE在线实验环境，推荐大家去看一看！<br><img src="/images/15205939273866.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15130766716183.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
      <category term="Numpy" scheme="http://frankchen.xyz/tags/Numpy/"/>
    
      <category term="Pandas" scheme="http://frankchen.xyz/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>理解triplet loss</title>
    <link href="http://frankchen.xyz/2017/12/01/understanding-triplet-loss-and-example-code/"/>
    <id>http://frankchen.xyz/2017/12/01/understanding-triplet-loss-and-example-code/</id>
    <published>2017-12-01T09:19:05.000Z</published>
    <updated>2018-05-23T07:43:15.095Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15121200710041.jpg" alt=""><br>理解triplet loss，与给出TensorFlow和numpy两种形式的example code。<br><a id="more"></a></p><p>Triplet Loss 是当前应用的很广泛的一种损失函数，在人脸识别和聚类领域，这是一种很自然的映射与计算损失的方式，比如<a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="external">FaceNet</a>里，通过构建一种embedding 方式，将人脸图像直接映射到欧式空间，而优化这种embedding的方法可以概括为，构建许多组三元组（Anchor，Positive，Negative），其中Anchor与Positive同label，Anchor与Negative不同label（在人脸识别里面，就是Anchor与Positive是同一个个体，而与Negative是不同个体），通过学习优化这个embedding，使得欧式空间内的Anchor与Positive 的距离比与Negative的距离要近。</p><h2 id="公式表示"><a href="#公式表示" class="headerlink" title="公式表示"></a>公式表示</h2><p>用公式表示就是，我们希望：</p><p>$$<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2  +<br>\alpha \lt \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 , \<br>\forall (f(x^a_i) , f(x^p_i) , f(x^n_i))  \in \mathscr T<br>$$</p><p>其中$\alpha$ 是强制的正例和负例之间的margin，$\mathscr T$是具有基数为$N$的训练集中的三元组的集合。</p><p>那么，损失函数很自然的可以写为：</p><p>$$<br>\sum^N_i<br>\Bigl [<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2   -<br> \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 + \alpha<br> \Bigr ] _ +<br>$$</p><p>其中加号指的，如果中括号内部分小于0，则没有损失（Anchor与Positive的距离加上margin小于与Negative的距离），否则计算这个距离为损失。</p><h2 id="代码表示"><a href="#代码表示" class="headerlink" title="代码表示"></a>代码表示</h2><p>Numpy 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line"></div><div class="line"><span class="comment"># 构造batch_size * embedding_size 维度的随机矩阵</span></div><div class="line">emb = np.random.uniform(size=[])</div><div class="line"></div><div class="line"><span class="comment"># 对emb逢三取1、2、3行分别为Anchor、Positive、Negative</span></div><div class="line"><span class="comment"># 计算其2范数的距离即欧氏距离</span></div><div class="line">pos_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </div><div class="line">neg_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># 这里就是照抄公式了，注意mean和sum是一样的</span></div><div class="line">np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</div></pre></td></tr></table></figure><p>TensorFlow 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line">alpha = <span class="number">0.2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(anchor, positive, negative, alpha)</span>:</span>   </div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'triplet_loss'</span>):</div><div class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</div><div class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</div><div class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</div><div class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="keyword">None</span>)</div><div class="line">    <span class="keyword">return</span> loss</div><div class="line"></div><div class="line"><span class="comment"># 构建矩阵</span></div><div class="line">embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">'embeddings'</span>)</div><div class="line"><span class="comment"># 先将embeddings矩阵第0维resize为(?, 3)维，第1维不变，变为三维矩阵(-1, 3, embedding_size)，再在其第二维度为3上unstack为三份</span></div><div class="line">anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(<span class="number">-1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</div></pre></td></tr></table></figure><p>完整代码如下，这里测试对比了两种实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></div><div class="line">embedding_size = <span class="number">16</span></div><div class="line">alpha = <span class="number">0.2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span><span class="params">(anchor, positive, negative, alpha)</span>:</span>   </div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'triplet_loss'</span>):</div><div class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</div><div class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</div><div class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</div><div class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="keyword">None</span>)</div><div class="line">    <span class="keyword">return</span> loss</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Graph().as_default():</div><div class="line">    embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">'embeddings'</span>)</div><div class="line">    anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(<span class="number">-1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</div><div class="line">    triplet_loss = triplet_loss(anchor, positive, negative, alpha)</div><div class="line">    </div><div class="line">    sess = tf.Session()</div><div class="line">    <span class="keyword">with</span> sess.as_default():</div><div class="line">        np.random.seed(<span class="number">666</span>)</div><div class="line">        emb = np.random.uniform(size=[batch_size, embedding_size])</div><div class="line">        tf_triplet_loss = sess.run(triplet_loss, feed_dict=&#123;embeddings:emb&#125;)</div><div class="line">        </div><div class="line">        pos_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </div><div class="line">        neg_dist_sqr = np.sum(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</div><div class="line">        np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</div><div class="line">        </div><div class="line">        np.testing.assert_almost_equal(tf_triplet_loss, np_triplet_loss, decimal=<span class="number">5</span>, err_msg=<span class="string">'Triplet loss is incorrect'</span>)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15121200710041.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;理解triplet loss，与给出TensorFlow和numpy两种形式的example code。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Algorithm" scheme="http://frankchen.xyz/tags/Algorithm/"/>
    
      <category term="TensorFlow" scheme="http://frankchen.xyz/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>数据的标准化与归一化</title>
    <link href="http://frankchen.xyz/2017/11/29/Data-Normalization-and-Standardization/"/>
    <id>http://frankchen.xyz/2017/11/29/Data-Normalization-and-Standardization/</id>
    <published>2017-11-29T03:53:57.000Z</published>
    <updated>2017-12-01T11:10:13.685Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/15119359203487.png" alt=""><br>聊一聊Normalization and Standardization<br><a id="more"></a></p><h2 id="什么是"><a href="#什么是" class="headerlink" title="什么是"></a>什么是</h2><p>Normalization就是归一化，是最小-最大缩放(min-max scaling)的特例，指的是将数据缩放到指定range，这个range通常是0~1或者-1~+1，直观来讲就是下图，在数据不包含离群点时很有用，<br><img src="/images/Screen%20Shot%202017-11-29%20at%2012.35.41.png" alt="Screen Shot 2017-11-29 at 12.35.41"></p><p>公式则是</p><p>$$<br>x^{(i)}_{norm} = \frac {x^{(i)} - x_{min}} {x_{max} - x_{min}}<br>$$</p><p>若要缩放至-1~+1，则是<br>$$<br>x’ = \frac{x - min}{max - min}<br>$$</p><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#导入数据预处理库</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line"><span class="comment">#范围缩放标准化</span></div><div class="line">min_max_scaler = preprocessing.MinMaxScaler()</div><div class="line"></div><div class="line"><span class="comment">#训练集缩放标准化</span></div><div class="line">min_max_scaler.fit_transform(X_train)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试集缩放标准化</span></div><div class="line">min_max_scaler.fit_transform(X_test)</div></pre></td></tr></table></figure><p>Z-score 标准化指的是，通过缩放让数据的均值为0（移除均值），标准差为固定值（比如1）。在许多模型里，如SVM的RBF、线性模型的 L1 &amp; L2 正则项对于所有的feature都有这样的假设。<br>$$<br>x^{(i)}_{std} = \frac{x^{(i)} - \mu_x}{\sigma_x}<br>$$</p><p>以下是一个简单的例子展示了两者的区别：</p><p><img src="/images/Screen%20Shot%202017-11-29%20at%2012.41.13.png" alt="Screen Shot 2017-11-29 at 12.41.13"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#导入数据预处理库</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line"><span class="comment">#数据标准化</span></div><div class="line">scaler = preprocessing.StandardScaler().fit(X_train)</div><div class="line"></div><div class="line"><span class="comment">#训练集数据标准化</span></div><div class="line">scaler.transform(X_train)</div></pre></td></tr></table></figure><p>同时对测试集的数据进行标准化处理，以保证训练集和测试集的变换方式相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#测试集数据标准化</span></div><div class="line">scaler.transform(X_test)</div></pre></td></tr></table></figure><h2 id="值得注意"><a href="#值得注意" class="headerlink" title="值得注意"></a>值得注意</h2><p>从流程上讲，标准化和归一化应该在读入数据、处理缺失值，切分训练测试集之后，而且我们要做的是在切分之后，在训练集fit，再去transform测试集，而不是在整个数据上转换以后再切分，因为<strong>无论是标准化还是归一化，我们要么利用到了数据的max min值，要么利用到了数据的均值和标准差，这些数值在训练之前是不能被测试集所影响的。</strong></p><p>类似于缺失值的填充，举个例子，我们使用均值填充以下数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#使用均值填充缺失值</span></div><div class="line">imp = Imputer(missing_values=<span class="string">"NaN"</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</div><div class="line">imp.fit(X_train)</div><div class="line"></div><div class="line"><span class="comment">#填充训练集</span></div><div class="line">X_train=imp.transform(X_train)</div></pre></td></tr></table></figure><p>以同样的方式填充测试集，以保证测试集和训练集的数据填充方式保持一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#填充测试集</span></div><div class="line">X_test=imp.transform(X_test)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/15119359203487.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;聊一聊Normalization and Standardization&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://frankchen.xyz/tags/python/"/>
    
      <category term="Data Science" scheme="http://frankchen.xyz/tags/Data-Science/"/>
    
  </entry>
  
</feed>
