<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>不正经的社长</title>
    <link>http://example.com/</link>
    
    <atom:link href="http://example.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Affiliate Marketing/Python/Clojure/Game/Resource</description>
    <pubDate>Sat, 30 Oct 2021 10:30:38 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Recommend some useful telegram channels 推荐一些有用的 telegram 频道</title>
      <link>http://example.com/2021/10/30/Recommend-some-useful-telegram-channels/</link>
      <guid>http://example.com/2021/10/30/Recommend-some-useful-telegram-channels/</guid>
      <pubDate>Sat, 30 Oct 2021 10:09:40 GMT</pubDate>
      
      <description>&lt;p&gt;推荐一些个人经常使用的免费电报资源频道,包括免费电子书\免费杂志\免费 udemy 课程等等.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>推荐一些个人经常使用的免费电报资源频道,包括免费电子书\免费杂志\免费 udemy 课程等等.</p><span id="more"></span><h3 id="免费-udemy-课程"><a href="#免费-udemy-课程" class="headerlink" title="免费 udemy 课程"></a>免费 udemy 课程</h3><p><a href="https://t.me/Ebooksenglish">https://t.me/Ebooksenglish</a></p><p>这个群可以免费领取 udemy 课程,点击其中的 link 一步步跳转即可,会把你带到最终结算,里面做了一些短链强制 Google 搜索而不是直接跳转到最终页面,应该是 seo 的小技巧,有 free 的优惠码,所以结算后是免费的,课程永久拥有.唯一要注意的是链接内的优惠码这些都是有有效期的.</p><p><img src="/images/1635589099722.jpg"></p><h3 id="免费电子书"><a href="#免费电子书" class="headerlink" title="免费电子书"></a>免费电子书</h3><p><a href="https://t.me/ebooksenglish2">https://t.me/ebooksenglish2</a></p><p><img src="/images/1635588979060.jpg"></p><h3 id="免费杂志"><a href="#免费杂志" class="headerlink" title="免费杂志"></a>免费杂志</h3><p><a href="https://t.me/inPDF">https://t.me/inPDF</a></p><p>可以看到,基本主流的杂志都有免费经济学人/免费Playboy/哈佛商业评论等等,直接下载即可,比若干下载后转卖的良心多了.</p><p><img src="/images/1635589361599.jpg"></p><h3 id="免费-Google-Drive-资源-免费阿里云资源"><a href="#免费-Google-Drive-资源-免费阿里云资源" class="headerlink" title="免费 Google Drive 资源/免费阿里云资源"></a>免费 Google Drive 资源/免费阿里云资源</h3><p><a href="https://t.me/gdsharing">https://t.me/gdsharing</a></p><p><img src="/images/1635589599683.jpg"></p><p>正经和不正经的资源都有,猎奇用.流量大的资源容易被限流.</p><h2 id="资讯类"><a href="#资讯类" class="headerlink" title="资讯类"></a>资讯类</h2><p>主要使用竹新社<br><a href="https://t.me/tnews365">https://t.me/tnews365</a><br>7×24不定时编译国内外媒体的即时新闻报道。</p><p>和风向旗<br><a href="https://t.me/xhqcankao">https://t.me/xhqcankao</a></p><p>风闻奏事，遍查访知。即时发布VPS、网盘等有价值虚拟资产的新闻和交易信息，提供互联网科技新闻快讯。为VPS信号旗播报筛选供稿。🚩</p><p>先列出这么多,后续再补充.</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/resources-Telegram/">resources Telegram</category>
      
      
      <comments>http://example.com/2021/10/30/Recommend-some-useful-telegram-channels/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>发放4个pt站的邀请码：海胆之家、HDcity</title>
      <link>http://example.com/2021/09/18/2021-09-18-pt-invite/</link>
      <guid>http://example.com/2021/09/18/2021-09-18-pt-invite/</guid>
      <pubDate>Sat, 18 Sep 2021 02:49:42 GMT</pubDate>
      
      <description>&lt;p&gt;玩 pt 站有一段时间了，赠送4个pt站的邀请码：海胆之家、HDcity给感兴趣的朋友。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>玩 pt 站有一段时间了，赠送4个pt站的邀请码：海胆之家、HDcity给感兴趣的朋友。</p><span id="more"></span><p><a href="https://www.haidan.video/">海胆之家</a>、<a href="https://hdcity.city/">HDcity</a>各两个：</p><p><img src="/images/1631936380423.jpg"><br><img src="/images/L20180831.22016014363i1.jpg"></p><p>留言留下邮箱和您这边关于 pt 的设备的情况（nas 等等）即可。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/pt/">pt</category>
      
      
      <comments>http://example.com/2021/09/18/2021-09-18-pt-invite/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>用python 自动计算亚马逊vat税款</title>
      <link>http://example.com/2019/10/24/amazon-vat-cal/</link>
      <guid>http://example.com/2019/10/24/amazon-vat-cal/</guid>
      <pubDate>Thu, 24 Oct 2019 09:17:01 GMT</pubDate>
      
      <description>&lt;p&gt;简述下如何使用pandas计算亚马逊英国vat税款，纯粹是pandas的业务代码。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>简述下如何使用pandas计算亚马逊英国vat税款，纯粹是pandas的业务代码。</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line">vat_csv = <span class="string">r&quot;C:\Users\Administrator\Downloads\18168935102018178.csv&quot;</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(vat_csv)</span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_free_tax_zone_post_code</span>(<span class="params">x : <span class="built_in">str</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> <span class="keyword">not</span> <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> x.startswith(<span class="string">&#x27;JE&#x27;</span>) <span class="keyword">or</span> x.startswith(<span class="string">&#x27;GY&#x27;</span>)</span><br><span class="line"><span class="comment"># # BN列邮编首字母为JE和GY的，是英国的附属岛屿，目前有免税优惠，不用计算</span></span><br><span class="line">df = df[~df[<span class="string">&#x27;ARRIVAL_POST_CODE&#x27;</span>].apply(filter_free_tax_zone_post_code)].copy()</span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="comment"># BO  SALE_DEPART_COUNTRY 发货国家 BP  SALE_ARRIVAL_COUNTRY 收货国家</span></span><br><span class="line"><span class="comment"># AZ TOTAL_ACTIVITY_VALUE_AMT_VAT_INCL 销售额 BA  TRANSACTION_CURRENCY_CODE 货币</span></span><br><span class="line">df[<span class="string">&#x27;SALE_DEPART_COUNTRY&#x27;</span>].value_counts()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line">SALE_ARRIVAL_COUNTRY_ = df[<span class="string">&#x27;SALE_ARRIVAL_COUNTRY&#x27;</span>].value_counts().index</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line">euro_nation_code_excel = <span class="string">&#x27;euro-nation-code.xlsx&#x27;</span></span><br><span class="line">euro_country = pd.read_excel(euro_nation_code_excel)[<span class="string">&#x27;CODE&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="comment"># step 1</span></span><br><span class="line">A = df[df[<span class="string">&#x27;SALE_DEPART_COUNTRY&#x27;</span>].isin(euro_country)]</span><br><span class="line">step_1_df = A[A[<span class="string">&#x27;SALE_ARRIVAL_COUNTRY&#x27;</span>] == <span class="string">&#x27;GB&#x27;</span>]</span><br><span class="line">step_1 = step_1_df[[<span class="string">&#x27;TOTAL_ACTIVITY_VALUE_AMT_VAT_INCL&#x27;</span>, <span class="string">&#x27;TRANSACTION_CURRENCY_CODE&#x27;</span>]].groupby([<span class="string">&#x27;TRANSACTION_CURRENCY_CODE&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">step_1 = step_1[<span class="string">&#x27;TOTAL_ACTIVITY_VALUE_AMT_VAT_INCL&#x27;</span>].to_dict()</span><br><span class="line">step_1</span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="comment"># step 2</span></span><br><span class="line">A = df[df[<span class="string">&#x27;SALE_DEPART_COUNTRY&#x27;</span>] == <span class="string">&#x27;GB&#x27;</span>]</span><br><span class="line">except_country = <span class="string">&quot;DE GB ES IT FR&quot;</span>.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">sub_euro_country = [i <span class="keyword">for</span> i <span class="keyword">in</span> euro_country <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> except_country]</span><br><span class="line">step_2_df = A[A[<span class="string">&#x27;SALE_ARRIVAL_COUNTRY&#x27;</span>] .isin(sub_euro_country)]</span><br><span class="line">step_2 = step_2_df[[<span class="string">&#x27;TOTAL_ACTIVITY_VALUE_AMT_VAT_INCL&#x27;</span>, <span class="string">&#x27;TRANSACTION_CURRENCY_CODE&#x27;</span>]].groupby([<span class="string">&#x27;TRANSACTION_CURRENCY_CODE&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">step_2 = step_2[<span class="string">&#x27;TOTAL_ACTIVITY_VALUE_AMT_VAT_INCL&#x27;</span>].to_dict()</span><br><span class="line">step_2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line"><span class="comment"># TOTAL</span></span><br><span class="line">euro2gbp = <span class="number">0.8637</span></span><br><span class="line"><span class="comment"># euro2gbp = 1 / 1.1504</span></span><br><span class="line">tax_rate = <span class="number">0.155</span></span><br><span class="line">other = <span class="number">26510.48</span></span><br><span class="line"></span><br><span class="line">euro = step_1.get(<span class="string">&#x27;EUR&#x27;</span>, <span class="number">0</span>) + step_2.get(<span class="string">&#x27;EUR&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">gbp = step_1.get(<span class="string">&#x27;GBP&#x27;</span>, <span class="number">0</span>) + step_2.get(<span class="string">&#x27;GBP&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">total = gbp + euro2gbp * euro</span><br><span class="line"></span><br><span class="line">vat = <span class="built_in">round</span>(total * tax_rate, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">vat</span><br><span class="line"><span class="comment">#%%</span></span><br><span class="line">s = <span class="string">f&quot;&quot;&quot;第一步中算的英镑 <span class="subst">&#123;step_1.get(<span class="string">&#x27;GBP&#x27;</span>, <span class="number">0</span>) :<span class="number">.2</span>f&#125;</span> 欧元 <span class="subst">&#123;step_1.get(<span class="string">&#x27;EUR&#x27;</span>, <span class="number">0</span>) :<span class="number">.2</span>f&#125;</span>，</span></span><br><span class="line"><span class="string">第二步中算的英镑 <span class="subst">&#123;step_2.get(<span class="string">&#x27;GBP&#x27;</span>, <span class="number">0</span>) :<span class="number">.2</span>f&#125;</span> 欧元 <span class="subst">&#123;step_2.get(<span class="string">&#x27;EUR&#x27;</span>, <span class="number">0</span>) :<span class="number">.2</span>f&#125;</span>，</span></span><br><span class="line"><span class="string">共计 英镑 <span class="subst">&#123;gbp :<span class="number">.2</span>f&#125;</span>元，欧元<span class="subst">&#123;euro :<span class="number">.2</span>f&#125;</span>元，</span></span><br><span class="line"><span class="string">按照当前欧元兑英镑汇率为 <span class="subst">&#123;euro2gbp :<span class="number">.2</span>f&#125;</span>，</span></span><br><span class="line"><span class="string">共计英镑 <span class="subst">&#123;total :<span class="number">.2</span>f&#125;</span> 元，</span></span><br><span class="line"><span class="string">按照vat税率 <span class="subst">&#123;tax_rate&#125;</span></span></span><br><span class="line"><span class="string">计算的vat税款为 <span class="subst">&#123;vat&#125;</span> 元</span></span><br><span class="line"><span class="string">与提供的数据差值为 <span class="subst">&#123;vat - other :<span class="number">.2</span>f&#125;</span> 元</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>附赠欧盟28国的国家代码，当前（2019-10-24）英国还算是欧盟国家</p><blockquote><p>德国DE<br>荷兰NL<br>比利时BE<br>卢森堡LU<br>法国FR<br>意大利IT<br>丹麦DK<br>英国GB<br>爱尔兰IE<br>希腊GR<br>西班牙ES<br>葡萄牙PT<br>瑞典SE<br>芬兰FI<br>奥地利AT<br>塞浦路斯CY<br>爱沙尼亚EE<br>拉脱维亚LV<br>立陶宛LT<br>波兰PL<br>捷克CZ<br>斯洛伐克SK<br>斯洛文尼亚SI<br>匈牙利HU<br>马耳他MT<br>罗马尼亚RO<br>保加利亚BG<br>克罗地亚HR</p></blockquote><p>现在Pycharm对于jupyter notebook的支持也很好了，我基本上直接在IDE里面写，这个主题是Gradianto Dark Fuchsia，Jetbrains官网可以下载，PyCharm不是只有Darcula的，好了，我大约一年没有更了，现在正式回归了，我现在做的是电商行业，以后我也许会更多的是生产力软件、爬虫与数据分析、企业系统方面转了，从来就不是正经的数据科学家。生命过程很复杂很丰富，继续做个顽强的人，祝大家<strong>1024程序员节快乐</strong>，我还算程序员的吧🤣哈哈哈</p><p><img src="/images/vat-auto.png"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/amazon/">amazon</category>
      
      <category domain="http://example.com/tags/pandas/">pandas</category>
      
      
      <comments>http://example.com/2019/10/24/amazon-vat-cal/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>python 发送带各种附件的邮件示例</title>
      <link>http://example.com/2018/12/20/attachments/</link>
      <guid>http://example.com/2018/12/20/attachments/</guid>
      <pubDate>Thu, 20 Dec 2018 12:47:39 GMT</pubDate>
      
      <description>&lt;p&gt;简述下如何使用python发送各种附件的邮件，比如word、excel、pdf、txt，以及在正文插入图片等等&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>简述下如何使用python发送各种附件的邮件，比如word、excel、pdf、txt，以及在正文插入图片等等</p><span id="more"></span><p>如下所示，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> smtplib</span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText</span><br><span class="line"><span class="keyword">from</span> email.header <span class="keyword">import</span> Header</span><br><span class="line"><span class="keyword">from</span> smtplib <span class="keyword">import</span> SMTP_SSL</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> email.mime.image <span class="keyword">import</span> MIMEImage</span><br><span class="line"><span class="keyword">from</span> email.mime.multipart <span class="keyword">import</span> MIMEMultipart</span><br><span class="line"><span class="keyword">from</span> email.mime.application <span class="keyword">import</span> MIMEApplication</span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText</span><br><span class="line"><span class="keyword">from</span> email.mime.base <span class="keyword">import</span> MIMEBase</span><br><span class="line"><span class="keyword">from</span> email.encoders <span class="keyword">import</span> encode_base64</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_mail</span>(<span class="params">mail_title,</span></span></span><br><span class="line"><span class="params"><span class="function">              mail_content=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              attachment_img=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              attachment_txt=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              attachment_pdf=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              attachment_excel=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              attachment_word=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># qq邮箱smtp服务器</span></span><br><span class="line">    host_server = <span class="string">&#x27;smtp.qq.com&#x27;</span></span><br><span class="line">    <span class="comment"># sender_qq为发件人的qq号码</span></span><br><span class="line">    sender_qq = <span class="string">&#x27;947118251&#x27;</span></span><br><span class="line">    <span class="comment"># pwd为qq邮箱的授权码</span></span><br><span class="line">    pwd = <span class="string">&#x27;tvjl******zpbebb&#x27;</span></span><br><span class="line">    <span class="comment"># 发件人的邮箱</span></span><br><span class="line">    sender_qq_mail = <span class="string">&#x27;947118251@qq.com&#x27;</span></span><br><span class="line">    <span class="comment"># 收件人邮箱</span></span><br><span class="line">    <span class="comment"># receiver = &#x27;znwindy@gmail.com&#x27;</span></span><br><span class="line">    receiver = <span class="string">&#x27;947118251@qq.com&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># ssl登录</span></span><br><span class="line">        smtp = SMTP_SSL(host_server)</span><br><span class="line">        <span class="comment"># set_debuglevel()是用来调试的。参数值为1表示开启调试模式，参数值为0关闭调试模式</span></span><br><span class="line">        smtp.set_debuglevel(<span class="number">1</span>)</span><br><span class="line">        smtp.ehlo(host_server)</span><br><span class="line">        smtp.login(sender_qq, pwd)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># msg = MIMEText(mail_content, &quot;plain&quot;, &#x27;utf-8&#x27;)</span></span><br><span class="line">        msg = MIMEMultipart(<span class="string">&#x27;related&#x27;</span>)</span><br><span class="line">        msg[<span class="string">&quot;Subject&quot;</span>] = Header(mail_title, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        msg[<span class="string">&quot;From&quot;</span>] = sender_qq_mail</span><br><span class="line">        msg[<span class="string">&quot;To&quot;</span>] = receiver</span><br><span class="line"></span><br><span class="line">        msgAlternative = MIMEMultipart(<span class="string">&#x27;alternative&#x27;</span>)</span><br><span class="line">        msg.attach(msgAlternative)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># image attach</span></span><br><span class="line">        <span class="keyword">if</span> attachment_img:</span><br><span class="line">            mail_body = <span class="string">&#x27;&lt;b&gt;%s&lt;/b&gt;&lt;br&gt;&lt;img src=&quot;cid:%s&quot;&gt;&lt;br&gt;&#x27;</span> % (mail_content, attachment_img)</span><br><span class="line">            msgText = (MIMEText(mail_body, <span class="string">&#x27;html&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">            msgAlternative.attach(msgText)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(attachment_img, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                msgImage = MIMEImage(fp.read())</span><br><span class="line">            msgImage.add_header(<span class="string">&#x27;Content-ID&#x27;</span>, <span class="string">&#x27;&lt;&#123;&#125;&gt;&#x27;</span>.<span class="built_in">format</span>(attachment_img))</span><br><span class="line">            msg.attach(msgImage)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># txt attach</span></span><br><span class="line">        <span class="keyword">if</span> attachment_txt:</span><br><span class="line">            file_name = os.path.split(attachment_txt)[<span class="number">1</span>]</span><br><span class="line">            att1 = MIMEText(<span class="built_in">open</span>(attachment_txt, <span class="string">&#x27;rb&#x27;</span>).read(), <span class="string">&#x27;base64&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">            att1[<span class="string">&quot;Content-Type&quot;</span>] = <span class="string">&#x27;application/octet-stream&#x27;</span></span><br><span class="line">            <span class="comment"># 这里的filename可以任意写，写什么名字，邮件中显示什么名字</span></span><br><span class="line">            att1[<span class="string">&quot;Content-Disposition&quot;</span>] = <span class="string">f&#x27;attachment; filename=&quot;<span class="subst">&#123;file_name&#125;</span>&quot;&#x27;</span></span><br><span class="line">            msg.attach(att1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># pdf attach</span></span><br><span class="line">        <span class="keyword">if</span> attachment_pdf:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(attachment_pdf, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                fileMsg = MIMEBase(<span class="string">&#x27;application&#x27;</span>, <span class="string">&#x27;pdf&#x27;</span>)</span><br><span class="line">                fileMsg.set_payload(fp.read())</span><br><span class="line">                encode_base64(fileMsg)</span><br><span class="line">                fileMsg.add_header(<span class="string">&#x27;Content-Disposition&#x27;</span>, <span class="string">f&#x27;attachment;filename=<span class="subst">&#123;os.path.split(attachment_pdf)[<span class="number">1</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">                msg.attach(fileMsg)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># excel attach</span></span><br><span class="line">        <span class="keyword">if</span> attachment_excel:</span><br><span class="line">            part = MIMEBase(<span class="string">&#x27;application&#x27;</span>, <span class="string">&quot;vnd.ms-excel&quot;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(attachment_excel, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                part.set_payload(fp.read())</span><br><span class="line">                encode_base64(part)</span><br><span class="line">                part.add_header(<span class="string">&#x27;Content-Disposition&#x27;</span>, <span class="string">f&#x27;attachment; filename=&quot;<span class="subst">&#123;os.path.split(attachment_excel)[<span class="number">1</span>]&#125;</span>&quot;&#x27;</span>)</span><br><span class="line">                msg.attach(part)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># word attach</span></span><br><span class="line">        <span class="keyword">if</span> attachment_word:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(attachment_word, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                part = MIMEApplication(fp.read())</span><br><span class="line">                part.add_header(<span class="string">&#x27;Content-Disposition&#x27;</span>, <span class="string">f&#x27;attachment; filename=&quot;<span class="subst">&#123;os.path.split(attachment_word)[<span class="number">1</span>]&#125;</span>&quot;&#x27;</span>)</span><br><span class="line">                part.set_charset(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">                msg.attach(part)</span><br><span class="line"></span><br><span class="line">        smtp.sendmail(sender_qq_mail, receiver, msg.as_string())</span><br><span class="line">        smtp.quit()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Success!&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Error!&#x27;</span>)</span><br><span class="line">        traceback.print_exc()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_mail(mail_title=<span class="string">&#x27;爬虫结束了，正常退出!&#x27;</span>,</span><br><span class="line">              mail_content=<span class="string">&#x27;你好，这是使用python登录qq邮箱发邮件的测试&#x27;</span>,</span><br><span class="line">              attachment_img=<span class="string">&#x27;../data/test.jpg&#x27;</span>,</span><br><span class="line">              attachment_txt=<span class="string">&#x27;../data/start_urls.txt&#x27;</span>,</span><br><span class="line">              attachment_pdf=<span class="string">&#x27;../data/Gmail - How to add images in the product description_.pdf&#x27;</span>,</span><br><span class="line">              attachment_excel=<span class="string">&#x27;../data/shops.xlsx&#x27;</span>,</span><br><span class="line">              attachment_word=<span class="string">&#x27;../data/asdasd.docx&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2018/12/20/attachments/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>PyQt5 编写并在Windows上用Cx_Freeze打包GUI程序</title>
      <link>http://example.com/2018/09/11/Pyqt5-GUI-package-on-Windows/</link>
      <guid>http://example.com/2018/09/11/Pyqt5-GUI-package-on-Windows/</guid>
      <pubDate>Tue, 11 Sep 2018 14:51:05 GMT</pubDate>
      
      <description>&lt;p&gt;简述下如何在Windows上用Cx_Freeze正确打包GUI程序&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>简述下如何在Windows上用Cx_Freeze正确打包GUI程序</p><span id="more"></span><p>为了防止出现&gt; This application failed to start because it could not find or load the Qt platform plugin “windows” 错误，如<a href="https://pythonexample.com/code/cx_freeze-pyqt5">Cx_Freeze Pyqt5 - pythonexample.com</a>这里简述的，我们需要PyQt5的库位置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> cx_Freeze <span class="keyword">import</span> setup, Executable</span><br><span class="line"></span><br><span class="line">path_platforms = ( <span class="string">&quot;C:\\Users\\zhaon\\Anaconda3\\pkgs\\qt-5.9.5-vc14he4a7d60_0\\Library\\plugins\\platforms\\qwindows.dll&quot;</span>, <span class="string">&quot;platforms\qwindows.dll&quot;</span> )</span><br><span class="line">includefiles = [path_platforms]</span><br><span class="line"><span class="comment"># Dependencies are automatically detected, but it might need fine tuning.</span></span><br><span class="line">build_exe_options = &#123;<span class="string">&quot;packages&quot;</span>: [<span class="string">&quot;os&quot;</span>],</span><br><span class="line">                     <span class="string">&quot;excludes&quot;</span>: [<span class="string">&quot;tkinter&quot;</span>],</span><br><span class="line">                     <span class="string">&quot;include_files&quot;</span>: includefiles,&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># GUI applications require a different base on Windows (the default is for a</span></span><br><span class="line"><span class="comment"># console application).</span></span><br><span class="line">base = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> sys.platform == <span class="string">&quot;win64&quot;</span>:</span><br><span class="line">    base = <span class="string">&quot;Win64GUI&quot;</span></span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">&quot;QuickJump&quot;</span>,</span><br><span class="line">      version=<span class="string">&quot;0.9&quot;</span>,</span><br><span class="line">      description=<span class="string">&quot;application!&quot;</span>,</span><br><span class="line">      options=&#123;<span class="string">&quot;build_exe&quot;</span>: build_exe_options&#125;,</span><br><span class="line">      executables=[Executable(<span class="string">&quot;app.py&quot;</span>, base=base)])</span><br></pre></td></tr></table></figure><p>再<code>python setup.py bdist_msi</code>即可打包msi安装包。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/PyQt5/">PyQt5</category>
      
      
      <comments>http://example.com/2018/09/11/Pyqt5-GUI-package-on-Windows/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Numpy中的mask</title>
      <link>http://example.com/2018/07/20/numpy-mask/</link>
      <guid>http://example.com/2018/07/20/numpy-mask/</guid>
      <pubDate>Fri, 20 Jul 2018 08:48:48 GMT</pubDate>
      
      <description>&lt;p&gt;numpy中矩阵选取子集或者以条件替换，用mask是一种很好的方法&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>numpy中矩阵选取子集或者以条件替换，用mask是一种很好的方法</p><span id="more"></span><p>简单来说就是用bool类型的indice矩阵去选择，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mask = np.ones(X.shape[<span class="number">0</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line">X[mask].shape</span><br><span class="line">mask.shape</span><br><span class="line">mask[indices[<span class="number">0</span>]] = <span class="literal">False</span></span><br><span class="line">mask.shape</span><br><span class="line">X[mask].shape</span><br><span class="line">X[~mask].shape</span><br><span class="line">(<span class="number">678</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">678</span>,)</span><br><span class="line">(<span class="number">678</span>,)</span><br><span class="line">(<span class="number">675</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">3</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>例如我们这里用来选取全部点中KNN选取的点以及所有剩余的点</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line">nbrs = NearestNeighbors(<span class="number">10</span>).fit(X)</span><br><span class="line">_,indices = nbrs.kneighbors(X)</span><br><span class="line">mask = np.ones(X.shape[<span class="number">0</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line">mask[indices[<span class="number">0</span>]] = <span class="literal">False</span></span><br><span class="line">plt.scatter(X[mask][:,<span class="number">0</span>],X[mask][:,<span class="number">1</span>],c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(X[~mask][:,<span class="number">0</span>],X[~mask][:,<span class="number">1</span>],c=<span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/15320771581233.jpg"></p><p>带条件选择替换，比如我们需要将a矩阵内某条件的行置换为888剩余置换为999，可以直接用mask或者再用where一步搞定：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mask = np.ones(a.shape,dtype=<span class="built_in">bool</span>) <span class="comment">#np.ones_like(a,dtype=bool)</span></span><br><span class="line">mask[indices] = <span class="literal">False</span></span><br><span class="line">a[~mask] = <span class="number">999</span></span><br><span class="line">a[mask] = <span class="number">888</span></span><br><span class="line"><span class="comment">#############</span></span><br><span class="line">np.where(mask, <span class="number">888</span>, <span class="number">999</span>)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Numpy/">Numpy</category>
      
      
      <comments>http://example.com/2018/07/20/numpy-mask/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>为什么我每天早上5:30起床</title>
      <link>http://example.com/2018/07/19/Why-I-Wake-Up-at-5-30-am-Every-Morning-And-What-You-Will-Gain-From-Doing-It-Too/</link>
      <guid>http://example.com/2018/07/19/Why-I-Wake-Up-at-5-30-am-Every-Morning-And-What-You-Will-Gain-From-Doing-It-Too/</guid>
      <pubDate>Thu, 19 Jul 2018 00:52:23 GMT</pubDate>
      
      <description>&lt;p&gt;几个月前，我做出一个对我来说完全不合时宜，几个月内会产生日常影响的决定。&lt;/p&gt;
&lt;p&gt;决定就是在每天早上5:30醒来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/15319616493254.gif&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>几个月前，我做出一个对我来说完全不合时宜，几个月内会产生日常影响的决定。</p><p>决定就是在每天早上5:30醒来。</p><p><img src="/images/15319616493254.gif"></p><span id="more"></span><p>“为什么？”</p><p>这是一个合理的问题。 （我必须承认，有些早晨，我问自己同样的问题。）</p><p>你有没有醒过来觉得你完全没有了？你睁开眼睛，你就会因怨恨而战胜。你会立即想象你无情的待办事项清单，你背后的一切，以及所有必须达到的最后期限。</p><p>结果：每天早上醒来，希望你可以在床上度过余下的一天。</p><p>我不了解你，但在我的余生中每天都开始这样做？不，谢谢。</p><p>然后我发现了Hal Elrod的奇迹早晨，以及<a href="http://uk.businessinsider.com/successful-tech-people-who-wake-up-reall-early-2015-8?r=US&IR=T">一些最成功的企业家的早晨例程</a>。</p><p>如果成千上万的The Miracle Morning粉丝，以及像Richard Branson（Virgin的创始人兼首席执行官），Tim Cook（Apple首席执行官），Howard Schulz（星巴克首席执行官）和Jack Dorsey（Twitter创始人兼首席执行官）等人和广场）努力做到这一点，必须有一些东西，对吧？</p><p>这不是为了在太阳之前在5:30起床（我喜欢我的床和下一个人一样）。这是关于有时间完成活动，这些活动已知会对我们的心理状态，效率和（顺便提一下）我们的幸福水平产生相当积极的影响。</p><p>如果以热情的热情开始新的一天，并且想要充分利用它的想法吸引你，这就是我采用的惯例，很大程度上受到了哈尔·埃尔罗德在“奇迹早晨”中提出的建议的启发。<br>（重要提示：早上5点半醒来并不是强制性的。为了有时间进行这些活动，只需要比平常早起来就足够了。</p><h2 id="清醒你的思想和专心"><a href="#清醒你的思想和专心" class="headerlink" title="清醒你的思想和专心"></a>清醒你的思想和专心</h2><p>我们即将谈论冥想。关于冥想益处的科学证据正在增长。</p><p>冥想不一定是盘腿坐在地板上整整一个小时。经常练习五分钟的冥想会给你同样的好处。</p><p>我测试了两个可以在一开始就指导您的应用程序：</p><ul><li>Headspace（无可挑剔的用户体验设计！）</li><li>Calm（我目前使用的是什么）</li></ul><p>在The Miracle Morning中，Hal Elrod给出了一个简单的技巧：</p><ul><li>找一个舒适的地方，坐直。</li><li>闭上眼睛或盯着你面前的固定点。</li><li>专注于你的呼吸;从你的腹部吸气，通过胸部呼气。</li><li>欣赏平静;尽量专注于你的呼吸，不要想其他任何事情。当你的思绪徘徊到流浪的思绪时，不要惊慌失措，平静地将你的焦点吸回你的呼吸。<br>优点：</li></ul><p>你感到压力减轻，你获得了安心。经过一些练习，一旦你在那10分钟后重新睁开眼睛，你会真正感觉到你处于不同的心态。</p><h2 id="写"><a href="#写" class="headerlink" title="写"></a>写</h2><p>每天早上花点时间写几分钟，真的可以帮到你。它允许您评估您的当前状态，并重新关注重要的事情。</p><p>你可以，例如：</p><ul><li>写下你感恩的三件事：亲密的朋友和家人，一些好消息，美好的回忆或成就。</li><li>写下你当时的想法。</li><li>写下你想在白天完成的一切。</li><li>写下一条激励你或你想要记住的引语。</li><li>记下你最近学到的一件事或者你有一个顿悟。</li><li>一开始我曾经写过一个空白的Moleskine笔记本。然后我使用了一种特殊的日记（不是那些14岁小孩用的小心脏的日记）。今天，我正在制作自己的期刊。它将有一个特殊的布局，我可以回答预定义的每日问题。</li></ul><p>优点：</p><p>你会感到更快乐，更专注。做这个练习也可以帮助你记录你的进步，以及你生活中所有积极的事情。</p><h2 id="提醒自己你的目标"><a href="#提醒自己你的目标" class="headerlink" title="提醒自己你的目标"></a>提醒自己你的目标</h2><p>有几种方法可以做到这一点。您可以选择其中之一或三者的组合。</p><ul><li>誓词。这些是可重复的短语，描述了您想成为的人。</li><li>可视化。想象一下自己正在完成你想要完成的事情，享受美好的一天。想象并想象您将体验到的感受。</li><li>提醒目标。这是抽出我们之前讨论过的每周工作表的时刻。您还可以花点时间写下您的目标并提醒您自己想要完成它们的原因。例如：“与家人共度美好的一天 - 因为他们是我的首要任务。”<br>我第一次听到肯定和可视化时的初步反应：<br>（起初我有一点肯定和可视化方面有点麻烦。当你最初开始尝试它们时，你会感觉到你已经落在其中一个美国大会的中间，在那里演讲者告诉你你是多么美妙，以及如何改变世界…但最终，我已经习惯了他们。）</li></ul><h2 id="动起来-！"><a href="#动起来-！" class="headerlink" title="动起来 ！"></a>动起来 ！</h2><p>这是我日常动机的镜头！它让我想起了我想做什么，为什么要这样做，以及我将如何去做。</p><p>成功人士经常锻炼是有原因的。这是因为他们意识到他们需要在游戏中处于领先地位，以实现他们的目标，并且每天都充分发挥作用。</p><p>蒂姆库克每天凌晨5点去健身房，或者杰克多尔西跑10公里开始他的休息日并不奇怪。</p><p>如果您想在没有购买任何设备的情况下开始，无需加入健身房，也没有承诺，您可以举例：</p><p>去跑步，即使你开始10-15分钟<br>做一个着名的七分钟训练（例如这个 -  <a href="https://itunes.apple.com/en/app/7-minute-workout/id650762525?mt=8%EF%BC%89">https://itunes.apple.com/en/app/7-minute-workout/id650762525?mt=8）</a></p><p>每天早上做一点是理想的。但我发现最有用的是每隔一个早晨锻炼一个半小时。当我不锻炼时，我休息。最后，当我不去健身房时，我希望能够做10分钟的瑜伽。</p><p>优点：</p><p>早上进行某种形式的身体活动，即使只进行10分钟的运动，也可以让你完全醒来，放松压力，充满活力。哦是的，它也很健康。非常好，对吧</p><h2 id="读"><a href="#读" class="headerlink" title="读"></a>读</h2><p>您可以随意使用无限的知识来源：书籍。无论你想要完成什么：跑马拉松，致富，环游世界……有关于这个主题的书籍可以提供相当大的帮助。</p><p>每天早上阅读20分钟（甚至10分钟）意味着吸收知识，你可以立即付诸实践，更接近实现目标。</p><p>我经常写一些对我来说最有用的书籍摘要。</p><p>一些对我产生真正影响的书籍的例子：</p><ul><li>Tim Ferris的The 4-Hour Workweek（阅读它以大大提高您的工作效率）</li><li>Dale Carnegie 的How to Win Friends and Influence People （无疑是关于人际交往和情商的最佳现存书籍）</li><li>Chris Guillebeau的The100 Startup（向您展示如何在追求激情的同时获得良好的生活）</li><li>The Power of Less：将自己限制在商业和生活中必不可少的美术Leo Babauta（教你消除不必要的更多）</li></ul><p><strong>😎站长推荐：外文原版电子书推荐下载网站<a href="http://gen.lib.rus.ec/">Library Genesis</a></strong><br><img src="/images/15319638830117.jpg"></p><p>优点：</p><p>为什么不从成功人士的经验中学习呢？你会节省很多时间。你会丰富自己。通过分享您学到的所有知识，您将能够帮助身边的人。</p><p>我已经练习了几个月的这种仪式，这里有一些好处：</p><ul><li>我从未读过那么多，因此学到了很多东西！ （我也在早晨的仪式之外阅读）</li><li>我（最终）成功地致力于定期锻炼（这个奇迹一下）</li><li>我知道我想去哪里，为什么（即使“如何”仍然含糊不清）<br>顺便说一句，我在早上6:10写了这篇文章。我刚刚完成了早上的仪式，我已经开始完成当天的第一项任务了：写这篇文章！</li></ul><p>我只能鼓励你给自己每天开始的机会，而不是迟到和压力，但要照顾好自己，充满动力，并决心充分利用每一分钟。</p><h2 id="你的待办事项列表，如果你愿意的话"><a href="#你的待办事项列表，如果你愿意的话" class="headerlink" title="你的待办事项列表，如果你愿意的话"></a>你的待办事项列表，如果你愿意的话</h2><ul><li>对于你们中间的核心：明天早上比平常提前一小时设置你的闹钟，并且每次这些活动都要做10分钟。</li><li>对于那些喜欢慢慢做的人：选择两三个对你有吸引力的任务，并明天早上开始做。</li><li>他们说，为了在你的生活中建立一个新的习惯，你必须通过“21天大关。”如果你想冒险，你知道你必须做什么。</li></ul><h2 id="译者的话"><a href="#译者的话" class="headerlink" title="译者的话"></a>译者的话</h2><p>我尝试了许多传说中对于早期有帮助的APP，许多的理念基于强制性的让你做一些动作（比如强迫扫码你的牙膏）来消除你的睡意，不过我认为这种理念本来就是不对的，惹急了用户要睡删了APP不就行了？！😂<br>现在我用的感觉很成功的一款APP叫做<a href="https://www.sleepcycle.com/">Sleep Cycle alarm clock</a>，基于在你浅睡眠的时候叫醒的这个理念，保证闹铃响起的时候起床概率超高！<br>比如下图，我定了5：30的闹钟，那么APP会探测我在5：00~5：30之间的一个浅睡眠时刻叫醒我。<br><img src="/images/15319625280582.jpg"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.huffingtonpost.com/entry/why-i-wake-up-at-530-am-e_b_8055880">Why I Wake Up at 5:30 am Every Morning (And What You Will Gain From Doing It Too) | HuffPost</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/chicken-soup/">chicken-soup</category>
      
      
      <comments>http://example.com/2018/07/19/Why-I-Wake-Up-at-5-30-am-Every-Morning-And-What-You-Will-Gain-From-Doing-It-Too/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Datacamp Git 笔记</title>
      <link>http://example.com/2018/07/13/Datacamp-Git-Nones/</link>
      <guid>http://example.com/2018/07/13/Datacamp-Git-Nones/</guid>
      <pubDate>Fri, 13 Jul 2018 09:14:07 GMT</pubDate>
      
      <description>&lt;p&gt;最近入了&lt;a href=&quot;https://item.taobao.com/item.htm?spm=a1z09.2.0.0.11752e8diqYgI7&amp;id=565426495436&amp;_u=dn2i5bf6736&quot;&gt;elecomI Pad贴膜&lt;/a&gt;后用iPad写字感觉超棒！🐱&lt;br&gt;这里是一段DataCamp上的Git课程的笔记，当然这是免费课程，其实我领取&lt;a href=&quot;http://www.10tiao.com/html/407/201801/2650545581/1.html&quot;&gt;微软送的的两月DataCamp会员&lt;/a&gt;过期了。。。😡&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>最近入了<a href="https://item.taobao.com/item.htm?spm=a1z09.2.0.0.11752e8diqYgI7&id=565426495436&_u=dn2i5bf6736">elecomI Pad贴膜</a>后用iPad写字感觉超棒！🐱<br>这里是一段DataCamp上的Git课程的笔记，当然这是免费课程，其实我领取<a href="http://www.10tiao.com/html/407/201801/2650545581/1.html">微软送的的两月DataCamp会员</a>过期了。。。😡</p><span id="more"></span><p>这就是[elecomI 的Pad贴膜]<br><img src="/images/15319713559370.jpg"></p><p><img src="/images/IMG_0150.png" alt="IMG_0150"><br><img src="/images/IMG_0151.png" alt="IMG_0151"></p><p>后续有更新再补充~</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/git/">git</category>
      
      
      <comments>http://example.com/2018/07/13/Datacamp-Git-Nones/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>在Linux上重新映射Win，Ctrl和Alt键</title>
      <link>http://example.com/2018/07/12/remap-win-ctrl-and-alt-keys-on-linux/</link>
      <guid>http://example.com/2018/07/12/remap-win-ctrl-and-alt-keys-on-linux/</guid>
      <pubDate>Thu, 12 Jul 2018 08:43:42 GMT</pubDate>
      
      <description>&lt;p&gt;用惯了Mac上的CMD + * 等操作，就习惯了左手大拇指这个组合键操作了，切换到Linux上必须要Ctrl各种小指不舒服。。。值得一提的是Mac上左侧按键顺序是control、alt/option、command，Ubuntu则是control、super、alt，Windows则是control、Win、alt。这里我们方便Mac用户起见，就把Ubuntu的control、super、alt映射为super、alt、control&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>用惯了Mac上的CMD + * 等操作，就习惯了左手大拇指这个组合键操作了，切换到Linux上必须要Ctrl各种小指不舒服。。。值得一提的是Mac上左侧按键顺序是control、alt/option、command，Ubuntu则是control、super、alt，Windows则是control、Win、alt。这里我们方便Mac用户起见，就把Ubuntu的control、super、alt映射为super、alt、control</p><span id="more"></span><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.Xmodmap</span><br><span class="line"></span><br><span class="line">clear control</span><br><span class="line">clear mod1</span><br><span class="line">clear mod4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">keycode 37  = Super_L     </span><br><span class="line">! left  Ctrl becomes Super</span><br><span class="line">keycode 64  = Control_L</span><br><span class="line">! left  Alt  becomes Control </span><br><span class="line">keycode 133 = Alt_L Meta_L</span><br><span class="line">! left  Win  becomes Alt</span><br><span class="line">keycode 108 = Control_R</span><br><span class="line">! right Alt  becomes Control </span><br><span class="line">keycode 134 = Alt_R Meta_R</span><br><span class="line">! right Win  becomes Alt</span><br><span class="line">keycode 105 = Super_R</span><br><span class="line">! right Ctrl becomes Super</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">add control = Control_L Control_R</span><br><span class="line">add mod1 = Alt_L Meta_L</span><br><span class="line">add mod4 = Super_L Super_R</span><br></pre></td></tr></table></figure><p>再<code>xmodmap ~/.Xmodmap</code>即可！</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2018/07/12/remap-win-ctrl-and-alt-keys-on-linux/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mac 双开 ss 方法</title>
      <link>http://example.com/2018/05/31/dual-ss-on-mac/</link>
      <guid>http://example.com/2018/05/31/dual-ss-on-mac/</guid>
      <pubDate>Thu, 31 May 2018 11:24:17 GMT</pubDate>
      
      <description>&lt;p&gt;有时候我们需要两个代理，譬如一个用来连需要经过跳板机代理的集群服务，一个则用来科学上网，不停切换麻烦且代价比较高，那我们除了ShadowsocksX-NG客户端之外，我们可以用命令行的方式再开启一个，&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>有时候我们需要两个代理，譬如一个用来连需要经过跳板机代理的集群服务，一个则用来科学上网，不停切换麻烦且代价比较高，那我们除了ShadowsocksX-NG客户端之外，我们可以用命令行的方式再开启一个，</p><span id="more"></span><p><img src="/images/15277663104280.jpg"></p><p><img src="/images/15277666370736.jpg"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用Homebrew安装</span></span><br><span class="line">brew install shadowsocks-libev</span><br><span class="line"><span class="comment"># 编辑配置信息</span></span><br><span class="line">sudo vim /usr/<span class="built_in">local</span>/etc/shadowsocks-libev.json</span><br><span class="line"><span class="comment"># 格式如下，注意与ShadowsocksX-NG的local_port也就是socks5不同</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;server&quot;</span>:<span class="string">&quot;107.167.185.234&quot;</span>,</span><br><span class="line">    <span class="string">&quot;server_port&quot;</span>:11499,</span><br><span class="line">    <span class="string">&quot;local_port&quot;</span>:1079,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>:<span class="string">&quot;xxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;timeout&quot;</span>:600,</span><br><span class="line">    <span class="string">&quot;method&quot;</span>:<span class="string">&quot;aes-256-gcm&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 重启 shadowsocks-libev，会自动添加开机自启</span></span><br><span class="line">brew services restart shadowsocks-libev</span><br></pre></td></tr></table></figure><p>再在SwitchyOmega里面设置两个不同的代理即可，<br><img src="/images/15277663992132.jpg"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Mac/">Mac</category>
      
      
      <comments>http://example.com/2018/05/31/dual-ss-on-mac/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>从 Hive 获取数据到本地的方法 🦄</title>
      <link>http://example.com/2018/05/03/get-table-from-spark/</link>
      <guid>http://example.com/2018/05/03/get-table-from-spark/</guid>
      <pubDate>Thu, 03 May 2018 12:51:14 GMT</pubDate>
      
      <description>&lt;p&gt;我们使用pyspark 读取Hive里的表格，存储到HDFS，再get到跳板机，再rsync到本地，再用dask读取为Dataframe。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>我们使用pyspark 读取Hive里的表格，存储到HDFS，再get到跳板机，再rsync到本地，再用dask读取为Dataframe。</p><span id="more"></span><h2 id="第一版"><a href="#第一版" class="headerlink" title="第一版"></a>第一版</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">1</span> <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> *</span><br><span class="line"> <span class="number">2</span> <span class="keyword">import</span> pyspark</span><br><span class="line"> <span class="number">3</span> <span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"> <span class="number">4</span>     spark = SparkSession.builder.master(<span class="string">&quot;yarn&quot;</span>).appName(<span class="string">&quot;pyspark location process&quot;</span>).enableHiveSupport().getOrCreate()</span><br><span class="line"> <span class="number">5</span>     sc = spark.sparkContext</span><br><span class="line"> <span class="number">6</span>    <span class="comment"># spark.sql(&#x27;show databases&#x27;).show()</span></span><br><span class="line"> <span class="number">7</span>     spark.sql(<span class="string">&#x27;use annals&#x27;</span>).show()</span><br><span class="line"> <span class="number">8</span>    <span class="comment"># spark.sql(&#x27;describe gps2&#x27;).show()</span></span><br><span class="line"> <span class="number">9</span>     spark.sql(<span class="string">&#x27;select * from gps2 limit 1&#x27;</span>).show()</span><br><span class="line"><span class="number">10</span>     sql_df = spark.sql(<span class="string">&#x27;select uid, lat, lgt, app_adjust_time from gps2 limit 5&#x27;</span>)</span><br><span class="line"><span class="number">11</span>     <span class="comment">#sql_df.show()</span></span><br><span class="line"><span class="number">12</span>     <span class="built_in">print</span>(<span class="built_in">type</span>(sql_df))</span><br><span class="line"><span class="number">13</span>     sql_df.write.save(<span class="string">&quot;data/GrMWKfDj9eIjsRuh.parquet&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="第二版"><a href="#第二版" class="headerlink" title="第二版"></a>第二版</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find pyspark and import</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gc </span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&quot;/opt/cloudera/parcels/SPARK2/lib/spark2&quot;</span></span><br><span class="line">sys.path.append(os.path.join(<span class="string">&quot;/home/ubuntu/data/pythonpackage&quot;</span>))</span><br><span class="line">sys.path.append(os.path.join(os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>], <span class="string">&quot;python&quot;</span>))</span><br><span class="line">sys.path.append(os.path.join(os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>], <span class="string">&quot;python/lib/py4j-0.10.6-src.zip&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">    <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> ImportError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;error importing spark modules&quot;</span>, e)</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#   SparkSession初始化</span></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .master(<span class="string">&quot;yarn&quot;</span>) \</span><br><span class="line">    .appName(<span class="string">&quot;gps&quot;</span>) \</span><br><span class="line">    .config(<span class="string">&quot;spark.submit.deployMode&quot;</span>,<span class="string">&quot;client&quot;</span>) \</span><br><span class="line">    .config(<span class="string">&quot;num-executors&quot;</span>, <span class="number">5</span>) \</span><br><span class="line">    .config(<span class="string">&quot;executor-cores&quot;</span>, <span class="number">4</span>) \</span><br><span class="line">    .config(<span class="string">&quot;executor-memory&quot;</span>, <span class="string">&quot;2g&quot;</span>) \</span><br><span class="line">    .config(<span class="string">&quot;driver-memory&quot;</span>, <span class="string">&quot;1g&quot;</span>) \</span><br><span class="line">    .enableHiveSupport() \</span><br><span class="line">    .getOrCreate() </span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># spark sql，得到dataframe</span></span><br><span class="line">df = spark.sql(<span class="string">&quot;SELECT * FROM tmp.czn_userlocation_filteredby_black&quot;</span>)</span><br><span class="line">df.printSchema()</span><br><span class="line">df.show(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写到hdfs上，parquet格式</span></span><br><span class="line">df.write.parquet(<span class="string">&quot;/user/akulaku/czn_userlocation_filteredby_black.parquet&quot;</span>) </span><br></pre></td></tr></table></figure><p>这样我们就在hdfs上得到了一份parquet格式的文件。</p><h2 id="第三版"><a href="#第三版" class="headerlink" title="第三版"></a>第三版</h2><p>有时候我们可以在hive或者impala上建表，例如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table tmp.czn_usersensorlog_of_may as SELECT uid, apptime, value0, value1, value2 FROM ods.usersensorlog WHERE month = <span class="string">&quot;2018_05&quot;</span> </span><br></pre></td></tr></table></figure><p><code>show create table tmp.czn_usersensorlog_of_may</code><br><code>CREATE TABLE tmp.czn_usersensorlog_of_may (   uid BIGINT,   apptime BIGINT,   value0 FLOAT,   value1 FLOAT,   value2 FLOAT ) STORED AS TEXTFILE LOCATION &#39;hdfs://nameservice1/user/hive/warehouse/tmp.db/czn_usersensorlog_of_may&#39; </code></p><h2 id="第四版"><a href="#第四版" class="headerlink" title="第四版"></a>第四版</h2><p>有时候我们需要指定表的格式为parquet，这样有利于用pandas或者dask读取，那么可以如下设置，这里我们先建表再插入数据，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">drop table <span class="keyword">if</span> exists tmp.czn_userlocation_tmp_test;</span><br><span class="line">CREATE TABLE tmp.czn_userlocation_tmp_test </span><br><span class="line">(   </span><br><span class="line">uid BIGINT,</span><br><span class="line">lat <span class="built_in">float</span>,</span><br><span class="line">lgt <span class="built_in">float</span>,</span><br><span class="line">apptime BIGINT,</span><br><span class="line">)</span><br><span class="line">STORED AS PARQUET</span><br><span class="line">TBLPROPERTIES (<span class="string">&#x27;parquet.compression&#x27;</span>=<span class="string">&#x27;SNAPPY&#x27;</span>);</span><br><span class="line"></span><br><span class="line">insert OVERWRITE TABLE tmp. czn_userlocation_tmp_test</span><br><span class="line">SELECT  uid, lat, lgt,  apptime </span><br><span class="line">from kafka_table.userlocation2 </span><br><span class="line">WHERE apptime between 1532156404000 and 1532156764000;</span><br></pre></td></tr></table></figure><p>得到了hdfs路径，这里我们可以直接用hdfs命令get</p><p>此时数据只是在hdfs上，我们要下载还需要将数据从hdfs 复制到跳板机，</p><p><code>hadoop fs -get /user/akulaku/czn_userlocation_filteredby_black.parquet chenzn/</code></p><p>再scp 之类的 复制到本地即可，不过相比scp，rsync更适合传输parquet，例如，可以压缩，断点续传等等，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -P -z -r -e ssh akulaku@cdh-master4:~/chenzn/czn_userlocation_filteredby_black.parquet ~</span><br></pre></td></tr></table></figure><p>parquet格式文件的读取可以使用dask，并选择‘pyarrow’引擎，可以顺利读取超过内存的数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dask.dataframe <span class="keyword">as</span> dd</span><br><span class="line">df = dd.read_parquet(file_path, engine=<span class="string">&#x27;pyarrow&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>rsync其中参数如下，参考自<a href="https://kyup.com/tutorials/copy-files-rsync-ssh/">How to copy files with rsync over SSH - Tutorials For Kyup.com</a>：</p><ul><li>–delete - delete files that don’t exist on sender (system)</li><li>-v - verbose (-vv will provide more detailed information)</li><li>-e “ssh options” - specify the ssh as remote shell</li><li>-a - archive mode - it preserves permissions (owners, groups), times, symbolic links, and devices</li><li>-r - recurse into directories</li><li>-z - compress file data during transfer</li><li>–exclude ‘foldername’ – excludes the corresponding folder from transfer</li><li>-P – show progress during transfer</li></ul><p>🐶🐒</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/spark/">spark</category>
      
      
      <comments>http://example.com/2018/05/03/get-table-from-spark/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mac 通过 socks5 代理 连接 ssh 的方法🏆</title>
      <link>http://example.com/2018/05/03/mac-ssh-through-socks5-proxy/</link>
      <guid>http://example.com/2018/05/03/mac-ssh-through-socks5-proxy/</guid>
      <pubDate>Thu, 03 May 2018 09:08:10 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;经过一番痛苦的折腾，我才发现**socks,http代理等使用的是TCP或UDP协议, 而ping命令则是ICMP协议, 所以proxychains4对ping命令无效.**，最终又折腾过tsocks等和proxychains一样德行的以后，最终在万能的Stack Over</description>
        
      
      
      
      <content:encoded><![CDATA[<p>经过一番痛苦的折腾，我才发现**socks,http代理等使用的是TCP或UDP协议, 而ping命令则是ICMP协议, 所以proxychains4对ping命令无效.**，最终又折腾过tsocks等和proxychains一样德行的以后，最终在万能的Stack Overflow找到<a href="https://serverfault.com/questions/315605/ssh-through-a-socks-proxy-client-openssh-os-x">答案</a>：即通过NetCat (nc)连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.ssh/config</span><br><span class="line"><span class="comment"># 添加以下内容</span></span><br><span class="line">Host 52.* <span class="comment"># 这里可以通配也可以指定IP</span></span><br><span class="line">    ProxyCommand nc -X 5 -x 127.0.0.1:1079 %h %p</span><br><span class="line">    <span class="comment"># &quot;5&quot; 是 SOCKS 5, &quot;1079&quot; 是本地socks端口</span></span><br></pre></td></tr></table></figure><p>之后直接使用<code>ssh</code>命令连接即可😎😂</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Mac/">Mac</category>
      
      
      <comments>http://example.com/2018/05/03/mac-ssh-through-socks5-proxy/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>moving averge 滑动平均</title>
      <link>http://example.com/2018/04/25/moving-averge/</link>
      <guid>http://example.com/2018/04/25/moving-averge/</guid>
      <pubDate>Wed, 25 Apr 2018 14:58:46 GMT</pubDate>
      
      <description>&lt;p&gt;moving averge 即滑动平均，时间序列处理中常见的方法，简单来说，就是对于一个给定数列，设定一个窗口值N，依次取第1项&lt;del&gt;第N项，第2项&lt;/del&gt;第N+1项，第3项~第N+2项的平均值，以此类推。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>moving averge 即滑动平均，时间序列处理中常见的方法，简单来说，就是对于一个给定数列，设定一个窗口值N，依次取第1项<del>第N项，第2项</del>第N+1项，第3项~第N+2项的平均值，以此类推。</p><span id="more"></span><p>数据来自<a href="http://blog.topspeedsnail.com/wp-content/uploads/2016/12/%E9%93%81%E8%B7%AF%E5%AE%A2%E8%BF%90%E9%87%8F.csv">铁路客运量.csv（2005-2016月度数据）</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line">pylab.style.use(<span class="string">&#x27;bmh&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line">rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = <span class="number">10</span>, <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">moving_average</span>(<span class="params">l, N</span>):</span></span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">result = <span class="built_in">list</span>( <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> l)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>( <span class="number">0</span>, N ):</span><br><span class="line">       <span class="comment"># 从左到右逐渐添加index在N之内的数字</span></span><br><span class="line"><span class="built_in">sum</span> = <span class="built_in">sum</span> + l[i]</span><br><span class="line">result[i] = <span class="built_in">sum</span> / (i+<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>( N, <span class="built_in">len</span>(l) ):</span><br><span class="line">       <span class="comment"># 加入最右边数字减去最左边数字</span></span><br><span class="line"><span class="built_in">sum</span> = <span class="built_in">sum</span> - l[i-N] + l[i]</span><br><span class="line">result[i] = <span class="built_in">sum</span> / N</span><br><span class="line"> </span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用效率更高的numpy</span></span><br><span class="line"><span class="comment"># http://stackoverflow.com/questions/13728392/moving-average-or-running-mean</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_moving_average</span>(<span class="params">x, N</span>):</span></span><br><span class="line"><span class="keyword">return</span> np.convolve(x, np.ones((N,))/N)[(N-<span class="number">1</span>):]</span><br><span class="line"> </span><br><span class="line">url = <span class="string">&#x27;铁路客运量.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">df = pd.read_csv(url)  <span class="comment"># python2使用StringIO.StringIO</span></span><br><span class="line"> </span><br><span class="line">data = np.array(df[<span class="string">&#x27;铁路客运量_当期值(万人)&#x27;</span>])</span><br><span class="line"> </span><br><span class="line">dic = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">3</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>]:</span><br><span class="line">    ma_data = moving_average(data, i)</span><br><span class="line">    dic[i] = ma_data</span><br><span class="line">ma_data_df = pd.DataFrame(dic)</span><br><span class="line"></span><br><span class="line">ma_data_df.plot()</span><br></pre></td></tr></table></figure><p>可以看到，趋势逐渐变得平滑，即对局部震荡不敏感。</p><p><img src="/images/download.png" alt="download"></p><p>使用numpy.convolve是一种更方便的方法，值得注意的是其有三种mode，分别是’full’（单个重叠也计算）, ‘same’（强制等长）, ‘valid’（完全重叠），</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_moving_average</span>(<span class="params">x, N, mode</span>):</span></span><br><span class="line"><span class="comment"># return np.convolve(x, np.ones((N,))/N, mode=&#x27;valid&#x27;)[(N-1):]</span></span><br><span class="line"><span class="keyword">return</span> np.convolve(x, np.ones((N,))/N, mode=mode)</span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">modes = [<span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;same&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>]</span><br><span class="line">i = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> mode <span class="keyword">in</span> modes:</span><br><span class="line">    ma_data = fast_moving_average(data, i, mode)</span><br><span class="line">    pylab.plot(ma_data)</span><br><span class="line">pylab.legend(modes)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/images/download%20-1-.png" alt="download -1-"></p><p>参考自斗大熊的博客<a href="http://blog.topspeedsnail.com/archives/11022">MovingAverage-滑动平均 – WTF Daily Blog</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/time-series/">time series</category>
      
      
      <comments>http://example.com/2018/04/25/moving-averge/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>keras 中模型的保存及重用</title>
      <link>http://example.com/2018/04/19/keras-reuse-model/</link>
      <guid>http://example.com/2018/04/19/keras-reuse-model/</guid>
      <pubDate>Thu, 19 Apr 2018 08:50:00 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15135840798621.jpg&quot;&gt;&lt;br&gt;深度学习中如何保存最佳模型，如何重用已经保存的模型？本文主要介绍Keras 保存及重用模型的方法&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15135840798621.jpg"><br>深度学习中如何保存最佳模型，如何重用已经保存的模型？本文主要介绍Keras 保存及重用模型的方法</p><span id="more"></span><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>如下，我们预定义保存的<code>hdf5</code>文件名，再初始化<code>ModelCheckpoint</code>，将其加入Keras的callback里（即每个batch结束后做的事情），那么模型就会在每次batch结束后对比，保存最好的模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line"><span class="comment"># Compile model</span></span><br><span class="line">model.<span class="built_in">compile</span>(...)</span><br><span class="line"><span class="comment"># checkpoint</span></span><br><span class="line">filepath=<span class="string">&quot;weights-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span></span><br><span class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">&#x27;val_acc&#x27;</span>, verbose=<span class="number">1</span>, save_best_only=<span class="literal">True</span>, mode=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=[checkpoint], verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>结束后，我们会得到如下的结果，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">weights-53-0.76.hdf5</span><br><span class="line">weights-71-0.76.hdf5</span><br><span class="line">weights-77-0.78.hdf5</span><br><span class="line">weights-99-0.78.hdf5</span><br></pre></td></tr></table></figure><p>如果我们只想保存一个最好的模型，那么把保存文件名字固定为<code>filepath=&quot;weights.best.hdf5&quot;</code>即可。</p><h2 id="load模型"><a href="#load模型" class="headerlink" title="load模型"></a>load模型</h2><p>注意，之前保存的只是模型的weights，重新load需要再次定义模型结构再load weights并再次combine，例如</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line"><span class="comment"># load weights</span></span><br><span class="line">model.load_weights(<span class="string">&quot;weights.best.hdf5&quot;</span>)</span><br><span class="line"><span class="comment"># Compile model </span></span><br><span class="line">model.<span class="built_in">compile</span>(...)</span><br><span class="line"><span class="comment"># estimate accuracy </span></span><br><span class="line">scores = model.evaluate(X, Y, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;: &#123;:.2%&#125;&#x27;</span>.<span class="built_in">format</span>(model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p>如果之前选择了连模型结构也一起保存（即在<code>ModelCheckpoint</code>中选择<code> save_weights_only=False</code>），那么load就很简单，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line">model.add(...)</span><br><span class="line"><span class="comment"># Compile model</span></span><br><span class="line">model.<span class="built_in">compile</span>(...)</span><br><span class="line"><span class="comment"># checkpoint</span></span><br><span class="line">filepath=<span class="string">&quot;weights-best.hdf5&quot;</span></span><br><span class="line">checkpoint = ModelCheckpoint(filepath, monitor=<span class="string">&#x27;val_acc&#x27;</span>, verbose=<span class="number">1</span>, save_best_only=<span class="literal">True</span>, mode=<span class="string">&#x27;max&#x27;</span>, save_weights_only=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">model.fit(X, Y, validation_split=<span class="number">0.33</span>, epochs=<span class="number">150</span>, batch_size=<span class="number">10</span>, callbacks=[checkpoint], verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">model= load_model(filepath)</span><br><span class="line">scores=model.evaluate(X, Y,verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;: &#123;:.2%&#125;&#x27;</span>.<span class="built_in">format</span>(model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Keras/">Keras</category>
      
      
      <comments>http://example.com/2018/04/19/keras-reuse-model/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>理解一维卷积</title>
      <link>http://example.com/2018/04/17/conv1d-in-keras/</link>
      <guid>http://example.com/2018/04/17/conv1d-in-keras/</guid>
      <pubDate>Tue, 17 Apr 2018 07:46:36 GMT</pubDate>
      
      <description>&lt;p&gt;理解一维卷积&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>理解一维卷积</p><span id="more"></span><p>下面是一个利用CNN进行NLP中的情感分类的例子，<br><img src="/images/15240224514694.png"></p><p>上图中，输入为表示为词表为d=5，长度为7的矩阵的句子，1D卷积核为长度分别为(2,3,4)的各两个，经过卷积并激活函数后，各自产生了(4x1, 5x1, 6x1)的各两个feature map，每个feature map经过一次1D max pooling后（即取每个feature map的最大值）再concatenate为一个6x1的1D向量，经过一个全连接层再softmax激活即可进行情感分类预测。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      
      <comments>http://example.com/2018/04/17/conv1d-in-keras/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>处理大数据集的建议</title>
      <link>http://example.com/2018/04/10/handle-big-datasets/</link>
      <guid>http://example.com/2018/04/10/handle-big-datasets/</guid>
      <pubDate>Tue, 10 Apr 2018 07:07:34 GMT</pubDate>
      
      <description>&lt;p&gt;最近的一些比赛如&lt;a href=&quot;https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection&quot;&gt;TalkingData AdTracking Fraud Detection Challenge | Kaggle&lt;/a&gt;提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>最近的一些比赛如<a href="https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection">TalkingData AdTracking Fraud Detection Challenge | Kaggle</a>提供了很大的数据集，一般来说，只有16G的内存的“小”电脑都无法直接处理这种数据集了，本文收集了一些关于处理这种数据的建议，供大家参考。</p><span id="more"></span><h2 id="1-及时删除无用变量并垃圾回收"><a href="#1-及时删除无用变量并垃圾回收" class="headerlink" title="1.及时删除无用变量并垃圾回收"></a>1.及时删除无用变量并垃圾回收</h2><p>通常我们在特征工程中会涉及大量的转换操作，产生很多的中间变量等，除了使用<code>del</code>以外，使用<code>gc.collect()</code>也是个不错的选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">temp = pd.read_csv(<span class="string">&#x27;../input/train_sample.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#do something to the file</span></span><br><span class="line">temp[<span class="string">&#x27;os&#x27;</span>] = temp[<span class="string">&#x27;os&#x27;</span>].astype(<span class="string">&#x27;str&#x27;</span>)</span><br><span class="line"><span class="comment">#delete when no longer needed</span></span><br><span class="line"><span class="keyword">del</span> temp</span><br><span class="line"><span class="comment">#collect residual garbage</span></span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure><h2 id="2-预定义数据类型"><a href="#2-预定义数据类型" class="headerlink" title="2.预定义数据类型"></a>2.预定义数据类型</h2><p>pandas一般会自己推断数据类型，不过倾向于使用耗费空间大的，如下面例子所示，预定义数据类型节省了超过一半的空间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">dtypes = &#123;</span><br><span class="line">        <span class="string">&#x27;ip&#x27;</span>            : <span class="string">&#x27;uint32&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;app&#x27;</span>           : <span class="string">&#x27;uint16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;device&#x27;</span>        : <span class="string">&#x27;uint16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;os&#x27;</span>            : <span class="string">&#x27;uint16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;channel&#x27;</span>       : <span class="string">&#x27;uint16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;is_attributed&#x27;</span> : <span class="string">&#x27;uint8&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">dtypes2 = &#123;</span><br><span class="line">        <span class="string">&#x27;ip&#x27;</span>            : <span class="string">&#x27;int32&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;app&#x27;</span>           : <span class="string">&#x27;int16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;device&#x27;</span>        : <span class="string">&#x27;int16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;os&#x27;</span>            : <span class="string">&#x27;int16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;channel&#x27;</span>       : <span class="string">&#x27;int16&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;is_attributed&#x27;</span> : <span class="string">&#x27;int8&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">train = pd.read_csv(train_sample_file,parse_dates=[<span class="string">&#x27;click_time&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#check datatypes:</span></span><br><span class="line">train.info()</span><br><span class="line"></span><br><span class="line">train = pd.read_csv(train_sample_file,dtype=dtypes,parse_dates=[<span class="string">&#x27;click_time&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#check datatypes:</span></span><br><span class="line">train.info()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train = pd.read_csv(train_sample_file,dtype=dtypes2,parse_dates=[<span class="string">&#x27;click_time&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#check datatypes:</span></span><br><span class="line">train.info()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="string">RangeIndex: 100000 entries, 0 to 99999</span></span><br><span class="line"><span class="string">Data columns (total 8 columns):</span></span><br><span class="line"><span class="string">ip                 100000 non-null int64</span></span><br><span class="line"><span class="string">app                100000 non-null int64</span></span><br><span class="line"><span class="string">device             100000 non-null int64</span></span><br><span class="line"><span class="string">os                 100000 non-null int64</span></span><br><span class="line"><span class="string">channel            100000 non-null int64</span></span><br><span class="line"><span class="string">click_time         100000 non-null datetime64[ns]</span></span><br><span class="line"><span class="string">attributed_time    227 non-null object</span></span><br><span class="line"><span class="string">is_attributed      100000 non-null int64</span></span><br><span class="line"><span class="string">dtypes: datetime64[ns](1), int64(6), object(1)</span></span><br><span class="line"><span class="string">memory usage: 6.1+ MB</span></span><br><span class="line"><span class="string">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="string">RangeIndex: 100000 entries, 0 to 99999</span></span><br><span class="line"><span class="string">Data columns (total 8 columns):</span></span><br><span class="line"><span class="string">ip                 100000 non-null uint32</span></span><br><span class="line"><span class="string">app                100000 non-null uint16</span></span><br><span class="line"><span class="string">device             100000 non-null uint16</span></span><br><span class="line"><span class="string">os                 100000 non-null uint16</span></span><br><span class="line"><span class="string">channel            100000 non-null uint16</span></span><br><span class="line"><span class="string">click_time         100000 non-null datetime64[ns]</span></span><br><span class="line"><span class="string">attributed_time    227 non-null object</span></span><br><span class="line"><span class="string">is_attributed      100000 non-null uint8</span></span><br><span class="line"><span class="string">dtypes: datetime64[ns](1), object(1), uint16(4), uint32(1), uint8(1)</span></span><br><span class="line"><span class="string">memory usage: 2.8+ MB</span></span><br><span class="line"><span class="string">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="string">RangeIndex: 100000 entries, 0 to 99999</span></span><br><span class="line"><span class="string">Data columns (total 8 columns):</span></span><br><span class="line"><span class="string">ip                 100000 non-null int32</span></span><br><span class="line"><span class="string">app                100000 non-null int16</span></span><br><span class="line"><span class="string">device             100000 non-null int16</span></span><br><span class="line"><span class="string">os                 100000 non-null int16</span></span><br><span class="line"><span class="string">channel            100000 non-null int16</span></span><br><span class="line"><span class="string">click_time         100000 non-null datetime64[ns]</span></span><br><span class="line"><span class="string">attributed_time    227 non-null object</span></span><br><span class="line"><span class="string">is_attributed      100000 non-null int8</span></span><br><span class="line"><span class="string">dtypes: datetime64[ns](1), int16(4), int32(1), int8(1), object(1)</span></span><br><span class="line"><span class="string">memory usage: 2.8+ MB</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="3-只使用csv文件内的指定行"><a href="#3-只使用csv文件内的指定行" class="headerlink" title="3.只使用csv文件内的指定行"></a>3.只使用csv文件内的指定行</h2><h3 id="a-指定行数"><a href="#a-指定行数" class="headerlink" title="a) 指定行数"></a>a) 指定行数</h3><p>直接使用nrows指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, nrows=<span class="number">1e5</span>, dtype=dtypes)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="b-跳过行数"><a href="#b-跳过行数" class="headerlink" title="b) 跳过行数"></a>b) 跳过行数</h3><p>比如我们跳过前500w取100w下面保留了head，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, skiprows=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">5000000</span>), nrows=<span class="number">1000000</span>, dtype=dtypes)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="c-sampling"><a href="#c-sampling" class="headerlink" title="c) sampling"></a>c) sampling</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# Line count:&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> [<span class="string">&#x27;train.csv&#x27;</span>, <span class="string">&#x27;test.csv&#x27;</span>, <span class="string">&#x27;train_sample.csv&#x27;</span>]:</span><br><span class="line">    lines = subprocess.run([<span class="string">&#x27;wc&#x27;</span>, <span class="string">&#x27;-l&#x27;</span>, <span class="string">&#x27;../input/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(file)], stdout=subprocess.PIPE).stdout.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(lines, end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># Line count:</span></span><br><span class="line"><span class="string">184903891 ../input/train.csv</span></span><br><span class="line"><span class="string">18790470 ../input/test.csv</span></span><br><span class="line"><span class="string">100001 ../input/train_sample.csv</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>train一共有<code>lines=184903891</code> 行，那么假设我们需要采样出100w行，那么我们需要跳过<code>lines - 1 - 1000000</code>行，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#generate list of lines to skip</span></span><br><span class="line">skiplines = np.random.choice(np.arange(<span class="number">1</span>, lines), size=lines-<span class="number">1</span>-<span class="number">1000000</span>, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sort the list</span></span><br><span class="line">skiplines=np.sort(skiplines)</span><br><span class="line"><span class="comment">#check our list</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lines to skip:&#x27;</span>, <span class="built_in">len</span>(skiplines))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;remaining lines in sample:&#x27;</span>, lines-<span class="built_in">len</span>(skiplines), <span class="string">&#x27;(remember that it includes the heading!)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">###################SANITY CHECK###################</span></span><br><span class="line"><span class="comment">#find lines that weren&#x27;t skipped by checking difference between each consecutive line</span></span><br><span class="line"><span class="comment">#how many out of first 100000 will be imported into the csv?</span></span><br><span class="line">diff = skiplines[<span class="number">1</span>:<span class="number">100000</span>]-skiplines[<span class="number">2</span>:<span class="number">100001</span>]</span><br><span class="line">remain = <span class="built_in">sum</span>(diff!=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Ratio of lines from first 100000 lines:&#x27;</span>,  <span class="string">&#x27;&#123;0:.5f&#125;&#x27;</span>.<span class="built_in">format</span>(remain/<span class="number">100000</span>) ) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Ratio imported from all lines:&#x27;</span>, <span class="string">&#x27;&#123;0:.5f&#125;&#x27;</span>.<span class="built_in">format</span>((lines-<span class="built_in">len</span>(skiplines))/lines) )</span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, skiprows=skiplines, dtype=dtypes)</span><br><span class="line">train.head()</span><br><span class="line"><span class="keyword">del</span> skiplines</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure><h2 id="4-使用pandas-的生成器，用chunk处理"><a href="#4-使用pandas-的生成器，用chunk处理" class="headerlink" title="4.使用pandas 的生成器，用chunk处理"></a>4.使用pandas 的生成器，用chunk处理</h2><p>这里我们使用np.where过滤掉‘is_attributed’为0的部分（例如<code>[xv if c else yv for (c,xv,yv) in zip(condition,x,y)] </code>）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#set up an empty dataframe</span></span><br><span class="line">df_converted = pd.DataFrame()</span><br><span class="line"></span><br><span class="line"><span class="comment">#we are going to work with chunks of size 1 million rows</span></span><br><span class="line">chunksize = <span class="number">10</span> ** <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#in each chunk, filter for values that have &#x27;is_attributed&#x27;==1, and merge these values into one dataframe</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, chunksize=chunksize, dtype=dtypes):</span><br><span class="line">    filtered = (chunk[(np.where(chunk[<span class="string">&#x27;is_attributed&#x27;</span>]==<span class="number">1</span>, <span class="literal">True</span>, <span class="literal">False</span>))])</span><br><span class="line">    df_converted = pd.concat([df_converted, filtered], ignore_index=<span class="literal">True</span>, )</span><br></pre></td></tr></table></figure><h2 id="5-只载入若干列"><a href="#5-只载入若干列" class="headerlink" title="5.只载入若干列"></a>5.只载入若干列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#wanted columns</span></span><br><span class="line">columns = [<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;click_time&#x27;</span>, <span class="string">&#x27;is_attributed&#x27;</span>]</span><br><span class="line">dtypes = &#123;</span><br><span class="line">        <span class="string">&#x27;ip&#x27;</span>            : <span class="string">&#x27;uint32&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;is_attributed&#x27;</span> : <span class="string">&#x27;uint8&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">ips_df = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>, usecols=columns, dtype=dtypes)</span><br><span class="line"><span class="built_in">print</span>(ips_df.info())</span><br><span class="line">ips_df.head()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="string">RangeIndex: 184903890 entries, 0 to 184903889</span></span><br><span class="line"><span class="string">Data columns (total 3 columns):</span></span><br><span class="line"><span class="string">ip               uint32</span></span><br><span class="line"><span class="string">click_time       object</span></span><br><span class="line"><span class="string">is_attributed    uint8</span></span><br><span class="line"><span class="string">dtypes: object(1), uint32(1), uint8(1)</span></span><br><span class="line"><span class="string">memory usage: 2.2+ GB</span></span><br><span class="line"><span class="string">None&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="6-结合多种方法创意性的处理数据"><a href="#6-结合多种方法创意性的处理数据" class="headerlink" title="6.结合多种方法创意性的处理数据"></a>6.结合多种方法创意性的处理数据</h2><p>例如无法使用整个数据来groupby那么可以分块来做，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">size=<span class="number">100000</span></span><br><span class="line">all_rows = <span class="built_in">len</span>(ips_df)</span><br><span class="line">num_parts = all_rows//size</span><br><span class="line"></span><br><span class="line"><span class="comment">#generate the first batch</span></span><br><span class="line">ip_sums = ips_df[<span class="number">0</span>:size][[<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;is_attributed&#x27;</span>]].groupby(<span class="string">&#x27;ip&#x27;</span>, as_index=<span class="literal">False</span>).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">#add remaining batches</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,num_parts):</span><br><span class="line">    start = p*size</span><br><span class="line">    end = p*size + size</span><br><span class="line">    <span class="keyword">if</span> end &lt; all_rows:</span><br><span class="line">        group = ips_df[start:end][[<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;is_attributed&#x27;</span>]].groupby(<span class="string">&#x27;ip&#x27;</span>, as_index=<span class="literal">False</span>).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        group = ips_df[start:][[<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;is_attributed&#x27;</span>]].groupby(<span class="string">&#x27;ip&#x27;</span>, as_index=<span class="literal">False</span>).<span class="built_in">sum</span>()</span><br><span class="line">    ip_sums = ip_sums.merge(group, on=<span class="string">&#x27;ip&#x27;</span>, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">    ip_sums.columns = [<span class="string">&#x27;ip&#x27;</span>, <span class="string">&#x27;sum1&#x27;</span>,<span class="string">&#x27;sum2&#x27;</span>]</span><br><span class="line">    ip_sums[<span class="string">&#x27;conversions_per_ip&#x27;</span>] = np.nansum((ip_sums[<span class="string">&#x27;sum1&#x27;</span>], ip_sums[<span class="string">&#x27;sum2&#x27;</span>]), axis = <span class="number">0</span>)</span><br><span class="line">    ip_sums.drop(columns=[<span class="string">&#x27;sum1&#x27;</span>, <span class="string">&#x27;sum2&#x27;</span>], axis = <span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="7-使用dask代替pandas"><a href="#7-使用dask代替pandas" class="headerlink" title="7.使用dask代替pandas"></a>7.使用dask代替pandas</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import dask</span><br><span class="line">import dask.dataframe as dd</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Kaggle/">Kaggle</category>
      
      
      <comments>http://example.com/2018/04/10/handle-big-datasets/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>机器学习之 sklearn中的pipeline</title>
      <link>http://example.com/2018/04/08/pipeline-in-machine-learning/</link>
      <guid>http://example.com/2018/04/08/pipeline-in-machine-learning/</guid>
      <pubDate>Sun, 08 Apr 2018 08:13:42 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15231874915799.jpg&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15231874915799.jpg"></p><span id="more"></span><p>如图所示，利用pipeline我们可以方便的减少代码量同时让机器学习的流程变得直观，<br><img src="/images/15231783974167.jpg"></p><p>例如我们需要做如下操作，容易看出，训练测试集重复了代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vect = CountVectorizer()</span><br><span class="line">tfidf = TfidfTransformer()</span><br><span class="line">clf = SGDClassifier()</span><br><span class="line"></span><br><span class="line">vX = vect.fit_transform(Xtrain)</span><br><span class="line">tfidfX = tfidf.fit_transform(vX)</span><br><span class="line">predicted = clf.fit_predict(tfidfX)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now evaluate all steps on test set</span></span><br><span class="line">vX = vect.fit_transform(Xtest)</span><br><span class="line">tfidfX = tfidf.fit_transform(vX)</span><br><span class="line">predicted = clf.fit_predict(tfidfX)</span><br></pre></td></tr></table></figure><p>利用pipeline，上面代码可以抽象为，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;vect&#x27;</span>, CountVectorizer()),</span><br><span class="line">    (<span class="string">&#x27;tfidf&#x27;</span>, TfidfTransformer()),</span><br><span class="line">    (<span class="string">&#x27;clf&#x27;</span>, SGDClassifier()),</span><br><span class="line">])</span><br><span class="line">predicted = pipeline.fit(Xtrain).predict(Xtrain)</span><br><span class="line"><span class="comment"># Now evaluate all steps on test set</span></span><br><span class="line">predicted = pipeline.predict(Xtest)</span><br></pre></td></tr></table></figure><p>注意，pipeline最后一步如果有predict()方法我们才可以对pipeline使用fit_predict()，同理，最后一步如果有transform()方法我们才可以对pipeline使用fit_transform()方法。</p><h2 id="使用pipeline做cross-validation"><a href="#使用pipeline做cross-validation" class="headerlink" title="使用pipeline做cross validation"></a>使用pipeline做cross validation</h2><p>看如下案例，即先对输入手写数字的数据进行PCA降维，再通过逻辑回归预测标签。其中我们通过pipeline对<br>PCA的降维维数n_components和逻辑回归的正则项C大小做交叉验证，主要步骤有：</p><ol><li>依次实例化各成分对象如<code>pca = decomposition.PCA()</code></li><li>以(name, object)的tuble为元素组装pipeline如<code>Pipeline(steps=[(&#39;pca&#39;, pca), (&#39;logistic&#39;, logistic)])</code></li><li>初始化CV参数如<code>n_components = [20, 40, 64]</code></li><li>实例化CV对象如<code>estimator = GridSearchCV(pipe, dict(pca__n_components=n_components, logistic__C=Cs))</code>，其中注意参数的传递方式，即key为pipeline元素名+函数参数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, decomposition, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">logistic = linear_model.LogisticRegression()</span><br><span class="line"></span><br><span class="line">pca = decomposition.PCA()</span><br><span class="line">pipe = Pipeline(steps=[(<span class="string">&#x27;pca&#x27;</span>, pca), (<span class="string">&#x27;logistic&#x27;</span>, logistic)])</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">X_digits = digits.data</span><br><span class="line">y_digits = digits.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prediction</span></span><br><span class="line">n_components = [<span class="number">20</span>, <span class="number">40</span>, <span class="number">64</span>]</span><br><span class="line">Cs = np.logspace(-<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">pca.fit(X_digits)</span><br><span class="line">estimator = GridSearchCV(pipe,</span><br><span class="line">                         <span class="built_in">dict</span>(pca__n_components=n_components, logistic__C=Cs))</span><br><span class="line">estimator.fit(X_digits, y_digits)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.clf()</span><br><span class="line">plt.axes([<span class="number">.2</span>, <span class="number">.2</span>, <span class="number">.7</span>, <span class="number">.7</span>])</span><br><span class="line">plt.plot(pca.explained_variance_, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;n_components&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;explained_variance_&#x27;</span>)</span><br><span class="line">plt.axvline(</span><br><span class="line">    estimator.best_estimator_.named_steps[<span class="string">&#x27;pca&#x27;</span>].n_components,</span><br><span class="line">    linestyle=<span class="string">&#x27;:&#x27;</span>,</span><br><span class="line">    label=<span class="string">&#x27;n_components chosen&#x27;</span>)</span><br><span class="line">plt.legend(prop=<span class="built_in">dict</span>(size=<span class="number">12</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="自定义transformer"><a href="#自定义transformer" class="headerlink" title="自定义transformer"></a>自定义transformer</h2><p>我们可以如下自定义transformer（来自<a href="http://michelleful.github.io/code-blog/2015/06/20/pipelines/">Using Pipelines and FeatureUnions in scikit-learn - Michelle Fullwood</a>）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SampleExtractor</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, <span class="built_in">vars</span></span>):</span></span><br><span class="line">        self.<span class="built_in">vars</span> = <span class="built_in">vars</span>  <span class="comment"># e.g. pass in a column name to extract</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> do_something_to(X, self.<span class="built_in">vars</span>)  <span class="comment"># where the actual feature extraction happens</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self  <span class="comment"># generally does nothing</span></span><br></pre></td></tr></table></figure><p>另外，我们也可以对每个feature单独处理，例如下面的这个比较大的流水线（来自<a href="http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html">Using scikit-learn Pipelines and FeatureUnions | zacstewart.com</a>），我们可以发现作者的pipeline中，首先是一个叫做<code>features</code>的FeatureUnion，其中，每个特征分别以一个pipeline来处理，这个pipeline首先是一个<code>ColumnExtractor</code>提取出这个特征，后续进行一系列处理转换，最终这些pipeline组合为特征组合，再喂给一系列<code>ModelTransformer</code>包装的模型来predict，最终使用<code>KNeighborsRegressor</code>预测（相当于两层stacking）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">&#x27;features&#x27;</span>, FeatureUnion([</span><br><span class="line">        (<span class="string">&#x27;continuous&#x27;</span>, Pipeline([</span><br><span class="line">            (<span class="string">&#x27;extract&#x27;</span>, ColumnExtractor(CONTINUOUS_FIELDS)),</span><br><span class="line">            (<span class="string">&#x27;scale&#x27;</span>, Normalizer())</span><br><span class="line">        ])),</span><br><span class="line">        (<span class="string">&#x27;factors&#x27;</span>, Pipeline([</span><br><span class="line">            (<span class="string">&#x27;extract&#x27;</span>, ColumnExtractor(FACTOR_FIELDS)),</span><br><span class="line">            (<span class="string">&#x27;one_hot&#x27;</span>, OneHotEncoder(n_values=<span class="number">5</span>)),</span><br><span class="line">            (<span class="string">&#x27;to_dense&#x27;</span>, DenseTransformer())</span><br><span class="line">        ])),</span><br><span class="line">        (<span class="string">&#x27;weekday&#x27;</span>, Pipeline([</span><br><span class="line">            (<span class="string">&#x27;extract&#x27;</span>, DayOfWeekTransformer()),</span><br><span class="line">            (<span class="string">&#x27;one_hot&#x27;</span>, OneHotEncoder()),</span><br><span class="line">            (<span class="string">&#x27;to_dense&#x27;</span>, DenseTransformer())</span><br><span class="line">        ])),</span><br><span class="line">        (<span class="string">&#x27;hour_of_day&#x27;</span>, HourOfDayTransformer()),</span><br><span class="line">        (<span class="string">&#x27;month&#x27;</span>, Pipeline([</span><br><span class="line">            (<span class="string">&#x27;extract&#x27;</span>, ColumnExtractor([<span class="string">&#x27;datetime&#x27;</span>])),</span><br><span class="line">            (<span class="string">&#x27;to_month&#x27;</span>, DateTransformer()),</span><br><span class="line">            (<span class="string">&#x27;one_hot&#x27;</span>, OneHotEncoder()),</span><br><span class="line">            (<span class="string">&#x27;to_dense&#x27;</span>, DenseTransformer())</span><br><span class="line">        ])),</span><br><span class="line">        (<span class="string">&#x27;growth&#x27;</span>, Pipeline([</span><br><span class="line">            (<span class="string">&#x27;datetime&#x27;</span>, ColumnExtractor([<span class="string">&#x27;datetime&#x27;</span>])),</span><br><span class="line">            (<span class="string">&#x27;to_numeric&#x27;</span>, MatrixConversion(<span class="built_in">int</span>)),</span><br><span class="line">            (<span class="string">&#x27;regression&#x27;</span>, ModelTransformer(LinearRegression()))</span><br><span class="line">        ]))</span><br><span class="line">    ])),</span><br><span class="line">    (<span class="string">&#x27;estimators&#x27;</span>, FeatureUnion([</span><br><span class="line">        (<span class="string">&#x27;knn&#x27;</span>, ModelTransformer(KNeighborsRegressor(n_neighbors=<span class="number">5</span>))),</span><br><span class="line">        (<span class="string">&#x27;gbr&#x27;</span>, ModelTransformer(GradientBoostingRegressor())),</span><br><span class="line">        (<span class="string">&#x27;dtr&#x27;</span>, ModelTransformer(DecisionTreeRegressor())),</span><br><span class="line">        (<span class="string">&#x27;etr&#x27;</span>, ModelTransformer(ExtraTreesRegressor())),</span><br><span class="line">        (<span class="string">&#x27;rfr&#x27;</span>, ModelTransformer(RandomForestRegressor())),</span><br><span class="line">        (<span class="string">&#x27;par&#x27;</span>, ModelTransformer(PassiveAggressiveRegressor())),</span><br><span class="line">        (<span class="string">&#x27;en&#x27;</span>, ModelTransformer(ElasticNet())),</span><br><span class="line">        (<span class="string">&#x27;cluster&#x27;</span>, ModelTransformer(KMeans(n_clusters=<span class="number">2</span>)))</span><br><span class="line">    ])),</span><br><span class="line">    (<span class="string">&#x27;estimator&#x27;</span>, KNeighborsRegressor())</span><br><span class="line">])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HourOfDayTransformer</span>(<span class="params">TransformerMixin</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X, **transform_params</span>):</span></span><br><span class="line">        hours = DataFrame(X[<span class="string">&#x27;datetime&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.hour))</span><br><span class="line">        <span class="keyword">return</span> hours</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y=<span class="literal">None</span>, **fit_params</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelTransformer</span>(<span class="params">TransformerMixin</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, model</span>):</span></span><br><span class="line">        self.model = model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.model.fit(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X, **transform_params</span>):</span></span><br><span class="line">        <span class="keyword">return</span> DataFrame(self.model.predict(X))</span><br></pre></td></tr></table></figure><h2 id="FeatureUnion"><a href="#FeatureUnion" class="headerlink" title="FeatureUnion"></a>FeatureUnion</h2><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html">sklearn.pipeline.FeatureUnion — scikit-learn 0.19.1 documentation</a> 和pipeline的序列执行不同，FeatureUnion指的是并行地应用许多transformer在input上，再将结果合并，所以自然地适合特征工程中的增加特征，而FeatureUnion与pipeline组合可以方便的完成许多复杂的操作，例如如下的例子，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pipeline = Pipeline([</span><br><span class="line">  (<span class="string">&#x27;extract_essays&#x27;</span>, EssayExractor()),</span><br><span class="line">  (<span class="string">&#x27;features&#x27;</span>, FeatureUnion([</span><br><span class="line">    (<span class="string">&#x27;ngram_tf_idf&#x27;</span>, Pipeline([</span><br><span class="line">      (<span class="string">&#x27;counts&#x27;</span>, CountVectorizer()),</span><br><span class="line">      (<span class="string">&#x27;tf_idf&#x27;</span>, TfidfTransformer())</span><br><span class="line">    ])),</span><br><span class="line">    (<span class="string">&#x27;essay_length&#x27;</span>, LengthTransformer()),</span><br><span class="line">    (<span class="string">&#x27;misspellings&#x27;</span>, MispellingCountTransformer())</span><br><span class="line">  ])),</span><br><span class="line">  (<span class="string">&#x27;classifier&#x27;</span>, MultinomialNB())</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>整个<code>features</code>是一个FeatureUnion，而其中的ngram_tf_idf又是一个包括两步的pipeline。<br><img src="/images/15233302459256.jpg"></p><p>下面的例子中，使用FeatureUnion结合PCA降维后特征以及选择原特征中的几个作为特征组合再喂给SVM分类，最后用grid_search 做了 pca的<code>n_components</code>、SelectKBest的<code>k</code>以及SVM的<code>C</code>的CV。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline, FeatureUnion</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X.shape, y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This dataset is way too high-dimensional. Better do PCA:</span></span><br><span class="line">pca = PCA()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Maybe some original features where good, too?</span></span><br><span class="line">selection = SelectKBest()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build estimator from PCA and Univariate selection:</span></span><br><span class="line"></span><br><span class="line">svm = SVC(kernel=<span class="string">&quot;linear&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Do grid search over k, n_components and C:</span></span><br><span class="line"></span><br><span class="line">pipeline = Pipeline([(<span class="string">&quot;features&quot;</span>,</span><br><span class="line">                      FeatureUnion([(<span class="string">&quot;pca&quot;</span>, pca), (<span class="string">&quot;univ_select&quot;</span>,</span><br><span class="line">                                                   selection)])), (<span class="string">&quot;svm&quot;</span>,</span><br><span class="line">                                                                   svm)])</span><br><span class="line"></span><br><span class="line">param_grid = <span class="built_in">dict</span>(</span><br><span class="line">    features__pca__n_components=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">    features__univ_select__k=[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    svm__C=[<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=<span class="number">10</span>)</span><br><span class="line">grid_search.fit(X, y)</span><br><span class="line"></span><br><span class="line">grid_search.best_estimator_</span><br><span class="line">grid_search.best_params_</span><br><span class="line">grid_search.best_score_</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      
      <comments>http://example.com/2018/04/08/pipeline-in-machine-learning/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>VPS搭建私人BT离线服务器</title>
      <link>http://example.com/2018/04/08/private-BT-server/</link>
      <guid>http://example.com/2018/04/08/private-BT-server/</guid>
      <pubDate>Sun, 08 Apr 2018 03:13:51 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15231584798585.jpg&quot;&gt;&lt;br&gt;使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15231584798585.jpg"><br>使用闲置的VPS搭建私人BT离线服务器的方法，亦或者推广至树莓派或者家用路由器亦可。</p><span id="more"></span> <h2 id="安装及配置-Transmission"><a href="#安装及配置-Transmission" class="headerlink" title="安装及配置 Transmission"></a>安装及配置 Transmission</h2><ul><li>安装 <code>sudo apt-get install transmission-daemon</code></li><li>配置 停止服务（否则配置文件锁定，无法修改）<code>sudo service transmission-daemon stop</code></li><li>编辑配置文件</li></ul><p><code>sudo vim /etc/transmission-daemon/settings.json</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;ratio-limit&quot;</span>: 0.0100, </span><br><span class="line">    <span class="string">&quot;ratio-limit-enabled&quot;</span>: <span class="literal">true</span>,  </span><br><span class="line">    <span class="string">&quot;rpc-password&quot;</span>: <span class="string">&quot;*******&quot;</span>,   </span><br><span class="line">    <span class="string">&quot;rpc-username&quot;</span>: <span class="string">&quot;frank&quot;</span>,</span><br><span class="line">    <span class="string">&quot;download-dir&quot;</span>: <span class="string">&quot;/var/www/html/Downloads&quot;</span>, </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 我只列出了我修改过且无法在 Transmission Web-GUI 中无法完成修改的几项，四项依次是下载完成做种率，开启限制做种率，Web-GUI 密码，Web-GUI 用户名。像保存路径，下载/ 上传速度限制，都可以在 Web-GUI 中直接设定，为了方便之后对下载文件的 Web 管理，我直接将保存路径改到了 Web 发布路径下的一个子目录。</p><p> 重启服务</p><p> <code>sudo service transmission-daemon start</code></p><p> 此时在浏览器打开<code>VPS的IP地址/域名:9091</code>并输入刚刚设置的用户名及密码应该就可以访问 Transmission 的 Web-GUI了。<br> <img src="/images/Screen%20Shot%202018-04-08%20at%2011.25.35.png" alt="Screen Shot 2018-04-08 at 11.25.35"></p><p> 可是在添加了第一个任务后出现保存路径写入权限的问题。<br>解决办法如<a href="https://askubuntu.com/questions/221081/permission-denied-when-downloading-with-transmission-deamon">Permission denied when downloading with transmission deamon - Ask Ubuntu</a>所示：</p><p>我们的下载地址是 <code>/var/www/html/Downloads</code> 用户名是<code>znwindy</code>:<br>那么 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将本用户加入 `debian-transmission`组</span></span><br><span class="line">sudo usermod -a -G debian-transmission znwindy</span><br><span class="line"><span class="comment"># 文件夹所有者</span></span><br><span class="line">sudo chgrp debian-transmission /var/www/html/Downloads</span><br><span class="line"><span class="comment"># 组添加写权限</span></span><br><span class="line">sudo chmod -R 755 /var/www</span><br><span class="line"><span class="comment"># 停止后台deamon </span></span><br><span class="line"></span><br><span class="line">sudo service transmission-daemon stop</span><br><span class="line"><span class="comment"># 更改 file creation mask</span></span><br><span class="line">sudo vim /etc/transmission-daemon/settings.json</span><br><span class="line"><span class="comment"># 把&quot;umask&quot;: 18 改为 &quot;umask&quot;: 2</span></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">sudo service transmission-daemon start</span><br></pre></td></tr></table></figure><p>即可解决写的问题。</p><h2 id="配置-Apache-加密区域"><a href="#配置-Apache-加密区域" class="headerlink" title="配置 Apache 加密区域"></a>配置 Apache 加密区域</h2><p>安装apache2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install apache2</span><br></pre></td></tr></table></figure><p>Adjust the Firewall</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw app list</span><br><span class="line">sudo ufw allow <span class="string">&#x27;Apache Full&#x27;</span></span><br><span class="line">sudo ufw status</span><br><span class="line">sudo systemctl status apache2</span><br></pre></td></tr></table></figure><p>密码生成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo htpasswd -c /etc/apache2/.htpasswd 用户名</span><br></pre></td></tr></table></figure><p>然后会被提示输入两次该 “用户名” 的密码。</p><p>修改虚拟 host 的配置文件<br><code>sudo vim /etc/apache2/sites-enabled/000-default.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;Directory <span class="string">&quot;/var/www/html&quot;</span>&gt;</span><br><span class="line">        AuthType Basic</span><br><span class="line">        AuthName <span class="string">&quot;Restricted Content&quot;</span></span><br><span class="line">        AuthUserFile /etc/apache2/.htpasswd</span><br><span class="line">        Require valid-user</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure><p>保存后重启</p><p><code>sudo service apache2 restart</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过 HTTP 将下载的任务取回本地，速度也很快！这样，通过访问 Transmission Web-GUI “投喂” 种子，磁力链，然后在下载完成后通过 HTTP 方式从 VPS 将资源取回本地，甚至直接对 .mp3、.mp4 等文件格式进行在线播放，实现了一个简化版的迅雷离线下载，可是它却在下载某些特定资源时远比迅雷离线管用。</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/24478342">在 VPS 上搭建私人离线下载</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/Old-Driver/">Old Driver</category>
      
      
      <comments>http://example.com/2018/04/08/private-BT-server/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>numpy 中增加channel的方法</title>
      <link>http://example.com/2018/03/29/numpy-add-channel/</link>
      <guid>http://example.com/2018/03/29/numpy-add-channel/</guid>
      <pubDate>Thu, 29 Mar 2018 12:15:30 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15223277046847.jpg&quot;&gt;&lt;br&gt;numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15223277046847.jpg"><br>numpy 数组中一维怎么转二维和多维？简述 numpy 中增加channel的方法。</p><span id="more"></span><p>在机器学习中，所有的数据都是向量和矩阵，而怎么根据我们所要解决的问题来调整模型以及数据的格式，也就是矩阵的维度和大小是一项重要的基本功，那么本文就具体介绍下numpy中数组的转换，也就是增加channel的方法。</p><h2 id="一维转二维"><a href="#一维转二维" class="headerlink" title="一维转二维"></a>一维转二维</h2><p>例如我们有一个一维的numpy array，有如下方法可以转为二维</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line">a.shape</span><br><span class="line">b = a[:,<span class="literal">None</span>]</span><br><span class="line">b</span><br><span class="line">b.shape</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span></span><br><span class="line"><span class="string">(10,)</span></span><br><span class="line"><span class="string">array([[0],</span></span><br><span class="line"><span class="string">       [1],</span></span><br><span class="line"><span class="string">       [2],</span></span><br><span class="line"><span class="string">       [3],</span></span><br><span class="line"><span class="string">       [4],</span></span><br><span class="line"><span class="string">       [5],</span></span><br><span class="line"><span class="string">       [6],</span></span><br><span class="line"><span class="string">       [7],</span></span><br><span class="line"><span class="string">       [8],</span></span><br><span class="line"><span class="string">       [9]])</span></span><br><span class="line"><span class="string">(10, 1)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p> 可以看到，<code>a</code>确实被转为了二维，以下方法是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">c = a[:,np.newaxis]</span><br><span class="line">c</span><br><span class="line">(c == b).<span class="built_in">all</span>()</span><br><span class="line">np.newaxis == <span class="literal">None</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[0],</span></span><br><span class="line"><span class="string">       [1],</span></span><br><span class="line"><span class="string">       [2],</span></span><br><span class="line"><span class="string">       [3],</span></span><br><span class="line"><span class="string">       [4],</span></span><br><span class="line"><span class="string">       [5],</span></span><br><span class="line"><span class="string">       [6],</span></span><br><span class="line"><span class="string">       [7],</span></span><br><span class="line"><span class="string">       [8],</span></span><br><span class="line"><span class="string">       [9]])</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="转为多维"><a href="#转为多维" class="headerlink" title="转为多维"></a>转为多维</h2><p>时间序列预测中，我们一般需要的是(sample，time_stamp，feature)的3 个channel的数据，即一个三维矩阵，包含若干个sample，每个sample包含若干个时间序列点，而每个时间序列点有包括若干个feature，哪怕我们只是做单变量的时间序列预测，输入RNN网络例如LSTM的时候，数据也必须是三维的格式，下面我们讲一讲这么做的方法。</p><p>例如我们有一个若干个时间点每个时间点有两个特征的数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">24</span>).reshape((-<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">a.shape</span><br><span class="line">a</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(12, 2)</span></span><br><span class="line"><span class="string">array([[ 0,  1],</span></span><br><span class="line"><span class="string">       [ 2,  3],</span></span><br><span class="line"><span class="string">       [ 4,  5],</span></span><br><span class="line"><span class="string">       [ 6,  7],</span></span><br><span class="line"><span class="string">       [ 8,  9],</span></span><br><span class="line"><span class="string">       [10, 11],</span></span><br><span class="line"><span class="string">       [12, 13],</span></span><br><span class="line"><span class="string">       [14, 15],</span></span><br><span class="line"><span class="string">       [16, 17],</span></span><br><span class="line"><span class="string">       [18, 19],</span></span><br><span class="line"><span class="string">       [20, 21],</span></span><br><span class="line"><span class="string">       [22, 23]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>我们将a转化为三个channel，即可以</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">b = a[:,<span class="literal">None</span>,:]</span><br><span class="line">b.shape</span><br><span class="line">b</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(12, 1, 2)</span></span><br><span class="line"><span class="string">array([[[ 0,  1]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 2,  3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 4,  5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 6,  7]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 8,  9]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[10, 11]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[12, 13]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[14, 15]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[16, 17]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[18, 19]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[20, 21]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[22, 23]]])</span></span><br><span class="line"><span class="string">       &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>以上对应着pandas的Dataframe，及我们对Dataframe取values属性，会得到一个二维矩阵，做法就如同上面一样，但是如果是Series的话，取values属性得到的是一个一维的，这时候我们的做法则是，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">c = np.arange(<span class="number">12</span>)</span><br><span class="line">c</span><br><span class="line">d = c[:,<span class="literal">None</span>,<span class="literal">None</span>]</span><br><span class="line">d.shape</span><br><span class="line">d</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</span></span><br><span class="line"><span class="string">(12, 1, 1)</span></span><br><span class="line"><span class="string">array([[[ 0]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 1]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 2]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 4]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 6]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 7]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 8]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 9]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[10]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[11]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="减少维度"><a href="#减少维度" class="headerlink" title="减少维度"></a>减少维度</h2><p>若要减少数据的维度，我们可以用的方法如下，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">d = np.arange(<span class="number">12</span>)[:,<span class="literal">None</span>,<span class="literal">None</span>]</span><br><span class="line">d.shape</span><br><span class="line">d</span><br><span class="line">e = np.squeeze(d)</span><br><span class="line">e.shape</span><br><span class="line">e</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;(12, 1, 1)</span></span><br><span class="line"><span class="string">array([[[ 0]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 1]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 2]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 3]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 4]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 5]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 6]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 7]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 8]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[ 9]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[10]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[11]]])</span></span><br><span class="line"><span class="string">(12,)</span></span><br><span class="line"><span class="string">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2018/03/29/numpy-add-channel/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>python 正则实用例子</title>
      <link>http://example.com/2018/02/24/re-basic-of-python/</link>
      <guid>http://example.com/2018/02/24/re-basic-of-python/</guid>
      <pubDate>Sat, 24 Feb 2018 10:52:00 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15194705842254.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文主要关于python的正则表达式的符号与方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15194705842254.png"></p><p>本文主要关于python的正则表达式的符号与方法。</p><span id="more"></span><ul><li>findall: 找寻所有匹配，返回所有组合的列表</li><li>search: 找寻第一个匹配并返回</li><li>sub: 替换符合规律的内容，并返回替换后的内容</li></ul><p>**.**：匹配除了换行符以外的任意字符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">&#x27;xy123&#x27;</span></span><br><span class="line">b = re.findall(<span class="string">&#x27;x...&#x27;</span>,a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># [&#x27;xy12&#x27;]</span></span><br></pre></td></tr></table></figure><p>*****：匹配前一个字符0次或者无限次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">&#x27;xyxy123&#x27;</span></span><br><span class="line">b = re.findall(<span class="string">&#x27;x*&#x27;</span>,a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># [&#x27;x&#x27;, &#x27;&#x27;, &#x27;x&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]</span></span><br></pre></td></tr></table></figure><p>**?**：匹配前一个字符0次或者1次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">&#x27;xy123&#x27;</span></span><br><span class="line">b = re.findall(<span class="string">&#x27;x?&#x27;</span>,a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># [&#x27;x&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;]</span></span><br></pre></td></tr></table></figure><p>**.***：贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b = re.findall(<span class="string">&#x27;xx.*xx&#x27;</span>,secret_code)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># [&#x27;xxIxxfasdjifja134xxlovexx23345sdfxxyouxx&#x27;]</span></span><br></pre></td></tr></table></figure><p>**.*?**：非贪心算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c = re.findall(<span class="string">&#x27;xx.*?xx&#x27;</span>,secret_code)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="comment"># [&#x27;xxIxx&#x27;, &#x27;xxlovexx&#x27;, &#x27;xxyouxx&#x27;]</span></span><br></pre></td></tr></table></figure><p>**()**：括号内结果返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">d = re.findall(<span class="string">&#x27;xx(.*?)xx&#x27;</span>,secret_code)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> d:</span><br><span class="line">    <span class="built_in">print</span>(each)</span><br><span class="line"><span class="comment"># [&#x27;I&#x27;, &#x27;love&#x27;, &#x27;you&#x27;]</span></span><br><span class="line"><span class="comment"># I</span></span><br><span class="line"><span class="comment"># love</span></span><br><span class="line"><span class="comment"># you</span></span><br></pre></td></tr></table></figure><p><strong>re.S</strong>使得.的作用域包括换行符”\n”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&#x27;&#x27;&#x27;sdfxxhello</span></span><br><span class="line"><span class="string">xxfsdfxxworldxxasdf&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">d = re.findall(<span class="string">&#x27;xx(.*?)xx&#x27;</span>,s,re.S)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="comment">#  [&#x27;hello\n&#x27;, &#x27;world&#x27;]</span></span><br></pre></td></tr></table></figure><p>对比findall与search的区别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s2 = <span class="string">&#x27;asdfxxIxx123xxlovexxdfd&#x27;</span></span><br><span class="line">f = re.search(<span class="string">&#x27;xx(.*?)xx123xx(.*?)xx&#x27;</span>,s2).group(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line">f2 = re.findall(<span class="string">&#x27;xx(.*?)xx123xx(.*?)xx&#x27;</span>,s2)</span><br><span class="line"><span class="built_in">print</span>(f2[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line"><span class="comment"># love</span></span><br><span class="line"><span class="comment"># love</span></span><br></pre></td></tr></table></figure><p>虽然两者结果相同，但是search是搭配group来得到第二个匹配，而findall的结果是[(‘I’, ‘love’)]，包含元组的列表，所以需要f2[0][1]来引入。</p><p><strong>sub</strong>的使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&#x27;123rrrrr123&#x27;</span></span><br><span class="line">output = re.sub(<span class="string">&#x27;123(.*?)123&#x27;</span>,<span class="string">&#x27;123%d123&#x27;</span>%<span class="number">789</span>,s)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># 123789123</span></span><br></pre></td></tr></table></figure><p>例如我们需要将文档中的所有的png图片改变路径，即需要找到所有的<code>.png</code>结尾，再将其都加上路径，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiply</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="comment"># Convert group 0 to an integer.</span></span><br><span class="line">    v = m.group(<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="comment"># Multiply integer by 2.</span></span><br><span class="line">    <span class="comment"># ... Convert back into string and return it.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;basic/&#x27;</span>+v)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;basic/&#x27;</span>+v</span><br></pre></td></tr></table></figure><p>结果如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>autoencoder.png</span><br><span class="line">    basic/autoencoder.png</span><br><span class="line">    RNN.png</span><br><span class="line">    basic/RNN.png</span><br><span class="line">    rnn_step_forward.png</span><br><span class="line">    basic/rnn_step_forward.png</span><br><span class="line">    rnns.png</span><br><span class="line">    basic/rnns.png</span><br><span class="line">    rnn_cell_backprop.png</span><br><span class="line">    basic/rnn_cell_backprop.png</span><br><span class="line">    LSTM.png</span><br><span class="line">    basic/LSTM.png</span><br><span class="line">    LSTM_rnn.png</span><br><span class="line">    basic/LSTM_rnn.png</span><br><span class="line">    attn_mechanism.png</span><br><span class="line">    basic/attn_mechanism.png</span><br><span class="line">    attn_model.png</span><br><span class="line">    basic/attn_model.png</span><br></pre></td></tr></table></figure><p>仿照上面案例，我们可以方便的对我们的任务进行定制。</p><p><strong>subn</strong> 相比sub，subn返回元组，第二个元素表示替换发生的次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="comment"># Convert.</span></span><br><span class="line">    v = <span class="built_in">int</span>(m.group(<span class="number">0</span>))</span><br><span class="line">    <span class="comment"># Add 2.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(v + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Call re.subn.</span></span><br><span class="line">result = re.subn(<span class="string">&quot;\d+&quot;</span>, add, <span class="string">&quot;1 2 3 4 5&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Result string:&quot;</span>, result[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of substitutions:&quot;</span>, result[<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line">Result string: <span class="number">11</span> <span class="number">21</span> <span class="number">31</span> <span class="number">41</span> <span class="number">51</span></span><br><span class="line">Number of substitutions: <span class="number">5</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/re/">re</category>
      
      
      <comments>http://example.com/2018/02/24/re-basic-of-python/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Tex 写（中文）毕业论文全攻略</title>
      <link>http://example.com/2018/02/08/Writing-Graduation-Thesis-in-Tex/</link>
      <guid>http://example.com/2018/02/08/Writing-Graduation-Thesis-in-Tex/</guid>
      <pubDate>Wed, 07 Feb 2018 17:36:41 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15180252634406.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15180252634406.png"></p><p>用 Tex 写（中文）毕业论文全攻略，高效、便捷、优雅！</p><span id="more"></span><p>这里我们并不存在鄙视链，说什么Tex 优于 Word之类的，其实Word作为极其复杂的文本处理软件，我相信Tex能做到的，Word一定有其实现方式，只不过大部分人都只会用到Word的一小部分功能，相比Word，Tex解决方案更加便捷优雅，比如自动排号（章节、表格、参考文献的编号），全局设置的字体、间距格式等等。相比Word事无巨细的维护修改成本，Tex 的解决方案更加programmer，即软件开发，后期主要工作是迭代维护，若能在前期即考虑这点，后期能省下极多的脑细胞和精力。好了不说多，发车吧~</p><h2 id="总论"><a href="#总论" class="headerlink" title="总论"></a>总论</h2><p> 总体来说，是用上交Tex模板结合Atom编辑器在本地编辑<a href="https://atom.io/">Atom</a>（这个用什么编辑器随意）以及Dropbox同步到云端<a href="https://www.dropbox.com/h">Dropbox</a>以及云端上在sharelatex服务器上即时编译所见即所得。</p><h2 id="工具使用方法"><a href="#工具使用方法" class="headerlink" title="工具使用方法"></a>工具使用方法</h2><p>首先我们在sharelatex官网<a href="https://www.sharelatex.com/project">Your Projects - ShareLaTeX, Online LaTeX Editor</a>注册账号，免费账号即可，如果需要多人协作可以用邀请小号的方式让自己增加权限（sharelatex新建账号不验证邮箱。。所以你懂的），接下来在上交模板<a href="https://github.com/sjtug/SJTUThesis">sjtug/SJTUThesis: 上海交通大学 XeLaTeX 学位论文模板 A XeLaTeX template for Shanghai Jiao Tong University (SJTU) thesis.</a>处点击此处添加最新版模板到我们的sharelatex项目，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.25.png" alt="Screen Shot 2018-02-08 at 01.58.25"></p><p><img src="/images/Screen%20Shot%202018-02-08%20at%2001.58.56.png" alt="Screen Shot 2018-02-08 at 01.58.56"></p><p>如图，再点进去，先别急着修改，我们先设置个网盘同步，Dropbox需要梯子，在sharelatex的账号设置处链接到Dropbox，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.00.57.png" alt="Screen Shot 2018-02-08 at 02.00.57"></p><p>同时Dropbox安装一个桌面版，需要设置代理，<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.02.29.png" alt="Screen Shot 2018-02-08 at 02.02.29"><br>如图，我们使用ss作为代理。</p><p>接下来安装Atom编辑器，在插件里装一个如下插件，这里我们需要它只是为了注释这一个功能，因为我们不需要本地编译。<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.03.38.png" alt="Screen Shot 2018-02-08 at 02.03.38"></p><p>接下来我们就可以在本地用Atom编辑Dropbox网盘在本地的Tex项目，只要我们保存，Dropbox就会同步到sharelatex，如果开启自动编译云端就会展示当下编译的PDF效果，如图<br><img src="/images/Screen%20Shot%202018-02-08%20at%2002.07.11.png" alt="Screen Shot 2018-02-08 at 02.07.11"></p><h2 id="Tex模板使用说明"><a href="#Tex模板使用说明" class="headerlink" title="Tex模板使用说明"></a>Tex模板使用说明</h2><p>详见此处<a href="http://sjtug.org/SJTUThesis/README.pdf">README.pdf</a>，主要思路就是把各章、摘要、参考文献等分为不同的tex文件，图表等资源放在一处文件夹内，逐个引用，有全局的的设置文件，编译时将这些零件拼接为pdf，后续会添加更多心得。</p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><ol><li><a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference">MathJax basic tutorial and quick reference - Mathematics Meta Stack Exchange</a>：一个常用Latex公式符号的全集</li><li>如果上面没找到，可以试试这里，手写识别latex字符<a href="http://detexify.kirelabs.org/classify.html">Detexify LaTeX handwritten symbol recognition</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Tex/">Tex</category>
      
      
      <comments>http://example.com/2018/02/08/Writing-Graduation-Thesis-in-Tex/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>理解TSNE算法</title>
      <link>http://example.com/2018/01/30/Understanding-TSNE/</link>
      <guid>http://example.com/2018/01/30/Understanding-TSNE/</guid>
      <pubDate>Tue, 30 Jan 2018 03:39:39 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15172836269060.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;结合&lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&quot;&gt;论文&lt;/a&gt;公式与几个python实现理解t-SNE算法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15172836269060.jpg"></p><p>结合<a href="http://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">论文</a>公式与几个python实现理解t-SNE算法。</p><span id="more"></span><p>t-SNE 是一种数据可视化工具，它可以将高维数据降维到2-3维以用于画图，局部相似性被这种embedding所保留。</p><p>t-SNE把原空间的数据点之间的距离转换为高斯分布概率，如果两点在高维空间距离越近，那么这个概率值越大。注意到高斯分布的这个标准差$\sigma_i$ 对每个点都是不同的，这也是算法的创新点之一，因为理论上空间不同位置的点的密度是不同的，条件概率如此计算，</p><p>$$p_{j|i} = \frac{\exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}<em>j) / (2 \sigma_i^2)})}{\sum</em>{i \neq k} \exp{(-d(\boldsymbol{x}_i, \boldsymbol{x}<em>k) / (2 \sigma_i^2)})}, \quad p</em>{i|i} = 0,$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.18.45.png" alt="Screen Shot 2018-01-30 at 15.18.45"></p><p>图中公式是理论方式，实际是先计算条件概率再用下面公式来产生联合分布，</p><p>$$p_{ij} = \frac{p_{j|i} + p_{i|j}}{2N}.$$</p><p>其中 $\sigma_i$ 将自动确定。这个过程可以通过设置算法的困惑性来影响。</p><p>用一个长尾分布(Student-t Distribution，简称为t分布)来表示 embed空间的相似性<br>$$q_{ij} = \frac{(1 + ||\boldsymbol{y}_i - \boldsymbol{y}<em>j)||^2)^{-1}}{\sum</em>{k \neq l} (1 + ||\boldsymbol{y}_k - \boldsymbol{y}_l)||^2)^{-1}},$$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.28.56.png" alt="Screen Shot 2018-01-30 at 15.28.56"></p><p>损失函数是两个分布之间的 Kullback-Leibler divergence（KL散度）</p><p>$$KL(P|Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$</p><p>而为什么说tsne保留的是局部相似性呢？我们从KL散度的公式出发来解释，<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.33.19.png" alt="Screen Shot 2018-01-30 at 15.33.19"><br>可以看到，当$p_{ij}$很大而$q_{ij}$很小（高维空间距离近，低维空间距离远）惩罚很大，反之惩罚小（高维空间距离远，低维空间距离近）。</p><p>而为什么高维空间用高斯分布，低维空间用Student-t Distribution呢？</p><p><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.32.png" alt="Screen Shot 2018-01-30 at 15.41.32"><img src="/images/Screen%20Shot%202018-01-30%20at%2015.41.43.png" alt="Screen Shot 2018-01-30 at 15.41.43"><br>原因就是因为降维是必然要带来信息损失，我们要保存局部信息那么必然要损失全局信息，比如我们要把上面的这个2维空间的三个成直角边的点降维到1维，那么把它们放平就保存了局部信息（左中和中右之间的距离保持不变），但是牺牲了全局信息（左右之间的距离变大了）。而Student-t Distribution就能放大这种密度，如下图（tsne默认t分布自由度为1），t分布相比高斯分布更加长尾。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.48.47.png" alt="Screen Shot 2018-01-30 at 15.48.47"><br>梯度计算时有优化技巧，如果按下图中的原公式计算，复杂度为$O(N^2)$ Barnes-Hut 树方法就可以优化到$ O(NlogN)$<br><img src="/images/Screen%20Shot%202018-01-30%20at%2015.59.02.png" alt="Screen Shot 2018-01-30 at 15.59.02"><br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.17.png" alt="Screen Shot 2018-01-30 at 16.01.17"><br>原理类似于用上图中ABC三点中心的距离乘以三来代替计算三者各自的距离。<br>那么把用barnes树结构来进行深度优先搜索，分别判断其距离是否大于阈值，分块计算距离，这样复杂度就降低了。<br><img src="/images/Screen%20Shot%202018-01-30%20at%2016.01.38.png" alt="Screen Shot 2018-01-30 at 16.01.38"></p><p>以下是计算损失KL散度的公式，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence</span>(<span class="params">params, P, degrees_of_freedom, n_samples, n_components,</span></span></span><br><span class="line"><span class="params"><span class="function">                   skip_num_points=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;t-SNE objective function: gradient of the KL divergence</span></span><br><span class="line"><span class="string">    of p_ijs and q_ijs and the absolute error.&quot;&quot;&quot;</span></span><br><span class="line">    X_embedded = params.reshape(n_samples, n_components)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Q is a heavy-tailed distribution: Student&#x27;s t-distribution</span></span><br><span class="line">    n = pdist(X_embedded, <span class="string">&quot;sqeuclidean&quot;</span>)</span><br><span class="line">    n += <span class="number">1.</span></span><br><span class="line">    n /= degrees_of_freedom</span><br><span class="line">    n **= (degrees_of_freedom + <span class="number">1.0</span>) / -<span class="number">2.0</span></span><br><span class="line">    Q = np.maximum(n / (<span class="number">2.0</span> * np.<span class="built_in">sum</span>(n)), MACHINE_EPSILON)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimization trick below: np.dot(x, y) is faster than</span></span><br><span class="line">    <span class="comment"># np.sum(x * y) because it calls BLAS</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Objective: C (Kullback-Leibler divergence of P and Q)</span></span><br><span class="line">    kl_divergence = <span class="number">2.0</span> * np.dot(P, np.log(P / Q))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Gradient: dC/dY</span></span><br><span class="line">    grad = np.ndarray((n_samples, n_components))</span><br><span class="line">    PQd = squareform((P - Q) * n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(skip_num_points, n_samples):</span><br><span class="line">        np.dot(_ravel(PQd[i]), X_embedded[i] - X_embedded, out=grad[i])</span><br><span class="line">    grad = grad.ravel()</span><br><span class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</span><br><span class="line">    grad *= c</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>用梯度下降（和一些tricks）优化，值得注意的是损失函数非对称，并且不同的训练会导致结果的不同。</p><p>sklearn里对于binary search计算 联合分布下面的(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_utils.pyx">_utils._binary_search_perplexity</a>)和Barnes-Hut 树计算梯度(<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/_barnes_hut_tsne.pyx">_barnes_hut_tsne.gradient</a>)都是C实现，有空再来研究。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_joint_probabilities</span>(<span class="params">distances, desired_perplexity, verbose</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute joint probabilities p_ij from distances.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Compute conditional probabilities such that they approximately match</span></span><br><span class="line">    <span class="comment"># the desired perplexity</span></span><br><span class="line">    distances = astype(distances, np.float32, copy=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    conditional_P = _utils._binary_search_perplexity(</span><br><span class="line">        distances, <span class="literal">None</span>, desired_perplexity, verbose)</span><br><span class="line">    P = conditional_P + conditional_P.T</span><br><span class="line">    sum_P = np.maximum(np.<span class="built_in">sum</span>(P), MACHINE_EPSILON)</span><br><span class="line">    P = np.maximum(squareform(P) / sum_P, MACHINE_EPSILON)</span><br><span class="line">    <span class="keyword">return</span> P</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence_bh</span>(<span class="params">params, P, neighbors, degrees_of_freedom, n_samples,</span></span></span><br><span class="line"><span class="params"><span class="function">                      n_components, angle=<span class="number">0.5</span>, skip_num_points=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                      verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;t-SNE objective function: KL divergence of p_ijs and q_ijs.&quot;&quot;&quot;</span></span><br><span class="line">    params = astype(params, np.float32, copy=<span class="literal">False</span>)</span><br><span class="line">    X_embedded = params.reshape(n_samples, n_components)</span><br><span class="line">    neighbors = astype(neighbors, np.int64, copy=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(P.shape) == <span class="number">1</span>:</span><br><span class="line">        sP = squareform(P).astype(np.float32)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sP = P.astype(np.float32)</span><br><span class="line"></span><br><span class="line">    grad = np.zeros(X_embedded.shape, dtype=np.float32)</span><br><span class="line">    error = _barnes_hut_tsne.gradient(sP, X_embedded, neighbors,</span><br><span class="line">                                      grad, angle, n_components, verbose,</span><br><span class="line">                                      dof=degrees_of_freedom)</span><br><span class="line">    c = <span class="number">2.0</span> * (degrees_of_freedom + <span class="number">1.0</span>) / degrees_of_freedom</span><br><span class="line">    grad = grad.ravel()</span><br><span class="line">    grad *= c</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> error, grad</span><br></pre></td></tr></table></figure><p><a href="http://lvdmaaten.github.io/tsne/">t-SNE – Laurens van der Maaten</a>这个链接是作者收集的各种tsne变种及相关实现。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2018/01/30/Understanding-TSNE/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Data Science Pipelines |  特征工程中的管道</title>
      <link>http://example.com/2018/01/12/Data-Science-Notes/</link>
      <guid>http://example.com/2018/01/12/Data-Science-Notes/</guid>
      <pubDate>Fri, 12 Jan 2018 06:22:50 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15161698020879.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15161698020879.png"></p><p>暂定为记录各式数据科学项目、Kaggle竞赛里面常用、有用的代码片段、API、神操作等，通常是Numpy、Pandas、Matplotlib、Seaborn等相关，通常来说，项目基本步骤可以分为EDA、特征工程以及调参。</p><span id="more"></span><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><ol><li><p>以一个Kaggle上的House Price为案例，机器学习流程分成两个大步骤 ：即<br>EDA与特征工程（只使用Pandas, StatsModel，scipy,numpy, seaborn等库）</p><ul><li><p>输入： 原始Train, Test 数据集，将原始Train和Test 合并成一个数据集combined</p></li><li><p>处理： Pandas Pipe</p><p>  根据各种可能和各种特征工程方法定义各种函数（输入combined, 输入pre_combined)<br>  用PandasPipe 将这个函数像搭积木一样连在一起。用列表按序存放这些函数）<br>  这个列表就是，1. 基本的填充空值, 2. 转换数据类型， 3. 空白函数（为了对齐美观而以，啥事不做），4. log 转换，类别数据哑元处理， 5. 导出到hdf5文件， 6.检查R2值<br>  利用各种排列组合，或者各种参数组合，可以产生丰富的pipes，每一个pipes都可以产生一个预处理过的文件。</p></li><li><p>输出：某文件夹下 的N个预处理过的hdf5文件。 针对各种特征工程的排列组合，或者是Kaggle上面的各种新奇的特征工程方法。</p></li></ul></li><li><p>机器学习阶段（训练和产生模型，目标是尽可能获得尽可能低的RMSE值（针对训练数据），同时要具有范化的能力（针对测试数据））</p><ul><li>第一步，建立基准，筛选出最好的一个（几个）预处理文件（随机数设成固定值）</li><li>第二步，针对筛选出来的预处理文件，进行调参。找到最合适的几个算法（通常是RMSE值最低，且不同Kernel）（随机数设成固定值）    </li><li>第三步，用调好的参数来预处理文件中的Traing数据的做average 和stacking</li><li>第四部，生成csv文件，提交到Kaggle 看看得分如何。</li></ul></li></ol><h2 id="准备阶段-与-NoteBook-Head"><a href="#准备阶段-与-NoteBook-Head" class="headerlink" title="准备阶段 与 NoteBook Head"></a>准备阶段 与 NoteBook Head</h2><p>过滤warning：有句话说的好，在计算机科学里，我们只在意错误不在意warning</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>) </span><br></pre></td></tr></table></figure><hr><p>工作目录切换到当前python文件所在目录</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(os.path.dirname(os.path.abspath(__file__)))</span><br></pre></td></tr></table></figure><hr><p>Notebook交互输出所有结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</span><br><span class="line">InteractiveShell.ast_node_interactivity=<span class="string">&#x27;all&#x27;</span></span><br></pre></td></tr></table></figure><p>结果如下<br><img src="/images/Screen%20Shot%202018-01-12%20at%2015.27.58.png" alt="Screen Shot 2018-01-12 at 15.27.58"></p><p>以上可以通过设置固定下来，方法如下：</p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.51.01.png" alt="Screen Shot 2018-02-05 at 14.51.01"></p><p><img src="/images/Screen%20Shot%202018-02-05%20at%2014.50.29.png" alt="Screen Shot 2018-02-05 at 14.50.29"></p><hr><p>一般对train以及test做一个concat，并记录train的条数ntrain</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&quot;train.csv.gz&quot;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&quot;test.csv.gz&quot;</span>)</span><br><span class="line"></span><br><span class="line">combined = pd.concat([train,test],axis =<span class="number">0</span>, ignore_index =<span class="literal">True</span>)</span><br><span class="line">ntrain = train.shape[<span class="number">0</span>]</span><br><span class="line">Y_train = train[<span class="string">&quot;SalePrice&quot;</span>]</span><br><span class="line">X_train = train.drop([<span class="string">&quot;Id&quot;</span>,<span class="string">&quot;SalePrice&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train data shape:\t &quot;</span>,train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test data shape:\t &quot;</span>,test.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;combined data shape:\t&quot;</span>,combined.shape)</span><br></pre></td></tr></table></figure><h2 id="EDA相关"><a href="#EDA相关" class="headerlink" title="EDA相关"></a>EDA相关</h2><p>1D Scatter</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nca = NCA(num_dims=<span class="number">1</span>)</span><br><span class="line">nca.fit(xx_t, yy)</span><br><span class="line">xxxxx = nca.transform(xx)</span><br><span class="line">zeros=np.zeros_like(xxxxx)</span><br><span class="line">plt.scatter(xxxxx, zeros+<span class="number">1</span>,c=yy[:,np.newaxis])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/myplot.png" alt="myplot"></p><hr><p>缺失值分析</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cols_missing_value = combined.isnull().<span class="built_in">sum</span>()/combined.shape[<span class="number">0</span>]</span><br><span class="line">cols_missing_value = cols_missing_value[cols_missing_value&gt;<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;How many features is bad/missing value? The answer is:&quot;</span>,cols_missing_value.shape[<span class="number">0</span>])</span><br><span class="line">cols_missing_value.sort_values(ascending=<span class="literal">False</span>).head(<span class="number">10</span>).plot.barh()</span><br></pre></td></tr></table></figure><p><img src="/images/15161679439549.jpg"></p><p>有缺失 - 需要填充或者删除，通常用均值或者中指，或者用人工分析（人工分析是提分关键）</p><hr><p>将若干个Dataframe画在同一个图里面相同坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果</span></span><br><span class="line"><span class="keyword">for</span> desc, group <span class="keyword">in</span> Energy_sources:</span><br><span class="line">    group.plot(x = group.index, y=<span class="string">&#x27;Value&#x27;</span>, label=desc,ax = ax, title=<span class="string">&#x27;Carbon Emissions per Energy Source&#x27;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Time(Monthly)&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Carbon Emissions in MMT&#x27;</span>)</span><br><span class="line">    ax.xaxis.label.set_size(<span class="number">20</span>)</span><br><span class="line">    ax.yaxis.label.set_size(<span class="number">20</span>)</span><br><span class="line">    ax.legend(fontsize = <span class="number">16</span>)</span><br></pre></td></tr></table></figure><p>结果如下图，<br><img src="/images/15157398435931.jpg"></p><hr><p>画a*b的子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">3</span>,<span class="number">3</span>, figsize = (<span class="number">30</span>, <span class="number">20</span>))</span><br><span class="line"><span class="comment"># desc, group 是一个Dataframe groupby desc 出的结果 也就是下面的Energy_sources</span></span><br><span class="line"><span class="keyword">for</span> (desc, group), ax <span class="keyword">in</span> <span class="built_in">zip</span>(Energy_sources, axes.flatten()):</span><br><span class="line">    group.plot(x = group.index, y=<span class="string">&#x27;Value&#x27;</span>,ax = ax, title=desc, fontsize = <span class="number">18</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Time(Monthly)&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Carbon Emissions in MMT&#x27;</span>)</span><br><span class="line">    ax.xaxis.label.set_size(<span class="number">18</span>)</span><br><span class="line">    ax.yaxis.label.set_size(<span class="number">18</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/15157402388676.jpg"></p><hr><p>画柱状图</p><p><img src="/images/Screen%20Shot%202018-01-12%20at%2015.19.32.png" alt="Screen Shot 2018-01-12 at 15.19.32"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize = (<span class="number">16</span>,<span class="number">9</span>))</span><br><span class="line"><span class="comment"># CO2_per_source的来源与结构如上图</span></span><br><span class="line">x_label = <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[:<span class="number">20</span>],CO2_per_source.index)</span><br><span class="line">x_tick = np.arange(<span class="built_in">len</span>(cols))</span><br><span class="line">plt.bar(x_tick, CO2_per_source, align = <span class="string">&#x27;center&#x27;</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">fig.suptitle(<span class="string">&quot;CO2 Emissions by Electric Power Sector&quot;</span>, fontsize= <span class="number">25</span>)</span><br><span class="line">plt.xticks(x_tick, x_label, rotation = <span class="number">70</span>, fontsize = <span class="number">15</span>)</span><br><span class="line">plt.yticks(fontsize = <span class="number">20</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Carbon Emissions in MMT&#x27;</span>, fontsize = <span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15157416530029.jpg"></p><hr><p>重叠图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.tsa.seasonal <span class="keyword">import</span> seasonal_decompose</span><br><span class="line">decomposition = seasonal_decompose(mte)</span><br><span class="line"></span><br><span class="line">trend = decomposition.trend</span><br><span class="line">seasonal = decomposition.seasonal</span><br><span class="line">residual = decomposition.resid</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">411</span>)</span><br><span class="line">plt.plot(mte, label=<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">412</span>)</span><br><span class="line">plt.plot(trend, label=<span class="string">&#x27;Trend&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">413</span>)</span><br><span class="line">plt.plot(seasonal,label=<span class="string">&#x27;Seasonality&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">414</span>)</span><br><span class="line">plt.plot(residual, label=<span class="string">&#x27;Residuals&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/images/15157543822442.jpg"></p><hr><p>环形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">data=response[<span class="string">&#x27;PublicDatasetsSelect&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">dataset=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.dropna():</span><br><span class="line">    dataset.extend(i)</span><br><span class="line">pd.Series(dataset).value_counts().plot.pie(autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>,colors=sns.color_palette(<span class="string">&#x27;Paired&#x27;</span>,<span class="number">10</span>),startangle=<span class="number">90</span>,wedgeprops = &#123; <span class="string">&#x27;linewidth&#x27;</span> : <span class="number">2</span>, <span class="string">&#x27;edgecolor&#x27;</span> : <span class="string">&#x27;white&#x27;</span> &#125;)</span><br><span class="line">plt.title(<span class="string">&#x27;Dataset Source&#x27;</span>)</span><br><span class="line">my_circle=plt.Circle( (<span class="number">0</span>,<span class="number">0</span>), <span class="number">0.7</span>, color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">p=plt.gcf()</span><br><span class="line">p.gca().add_artist(my_circle)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159953413652.jpg"></p><hr><p>饼状图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</span><br><span class="line">response[<span class="string">&#x27;JobSkillImportancePython&#x27;</span>].value_counts().plot.pie(ax=ax[<span class="number">0</span>],autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>,explode=[<span class="number">0.1</span>,<span class="number">0</span>,<span class="number">0</span>],shadow=<span class="literal">True</span>,colors=[<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;lightblue&#x27;</span>,<span class="string">&#x27;r&#x27;</span>])</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Python Necessity&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">response[<span class="string">&#x27;JobSkillImportanceR&#x27;</span>].value_counts().plot.pie(ax=ax[<span class="number">1</span>],autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>,explode=[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0</span>],shadow=<span class="literal">True</span>,colors=[<span class="string">&#x27;lightblue&#x27;</span>,<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;r&#x27;</span>])</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;R Necessity&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159954686370.jpg"></p><hr><p>维恩图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</span><br><span class="line">pd.Series([python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]],index=[<span class="string">&#x27;Python&#x27;</span>,<span class="string">&#x27;R&#x27;</span>,<span class="string">&#x27;Both&#x27;</span>]).plot.bar(ax=ax[<span class="number">0</span>])</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Number of Users&#x27;</span>)</span><br><span class="line">venn2(subsets = (python.shape[<span class="number">0</span>],R.shape[<span class="number">0</span>],both.shape[<span class="number">0</span>]), set_labels = (<span class="string">&#x27;Python Users&#x27;</span>, <span class="string">&#x27;R Users&#x27;</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Venn Diagram for Users&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="/images/15159955616741.jpg"></p><h2 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h2><p>count plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.subplots(figsize=(<span class="number">22</span>,<span class="number">12</span>))</span><br><span class="line">sns.countplot(y=response[<span class="string">&#x27;GenderSelect&#x27;</span>],order=response[<span class="string">&#x27;GenderSelect&#x27;</span>].value_counts().index)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159941639903.jpg"></p><hr><p>利用squarify画树形图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> squarify</span><br><span class="line">tree=response[<span class="string">&#x27;Country&#x27;</span>].value_counts().to_frame()</span><br><span class="line">squarify.plot(sizes=tree[<span class="string">&#x27;Country&#x27;</span>].values,label=tree.index,color=sns.color_palette(<span class="string">&#x27;RdYlGn_r&#x27;</span>,<span class="number">52</span>))</span><br><span class="line">plt.rcParams.update(&#123;<span class="string">&#x27;font.size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">fig=plt.gcf()</span><br><span class="line">fig.set_size_inches(<span class="number">40</span>,<span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159945932245.jpg"></p><hr><p>sns画分布图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.subplots(figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line">salary=salary[salary[<span class="string">&#x27;Salary&#x27;</span>]&lt;<span class="number">1000000</span>]</span><br><span class="line">sns.distplot(salary[<span class="string">&#x27;Salary&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Salary Distribution&#x27;</span>,size=<span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159947979455.jpg"></p><hr><p>sns子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">18</span>,<span class="number">8</span>))</span><br><span class="line">sal_coun=salary.groupby(<span class="string">&#x27;Country&#x27;</span>)[<span class="string">&#x27;Salary&#x27;</span>].median().sort_values(ascending=<span class="literal">False</span>)[:<span class="number">15</span>].to_frame()</span><br><span class="line">sns.barplot(<span class="string">&#x27;Salary&#x27;</span>,sal_coun.index,data=sal_coun,palette=<span class="string">&#x27;RdYlGn&#x27;</span>,ax=ax[<span class="number">0</span>])</span><br><span class="line">ax[<span class="number">0</span>].axvline(salary[<span class="string">&#x27;Salary&#x27;</span>].median(),linestyle=<span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Highest Salary Paying Countries&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">max_coun=salary.groupby(<span class="string">&#x27;Country&#x27;</span>)[<span class="string">&#x27;Salary&#x27;</span>].median().to_frame()</span><br><span class="line">max_coun=max_coun[max_coun.index.isin(resp_coun.index)]</span><br><span class="line">max_coun.sort_values(by=<span class="string">&#x27;Salary&#x27;</span>,ascending=<span class="literal">True</span>).plot.barh(width=<span class="number">0.8</span>,ax=ax[<span class="number">1</span>],color=sns.color_palette(<span class="string">&#x27;RdYlGn&#x27;</span>))</span><br><span class="line">ax[<span class="number">1</span>].axvline(salary[<span class="string">&#x27;Salary&#x27;</span>].median(),linestyle=<span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Compensation of Top 15 Respondent Countries&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159948678550.jpg"></p><hr><p>seaborn箱型图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.subplots(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">sns.boxplot(y=<span class="string">&#x27;GenderSelect&#x27;</span>,x=<span class="string">&#x27;Salary&#x27;</span>,data=salary)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159949427978.jpg"></p><hr><p>seaborn count_plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">f,ax=plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">25</span>,<span class="number">15</span>))</span><br><span class="line">sns.countplot(y=response[<span class="string">&#x27;MajorSelect&#x27;</span>],ax=ax[<span class="number">0</span>],order=response[<span class="string">&#x27;MajorSelect&#x27;</span>].value_counts().index)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Major&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">sns.countplot(y=response[<span class="string">&#x27;CurrentJobTitleSelect&#x27;</span>],ax=ax[<span class="number">1</span>],order=response[<span class="string">&#x27;CurrentJobTitleSelect&#x27;</span>].value_counts().index)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Current Job&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.8</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159950249702.jpg"></p><hr><p>seaborn 图中添加文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sal_job=salary.groupby(<span class="string">&#x27;CurrentJobTitleSelect&#x27;</span>)[<span class="string">&#x27;Salary&#x27;</span>].median().to_frame().sort_values(by=<span class="string">&#x27;Salary&#x27;</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">ax=sns.barplot(sal_job.Salary,sal_job.index,palette=sns.color_palette(<span class="string">&#x27;inferno&#x27;</span>,<span class="number">20</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Compensation By Job Title&#x27;</span>,size=<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(sal_job.Salary): </span><br><span class="line">    ax.text(<span class="number">.5</span>, i, v,fontsize=<span class="number">10</span>,color=<span class="string">&#x27;white&#x27;</span>,weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">fig=plt.gcf()</span><br><span class="line">fig.set_size_inches(<span class="number">8</span>,<span class="number">8</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159951024672.jpg"></p><hr><p>词云</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud, STOPWORDS</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line">free=pd.read_csv(<span class="string">&#x27;../input/freeformResponses.csv&#x27;</span>)</span><br><span class="line">stop_words=<span class="built_in">set</span>(stopwords.words(<span class="string">&#x27;english&#x27;</span>))</span><br><span class="line">stop_words.update(<span class="string">&#x27;,&#x27;</span>,<span class="string">&#x27;;&#x27;</span>,<span class="string">&#x27;!&#x27;</span>,<span class="string">&#x27;?&#x27;</span>,<span class="string">&#x27;.&#x27;</span>,<span class="string">&#x27;(&#x27;</span>,<span class="string">&#x27;)&#x27;</span>,<span class="string">&#x27;$&#x27;</span>,<span class="string">&#x27;#&#x27;</span>,<span class="string">&#x27;+&#x27;</span>,<span class="string">&#x27;:&#x27;</span>,<span class="string">&#x27;...&#x27;</span>)</span><br><span class="line">motivation=free[<span class="string">&#x27;KaggleMotivationFreeForm&#x27;</span>].dropna().apply(nltk.word_tokenize)</span><br><span class="line">motivate=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> motivation:</span><br><span class="line">    motivate.extend(i)</span><br><span class="line">motivate=pd.Series(motivate)</span><br><span class="line">motivate=([i <span class="keyword">for</span> i <span class="keyword">in</span> motivate.<span class="built_in">str</span>.lower() <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> stop_words])</span><br><span class="line">f1=<span class="built_in">open</span>(<span class="string">&quot;kaggle.png&quot;</span>, <span class="string">&quot;wb&quot;</span>)</span><br><span class="line">f1.write(codecs.decode(kaggle,<span class="string">&#x27;base64&#x27;</span>))</span><br><span class="line">f1.close()</span><br><span class="line">img1 = imread(<span class="string">&quot;kaggle.png&quot;</span>)</span><br><span class="line">hcmask1 = img1</span><br><span class="line">wc = WordCloud(background_color=<span class="string">&quot;black&quot;</span>, max_words=<span class="number">4000</span>, mask=hcmask1, </span><br><span class="line">               stopwords=STOPWORDS, max_font_size= <span class="number">60</span>,width=<span class="number">1000</span>,height=<span class="number">1000</span>)</span><br><span class="line">wc.generate(<span class="string">&quot; &quot;</span>.join(motivate))</span><br><span class="line">plt.imshow(wc)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">fig=plt.gcf()</span><br><span class="line">fig.set_size_inches(<span class="number">10</span>,<span class="number">10</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15159971204332.jpg"></p><hr><p>简单情况下的分类展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"></span><br><span class="line">h = <span class="number">0.01</span></span><br><span class="line">x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span>(<span class="params">X, y, w, history</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;draws classifier prediction with matplotlib magic&quot;&quot;&quot;</span></span><br><span class="line">    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.contourf(xx, yy, Z, alpha=<span class="number">0.8</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(history)</span><br><span class="line">    plt.grid()</span><br><span class="line">    ymin, ymax = plt.ylim()</span><br><span class="line">    plt.ylim(<span class="number">0</span>, ymax)</span><br><span class="line">    display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15163355887784.jpg"></p><hr><p>图中插入LaTeX公式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">x_squared, x_squared_der = s.run([scalar_squared, derivative[<span class="number">0</span>]],</span><br><span class="line">                                 &#123;my_scalar:x&#125;)</span><br><span class="line"></span><br><span class="line">plt.plot(x, x_squared,label=<span class="string">&quot;$x^2$&quot;</span>)</span><br><span class="line">plt.plot(x, x_squared_der, label=<span class="string">r&quot;$\frac&#123;dx^2&#125;&#123;dx&#125;$&quot;</span>)</span><br><span class="line">plt.legend();</span><br></pre></td></tr></table></figure><p><img src="/images/15163465540386.jpg"></p><hr><p>画多张子图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show random images from train</span></span><br><span class="line">cols = <span class="number">8</span></span><br><span class="line">rows = <span class="number">2</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">2</span> * cols - <span class="number">1</span>, <span class="number">2.5</span> * rows - <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        random_index = np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(y_train))</span><br><span class="line">        ax = fig.add_subplot(rows, cols, i * rows + j + <span class="number">1</span>)</span><br><span class="line">        ax.grid(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax.imshow(x_train[random_index, :])</span><br><span class="line">        ax.set_title(cifar10_classes[y_train[random_index, <span class="number">0</span>]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/15167635233971.jpg"></p><h2 id="特征工程阶段"><a href="#特征工程阶段" class="headerlink" title="特征工程阶段"></a>特征工程阶段</h2><p>Numpy区间百分比切分异常值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cut off long distance trips</span></span><br><span class="line">lat_low, lat_hgh = np.percentile(latlong[:,<span class="number">0</span>], [<span class="number">2</span>, <span class="number">98</span>])</span><br><span class="line">lon_low, lon_hgh = np.percentile(latlong[:,<span class="number">1</span>], [<span class="number">2</span>, <span class="number">98</span>])</span><br></pre></td></tr></table></figure><hr><p>初始化同shape向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">g2 = np.zeros_like(w)</span><br><span class="line">``</span><br><span class="line"></span><br><span class="line">-------</span><br><span class="line"></span><br><span class="line">累积<span class="built_in">sum</span></span><br><span class="line">``` python</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.cumsum(a,axis=<span class="number">1</span>)      <span class="comment"># sum over columns for each of the 2 rows</span></span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">3</span>,  <span class="number">6</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">9</span>, <span class="number">15</span>]])</span><br></pre></td></tr></table></figure><hr><p>numpy array 扩展维度，很简单地将Numpy向量扩展为二维矩阵<br><img src="/images/15167894435840.png"><br><img src="/images/Screen%20Shot%202018-01-24%20at%2019.02.32.png" alt="Screen Shot 2018-01-24 at 19.02.32"></p><hr><p>Numpy 竖着叠放向量<br><code>np.column_stack</code></p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于查看Dataframe各列数据类型</span></span><br><span class="line">ts.dtypes</span><br></pre></td></tr></table></figure><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#skew是单变量工具，用来监测数据是否有长尾，左偏或者右偏</span></span><br><span class="line"><span class="built_in">print</span>(Y_train.skew())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#np.abs 是绝对值函数，用来取整个向量绝对值</span></span><br><span class="line"><span class="comment"># 这里对所有train里的特征求偏度并排序</span></span><br><span class="line">np.<span class="built_in">abs</span>(combined[:ntrain].skew()).sort_values(ascending = <span class="literal">False</span> ).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>有偏度 - 需要处理。通常是用log1p </p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于将Dataframe中被读取为object的数据转换为数值型，errors=&#x27;coerce&#x27;代表错误将被置为NaN</span></span><br><span class="line">ts[<span class="string">&#x27;Value&#x27;</span>] = pd.to_numeric(ts[<span class="string">&#x27;Value&#x27;</span>] , errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br></pre></td></tr></table></figure><hr><p>过滤index 里面的NaN值，推广也可以过滤其他列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ts = df.loc[pd.Series(pd.to_datetime(df.index, errors=<span class="string">&#x27;coerce&#x27;</span>)).notnull().values]</span><br></pre></td></tr></table></figure><hr><p>按月groupby，以及unstack解构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Emissions.groupby([<span class="string">&#x27;Description&#x27;</span>, pd.TimeGrouper(<span class="string">&#x27;M&#x27;</span>)])[<span class="string">&#x27;Value&#x27;</span>].<span class="built_in">sum</span>().unstack(level = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202018-01-12%20at%2016.16.30.png" alt="Screen Shot 2018-01-12 at 16.16.30"></p><hr><p>将value_counts、groupby等Series转换为Dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree=response[<span class="string">&#x27;Country&#x27;</span>].value_counts().to_frame()</span><br></pre></td></tr></table></figure><hr><p>特征工程大杀器，<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html?highlight=pipe#tablewise-function-application">Pandas Pipe</a><br>这里有个简单的例子，,每个pipes里面都有若干个特征处理函数和一个快速测试的函数，其中为了对齐美观，用bypass函数来填充空白的地方（无用但是为了强行让pipes长度相同）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">pipe_basic = [pipe_basic_fillna,pipe_bypass,\</span><br><span class="line">              pipe_bypass,pipe_bypass,\</span><br><span class="line">              pipe_bypass,pipe_bypass,\</span><br><span class="line">              pipe_log_getdummies,pipe_bypass, \</span><br><span class="line">              pipe_export,pipe_r2test]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pipe_ascat = [pipe_fillna_ascat,pipe_drop_cols,\</span><br><span class="line">              pipe_drop4cols,pipe_outliersdrop,\</span><br><span class="line">              pipe_extract,pipe_bypass,\</span><br><span class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</span><br><span class="line">              pipe_export,pipe_r2test]</span><br><span class="line"></span><br><span class="line">pipe_ascat_unitprice = [pipe_fillna_ascat,pipe_drop_cols,\</span><br><span class="line">              pipe_drop4cols,pipe_outliersdrop,\</span><br><span class="line">              pipe_extract,pipe_unitprice,\</span><br><span class="line">              pipe_log_getdummies,pipe_drop_dummycols, \</span><br><span class="line">              pipe_export,pipe_r2test]</span><br><span class="line"></span><br><span class="line">pipes = [pipe_basic,pipe_ascat,pipe_ascat_unitprice ]</span><br></pre></td></tr></table></figure><p>跑的代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pipes)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">10</span>,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    pipe_output=pipes[i]</span><br><span class="line">    output_name =<span class="string">&quot;_&quot;</span>.join([x.__name__[<span class="number">5</span>:] <span class="keyword">for</span> x <span class="keyword">in</span> pipe_output <span class="keyword">if</span> x.__name__ <span class="keyword">is</span> <span class="keyword">not</span> <span class="string">&quot;pipe_bypass&quot;</span>])</span><br><span class="line">    output_name = <span class="string">&quot;PIPE_&quot;</span> +output_name</span><br><span class="line">    <span class="built_in">print</span>(output_name)</span><br><span class="line">    (combined.pipe(pipe_output[<span class="number">0</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">1</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">2</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">3</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">4</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">5</span>])          </span><br><span class="line">             .pipe(pipe_output[<span class="number">6</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">7</span>])</span><br><span class="line">             .pipe(pipe_output[<span class="number">8</span>],name=output_name)</span><br><span class="line">             .pipe(pipe_output[<span class="number">9</span>])</span><br><span class="line">             ）</span><br></pre></td></tr></table></figure><p>在这一步，我们可以初步看到三个特征工程的性能。并且文件已经输出到hd5格式文件。后期在训练和预测时，直接取出预处理的文件就可以。各个pipe代码可见<a href="https://gist.github.com/frankchen0130/5950eaa4d98ea4f93deed707b027b517">此处</a>。</p><h2 id="调参阶段"><a href="#调参阶段" class="headerlink" title="调参阶段"></a>调参阶段</h2><p>在数据准备好后训练时，最基本的就是要调整超参（Hyperparameter）耗时耗力，并且和发生错误和遗漏情况。<br>Stackoverflow上常见的算法训练错误有：</p><ul><li>算法预测的结果差异非常大。 其中一个可能就是训练时的标准化步骤，在预测时遗漏了。</li><li>算法的调参结果差异非常大。（有的是0.01,有的就是10）。其中的一个可能就是不同的训练步骤中采用的标准化算法不同（例如,一次用了StandardScaler, 另一次用了RobustScaler)</li><li>此外，繁多的超参数调整起来异常繁琐。比较容易错误或者写错。</li></ul><p><strong>解决方法：Pipeline + Gridsearch + 参数字典 + 容器。</strong><br>使用Pipeline的例子</p><p>针对线形回归问题，Sklearn提供了超过15种回归算法。利用Pipeline 大法可以综合测试所有算法，找到最合适的算法。 具体步骤如下：</p><ol><li><p>初始化所有希望调测线形回归。</p></li><li><p>建立一个字典容器。{“算法名称”:[初始算法对象，参数字典，训练好的Pipeline模型对象，CV的成绩}</p></li><li><p>在调参步骤，将初始算法用Pipeline包装起来，利用Gridsearch进行调参。调参完成后可以得到针对相应的CV而获得的最后模型对象。 例如： lasso 算法的步骤如下：</p></li></ol><ul><li><pre><code>包装 pipe=Pipeline([(&quot;scaler&quot;:None),(&quot;selector&quot;:None),(&quot;clf&quot;:Lasso())    * Pipe就是刚刚包装好的算法。可以直接用于 训练(fit)和预测(predict)    * 使用Pipe来处理训练集和测试集可以避免错误和遗漏，提高效率。    * 但是Pipe中算法是默认的参数，直接训练出的模型RMSE不太理想。（例如：local CV, 0.12~0.14左右）。这时可以考虑调参。</code></pre></li><li>调参第一步：准备参数字典：<br>  Params_lasso ={<br>  “Scaler”:[RobustScaler(),StandardScaler()], #两个标准化算法供调模型<br>  “selector__threshold”:np.logspace(-5,-4,3), #3个选择门限供选特征<br>  “clf__alpha”:np.logspace(-5,-1,10) }， #10个alpha指供调参</li><li>调参第二步：暴力调参和生成模型 rsearch = GridSearchCV(pipe, param_grid=Params_lasso,scoring =’neg_mean_squared_error’,verbose=verbose,cv=10,refit =True)<ul><li>GridSearch 是暴力调参。遍历所有参数组合，另外有一个RandomedSearch 可以随机选择参数组合，缩短调参时间，并且获得近似的调参性能</li><li>Pipe就是刚刚包装好的算法。GridSearch把可选的参数和算法（放入，或者更好的组合。</li><li>调参的训练标准是“’neg_mean_squared_error”, RMSE的负数。 这种处理方法，让最大值称为最小的MSE指。只需要对结果做一次np.sqrt( 结果负数）就能获得RMSE值。</li><li>cv=10. Cross Validate 数据集为9：1。数据集小的情况，例如House Price. 3折和10折结果甚至比调参差异还大。</li><li>refit =True. 在调参完成后，再需要做一次所有数据集的fit. 生成完整的训练模型</li></ul></li></ul><hr><p>Sklearn 流程图<br><img src="/images/15161696298310.jpg"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Python/">Python</category>
      
      
      <comments>http://example.com/2018/01/12/Data-Science-Notes/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DIY远程Jupyter Notebook服务器</title>
      <link>http://example.com/2017/12/25/Remote-jupyter-notebook/</link>
      <guid>http://example.com/2017/12/25/Remote-jupyter-notebook/</guid>
      <pubDate>Mon, 25 Dec 2017 11:43:17 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15142020075328.jpg&quot; alt=&quot;Screen Shot 2017-07-18 at 14.16.18&quot;&gt;&lt;br&gt;构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15142020075328.jpg" alt="Screen Shot 2017-07-18 at 14.16.18"><br>构建自己的远程Jupyter Notebook服务器，添加system开机自启，让Jupyter Notebook支持跨网络访问的方法。</p><span id="more"></span><h2 id="完全开放，不需密码"><a href="#完全开放，不需密码" class="headerlink" title="完全开放，不需密码"></a>完全开放，不需密码</h2><h3 id="1-登陆远程服务器"><a href="#1-登陆远程服务器" class="headerlink" title="1.  登陆远程服务器"></a>1.  登陆远程服务器</h3><h3 id="2-生成配置文件"><a href="#2-生成配置文件" class="headerlink" title="2.生成配置文件"></a>2.生成配置文件</h3><p><code>$jupyter notebook --generate-config</code></p><h3 id="3-修改默认配置文件"><a href="#3-修改默认配置文件" class="headerlink" title="3. 修改默认配置文件"></a>3. 修改默认配置文件</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py </code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">&#x27;0.0.0.0&#x27;</span>      <span class="comment">#支持其它IP访问，关键</span></span><br><span class="line">c.NotebookApp.port = <span class="number">10000</span> <span class="comment">#随便指定一个端口</span></span><br></pre></td></tr></table></figure><h3 id="4-启动jupyter-notebook："><a href="#4-启动jupyter-notebook：" class="headerlink" title="4. 启动jupyter notebook："></a>4. 启动jupyter notebook：</h3><p><code>jupyter notebook</code></p><h3 id="5-远程访问"><a href="#5-远程访问" class="headerlink" title="5. 远程访问"></a>5. 远程访问</h3><p>此时应该可以直接从本地浏览器直接访问<code>http://address_of_remote:10000</code>就可以看到jupyter的登陆界面，输入密码即可。</p><h2 id="需要密码"><a href="#需要密码" class="headerlink" title="需要密码"></a>需要密码</h2><h3 id="1-生成密码"><a href="#1-生成密码" class="headerlink" title="1. 生成密码"></a>1. 生成密码</h3><p>打开ipython，创建一个密文的密码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">In [<span class="number">2</span>]: passwd()</span><br><span class="line">Enter password: </span><br><span class="line">Verify password: </span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">&#x27;sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-添加密码"><a href="#2-添加密码" class="headerlink" title="2. 添加密码"></a>2. 添加密码</h3><p><code>$vim ~/.jupyter/jupyter_notebook_config.py </code><br>进行如下修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.password = <span class="string">u&#x27;sha:ce...刚才复制的那个密文&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="/images/Screen%20Shot%202017-07-18%20at%2014.16.18.png" alt="Screen Shot 2017-07-18 at 14.16.18"></p><h3 id="3-建立ssh通道"><a href="#3-建立ssh通道" class="headerlink" title="3. 建立ssh通道"></a>3. 建立ssh通道</h3><p>若还是无法登录，也可用</p><p><code>ssh username@address_of_remote -L 127.0.0.1:10000:127.0.0.1:10000</code></p><p>建立ssh通道，便可以在localhost:10000直接访问远程的jupyter了。</p><h2 id="添加system开机自启"><a href="#添加system开机自启" class="headerlink" title="添加system开机自启"></a>添加system开机自启</h2><p>将 Jupyter Notebook 设定为系统服务并且开机自动启动，这里以 systemd 下的设定为例，创建文件 <code>sudo vim /etc/systemd/system/jupyter.service </code>文件，内容是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Jupyter Notebook</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/home/frank/anaconda3/bin/jupyter-notebook  --config=/home/frank/.jupyter/jupyter_notebook_config.py --no-browser</span><br><span class="line">User=frank</span><br><span class="line">Group=frank</span><br><span class="line">WorkingDirectory=/home/frank/</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>上面你需要把我的用户名frank替换掉，保存文件之后执行<br><code>systemctl enable jupyter</code><br>再执行<br><code>systemctl start jupyter</code><br>即可，需要输入几次密码，之后重启Notebook会自启。</p><p><img src="/images/Screen%20Shot%202017-12-25%20at%2019.32.28.png" alt="Screen Shot 2017-12-25 at 19.32.28"></p><h2 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h2><p>结合下文的方法，用ftp即可做到</p><ul><li><a href="http://frankchen.xyz/2017/11/12/ftp-using/">frp的内网穿透及外网访问内网jupyter-notebook的实现 | 不正经数据科学家</a></li></ul><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/23110830">Jupyter (IPython notebook)用于服务器的配置方法(Windows) - 知乎专栏</a></li><li><a href="http://blog.leanote.com/post/jevonswang/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AEjupyter-notebook">远程访问jupyter notebook</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Jupyter-Notebook/">Jupyter Notebook</category>
      
      
      <comments>http://example.com/2017/12/25/Remote-jupyter-notebook/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>深度学习中Keras中的Embedding层的理解与使用</title>
      <link>http://example.com/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/</link>
      <guid>http://example.com/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/</guid>
      <pubDate>Mon, 18 Dec 2017 07:59:41 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15135840798621.jpg&quot;&gt;&lt;br&gt;单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15135840798621.jpg"><br>单词嵌入提供了单词的密集表示及其相对含义，它们是对简单包模型表示中使用的稀疏表示的改进，可以从文本数据中学习字嵌入，并在项目之间重复使用。它们也可以作为拟合文本数据的神经网络的一部分来学习。</p><span id="more"></span><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>单词嵌入是使用密集的矢量表示来表示单词和文档的一类方法。</p><p>词嵌入是对传统的词袋模型编码方案的改进，传统方法使用大而稀疏的矢量来表示每个单词或者在矢量内对每个单词进行评分以表示整个词汇表，这些表示是稀疏的，因为每个词汇的表示是巨大的，给定的词或文档主要由零值组成的大向量表示。</p><p>相反，在嵌入中，单词由密集向量表示，其中向量表示将单词投影到连续向量空间中。</p><p>向量空间中的单词的位置是从文本中学习的，并且基于在使用单词时围绕单词的单词。</p><p>学习到的向量空间中的单词的位置被称为它的嵌入：Embedding。</p><p>从文本学习单词嵌入方法的两个流行例子包括：</p><ul><li>Word2Vec.</li><li>GloVe.</li></ul><p>除了这些精心设计的方法之外，还可以将词嵌入学习作为深度学习模型的一部分。这可能是一个较慢的方法，但可以通过这样为特定数据集定制模型。</p><h2 id="Keras-Embedding-Layer"><a href="#Keras-Embedding-Layer" class="headerlink" title="Keras Embedding Layer"></a>Keras Embedding Layer</h2><p>Keras提供了一个嵌入层，适用于文本数据的神经网络。</p><p>它要求输入数据是整数编码的，所以每个字都用一个唯一的整数表示。这个数据准备步骤可以使用Keras提供的Tokenizer API来执行。</p><p>嵌入层用随机权重进行初始化，并将学习训练数据集中所有单词的嵌入。</p><p>它是一个灵活的图层，可以以多种方式使用，例如：</p><ul><li>它可以单独使用来学习一个单词嵌入，以后可以保存并在另一个模型中使用。</li><li>它可以用作深度学习模型的一部分，其中嵌入与模型本身一起学习。</li><li>它可以用来加载预先训练的词嵌入模型，这是一种迁移学习。</li></ul><p>嵌入层被定义为网络的第一个隐藏层。它必须指定3个参数：</p><ul><li>input_dim：这是文本数据中词汇的取值可能数。例如，如果您的数据是整数编码为0-9之间的值，那么词汇的大小就是10个单词；</li><li>output_dim：这是嵌入单词的向量空间的大小。它为每个单词定义了这个层的输出向量的大小。例如，它可能是32或100甚至更大，可以视为具体问题的超参数；</li><li>input_length：这是输入序列的长度，就像您为Keras模型的任何输入层所定义的一样，也就是一次输入带有的词汇个数。例如，如果您的所有输入文档都由1000个字组成，那么input_length就是1000。</li></ul><p>例如，下面我们定义一个词汇表为200的嵌入层（例如从0到199的整数编码的字，包括0到199），一个32维的向量空间，其中将嵌入单词，以及输入文档，每个单词有50个单词。</p><p><code>e = Embedding(input_dim=200, output_dim=32, input_length=50)</code></p><p>嵌入层自带学习的权重，如果将模型保存到文件中，则将包含嵌入图层的权重。</p><p>嵌入层的输出是一个二维向量，每个单词在输入文本（输入文档）序列中嵌入一个。</p><p>如果您希望直接将Dense层接到Embedding层后面，则必须先使用Flatten层将Embedding层的2D输出矩阵平铺为一维矢量。</p><p>现在，让我们看看我们如何在实践中使用嵌入层。</p><h2 id="学习-Embedding的例子"><a href="#学习-Embedding的例子" class="headerlink" title="学习 Embedding的例子"></a>学习 Embedding的例子</h2><p>在本节中，我们将看看如何在文本分类问题上拟合神经网络的同时学习单词嵌入。</p><p>我们将定义一个小问题，我们有10个文本文档，每个文档都有一个学生提交的工作评论。每个文本文档被分类为正的“1”或负的“0”。这是一个简单的情感分析问题。</p><p>首先，我们将定义文档及其类别标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define documents 定义文档</span></span><br><span class="line">docs = [<span class="string">&#x27;Well done!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Good work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Great effort&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;nice work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Excellent!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Weak&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Poor effort!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;not good&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;poor work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Could have done better.&#x27;</span>]</span><br><span class="line"><span class="comment"># define class labels 定义分类标签</span></span><br><span class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>接下来，我们来整数编码每个文件。这意味着把输入，嵌入层将具有整数序列。我们可以尝试其他更复杂的bag of word 模型比如计数或TF-IDF。</p><p>Keras提供<a href="https://keras.io/preprocessing/text/#one_hot">one_hot()</a>函数来创建每个单词的散列作为一个有效的整数编码。我们用估计50的词汇表大小，这大大减少了hash函数的冲突概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># integer encode the documents 独热编码</span></span><br><span class="line">vocab_size = <span class="number">50</span></span><br><span class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</span><br><span class="line"><span class="built_in">print</span>(encoded_docs)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[6, 16], [42, 24], [2, 17], [42, 24], [18], [17], [22, 17], [27, 42], [22, 24], [49, 46, 16, 34]]</span><br></pre></td></tr></table></figure><p>这样以后序列具有不同的长度，但是Keras更喜欢输入矢量化和所有输入具有相同的长度。我们将填充所有输入序列的长度为4，同样，我们可以使用内置的Keras函数（在这种情况下为<a href="https://keras.io/preprocessing/sequence/#pad_sequences">pad_sequences()</a>函数）执行此操作,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pad documents to a max length of 4 words 将不足长度的用0填充为长度4</span></span><br><span class="line">max_length = <span class="number">4</span></span><br><span class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(padded_docs)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[ 6 16  0  0]</span><br><span class="line"> [42 24  0  0]</span><br><span class="line"> [ 2 17  0  0]</span><br><span class="line"> [42 24  0  0]</span><br><span class="line"> [18  0  0  0]</span><br><span class="line"> [17  0  0  0]</span><br><span class="line"> [22 17  0  0]</span><br><span class="line"> [27 42  0  0]</span><br><span class="line"> [22 24  0  0]</span><br><span class="line"> [49 46 16 34]]</span><br></pre></td></tr></table></figure><p>我们现在准备将我们的嵌入层定义为我们的神经网络模型的一部分。</p><p>嵌入的词汇量为50，输入长度为4，我们将选择一个8维的嵌入空间。</p><p>该模型是一个简单的二元分类模型。重要的是，嵌入层的输出将是每个8维的4个矢量，每个单词一个。我们将其平铺到一个32个元素的向量上以传递到密集输出层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define the model 定义模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(vocab_size, <span class="number">8</span>, input_length=max_length))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment"># compile the model 编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"><span class="comment"># summarize the model 打印模型信息</span></span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #</span><br><span class="line">=================================================================</span><br><span class="line">embedding_1 (Embedding)      (None, 4, 8)              400</span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)          (None, 32)                0</span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 1)                 33</span><br><span class="line">=================================================================</span><br><span class="line">Total params: 433</span><br><span class="line">Trainable params: 433</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><p>最后，我们可以拟合和评估分类模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fit the model 拟合</span></span><br><span class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># evaluate the model 评估</span></span><br><span class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy: %f&#x27;</span> % (accuracy*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 100.000000</span><br></pre></td></tr></table></figure><p>下面是完整的代码，这里我们用函数式API改写了模型定义，不过结构和上面是完全一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Flatten, Input</span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> one_hot</span><br><span class="line"></span><br><span class="line"><span class="comment"># define documents</span></span><br><span class="line">docs = [<span class="string">&#x27;Well done!&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Good work&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Great effort&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;nice work&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Excellent!&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Weak&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Poor effort!&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;not good&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;poor work&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Could have done better.&#x27;</span>]</span><br><span class="line"><span class="comment"># define class labels</span></span><br><span class="line">labels = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="comment"># integer encode the documents</span></span><br><span class="line">vocab_size = <span class="number">50</span></span><br><span class="line">encoded_docs = [one_hot(d, vocab_size) <span class="keyword">for</span> d <span class="keyword">in</span> docs]</span><br><span class="line"><span class="built_in">print</span>(encoded_docs)</span><br><span class="line"><span class="comment"># pad documents to a max length of 4 words</span></span><br><span class="line">max_length = <span class="number">4</span></span><br><span class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(padded_docs)</span><br><span class="line"><span class="comment"># define the model</span></span><br><span class="line"><span class="built_in">input</span> = Input(shape=(<span class="number">4</span>, ))</span><br><span class="line">x = Embedding(vocab_size, <span class="number">8</span>, input_length=max_length)(<span class="built_in">input</span>)</span><br><span class="line">x = Flatten()(x)</span><br><span class="line">x = Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)(x)</span><br><span class="line">model = Model(inputs=<span class="built_in">input</span>, outputs=x)</span><br><span class="line"><span class="comment"># compile the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"><span class="comment"># summarize the model</span></span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br><span class="line"><span class="comment"># fit the model</span></span><br><span class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># evaluate the model</span></span><br><span class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy: %f&#x27;</span> % (accuracy * <span class="number">100</span>))</span><br></pre></td></tr></table></figure><p>之后，我们可以将嵌入图层中学习的权重保存到文件中，以便以后在其他模型中使用。</p><p>通常也可以使用这个模型来分类在测试数据集中看到的同类词汇的其他文档。</p><p>接下来，让我们看看在Keras中加载预先训练的词嵌入。</p><h2 id="使用预训练GloVE嵌入的示例"><a href="#使用预训练GloVE嵌入的示例" class="headerlink" title="使用预训练GloVE嵌入的示例"></a>使用预训练GloVE嵌入的示例</h2><p>Keras嵌入层也可以使用在其他地方学习的嵌入字。</p><p>在自然语言处理领域，学习，保存和分享提供词嵌入是很常见的。</p><p>例如，GloVe方法背后的研究人员提供了一套在公共领域许可下发布的预先训练的词嵌入。看到：</p><ul><li><a href="https://nlp.stanford.edu/projects/glove/">GloVe: Global Vectors for Word Representation</a></li></ul><p>最小的包是822Mb，叫做“glove.6B.zip”。它训练了10亿个词汇（单词）的数据集，词汇量为40万字，有几种不同的嵌入矢量尺寸，包括50,100,200和300size。</p><p>您可以下载这个嵌入的集合，可以作为Keras嵌入层中训练数据集中的单词预先训练嵌入的权重。</p><p>这个例子受Keras项目中的一个例子的启发：<a href="https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py">pretrained_word_embeddings.py</a>。</p><p>下载并解压缩后，您将看到几个文件，其中一个是“glove.6B.100d.txt”，其中包含一个100维版本的嵌入。</p><p>如果你在文件内部偷看，你会看到一个token（单词），后面是每行的权重（100个数字）。例如，下面是嵌入的ASCII文本文件的第一行，显示“the”的嵌入。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062</span><br></pre></td></tr></table></figure><p>如前一节所述，第一步是定义这些示例，将它们编码为整数，然后将这些序列填充为相同的长度。</p><p>在这种情况下，我们需要能够将单词映射到整数以及整数到单词。</p><p>Keras提供了一个<a href="https://keras.io/preprocessing/text/#tokenizer">Tokenizer</a>类，可以适应训练数据，通过调用Tokenizer类的texts_to_sequences（）方法，可以一致地将文本转换为序列，并且可以访问单词在word_index属性中的整数字典映射。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define documents</span></span><br><span class="line">docs = [<span class="string">&#x27;Well done!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Good work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Great effort&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;nice work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Excellent!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Weak&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Poor effort!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;not good&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;poor work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Could have done better.&#x27;</span>]</span><br><span class="line"><span class="comment"># define class labels</span></span><br><span class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="comment"># prepare tokenizer</span></span><br><span class="line">t = Tokenizer()</span><br><span class="line">t.fit_on_texts(docs)</span><br><span class="line">vocab_size = <span class="built_in">len</span>(t.word_index) + <span class="number">1</span></span><br><span class="line"><span class="comment"># integer encode the documents</span></span><br><span class="line">encoded_docs = t.texts_to_sequences(docs)</span><br><span class="line"><span class="built_in">print</span>(encoded_docs)</span><br><span class="line"><span class="comment"># pad documents to a max length of 4 words</span></span><br><span class="line">max_length = <span class="number">4</span></span><br><span class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(padded_docs)</span><br></pre></td></tr></table></figure><p>接下来，我们需要将整个Glove字嵌入文件作为字的字典加载到内存中以嵌入数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the whole embedding into memory</span></span><br><span class="line">embeddings_index = <span class="built_in">dict</span>()</span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;glove.6B.100d.txt&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">values = line.split()</span><br><span class="line">word = values[<span class="number">0</span>]</span><br><span class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">embeddings_index[word] = coefs</span><br><span class="line">f.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Loaded %s word vectors.&#x27;</span> % <span class="built_in">len</span>(embeddings_index))</span><br></pre></td></tr></table></figure><p>这很慢。在训练数据中过滤特殊字词的嵌入可能会更好。</p><p>接下来，我们需要为训练数据集中的每个单词创建一个嵌入矩阵。我们可以通过枚举Tokenizer.word_index中的所有唯一单词并从加载的GloVe嵌入中找到嵌入权重向量来实现这一点。</p><p>结果是一个仅用于训练期间将会看到的单词的权重矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a weight matrix for words in training docs</span></span><br><span class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</span><br><span class="line">embedding_vector = embeddings_index.get(word)</span><br><span class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">embedding_matrix[i] = embedding_vector</span><br></pre></td></tr></table></figure><p>现在我们可以像以前一样定义我们的模型，并进行评估。</p><p>关键的区别是嵌入层可以用GloVe字嵌入权重来播种。我们选择了100维版本，因此必须使用output_dim将其设置为100来定义嵌入层。最后，我们不希望更新此模型中的学习单词权重，因此我们将设置模型的可训练属性为False 。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)</span><br></pre></td></tr></table></figure><p>下面列出了完整的工作示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> asarray</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="comment"># define documents</span></span><br><span class="line">docs = [<span class="string">&#x27;Well done!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Good work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Great effort&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;nice work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Excellent!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Weak&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Poor effort!&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;not good&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;poor work&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;Could have done better.&#x27;</span>]</span><br><span class="line"><span class="comment"># define class labels</span></span><br><span class="line">labels = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="comment"># prepare tokenizer</span></span><br><span class="line">t = Tokenizer()</span><br><span class="line">t.fit_on_texts(docs)</span><br><span class="line">vocab_size = <span class="built_in">len</span>(t.word_index) + <span class="number">1</span></span><br><span class="line"><span class="comment"># integer encode the documents</span></span><br><span class="line">encoded_docs = t.texts_to_sequences(docs)</span><br><span class="line"><span class="built_in">print</span>(encoded_docs)</span><br><span class="line"><span class="comment"># pad documents to a max length of 4 words</span></span><br><span class="line">max_length = <span class="number">4</span></span><br><span class="line">padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(padded_docs)</span><br><span class="line"><span class="comment"># load the whole embedding into memory</span></span><br><span class="line">embeddings_index = <span class="built_in">dict</span>()</span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;../glove_data/glove.6B/glove.6B.100d.txt&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">values = line.split()</span><br><span class="line">word = values[<span class="number">0</span>]</span><br><span class="line">coefs = asarray(values[<span class="number">1</span>:], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">embeddings_index[word] = coefs</span><br><span class="line">f.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Loaded %s word vectors.&#x27;</span> % <span class="built_in">len</span>(embeddings_index))</span><br><span class="line"><span class="comment"># create a weight matrix for words in training docs</span></span><br><span class="line">embedding_matrix = zeros((vocab_size, <span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> t.word_index.items():</span><br><span class="line">embedding_vector = embeddings_index.get(word)</span><br><span class="line"><span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">embedding_matrix[i] = embedding_vector</span><br><span class="line"><span class="comment"># define model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">e = Embedding(vocab_size, <span class="number">100</span>, weights=[embedding_matrix], input_length=<span class="number">4</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">model.add(e)</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment"># compile the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"><span class="comment"># summarize the model</span></span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br><span class="line"><span class="comment"># fit the model</span></span><br><span class="line">model.fit(padded_docs, labels, epochs=<span class="number">50</span>, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># evaluate the model</span></span><br><span class="line">loss, accuracy = model.evaluate(padded_docs, labels, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy: %f&#x27;</span> % (accuracy*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><p>运行这个例子可能需要更长的时间，但是这表明它能够适应这个简单的问题。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]</span><br><span class="line"></span><br><span class="line">[[ 6  2  0  0]</span><br><span class="line"> [ 3  1  0  0]</span><br><span class="line"> [ 7  4  0  0]</span><br><span class="line"> [ 8  1  0  0]</span><br><span class="line"> [ 9  0  0  0]</span><br><span class="line"> [10  0  0  0]</span><br><span class="line"> [ 5  4  0  0]</span><br><span class="line"> [11  3  0  0]</span><br><span class="line"> [ 5  1  0  0]</span><br><span class="line"> [12 13  2 14]]</span><br><span class="line"></span><br><span class="line">Loaded 400000 word vectors.</span><br><span class="line"></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #</span><br><span class="line">=================================================================</span><br><span class="line">embedding_1 (Embedding)      (None, 4, 100)            1500</span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)          (None, 400)               0</span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 1)                 401</span><br><span class="line">=================================================================</span><br><span class="line">Total params: 1,901</span><br><span class="line">Trainable params: 401</span><br><span class="line">Non-trainable params: 1,500</span><br><span class="line">_________________________________________________________________</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Accuracy: 100.000000</span><br></pre></td></tr></table></figure><p>在实践中，最好还是尝试使用预先训练好的嵌入来学习单词嵌入，因为它是固定的，并尝试在预先训练好的嵌入之上进行学习，这就类似于计算机视觉里面用预训练的VGG或者res-net迁移具体问题那样。</p><p>不过这取决于什么最适合你的具体问题。</p><h2 id="IMDB-数据集Embedding实例"><a href="#IMDB-数据集Embedding实例" class="headerlink" title="IMDB 数据集Embedding实例"></a>IMDB 数据集Embedding实例</h2><p><img src="/images/15204978301733.jpg"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential,Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten, Dense, Embedding, Input</span><br><span class="line"></span><br><span class="line">input_layer = Input(shape=(maxlen,)) </span><br><span class="line">x = Embedding(input_dim=<span class="number">10000</span>,output_dim=<span class="number">8</span>)(input_layer)</span><br><span class="line"><span class="comment"># 单独做一个embedding模型，利于后面观察</span></span><br><span class="line">embedding = Model(input_layer,x)</span><br><span class="line">x = Flatten()(x)</span><br><span class="line">x = Dense(<span class="number">1</span>,activation=<span class="string">&#x27;sigmoid&#x27;</span>)(x)</span><br><span class="line">model = Model(input_layer,x)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">model.summary()</span><br><span class="line">history = modhistory = modhistory = mod&gt; history = model.fit(x_train,y_train,epochs=<span class="number">10</span>,batch_size=<span class="number">32</span>,validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">input_4 (InputLayer)         (<span class="literal">None</span>, <span class="number">20</span>)                <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">embedding_5 (Embedding)      (<span class="literal">None</span>, <span class="number">20</span>, <span class="number">8</span>)             <span class="number">80000</span>     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_5 (Flatten)          (<span class="literal">None</span>, <span class="number">160</span>)               <span class="number">0</span>         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_5 (Dense)              (<span class="literal">None</span>, <span class="number">1</span>)                 <span class="number">161</span>       </span><br><span class="line">=================================================================</span><br><span class="line"></span><br><span class="line">Total params: <span class="number">80</span>,<span class="number">161</span></span><br><span class="line">Trainable params: <span class="number">80</span>,<span class="number">161</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br><span class="line">Train on <span class="number">20000</span> samples, validate on <span class="number">5000</span> samples</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 105us/step - loss: <span class="number">0.6772</span> - acc: <span class="number">0.6006</span> - val_loss: <span class="number">0.6448</span> - val_acc: <span class="number">0.6704</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 93us/step - loss: <span class="number">0.5830</span> - acc: <span class="number">0.7188</span> - val_loss: <span class="number">0.5629</span> - val_acc: <span class="number">0.7046</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 95us/step - loss: <span class="number">0.5152</span> - acc: <span class="number">0.7464</span> - val_loss: <span class="number">0.5362</span> - val_acc: <span class="number">0.7208</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 93us/step - loss: <span class="number">0.4879</span> - acc: <span class="number">0.7607</span> - val_loss: <span class="number">0.5299</span> - val_acc: <span class="number">0.7292</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 97us/step - loss: <span class="number">0.4731</span> - acc: <span class="number">0.7694</span> - val_loss: <span class="number">0.5290</span> - val_acc: <span class="number">0.7334</span></span><br><span class="line">Epoch <span class="number">6</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 98us/step - loss: <span class="number">0.4633</span> - acc: <span class="number">0.7773</span> - val_loss: <span class="number">0.5317</span> - val_acc: <span class="number">0.7344</span></span><br><span class="line">Epoch <span class="number">7</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 96us/step - loss: <span class="number">0.4548</span> - acc: <span class="number">0.7819</span> - val_loss: <span class="number">0.5333</span> - val_acc: <span class="number">0.7318</span></span><br><span class="line">Epoch <span class="number">8</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 93us/step - loss: <span class="number">0.4471</span> - acc: <span class="number">0.7870</span> - val_loss: <span class="number">0.5377</span> - val_acc: <span class="number">0.7288</span></span><br><span class="line">Epoch <span class="number">9</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 95us/step - loss: <span class="number">0.4399</span> - acc: <span class="number">0.7924</span> - val_loss: <span class="number">0.5422</span> - val_acc: <span class="number">0.7278</span></span><br><span class="line">Epoch <span class="number">10</span>/<span class="number">10</span></span><br><span class="line"><span class="number">20000</span>/<span class="number">20000</span> [==============================] - 2s 90us/step - loss: <span class="number">0.4328</span> - acc: <span class="number">0.7957</span> - val_loss: <span class="number">0.5458</span> - val_acc: <span class="number">0.7290</span></span><br></pre></td></tr></table></figure><p>我们观察一下input的shape</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x_train[<span class="number">1</span>].shape</span><br><span class="line">x_train[<span class="number">1</span>]</span><br><span class="line">x_train[:<span class="number">1</span>].shape</span><br><span class="line">x_train[:<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">(<span class="number">20</span>,)</span><br><span class="line">array([ <span class="number">23</span>,   <span class="number">4</span>,   <span class="number">2</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">4</span>,   <span class="number">2</span>,   <span class="number">5</span>,  <span class="number">28</span>,   <span class="number">6</span>,  <span class="number">52</span>, <span class="number">154</span>, <span class="number">462</span>,</span><br><span class="line">        <span class="number">33</span>,  <span class="number">89</span>,  <span class="number">78</span>, <span class="number">285</span>,  <span class="number">16</span>, <span class="number">145</span>,  <span class="number">95</span>], dtype=int32)</span><br><span class="line">(<span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line">array([[ <span class="number">65</span>,  <span class="number">16</span>,  <span class="number">38</span>,   <span class="number">2</span>,  <span class="number">88</span>,  <span class="number">12</span>,  <span class="number">16</span>, <span class="number">283</span>,   <span class="number">5</span>,  <span class="number">16</span>,   <span class="number">2</span>, <span class="number">113</span>, <span class="number">103</span>,</span><br><span class="line">         <span class="number">32</span>,  <span class="number">15</span>,  <span class="number">16</span>,   <span class="number">2</span>,  <span class="number">19</span>, <span class="number">178</span>,  <span class="number">32</span>]], dtype=int32)</span><br></pre></td></tr></table></figure><p>再看看embedding的输出，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">embedding.predict(x_train[:<span class="number">1</span>]).shape</span><br><span class="line">embedding.predict(x_train[:<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">(<span class="number">1</span>, <span class="number">20</span>, <span class="number">8</span>)</span><br><span class="line">array([[[-<span class="number">0.17401133</span>, -<span class="number">0.08743777</span>,  <span class="number">0.15631911</span>, -<span class="number">0.06831486</span>, -<span class="number">0.09105065</span>,</span><br><span class="line">          <span class="number">0.06253908</span>, -<span class="number">0.0798945</span> ,  <span class="number">0.07671431</span>],</span><br><span class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, -<span class="number">0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</span><br><span class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</span><br><span class="line">        [ <span class="number">0.06872956</span>, -<span class="number">0.00586612</span>,  <span class="number">0.07713806</span>, -<span class="number">0.00182899</span>,  <span class="number">0.00882899</span>,</span><br><span class="line">         -<span class="number">0.18892162</span>, -<span class="number">0.13580748</span>, -<span class="number">0.03166043</span>],</span><br><span class="line">        [-<span class="number">0.01912907</span>, -<span class="number">0.01732869</span>,  <span class="number">0.00391375</span>, -<span class="number">0.02338142</span>,  <span class="number">0.02787969</span>,</span><br><span class="line">         -<span class="number">0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</span><br><span class="line">        [ <span class="number">0.20604047</span>,  <span class="number">0.10910885</span>,  <span class="number">0.06304865</span>, -<span class="number">0.14038748</span>,  <span class="number">0.12123005</span>,</span><br><span class="line">          <span class="number">0.06124007</span>,  <span class="number">0.0532628</span> ,  <span class="number">0.17591232</span>],</span><br><span class="line">        [-<span class="number">0.19636872</span>, -<span class="number">0.0027669</span> ,  <span class="number">0.01087157</span>, -<span class="number">0.02332311</span>, -<span class="number">0.04321857</span>,</span><br><span class="line">         -<span class="number">0.09228673</span>, -<span class="number">0.03061322</span>, -<span class="number">0.13376454</span>],</span><br><span class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, -<span class="number">0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</span><br><span class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</span><br><span class="line">        [-<span class="number">0.27160701</span>, -<span class="number">0.29296583</span>,  <span class="number">0.1055108</span> ,  <span class="number">0.15896739</span>, -<span class="number">0.24833643</span>,</span><br><span class="line">         -<span class="number">0.17791845</span>, -<span class="number">0.27316946</span>, -<span class="number">0.241273</span>  ],</span><br><span class="line">        [-<span class="number">0.02175452</span>, -<span class="number">0.0839383</span> ,  <span class="number">0.04338101</span>,  <span class="number">0.01062139</span>, -<span class="number">0.11473208</span>,</span><br><span class="line">         -<span class="number">0.18394938</span>, -<span class="number">0.05141308</span>, -<span class="number">0.10405254</span>],</span><br><span class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, -<span class="number">0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</span><br><span class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</span><br><span class="line">        [-<span class="number">0.01912907</span>, -<span class="number">0.01732869</span>,  <span class="number">0.00391375</span>, -<span class="number">0.02338142</span>,  <span class="number">0.02787969</span>,</span><br><span class="line">         -<span class="number">0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</span><br><span class="line">        [-<span class="number">0.14751843</span>,  <span class="number">0.05572686</span>,  <span class="number">0.20332271</span>, -<span class="number">0.01759946</span>, -<span class="number">0.0946402</span> ,</span><br><span class="line">         -<span class="number">0.14416233</span>,  <span class="number">0.16961734</span>,  <span class="number">0.01381243</span>],</span><br><span class="line">        [ <span class="number">0.00282665</span>, -<span class="number">0.17532936</span>, -<span class="number">0.09342033</span>,  <span class="number">0.04514923</span>, -<span class="number">0.04684081</span>,</span><br><span class="line">          <span class="number">0.1748796</span> , -<span class="number">0.09669576</span>, -<span class="number">0.10699435</span>],</span><br><span class="line">        [ <span class="number">0.00225757</span>, -<span class="number">0.12751001</span>, -<span class="number">0.12703758</span>,  <span class="number">0.17167819</span>, -<span class="number">0.03712473</span>,</span><br><span class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, -<span class="number">0.02731293</span>],</span><br><span class="line">        [ <span class="number">0.02198115</span>,  <span class="number">0.03989581</span>,  <span class="number">0.13165356</span>,  <span class="number">0.06523556</span>,  <span class="number">0.14900513</span>,</span><br><span class="line">          <span class="number">0.01858517</span>, -<span class="number">0.01644249</span>, -<span class="number">0.02377043</span>],</span><br><span class="line">        [ <span class="number">0.18718374</span>,  <span class="number">0.10347525</span>, -<span class="number">0.06668846</span>,  <span class="number">0.25818944</span>,  <span class="number">0.07522523</span>,</span><br><span class="line">          <span class="number">0.07082067</span>,  <span class="number">0.05170904</span>,  <span class="number">0.22902426</span>],</span><br><span class="line">        [-<span class="number">0.01912907</span>, -<span class="number">0.01732869</span>,  <span class="number">0.00391375</span>, -<span class="number">0.02338142</span>,  <span class="number">0.02787969</span>,</span><br><span class="line">         -<span class="number">0.02744135</span>,  <span class="number">0.0074541</span> ,  <span class="number">0.01806928</span>],</span><br><span class="line">        [-<span class="number">0.01993229</span>, -<span class="number">0.04436176</span>,  <span class="number">0.07624088</span>,  <span class="number">0.04268746</span>, -<span class="number">0.00883252</span>,</span><br><span class="line">          <span class="number">0.00789542</span>, -<span class="number">0.03039453</span>,  <span class="number">0.05851226</span>],</span><br><span class="line">        [-<span class="number">0.12873659</span>, -<span class="number">0.00083202</span>, -<span class="number">0.03246918</span>,  <span class="number">0.23910245</span>, -<span class="number">0.24635716</span>,</span><br><span class="line">          <span class="number">0.10966355</span>,  <span class="number">0.02079294</span>, -<span class="number">0.03829115</span>],</span><br><span class="line">        [ <span class="number">0.00225757</span>, -<span class="number">0.12751001</span>, -<span class="number">0.12703758</span>,  <span class="number">0.17167819</span>, -<span class="number">0.03712473</span>,</span><br><span class="line">          <span class="number">0.04252302</span>,  <span class="number">0.04741228</span>, -<span class="number">0.02731293</span>]]], dtype=float32)</span><br></pre></td></tr></table></figure><p>可以看出，embedding层将(1, 20)的一个输入sample（最长为20个单词的句子，其中每个单词表示为一个int数字），嵌入为一个(1, 20, 8)的向量，即将每个单词embed为一个8维的向量，而整个embedding层的参数就由神经网络学习得到，数据经过embedding层之后就方便地转换为了可以由CNN或者RNN进一步处理的格式。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/">How to Use Word Embedding Layers for Deep Learning with Keras - Machine Learning Mastery</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/Keras/">Keras</category>
      
      
      <comments>http://example.com/2017/12/18/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>神经网络术语大百科：优化函数、激活函数、损失函数、正则方法的简介</title>
      <link>http://example.com/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/</link>
      <guid>http://example.com/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/</guid>
      <pubDate>Fri, 15 Dec 2017 04:45:44 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/neuralnetworks.png&quot; alt=&quot;neuralnetworks&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/neuralnetworks.png" alt="neuralnetworks"></p><p>简述关于神经网络的各种优化函数（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam）、各种激活函数（Sigmoid，Tanh、Hard Sigmoid、Softplus、ReLU、ElU、PReLU、RReLU）、各种损失函数以及正则方法的简述，并附带代码实现例子。</p><span id="more"></span><h1 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h1><p>先上两张图</p><figure class="three">   <img src="/images/2017/05/contours_evaluation_optimizers.gif" title="Logo" width="300" />   <img src="/images/2017/05/saddle_point_evaluation_optimizers.gif" title="Logo" width="300" /></figure><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>没有激活函数，神经元就只是一个线性函数，那么无论多少层的神经元叠加是没有意义的。而主流激活函数也随着神经网络、深度学习的发展迭代进化了许多次代。</p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p><img src="/images/15134144452960.jpg"><br>Sigmoid是S形状的意思，又因为它是逻辑回归的激活函数又叫logistic函数，函数式为$<code>y = 1 / (1 + exp(-x))</code>$是很早以前最常用的激活函数，其实也是有一些优点的，比如，</p><ul><li>值域位于0-1，那么对于逻辑回归，这是对于二分类的一个很自然的表达，也就是概率</li><li>处处连续可导</li></ul><p>不过呢，我们观察它的形状，可以得出，Sigmoid函数在两端（靠近0和1的部分）梯度很小，这也意味着，如果神经元的输出落到了这个地方，那么它几乎没什么梯度可以传到后面，而随着神经网络的层层削弱，后面的层（靠近输入的层）没有多少梯度能传过来，几乎就“学不到什么”了。这叫做梯度消失问题，一度是阻碍神经网络往更深的层进化的主要困难，导致深度学习专家们绞尽脑汁想了许多方法来对抗这个问题，比如“Xavier and He Initialization”，比如我们要把weight随机初始化为如下的范围，<br><img src="/images/Screen%20Shot%202017-12-16%20at%2017.03.18.png" alt="Screen Shot 2017-12-16 at 17.03.18"></p><p>sigmoid的另一个问题是它不是0均值的，Sigmoid函数的输出值恒大于0，这会导致模型训练的收敛速度变慢。举例来讲，对，如果所有均为正数或负数，那么其对的导数总是正数或负数，这会导致如下图红色箭头所示的阶梯式更新，这显然并非一个好的优化路径。深度学习往往需要大量时间来处理大量数据，模型的收敛速度是尤为重要的。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。</p><p><img src="/images/15134157378274.jpg"></p><p>如今，sigmoid函数应用最广泛的在于其变种softmax在多元分类中，比如手写数字识别，经过卷积神经网络的处理，最后我们需要网络输出每个预测的概率值，最后预测为某一个数字，这里就需要用到softmax，<br><img src="/images/15134154076033.jpg"><br>以下是softmax的Keras代码，注意其中一个trick，<code>e = K.exp(x - K.max(x, axis=axis, keepdims=True))</code>这里每个分量减去最大值是为了减少计算量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">x, axis=-<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Softmax activation function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        x : Tensor.</span></span><br><span class="line"><span class="string">        axis: Integer, axis along which the softmax normalization is applied.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        Tensor, output of softmax transformation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Raises</span></span><br><span class="line"><span class="string">        ValueError: In case `dim(x) == 1`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ndim = K.ndim(x)</span><br><span class="line">    <span class="keyword">if</span> ndim == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> K.softmax(x)</span><br><span class="line">    <span class="keyword">elif</span> ndim &gt; <span class="number">2</span>:</span><br><span class="line">        e = K.exp(x - K.<span class="built_in">max</span>(x, axis=axis, keepdims=<span class="literal">True</span>))</span><br><span class="line">        s = K.<span class="built_in">sum</span>(e, axis=axis, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> e / s</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Cannot apply softmax to a tensor that is 1D&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><p><img src="/images/15134156685588.jpg"></p><p>tanh 是sigmoid的变形： $tanh(x)=2sigmoid(2x)-1$，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好一些，</p><p><img src="/images/15134156615077.jpg"></p><h2 id="ReLU家族"><a href="#ReLU家族" class="headerlink" title="ReLU家族"></a>ReLU家族</h2><p>然而标准ReLU不是完美的，比如因为ReLU在小于0的坐标梯度都是0，那么会造成“死亡”的神经元的问题：一旦神经元的输入与权重之乘积是负的，那么经过ReLU的激活，输出就是0，而ReLU的0梯度让“死亡”的神经元无法“复活”：没办法回到输出不是0的状态，这样就出现了许多在ReLU的变种，一般都是对标准ReLU坐标轴左边的部分做文章，比如<strong>leaky ReLU</strong>。其公式就是$LeakyReLU_ α (z) = max(\alpha z,z)$。如图，<br><img src="/images/15134123600394.jpg"></p><p>这篇文章<a href="https://arxiv.org/pdf/1505.00853.pdf">Empirical Evaluation of Rectified Activations in Convolution Network</a>对比了几种leaky ReLU，比如把$\alpha$设置为0.2效果总是好过0.01，并且，对于randomized leaky ReLU (RReLU)（其中$\alpha$设置为一个在指定范围内的随机数），效果也不错，而且还具有一定的正则作用。另外，对于parametric leaky ReLU (PReLU)（其中$\alpha$作为网络的一个参数，被反向传播学习出来，之前的$\alpha$都是超参数，不能学只能调节），这种变种对于大数据集不错，但是数据量过小就有过拟合的风险。以下是Keras里面relu的代码，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span>(<span class="params">x, alpha=<span class="number">0.</span>, max_value=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rectified linear unit.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    With default values, it returns element-wise `max(x, 0)`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        x: A tensor or variable.</span></span><br><span class="line"><span class="string">        alpha: A scalar, slope of negative section (default=`0.`).</span></span><br><span class="line"><span class="string">        max_value: Saturation threshold.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A tensor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</span><br><span class="line">        negative_part = tf.nn.relu(-x)</span><br><span class="line">    x = tf.nn.relu(x)</span><br><span class="line">    <span class="keyword">if</span> max_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        max_value = _to_tensor(max_value, x.dtype.base_dtype)</span><br><span class="line">        zero = _to_tensor(<span class="number">0.</span>, x.dtype.base_dtype)</span><br><span class="line">        x = tf.clip_by_value(x, zero, max_value)</span><br><span class="line">    <span class="keyword">if</span> alpha != <span class="number">0.</span>:</span><br><span class="line">        alpha = _to_tensor(alpha, x.dtype.base_dtype)</span><br><span class="line">        x -= alpha * negative_part</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>另外，在这篇文章里面<a href="https://arxiv.org/pdf/1511.07289v5.pdf">FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)</a>，引入了一种新的ReLU，exponential linear unit (ELU)，公式如下，<br>$$<br>ELU_{\alpha}(z) = \alpha (\exp(z)-1) \ if \ z \lt 0 ; \ z \ if \ z \gt 0;<br>$$<br><img src="/images/15134129990682.jpg"></p><p>与标准ReLU最大的区别在于它处处连续可导，这使得梯度下降得到加速，收敛得到了加速，而使用了指数函数使得其测试阶段的计算代价更高。Keras里elu的实现，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">elu</span>(<span class="params">x, alpha=<span class="number">1.</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Exponential linear unit.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        x: A tenor or variable to compute the activation function for.</span></span><br><span class="line"><span class="string">        alpha: A scalar, slope of positive section.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        A tensor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    res = tf.nn.elu(x)</span><br><span class="line">    <span class="keyword">if</span> alpha == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> tf.where(x &gt; <span class="number">0</span>, res, alpha * res)</span><br></pre></td></tr></table></figure><h2 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h2><p>一般来说，我们的选择顺序可以理解为：<br>ELU &gt; leaky ReLU (以及其变种) &gt; ReLU &gt; tanh &gt; logistic。但是，</p><ul><li>如果我们更顾虑模型运行速度，那么leaky ReLU可能比ELU更好；</li><li>如果我们不想调节超参数，那么用默认的$\alpha$就行，ReLU和ELU的分别是0.01和1； </li><li>如果算力足够可以用来调参，那么如果网络过拟合我们会选择RReLU，如果训练集数据足够多，那可以用PReLU。</li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Python/">Python</category>
      
      
      <comments>http://example.com/2017/12/15/Neural-Network-Terms-Introduction-to-Optimization-Functions-Activation-Functions-Loss-Functions-and-Regular-Functions/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>如何理解Pandas 和 Numpy里的axis</title>
      <link>http://example.com/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/</link>
      <guid>http://example.com/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/</guid>
      <pubDate>Tue, 12 Dec 2017 10:36:04 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15130766716183.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15130766716183.jpg"></p><p>简述一种如何直观的理解Pandas 和 Numpy里面的axis参数的方法。</p><span id="more"></span><p>Numpy 和 Pandas里的sort、mean、drop等操作，不是分行或者列分别用一个method来定义，而是一个method里面用户指定axis来操作的，举例来说：</p><p>我们先在<a href="https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/drinks.csv">此处</a>下载了一份各国酒类消费的csv文件为例。<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.14.png" alt="Screen Shot 2017-12-12 at 18.46.14"><br>如下是pandas里按axis 0和1进行drop的操作示例，我们很容易看出，axis 0是按行drop，而axis 1是按列drop：<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.46.22.png" alt="Screen Shot 2017-12-12 at 18.46.22"></p><p>但是，mean操作呢？<br><img src="/images/Screen%20Shot%202017-12-12%20at%2018.49.18.png" alt="Screen Shot 2017-12-12 at 18.49.18"></p><p>容易看出，axis 0得出了每一列的均值，而axis 1得出了则是每一行的均值。<br>那么，在Numpy里呢？</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2019.06.17.png" alt="Screen Shot 2017-12-12 at 19.06.17"></p><p>容易看出，axis为1的时候得出的是每行的sum，axis为0的时候得出了每列的sum。</p><p>由上面的例子，我们似乎可以看出，axis为1代表水平方向上的操作，axis为0代表垂直方向上的操作，比如axis为1的sum得出的就是每一行的和。</p><p><img src="/images/15130760734631.jpg"></p><p>但是，在Pandas的Dataframe里面，为什么axis=1代表的是drop整个列呢？以下这个例子也可以说明一些情况：</p><p><img src="/images/Screen%20Shot%202017-12-12%20at%2018.56.53.png" alt="Screen Shot 2017-12-12 at 18.56.53"></p><p>联系这个视频<a href="https://www.youtube.com/watch?v=PtO3t6ynH-8">How do I use the “axis” parameter in pandas? - YouTube</a>，大家也可以得到一些结论，作者说：</p><blockquote><p>0 is the row axis, and 1 is the column axis. When you drop with axis=1, that means drop a column. When you take the mean with axis=1, that means the operation should “move across” the column axis, which produces row means.<br>指的就是一种更加容易理解的方式，“0就是行的axis，1就是列的axis，当以axis=1来drop，那么就是drop一个column，而axis=1 来取mean，那么就是这个操作‘穿越’了列的axis，产生了行上的mean”。</p></blockquote><p>另外，其实我们也可以这样来操作，<br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.27.png" alt="Screen Shot 2017-12-12 at 19.01.27"><br><img src="/images/Screen%20Shot%202017-12-12%20at%2019.01.45.png" alt="Screen Shot 2017-12-12 at 19.01.45"></p><p>可以看出，axis=0与axis=’rows’是一样的（在Pandas里），是不是更加容易理解了？</p><p><a href="https://distill.pub/2016/misread-tsne/">How to Use t-SNE Effectively</a>这个网站给了一个非常形象的t-SNE在线实验环境，推荐大家去看一看！<br><img src="/images/15205939273866.jpg"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Numpy/">Numpy</category>
      
      <category domain="http://example.com/tags/Pandas/">Pandas</category>
      
      
      <comments>http://example.com/2017/12/12/Understanding-the-axis-parameter-in-Pandas-and-Numpy/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>理解triplet loss</title>
      <link>http://example.com/2017/12/01/understanding-triplet-loss-and-example-code/</link>
      <guid>http://example.com/2017/12/01/understanding-triplet-loss-and-example-code/</guid>
      <pubDate>Fri, 01 Dec 2017 09:19:05 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15121200710041.jpg&quot;&gt;&lt;br&gt;理解triplet loss，与给出TensorFlow和numpy两种形式的example code。 &lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15121200710041.jpg"><br>理解triplet loss，与给出TensorFlow和numpy两种形式的example code。 </p><span id="more"></span><p>Triplet Loss 是当前应用的很广泛的一种损失函数，在人脸识别和聚类领域，这是一种很自然的映射与计算损失的方式，比如<a href="https://arxiv.org/abs/1503.03832">FaceNet</a>里，通过构建一种embedding 方式，将人脸图像直接映射到欧式空间，而优化这种embedding的方法可以概括为，构建许多组三元组（Anchor，Positive，Negative），其中Anchor与Positive同label，Anchor与Negative不同label（在人脸识别里面，就是Anchor与Positive是同一个个体，而与Negative是不同个体），通过学习优化这个embedding，使得欧式空间内的Anchor与Positive 的距离比与Negative的距离要近。</p><h2 id="公式表示"><a href="#公式表示" class="headerlink" title="公式表示"></a>公式表示</h2><p>用公式表示就是，我们希望：</p><p>$$<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2  +<br>\alpha \lt \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 , \<br>\forall (f(x^a_i) , f(x^p_i) , f(x^n_i))  \in \mathscr T<br>$$</p><p>其中$\alpha$ 是强制的正例和负例之间的margin，$\mathscr T$是具有基数为$N$的训练集中的三元组的集合。</p><p>那么，损失函数很自然的可以写为：</p><p>$$<br>\sum^N_i<br>\Bigl [<br>\left\lVert  f(x^a_i) - f(x^p_i) \right\rVert ^2_2   -<br> \left\lVert  f(x^a_i) - f(x^n_i) \right\rVert ^2_2 + \alpha<br> \Bigr ] _ +<br>$$</p><p>其中加号指的，如果中括号内部分小于0，则没有损失（Anchor与Positive的距离加上margin小于与Negative的距离），否则计算这个距离为损失。</p><h2 id="代码表示"><a href="#代码表示" class="headerlink" title="代码表示"></a>代码表示</h2><p>Numpy 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></span><br><span class="line">embedding_size = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造batch_size * embedding_size 维度的随机矩阵</span></span><br><span class="line">emb = np.random.uniform(size=[])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对emb逢三取1、2、3行分别为Anchor、Positive、Negative</span></span><br><span class="line"><span class="comment"># 计算其2范数的距离即欧氏距离</span></span><br><span class="line">pos_dist_sqr = np.<span class="built_in">sum</span>(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </span><br><span class="line">neg_dist_sqr = np.<span class="built_in">sum</span>(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里就是照抄公式了，注意mean和sum是一样的</span></span><br><span class="line">np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</span><br></pre></td></tr></table></figure><p>TensorFlow 实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></span><br><span class="line">embedding_size = <span class="number">16</span></span><br><span class="line">alpha = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span>(<span class="params">anchor, positive, negative, alpha</span>):</span>   </span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;triplet_loss&#x27;</span>):</span><br><span class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</span><br><span class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</span><br><span class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</span><br><span class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建矩阵</span></span><br><span class="line">embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">&#x27;embeddings&#x27;</span>)</span><br><span class="line"><span class="comment"># 先将embeddings矩阵第0维resize为(?, 3)维，第1维不变，变为三维矩阵(-1, 3, embedding_size)，再在其第二维度为3上unstack为三份</span></span><br><span class="line">anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(-<span class="number">1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>完整代码如下，这里测试对比了两种实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">3</span>*<span class="number">12</span></span><br><span class="line">embedding_size = <span class="number">16</span></span><br><span class="line">alpha = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triplet_loss</span>(<span class="params">anchor, positive, negative, alpha</span>):</span>   </span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;triplet_loss&#x27;</span>):</span><br><span class="line">        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), <span class="number">1</span>)</span><br><span class="line">        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), <span class="number">1</span>)</span><br><span class="line">        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)</span><br><span class="line">        loss = tf.reduce_mean(tf.maximum(basic_loss, <span class="number">0.0</span>), <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">    embeddings = tf.placeholder(np.float64, shape=(batch_size, embedding_size), name=<span class="string">&#x27;embeddings&#x27;</span>)</span><br><span class="line">    anchor, positive, negative = tf.unstack(tf.reshape(embeddings, shape=(-<span class="number">1</span>, <span class="number">3</span>, embedding_size)), axis=<span class="number">1</span>)</span><br><span class="line">    triplet_loss = triplet_loss(anchor, positive, negative, alpha)</span><br><span class="line">    </span><br><span class="line">    sess = tf.Session()</span><br><span class="line">    <span class="keyword">with</span> sess.as_default():</span><br><span class="line">        np.random.seed(<span class="number">666</span>)</span><br><span class="line">        emb = np.random.uniform(size=[batch_size, embedding_size])</span><br><span class="line">        tf_triplet_loss = sess.run(triplet_loss, feed_dict=&#123;embeddings:emb&#125;)</span><br><span class="line">        </span><br><span class="line">        pos_dist_sqr = np.<span class="built_in">sum</span>(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">1</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)        </span><br><span class="line">        neg_dist_sqr = np.<span class="built_in">sum</span>(np.square(emb[<span class="number">0</span>::<span class="number">3</span>,:]-emb[<span class="number">2</span>::<span class="number">3</span>,:]), axis=<span class="number">1</span>)</span><br><span class="line">        np_triplet_loss = np.mean(np.maximum(<span class="number">0.</span>, pos_dist_sqr-neg_dist_sqr+alpha))</span><br><span class="line">        </span><br><span class="line">        np.testing.assert_almost_equal(tf_triplet_loss, np_triplet_loss, decimal=<span class="number">5</span>, err_msg=<span class="string">&#x27;Triplet loss is incorrect&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      <category domain="http://example.com/tags/TensorFlow/">TensorFlow</category>
      
      
      <comments>http://example.com/2017/12/01/understanding-triplet-loss-and-example-code/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>数据的标准化与归一化</title>
      <link>http://example.com/2017/11/29/Data-Normalization-and-Standardization/</link>
      <guid>http://example.com/2017/11/29/Data-Normalization-and-Standardization/</guid>
      <pubDate>Wed, 29 Nov 2017 03:53:57 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15119359203487.png&quot;&gt;&lt;br&gt;聊一聊Normalization and Standardization&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15119359203487.png"><br>聊一聊Normalization and Standardization</p><span id="more"></span><h2 id="什么是"><a href="#什么是" class="headerlink" title="什么是"></a>什么是</h2><p>Normalization就是归一化，是最小-最大缩放(min-max scaling)的特例，指的是将数据缩放到指定range，这个range通常是0<del>1或者-1</del>+1，直观来讲就是下图，在数据不包含离群点时很有用，<br><img src="/images/Screen%20Shot%202017-11-29%20at%2012.35.41.png" alt="Screen Shot 2017-11-29 at 12.35.41"></p><p>公式则是</p><p>$$<br>x^{(i)}<em>{norm} = \frac {x^{(i)} - x</em>{min}} {x_{max} - x_{min}}<br>$$</p><p>若要缩放至-1~+1，则是<br>$$<br>x’ = \frac{x - min}{max - min}<br>$$</p><p>代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据预处理库</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment">#范围缩放标准化</span></span><br><span class="line">min_max_scaler = preprocessing.MinMaxScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练集缩放标准化</span></span><br><span class="line">min_max_scaler.fit_transform(X_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试集缩放标准化</span></span><br><span class="line">min_max_scaler.fit_transform(X_test)</span><br></pre></td></tr></table></figure><p>Z-score 标准化指的是，通过缩放让数据的均值为0（移除均值），标准差为固定值（比如1）。在许多模型里，如SVM的RBF、线性模型的 L1 &amp; L2 正则项对于所有的feature都有这样的假设。<br>$$<br>x^{(i)}_{std} = \frac{x^{(i)} - \mu_x}{\sigma_x}<br>$$</p><p>以下是一个简单的例子展示了两者的区别：</p><p><img src="/images/Screen%20Shot%202017-11-29%20at%2012.41.13.png" alt="Screen Shot 2017-11-29 at 12.41.13"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据预处理库</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据标准化</span></span><br><span class="line">scaler = preprocessing.StandardScaler().fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练集数据标准化</span></span><br><span class="line">scaler.transform(X_train)</span><br></pre></td></tr></table></figure><p>同时对测试集的数据进行标准化处理，以保证训练集和测试集的变换方式相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试集数据标准化</span></span><br><span class="line">scaler.transform(X_test)</span><br></pre></td></tr></table></figure><h2 id="值得注意"><a href="#值得注意" class="headerlink" title="值得注意"></a>值得注意</h2><p>从流程上讲，标准化和归一化应该在读入数据、处理缺失值，切分训练测试集之后，而且我们要做的是在切分之后，在训练集fit，再去transform测试集，而不是在整个数据上转换以后再切分，因为<strong>无论是标准化还是归一化，我们要么利用到了数据的max min值，要么利用到了数据的均值和标准差，这些数值在训练之前是不能被测试集所影响的。</strong></p><p>类似于缺失值的填充，举个例子，我们使用均值填充以下数据，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用均值填充缺失值</span></span><br><span class="line">imp = Imputer(missing_values=<span class="string">&quot;NaN&quot;</span>, strategy=<span class="string">&#x27;mean&#x27;</span>, axis=<span class="number">0</span>)</span><br><span class="line">imp.fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#填充训练集</span></span><br><span class="line">X_train=imp.transform(X_train)</span><br></pre></td></tr></table></figure><p>以同样的方式填充测试集，以保证测试集和训练集的数据填充方式保持一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#填充测试集</span></span><br><span class="line">X_test=imp.transform(X_test)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      
      <comments>http://example.com/2017/11/29/Data-Normalization-and-Standardization/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TensorFlow on a GTX 1080</title>
      <link>http://example.com/2017/11/13/TensorFlow-on-a-GTX-1080/</link>
      <guid>http://example.com/2017/11/13/TensorFlow-on-a-GTX-1080/</guid>
      <pubDate>Mon, 13 Nov 2017 10:23:28 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15105686803158.jpg&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15105687114770.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ubuntu 16.03 安装 CUDA、NVIDIA驱动，CUDNN及GPU版TensorFlow。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15105686803158.jpg"><br><img src="/images/15105687114770.jpg"></p><p>Ubuntu 16.03 安装 CUDA、NVIDIA驱动，CUDNN及GPU版TensorFlow。</p><span id="more"></span><p>GPU 支持的TensorFlow让算力大幅提升，但是安装好一切支持却不那么容易！其实主要是三个东西：</p><ol><li>Nvidia 驱动：显卡驱动</li><li>CUDA Toolkit CUDA工具箱</li><li>CUDNN：CUDA Deep Neural Network library  神经网络库函数<h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install \</span><br><span class="line">    freeglut3-dev \</span><br><span class="line">    g++-4.9 \</span><br><span class="line">    gcc-4.9 \</span><br><span class="line">    libglu1-mesa-dev \</span><br><span class="line">    libx11-dev \</span><br><span class="line">    libxi-dev \</span><br><span class="line">    libxmu-dev \</span><br><span class="line">    nvidia-modprobe \</span><br><span class="line">    python-dev \</span><br><span class="line">    python-pip \</span><br><span class="line">    python-virtualenv</span><br></pre></td></tr></table></figure><h2 id="安装Nvidia驱动"><a href="#安装Nvidia驱动" class="headerlink" title="安装Nvidia驱动"></a>安装Nvidia驱动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get purge nvidia-* 删除nvidia 之前的</span><br><span class="line">$ sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install nvidia-384</span><br></pre></td></tr></table></figure><p>可在<a href="https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa">Proprietary GPU Drivers : “Graphics Drivers” team</a>查看当前稳定版本Nvidia驱动，如笔者当前（2017-11-13）版本是‘nvidia-384’。</p><p>接下来重启<code>$ sudo reboot</code>。<br>重启后，检测Nvidia驱动安装情况，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/driver/nvidia/version</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.98  Thu Oct 26 15:16:01 PDT 2017</span><br><span class="line">GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)</span><br></pre></td></tr></table></figure><p>显示Nvidia’s system management interface：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nvidia-smi</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">|  0%   47C    P8    12W / 215W |   7992MiB /  8112MiB |      2%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0       994      G   /usr/lib/xorg/Xorg                           193MiB |</span><br><span class="line">|    0      1889      G   compiz                                       151MiB |</span><br><span class="line">|    0      5068      C   /home/frank/anaconda3/bin/python            7643MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>设置GCC 4.9为默认</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 10</span><br><span class="line">$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 20</span><br><span class="line"></span><br><span class="line">$ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 10</span><br><span class="line">$ sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 20</span><br></pre></td></tr></table></figure><h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><p>当前虽然CUDA-9.0已经发布，但是TensorFlow默认编译版本还是基于CUDA-8.0的，我们在这里<a href="https://developer.nvidia.com/cuda-80-ga2-download-archive">CUDA Toolkit 8.0 - Feb 2017 | NVIDIA Developer</a>下载runfile<br><img src="/images/Screen%20Shot%202017-11-13%20at%2018.35.28.png" alt="Screen Shot 2017-11-13 at 18.35.28"></p><p>使用如下安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cuda_8.0.61_375.26_linux.run --override</span><br></pre></td></tr></table></figure><p>安装时记得</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Do you accept the previously <span class="built_in">read</span> EULA? (accept/decline/quit): accept</span><br><span class="line">You are attempting to install on an unsupported configuration. Do you wish to <span class="built_in">continue</span>? ((y)es/(n)o) [ default is no ]: yes</span><br><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 352.39? ((y)es/(n)o/(q)uit): no</span><br><span class="line">Install the CUDA 8.0 Toolkit? ((y)es/(n)o/(q)uit): yes</span><br><span class="line">Enter Toolkit Location [ default is /usr/<span class="built_in">local</span>/cuda-8.0 ]:</span><br><span class="line">Do you want to install a symbolic link at /usr/<span class="built_in">local</span>/cuda? ((y)es/(n)o/(q)uit): yes</span><br><span class="line">Install the CUDA 8.0 Samples? ((y)es/(n)o/(q)uit): no</span><br><span class="line">Installing the CUDA Toolkit <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0 ...</span><br><span class="line"></span><br><span class="line">===========</span><br><span class="line">= Summary =8.0</span><br><span class="line">===========</span><br><span class="line"></span><br><span class="line">Driver:   Not Selected</span><br><span class="line">Toolkit:  Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line">Samples:  Not Selected</span><br><span class="line"></span><br><span class="line">Please make sure that</span><br><span class="line"> -   PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line"> -   LD_LIBRARY_PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/lib64, or, add /usr/<span class="built_in">local</span>/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</span><br><span class="line"></span><br><span class="line">To uninstall the CUDA Toolkit, run the uninstall script <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line">To uninstall the NVIDIA Driver, run nvidia-uninstall</span><br><span class="line"></span><br><span class="line">Please see CUDA_Installation_Guide_Linux.pdf <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/doc/pdf <span class="keyword">for</span> detailed information on setting up CUDA.</span><br><span class="line"></span><br><span class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 352.00 is required <span class="keyword">for</span> CUDA 8.0 functionality to work.</span><br><span class="line">To install the driver using this installer, run the following <span class="built_in">command</span>, replacing &lt;CudaInstaller&gt; with the name of this run file:</span><br><span class="line">    sudo &lt;CudaInstaller&gt;.run -silent -driver</span><br><span class="line"></span><br><span class="line">Logfile is /tmp/cuda_install_14557.log</span><br></pre></td></tr></table></figure><p>记得上面这里也有个询问你是否安装Nvidia驱动的地方，因为我们前面已经安装了最新的版本，这里当然选择no。</p><p>添加环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export PATH=/usr/local/cuda/bin:$PATH&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>查看CUDA compiler</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nvcc -V</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2016 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jan_10_13:22:03_CST_2017</span><br><span class="line">Cuda compilation tools, release 8.0, V8.0.61</span><br></pre></td></tr></table></figure><h2 id="安装CUDA-Deep-Neural-Network-library-：CUDNN"><a href="#安装CUDA-Deep-Neural-Network-library-：CUDNN" class="headerlink" title="安装CUDA Deep Neural Network library ：CUDNN"></a>安装CUDA Deep Neural Network library ：CUDNN</h2><p>在此处下载<a href="https://developer.nvidia.com/rdp/cudnn-download">cuDNN Download | NVIDIA Developer</a>，可能需要我们注册账号登录。<br>选择适配CUDA的版本，以及cuDNN v7.0 Library for Linux，这个就是个targz文件。<br><img src="/images/Screen%20Shot%202017-11-13%20at%2018.42.51.png" alt="Screen Shot 2017-11-13 at 18.42.51"></p><p>接下来操作就是把cudnn的几个库放到cuda里面：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tar xvf cudnn-8.0-linux-x64-v7.tgz</span><br><span class="line">$ sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/</span><br><span class="line">$ sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure><h2 id="TensorFlow安装"><a href="#TensorFlow安装" class="headerlink" title="TensorFlow安装"></a>TensorFlow安装</h2><p><code>pip  install --upgrade tfBinaryURL </code>即可，这里的<code>tfBinaryURL</code>可在<a href="https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package">Installing TensorFlow on Ubuntu  |  TensorFlow</a>选取，例如我这里选取Python3.6的GPU Support：</p><p><img src="/images/Screen%20Shot%202017-11-13%20at%2018.47.45.png" alt="Screen Shot 2017-11-13 at 18.47.45"></p><h2 id="验证TensorFlow安装"><a href="#验证TensorFlow安装" class="headerlink" title="验证TensorFlow安装"></a>验证TensorFlow安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import tensorflow as tf</span><br><span class="line"></span><br><span class="line">In [2]: sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br><span class="line">2017-11-13 18:54:59.081831: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">2017-11-13 18:54:59.186280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node <span class="built_in">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2017-11-13 18:54:59.186604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:</span><br><span class="line">name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.86</span><br><span class="line">pciBusID: 0000:01:00.0</span><br><span class="line">totalMemory: 7.92GiB freeMemory: 7.46GiB</span><br><span class="line">2017-11-13 18:54:59.186617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)</span><br><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1</span><br><span class="line">2017-11-13 18:54:59.216573: I tensorflow/core/common_runtime/direct_session.cc:299] Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1</span><br></pre></td></tr></table></figure><p>如上，打印出这些信息就证明安装成功啦！</p><h2 id="CUDA-ToolKit-8-0-升级到9-0指南"><a href="#CUDA-ToolKit-8-0-升级到9-0指南" class="headerlink" title="CUDA ToolKit 8.0 升级到9.0指南"></a>CUDA ToolKit 8.0 升级到9.0指南</h2><p>主要就是需要下载CUDA ToolKit 9.0 的安装包，和8.0一样安装，注意下面的四步骤我们只需要第二步（ToolKit）和第四步（创建软链接，原有的是指向8.0的）</p><p><img src="/images/15210144246547.jpg"></p><p>因为CUDNN被放在CUDA ToolKit 8.0内，所有这里我们需要重新下载CUDNN并解压到CUDA ToolKit 9.0文件夹内，</p><p>再在<a href="https://www.tensorflow.org/install/install_linux#InstallingAnaconda">Installing TensorFlow on Ubuntu  |  TensorFlow</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install --ignore-installed --upgrade \</span><br><span class="line">&lt;url&gt;</span><br></pre></td></tr></table></figure><p><code>url</code>选取如下的你需要的python版本的GPU网址即可。<br><img src="/images/15210146789201.jpg"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/TensorFlow/">TensorFlow</category>
      
      
      <comments>http://example.com/2017/11/13/TensorFlow-on-a-GTX-1080/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>frp的内网穿透及外网访问内网jupyter-notebook的实现</title>
      <link>http://example.com/2017/11/12/ftp-using/</link>
      <guid>http://example.com/2017/11/12/ftp-using/</guid>
      <pubDate>Sat, 11 Nov 2017 18:20:38 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15104246654723.png&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15104246654723.png"></p><span id="more"></span><p><a href="https://github.com/fatedier/frp">fatedier/frp: A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.</a>是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议， 这里我们用它来搭建外网访问内网jupyter-notebook的服务。<br>我们基于Ubuntu16.04 选用amd64版本，<br><img src="/images/Screen%20Shot%202017-11-12%20at%2002.25.46.png" alt="Screen Shot 2017-11-12 at 02.25.46"></p><h3 id="server设置"><a href="#server设置" class="headerlink" title="server设置"></a>server设置</h3><p>server就是你拥有外网IP的服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[common]</span><br><span class="line">bind_port = 7000</span><br><span class="line">vhost_http_port = 8888</span><br></pre></td></tr></table></figure><p>用<code>./frps -c ./frps.ini</code>启动，注意服务端需要先启动。</p><h3 id="client设置"><a href="#client设置" class="headerlink" title="client设置"></a>client设置</h3><p>client就是没有外网IP，但是你想在外网访问的机器，</p><p>XXXXXXXXX就是上面的server的外网IP。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr = XXXXXXXXX</span><br><span class="line">server_port = 7000</span><br><span class="line"></span><br><span class="line">[web]</span><br><span class="line"><span class="built_in">type</span> = http</span><br><span class="line">local_port = 8888</span><br><span class="line">custom_domains = XXXXXXXXX</span><br></pre></td></tr></table></figure><p>以<code>./frpc -c ./frpc.ini</code>启动。</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>接下来，在client端，在8888段端口启动jupyter-notebook即可在XXXXXXXXX:8888访问内网机器上的Notebook了。</p><p><img src="/images/Screen%20Shot%202017-11-12%20at%2002.37.55.png" alt="Screen Shot 2017-11-12 at 02.37.55"></p><p>另外，由于jupyter-notebook自带终端，这也一举两得，也是一个内网穿透ssh的方案。<br>当然，必须使用一些运维工具来保证服务的稳定性，如supervisor，可参考<a href="http://frankchen.xyz/2017/07/06/Use-supervisor-support-Python3-program/">使用supervisor支持Python3程序 | 不正经数据科学家</a>。<br><img src="/images/Screen%20Shot%202017-11-12%20at%2002.39.36.png" alt="Screen Shot 2017-11-12 at 02.39.36"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/11/12/ftp-using/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pycharm Pro</title>
      <link>http://example.com/2017/11/08/pycharm-pro/</link>
      <guid>http://example.com/2017/11/08/pycharm-pro/</guid>
      <pubDate>Wed, 08 Nov 2017 10:44:13 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15101362178541.jpg&quot;&gt;&lt;br&gt;Pycharm，只为提高python开发者的生产力！&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15101362178541.jpg"><br>Pycharm，只为提高python开发者的生产力！</p><span id="more"></span><h2 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h2><p><img src="/images/Screen%20Shot%202017-11-08%20at%2018.17.59.png" alt="Screen Shot 2017-11-08 at 18.17.59"><br>版本管理，主要是依靠这两个按钮，左边是pull，右边是commit。一般我们开发，打开项目，先pull下代码仓库的变更，开始开发，然后commit，再pull，合并冲突，再push。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.21.55.png" alt="Screen Shot 2017-11-08 at 18.21.55"><br>pycharm非常人性化地为我们标出了，黑色则是没有变更，蓝色是有变更，绿色是新add的文件。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.23.21.png" alt="Screen Shot 2017-11-08 at 18.23.21"><br>commit时，可以很方便地看出变更对比，对于需要回滚的零时操作文件可以用紫色的revert按钮回退变更，总之填写commit message之后就可以commit了。<br>然后，为防止在此期间，代码仓库又有人push了新变更，在push之前，我们需要再次pull，如果没有变更，push即可。<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.26.24.png" alt="Screen Shot 2017-11-08 at 18.26.24"><br>如果有冲突呢，pycharm有非常human的解决冲突界面，<br><img src="/images/15101368989889.jpg"><br>总之，选择修改的、丢弃的、保留的，就可以push了，当然，这次push会有两条message，第二条是解决冲突的。</p><h2 id="远程调试"><a href="#远程调试" class="headerlink" title="远程调试"></a>远程调试</h2><p>利用pycharm我们可以在服务器直接run、debug，非常的便捷。<br>首先要设置deployment，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.31.20.png" alt="Screen Shot 2017-11-08 at 18.31.20"><br>选择SFTP，也就是ssh，这里用密码或者私钥都是ok的。设置好映射目录，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.31.56.png" alt="Screen Shot 2017-11-08 at 18.31.56"><br>接下来添加远程解释器，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.33.05.png" alt="Screen Shot 2017-11-08 at 18.33.05"><br>，并勾选auto upload，<br><img src="/images/Screen%20Shot%202017-11-08%20at%2018.33.46.png" alt="Screen Shot 2017-11-08 at 18.33.46"><br>那么，每次本地的更改都会同步到服务器，直接run或者debug都是获取服务器的结果，非常方便。</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="DEBUG"><a href="#DEBUG" class="headerlink" title="DEBUG"></a>DEBUG</h2><p>DEBUG可谓是开发中最最重要的技能了，也许我们在初级的开发的时候，还可以依靠各种print变量来查看，那么工程一旦变复杂，debug就必不可少了，；举个栗子，我们用TensorFlow写深度学习工程的时候，如果出现矩阵维度不匹配的情况，这个时候用debug去观察各个维度就相当高效了。<br>以下图为例，我们做debug，当然先要在我们希望观察的代码处打断点（Break Point），就是左边的红色小点，第一个断点debug停下来的地方。接下来就是debug按钮了，也就是红框内的这些箭头，依次是</p><ul><li>Step Over 直接从当前断点步进到下一个断点，也就是我们不希望看到中间的任何调用，直接跳过</li><li>Step Into，从当前断点，每一次调用都进入，如果调用比较多，可能很繁因为会一步步深入</li><li>Step Into Mycode，简单明了，一行一行的步进，不跳转到调用</li><li>Force Step Into，强制步进进入</li><li>Step Out 跳出当前调用，和Step Into结合，一个进入、一个跳出</li><li>Run to Cursor 不需打断点，直接步进到光标所在处，这个也很方便，只需把光标放在某处点击即可<br><img src="/images/Screen%20Shot%202017-11-09%20at%2015.49.12.png" alt="Screen Shot 2017-11-09 at 15.49.12"><br>此处类似堆栈，后面调用的进程在上面。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2016.19.42.png" alt="Screen Shot 2017-11-09 at 16.19.42"><br>当然，最主要的，上面这些步骤按钮的最终目的就是观察Variable的变化，通过步进观察各个变量的信息，以找出bug等等。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2016.21.15.png" alt="Screen Shot 2017-11-09 at 16.21.15"></li></ul><h2 id="Python-Console"><a href="#Python-Console" class="headerlink" title="Python Console"></a>Python Console</h2><p>相比iPython与Notebook，Pycharm自带的Python Console有其独到的优势，比如Special Variables与Code History ，如图，分别用一个两个三个下划线代表上一次上两次上三次的变量，在这里可以直接像debug一样查看各个变量的值；Code History则是使用户方便地使用之前的代码。<br><img src="/images/Screen%20Shot%202017-11-09%20at%2015.23.52.png" alt="Screen Shot 2017-11-09 at 15.23.52"></p><h2 id="run-file-in-console"><a href="#run-file-in-console" class="headerlink" title="run file in console"></a>run file in console</h2><p><img src="/images/15240386105863.jpg"></p><p>右键的run file in console非常有用，之后我们可以在变量中直接观察，甚至在左侧直接调用计算。</p><p><img src="/images/15240387558710.jpg"></p><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><h3 id="调整代码行次序"><a href="#调整代码行次序" class="headerlink" title="调整代码行次序"></a>调整代码行次序</h3><p>Command + Shift + ⬆️/⬇️<br>有时我们需要调整两行代码的上下次序，那么用剪切、粘贴的方法不如这个方法简洁自然。</p><h3 id="查看源码及跳转"><a href="#查看源码及跳转" class="headerlink" title="查看源码及跳转"></a>查看源码及跳转</h3><p>摁住Command键去点击即可跳转到源码处，而查看源码时我们可以通过Command + [/]来方便的前进或后退。</p><h3 id="批量展开收缩代码"><a href="#批量展开收缩代码" class="headerlink" title="批量展开收缩代码"></a>批量展开收缩代码</h3><p>Command + Shift +/-</p><p>当项目写到一定规模的时候，难免方法/函数会很多，这个时候我们可以使用此命令来收缩代码，这个主要是为了方便查看。</p><h3 id="快速插入常用代码"><a href="#快速插入常用代码" class="headerlink" title="快速插入常用代码"></a>快速插入常用代码</h3><p>Command + J 是弹出插入常用代码块的快捷键，比如Dict/List/Set 的comprehension都有，之前我只会‘main’然后跳出<code>if __name__ == &#39;__main__&#39;:</code>😜</p><p><img src="/images/2017/06/05.png"></p><h3 id="一键-PEP8"><a href="#一键-PEP8" class="headerlink" title="一键 PEP8"></a>一键 PEP8</h3><p>其实在了解这个tips之前我都是点击函数名，等待一个黄色的小灯泡再去点击灯泡。。。其实只需要<code>Command+Option+L</code>即可！</p><h3 id="cheat-sheet"><a href="#cheat-sheet" class="headerlink" title="cheat sheet"></a>cheat sheet</h3><p>顺便更新两张cheat sheet</p><p><img src="/images/2017/06/06.png"><br><img src="/images/2017/06/07.png"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Pycharm/">Pycharm</category>
      
      
      <comments>http://example.com/2017/11/08/pycharm-pro/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Go 语言操作与扫描 Hbase 实例</title>
      <link>http://example.com/2017/11/08/go-hbase/</link>
      <guid>http://example.com/2017/11/08/go-hbase/</guid>
      <pubDate>Wed, 08 Nov 2017 03:10:21 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15101107329028.jpg&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15101107462857.jpg&quot;&gt;&lt;br&gt;记录纯go语言的gohbase客户端的扫描操作。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15101107329028.jpg"><br><img src="/images/15101107462857.jpg"><br>记录纯go语言的gohbase客户端的扫描操作。</p><span id="more"></span><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;github.com/tsuna/gohbase&quot;</span></span><br><span class="line"><span class="string">&quot;github.com/tsuna/gohbase/hrpc&quot;</span></span><br><span class="line"><span class="string">&quot;context&quot;</span></span><br><span class="line"><span class="string">&quot;io&quot;</span></span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;github.com/tsuna/gohbase/filter&quot;</span></span><br><span class="line"><span class="string">&quot;strconv&quot;</span></span><br><span class="line"><span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> table = <span class="string">&quot;user&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">beforeMiniTimeStamps</span><span class="params">(beforeMini <span class="keyword">int</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="comment">//当前时刻某分钟之前的时间戳</span></span><br><span class="line"><span class="keyword">return</span> strconv.Itoa(<span class="keyword">int</span>(time.Now().Add(- time.Duration(beforeMini) * time.Minute).UnixNano() / <span class="number">1000000</span>))</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fetch</span><span class="params">()</span> []*<span class="title">hrpc</span>.<span class="title">Result</span></span> &#123;</span><br><span class="line">client := gohbase.NewClient(<span class="string">&quot;hmaster.shise.com,rm.shise.com,nn.shise.com&quot;</span>)</span><br><span class="line"><span class="comment">//client := gohbase.NewClient(&quot;wwj.shise.com,czn.shise.com,czn.shise.com&quot;)</span></span><br><span class="line"><span class="comment">// 列族</span></span><br><span class="line">family := hrpc.Families(<span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">string</span>&#123;<span class="string">&quot;c&quot;</span>: <span class="literal">nil</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局hbase filter时间间隔</span></span><br><span class="line"><span class="comment">//timeRange := hrpc.TimeRange(time.Now().Add(- time.Duration(minute)*time.Minute), time.Now())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 某列value的filter</span></span><br><span class="line">notRecommendFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">&quot;c&quot;</span>),</span><br><span class="line">[]<span class="keyword">byte</span>(<span class="string">&quot;notRecommend&quot;</span>),</span><br><span class="line">filter.NotEqual,</span><br><span class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(<span class="string">&quot;true&quot;</span>))),</span><br><span class="line"><span class="literal">true</span>,</span><br><span class="line"><span class="literal">true</span>)</span><br><span class="line">violationFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">&quot;c&quot;</span>),</span><br><span class="line">[]<span class="keyword">byte</span>(<span class="string">&quot;violation&quot;</span>),</span><br><span class="line">filter.NotEqual,</span><br><span class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(<span class="string">&quot;true&quot;</span>))),</span><br><span class="line"><span class="literal">true</span>,</span><br><span class="line"><span class="literal">true</span>)</span><br><span class="line"><span class="comment">//filter某列value的时间戳</span></span><br><span class="line">timeStartFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">&quot;c&quot;</span>),</span><br><span class="line">[]<span class="keyword">byte</span>(<span class="string">&quot;createDate&quot;</span>),</span><br><span class="line">filter.Greater,</span><br><span class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(beforeMiniTimeStamps(<span class="number">4</span>*<span class="number">60</span>)))),</span><br><span class="line"><span class="literal">true</span>,</span><br><span class="line"><span class="literal">true</span>)</span><br><span class="line">timeEndFilter := filter.NewSingleColumnValueFilter([]<span class="keyword">byte</span>(<span class="string">&quot;c&quot;</span>),</span><br><span class="line">[]<span class="keyword">byte</span>(<span class="string">&quot;createDate&quot;</span>),</span><br><span class="line">filter.Less,</span><br><span class="line">filter.NewBinaryComparator(filter.NewByteArrayComparable([]<span class="keyword">byte</span>(beforeMiniTimeStamps(<span class="number">2</span>*<span class="number">60</span>)))),</span><br><span class="line"><span class="literal">true</span>,</span><br><span class="line"><span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//filter 列表</span></span><br><span class="line">filters := filter.NewList(filter.MustPassAll, notRecommendFilter, violationFilter, timeStartFilter, timeEndFilter)</span><br><span class="line"><span class="comment">//创建scan对象</span></span><br><span class="line">scan, _ := hrpc.NewScanStr(context.Background(), table, family, hrpc.Filters(filters))</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> rsp []*hrpc.Result</span><br><span class="line">scanner := client.Scan(scan)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">res, err := scanner.Next()</span><br><span class="line"><span class="keyword">if</span> err == io.EOF &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">print</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> hasHeadImage(res) &#123;</span><br><span class="line">rsp = <span class="built_in">append</span>(rsp, res)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> rsp</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hasHeadImage</span><span class="params">(res *hrpc.Result)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">rsp := fetch()</span><br><span class="line"><span class="keyword">for</span> _, item := <span class="keyword">range</span> rsp &#123;</span><br><span class="line">fmt.Println(*item)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="built_in">len</span>(rsp))</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Go/">Go</category>
      
      <category domain="http://example.com/tags/Hbase/">Hbase</category>
      
      
      <comments>http://example.com/2017/11/08/go-hbase/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Ubuntu16.04 安装IKEV2 VPN 并在Mac上使用以解决Google Drive 同步问题</title>
      <link>http://example.com/2017/11/01/Google-Drive-Sync/</link>
      <guid>http://example.com/2017/11/01/Google-Drive-Sync/</guid>
      <pubDate>Wed, 01 Nov 2017 01:56:43 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15095018008987.jpg&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/15095018930547.jpg&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15095018008987.jpg"><br><img src="/images/15095018930547.jpg"></p><span id="more"></span><p>Google Drive无法识别shadowsocks所用的socks5代理，故这边有需求在VPS上部署http代理的VPN。</p><h2 id="服务端安装说明"><a href="#服务端安装说明" class="headerlink" title="服务端安装说明"></a>服务端安装说明</h2><ul><li>下载脚本:   <code>wget --no-check-certificate https://raw.githubusercontent.com/quericy/one-key-ikev2-vpn/master/one-key-ikev2.sh</code></li><li>运行脚本：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod +x one-key-ikev2.sh</span><br><span class="line">bash one-key-ikev2.sh</span><br></pre></td></tr></table></figure></li><li>等待自动配置部分内容后，选择vps类型（OpenVZ还是Xen、KVM），选错将无法成功连接，请务必核实服务器的类型。输入服务器ip或者绑定的域名(连接vpn时服务器地址将需要与此保持一致,如果是导入泛域名证书这里需要写*.域名的形式),这里推荐直接输入域名。</li><li>选择使用使用证书颁发机构签发的SSL证书还是生成自签名证书，这里我们选择自签名即选择no：‘’<ul><li>如果选择no,使用自签名证书（客户端如果使用IkeV2方式连接，将需要导入生成的证书并信任）则需要填写证书的相关信息(C,O,CN)，为空将使用默认值(default value)，确认无误后按任意键继续,后续安装过程中会出现输入两次pkcs12证书的密码的提示(可以设置为空)    </li></ul></li><li>接下来一直空格即可。</li><li>看到install Complete字样即表示安装完成。默认用户名密码将以黄字显示，可根据提示自行修改配置文件中的用户名密码,多用户则在配置文件中按格式一行一个(多用户时用户名不能使用%any),保存并重启服务生效。</li><li>将提示信息中的证书文件ca.cert.pem拷贝到客户端，修改后缀名为.cer后导入。ios设备使用Ikev1无需导入证书，而是需要在连接时输入共享密钥，共享密钥即是提示信息中的黄字PSK.<ul><li>  <img src="/images/15095022245212.jpg"><h2 id="客户端配置说明"><a href="#客户端配置说明" class="headerlink" title="客户端配置说明"></a>客户端配置说明</h2></li></ul></li><li>iOS/OSX/Windows7+/WindowsPhone8.1+/Linux 均可使用IkeV2,认证方式为用户名+密码。使用SSL证书则无需导入证书；使用自签名证书则需要先导入证书才能连接,可将ca.cert.pem更改后缀名作为邮件附件发送给客户端,手机端也可通过浏览器导入,其中:<ul><li>iOS/OSX 的远程ID和服务器地址保持一致,用户鉴定选择”用户名”.如果通过浏览器导入,将证书放在可访问的远程外链上,并在系统浏览器(Safari)中访问外链地址;</li></ul></li><li>注意OSX导入后需要在钥匙串内设置信任，如：<ul><li><img src="/images/15095023464796.png"></li></ul></li><li>设置连接成功后Google Drive就会连接成功开始同步<br>😎😎😎😎😎😎<ul><li><img src="/images/Screen%20Shot%202017-11-01%20at%2010.13.03.png" alt="Screen Shot 2017-11-01 at 10.13.03"></li></ul></li></ul><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="https://quericy.me/blog/699/">CentOS/Ubuntu一键安装IPSEC/IKEV2 VPN服务器 | Quericy Eden*</a></li><li><a href="https://github.com/quericy/one-key-ikev2-vpn/issues/58">安装完成后，mac不能连接 · Issue #58 · quericy/one-key-ikev2-vpn</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/VPN/">VPN</category>
      
      
      <comments>http://example.com/2017/11/01/Google-Drive-Sync/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Install Opencv3.2 on Ununtu 16.04</title>
      <link>http://example.com/2017/10/25/Install-Opencv3-2-on-Ununtu-16-04/</link>
      <guid>http://example.com/2017/10/25/Install-Opencv3-2-on-Ununtu-16-04/</guid>
      <pubDate>Wed, 25 Oct 2017 04:34:28 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15101928106001.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Opencv3.2 在 Ununtu 16.04 上的编译安装&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15101928106001.jpg"></p><p>Opencv3.2 在 Ununtu 16.04 上的编译安装</p><span id="more"></span><p>参考自<a href="http://blog.topspeedsnail.com/archives/4755">Ubuntu 16.04编译安装OpenCV（Python） – WTF Daily Blog</a>，不过这位博主装的是3.1版本，而且有些问题。</p><h2 id="安装OpenCV依赖"><a href="#安装OpenCV依赖" class="headerlink" title="安装OpenCV依赖"></a>安装OpenCV依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br><span class="line">sudo apt-get install build-essential cmake pkg-config</span><br><span class="line"> sudo apt-get install libjpeg8-dev libtiff5-dev libjasper-dev libpng12-dev</span><br><span class="line"> sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</span><br><span class="line"> sudo apt-get install libxvidcore-dev libx264-dev</span><br><span class="line">sudo apt-get install libgtk-3-dev</span><br><span class="line">sudo apt-get install libatlas-base-dev gfortran</span><br><span class="line">sudo apt-get install python2.7-dev python3.5-dev</span><br></pre></td></tr></table></figure><h2 id="下载OpenCV源码"><a href="#下载OpenCV源码" class="headerlink" title="下载OpenCV源码"></a>下载OpenCV源码</h2><p>这里下载 3.2.0</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~</span><br><span class="line">$ wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.2.0.zip</span><br><span class="line">$ unzip opencv.zip</span><br></pre></td></tr></table></figure><p>下载和OpenCV版本对应的opencv_contrib（一些扩展功能和non-free代码）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ wget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.2.0.zip</span><br><span class="line">$ unzip opencv_contrib.zip</span><br></pre></td></tr></table></figure><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/opencv-3.2.0/</span><br><span class="line">$ mkdir build</span><br><span class="line">$ <span class="built_in">cd</span> build</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line">    -D CMAKE_INSTALL_PREFIX=/usr/<span class="built_in">local</span> \</span><br><span class="line">    -D INSTALL_PYTHON_EXAMPLES=ON \</span><br><span class="line">    -D INSTALL_C_EXAMPLES=OFF \</span><br><span class="line">    -D OPENCV_EXTRA_MODULES_PATH=/root/Downloads/opencv_contrib-3.2.0/modules  -D PYTHON_EXECUTABLE=/root/miniconda3/bin/python  .. </span><br></pre></td></tr></table></figure><p>其中<code>OPENCV_EXTRA_MODULES_PATH</code>是opencv_contrib的解压后的地址，<code>PYTHON_EXECUTABLE</code>是# 你的python 解释器地址 可用<code>witch python</code> 查看。<br>若出现，需要下载<code>ippicv_linux_20151201.tgz</code>的长时间等待，可在此<a href="https://github.com/opencv/opencv_3rdparty/tree/ippicv/master_20151201/ippicv">opencv_3rdparty/ippicv at ippicv/master_20151201 · opencv/opencv_3rdparty</a>手动下载对应文件，并放在对应位置如Put the ippicv_linux…tgz under<br>&lt;…&gt;/opencv-3.2.0/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e/， 参考自<a href="https://github.com/opencv/opencv/issues/5973">incorrect hash in cmake ippicv when installing · Issue #5973 · opencv/opencv</a>。</p><p>编译：</p><p><code>$ make</code></p><p>安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo make install</span><br><span class="line">$ sudo ldconfig</span><br></pre></td></tr></table></figure><p>再<code>pip install opencv</code>即可😎</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/10/25/Install-Opencv3-2-on-Ununtu-16-04/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>git notes in action | 生产环境各场景下git常用命令</title>
      <link>http://example.com/2017/10/21/git-notes-in-action/</link>
      <guid>http://example.com/2017/10/21/git-notes-in-action/</guid>
      <pubDate>Sat, 21 Oct 2017 06:03:47 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15085663573989.jpg&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15085663573989.jpg"></p><span id="more"></span><ol><li>更改远程链接 <a href="https://help.github.com/articles/changing-a-remote-s-url/">Changing a remote’s URL - User Documentation</a></li><li> redo add单文件操作 <a href="http://data.agaric.com/undo-git-add-remove-files-staged-git-commit">Undo a git add - remove files staged for a git commit | Open Data</a> </li><li>移除所有已经add的文件，场景例如你刚刚add了all，才发现有许多是可以ignore的，那么就运行<code>git rm --cached -r .</code>移除也就是撤回刚刚add的所有文件，再去管理ignore，再add就好了。</li><li>revert当前文件变更，场景例如比如你上传本地的一个config上服务器调试，调试结束，需要将这个文件回滚变更，那么<code>git checkout -- &lt;file-you-want-revert&gt;</code>即可。</li></ol>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/git/">git</category>
      
      
      <comments>http://example.com/2017/10/21/git-notes-in-action/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>服务器负载GUI 神器sargraph 的安装</title>
      <link>http://example.com/2017/10/11/sargraph-install/</link>
      <guid>http://example.com/2017/10/11/sargraph-install/</guid>
      <pubDate>Wed, 11 Oct 2017 03:40:21 GMT</pubDate>
      
      <description>&lt;p&gt;通过Linux 的&lt;code&gt;sar&lt;/code&gt;命令可以很容易知道服务器的负载，那么如何通过网页等更好地可视化呢？本文介绍实现此功能的神器&lt;a href=&quot;http://www.sargraph.com/sargraph/chart.php?id=dbserv&quot;&gt;SARGRAPH-Graphical front-end for sar&lt;/a&gt;的使用及安装。&lt;/p&gt;
&lt;h2 id=&quot;sar的配置&quot;&gt;&lt;a href=&quot;#sar的配置&quot; class=&quot;headerlink&quot; title=&quot;sar的配置&quot;&gt;&lt;/a&gt;sar的配置&lt;/h2&gt;&lt;p&gt;通过这里我们可以看到&lt;br&gt;&lt;a href=&quot;http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/sar.html&quot;&gt;sar 找出系统瓶颈的利器 — Linux Tools Quick Tutorial&lt;/a&gt;&lt;br&gt;安装sar&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;有的linux系统下，默认可能没有安装这个包，使用apt-get install sysstat 来安装；&lt;/li&gt;
&lt;li&gt;安装完毕，将性能收集工具的开关打开： vi /etc/default/sysstat&lt;/li&gt;
&lt;li&gt;设置 ENABLED=”true”&lt;/li&gt;
&lt;li&gt;启动这个工具来收集系统性能数据： /etc/init.d/sysstat start&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>通过Linux 的<code>sar</code>命令可以很容易知道服务器的负载，那么如何通过网页等更好地可视化呢？本文介绍实现此功能的神器<a href="http://www.sargraph.com/sargraph/chart.php?id=dbserv">SARGRAPH-Graphical front-end for sar</a>的使用及安装。</p><h2 id="sar的配置"><a href="#sar的配置" class="headerlink" title="sar的配置"></a>sar的配置</h2><p>通过这里我们可以看到<br><a href="http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/sar.html">sar 找出系统瓶颈的利器 — Linux Tools Quick Tutorial</a><br>安装sar</p><blockquote><ol><li>有的linux系统下，默认可能没有安装这个包，使用apt-get install sysstat 来安装；</li><li>安装完毕，将性能收集工具的开关打开： vi /etc/default/sysstat</li><li>设置 ENABLED=”true”</li><li>启动这个工具来收集系统性能数据： /etc/init.d/sysstat start</li></ol></blockquote><span id="more"></span><p>可使用命令<code>vi /etc/cron.d/sysstat</code>调整报告频率，例如下面就将默认的十分钟修改为隔两分钟报告一次。<br><img src="/images/Screen%20Shot%202017-10-12%20at%2017.23.55.png" alt="Screen Shot 2017-10-12 at 17.23.55"></p><h2 id="sargraph-的安装"><a href="#sargraph-的安装" class="headerlink" title="sargraph 的安装"></a>sargraph 的安装</h2><h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><p>根据<a href="http://sargraph.com/index.php?option=com_content&view=article&id=48&Itemid=13">Documentation</a>，<br><img src="/images/Screen%20Shot%202017-10-11%20at%2011.52.07-1.png" alt="Screen Shot 2017-10-11 at 11.52.07"></p><ul><li>安装php</li></ul><p><code>sudo apt-get install php libapache2-mod-php</code></p><ul><li> 安装apache2 </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install apache2</span><br></pre></td></tr></table></figure><h2 id="配置apache2"><a href="#配置apache2" class="headerlink" title="配置apache2"></a>配置apache2</h2><p><code>systemctl status apache2</code>查看apache2的情况，若发现其不是active，可能是由于与nginx监听默认端口冲突，那么需要在<code>vim /etc/apache2/ports.conf</code>，把80修改为81即可。<br><img src="/images/Screen%20Shot%202017-10-11%20at%2011.57.39.png" alt="Screen Shot 2017-10-11 at 11.57.39"><br>再‘service apache2 restart’，查看<code>systemctl status apache2</code>为active即成功，</p><p><img src="/images/Screen%20Shot%202017-10-11%20at%2011.55.59.png" alt="Screen Shot 2017-10-11 at 11.55.59"></p><h2 id="sargraph安装及配置"><a href="#sargraph安装及配置" class="headerlink" title="sargraph安装及配置"></a>sargraph安装及配置</h2><p>参考<a href="http://www.sargraph.com/index.php?option=com_content&view=article&id=47&Itemid=14">Download Sargraph</a>安装即可，</p><blockquote><p>Download sargraph_version3.tgz to /tmp. Unzip and untar it. And run the INSTALLER</p></blockquote><blockquote><p>tar xzf sargraph_version3.tgz</p></blockquote><blockquote><p>cd sargraph_version3</p></blockquote><blockquote><p> ./INSTALLER</p></blockquote><p>注意需要修改其config，<code>vim /etc/sargraph.conf</code>，</p><p><img src="/images/Screen%20Shot%202017-10-11%20at%2012.00.55.png" alt="Screen Shot 2017-10-11 at 12.00.55"></p><p>注意是SARUSER修改为需要监听的服务器的用户名，KEY修改为sargraph服务器当前用户公钥文件即可。</p><h3 id="添加server"><a href="#添加server" class="headerlink" title="添加server"></a>添加server</h3><p>使用<code>/var/www/html/sargraph/scripts/addserver datalab</code>添加server，比如之前我们把config里user改为root，那么这里我们添加的server就是<code>root@datalab</code>，再可用<code>/var/www/html/sargraph/scripts</code>里的脚本添加删除用户修改密码等等。</p><p>最后在如<a href="http://datalab:81/sargraph/">Sargraph Login</a>访问即可，负载等信息可视化出现！<img src="/images/Screen%20Shot%202017-10-11%20at%2012.05.12.png" alt="Screen Shot 2017-10-11 at 12.05.12"></p><p>😎</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/10/11/sargraph-install/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>避免 spark 提交 上传自带 jar包解决办法</title>
      <link>http://example.com/2017/09/01/spark-submit-avoid-upload-jars/</link>
      <guid>http://example.com/2017/09/01/spark-submit-avoid-upload-jars/</guid>
      <pubDate>Fri, 01 Sep 2017 08:15:04 GMT</pubDate>
      
        
        
      <description>&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">17/09/01 15:38:59 INFO yarn.Client: Uploading resource file:/usr/<span class="built_in">local</span>/spark-2.1.1-bin-without-hadoop/spark-46d1bd70-b346-4027-bce4-9540f4b6035a/__spark_libs__4051900056689219834.zip -&gt; hdfs://wwj.shise.com:9000/user/hadoop/.sparkStaging/application_1504148698505_0021/__spark_libs__4051900056689219834.zip</span><br><span class="line">17/09/01 15:41:45 INFO yarn.Client: Uploading resource file:/Users/frank/IdeaProjects/simpleApp/target/scala-2.11/simpleApp-assembly-1.0.jar -&gt; hdfs://wwj.shise.com:9000/user/hadoop/.sparkStaging/application_1504148698505_0021/simpleApp-assembly-1.0.jar</span><br></pre></td></tr></table></figure><p>可以看到，上传花费约3分钟，这段时间是为了将$SPARK_HOME/jar下的所有jar包上传到yarn，实际上可以完全避免。<br><img src="/images/Screen%20Shot%202017-09-01%20at%2016.16.35.png" alt="Screen Shot 2017-09-01 at 16.16.35"></p><p>实际上这部分文件完全可以就放在hdfs上，<br><img src="/images/Screen%20Shot%202017-09-01%20at%2016.21.32.png" alt="Screen Shot 2017-09-01 at 16.21.32"></p><p>先将这部分jar包复制到hdfs：<br>hadoop fs -mkdir /tmp/spark/lib_jars/<br>hadoop fs -put  $SPARK_HOME/jars/* /tmp/spark/lib_jars/</p><p>设置<code>vim $SPARK_HOME/conf/spark-defaults.conf</code>：<br>添加这行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.jars                  /tmp/spark/lib_jars/* <span class="comment">##这里用hdfs相对路径即可</span></span><br></pre></td></tr></table></figure><p>再submit不会出现将jar文件打包成zip文件上传的信息了。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/spark/">spark</category>
      
      
      <comments>http://example.com/2017/09/01/spark-submit-avoid-upload-jars/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>hbase rest 绑定到内网localhost</title>
      <link>http://example.com/2017/08/29/hbase-rest-bindAddress-to-localhost/</link>
      <guid>http://example.com/2017/08/29/hbase-rest-bindAddress-to-localhost/</guid>
      <pubDate>Tue, 29 Aug 2017 08:34:08 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;通过开启Hbase 的REST 服务我们可以很方便的以API的形式访问Hbase，&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/spa</description>
        
      
      
      
      <content:encoded><![CDATA[<p>通过开启Hbase 的REST 服务我们可以很方便的以API的形式访问Hbase，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Foreground</span></span><br><span class="line">$ bin/hbase rest start -p &lt;port&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Background, logging to a file in $HBASE_LOGS_DIR</span></span><br><span class="line">$ bin/hbase-daemon.sh start rest -p &lt;port&gt;</span><br></pre></td></tr></table></figure><p>但是其默认是绑定<code>0.0.0.0</code>地址的，也就是对外网开放，而通过REST 服务别有用心的人是可以删表的。。。如何只对内网开放呢？</p><p>查了无数中英文网页不得，最后决定：看源码！最后在这里发现如下片段，<a href="https://github.com/apache/hbase/blob/master/hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java">hbase/RESTServer.java at master · apache/hbase</a><br><img src="/images/Screen%20Shot%202017-08-29%20at%2016.30.16.png" alt="Screen Shot 2017-08-29 at 16.30.16"><br>那么解决方法就显而易见了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sudo vim /usr/local/hbase/conf/hbase-site.xml</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">         &lt;name&gt;hbase.rest.host&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;127.0.0.1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Hbase/">Hbase</category>
      
      
      <comments>http://example.com/2017/08/29/hbase-rest-bindAddress-to-localhost/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>scala-notes</title>
      <link>http://example.com/2017/08/22/scala-note/</link>
      <guid>http://example.com/2017/08/22/scala-note/</guid>
      <pubDate>Tue, 22 Aug 2017 03:06:48 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;call-by-name-与-call-by-value的区别&quot;&gt;&lt;a href=&quot;#call-by-name-与-call-by-value的区别&quot; class=&quot;headerlink&quot; title=&quot;call by name 与 call by value的区</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="call-by-name-与-call-by-value的区别"><a href="#call-by-name-与-call-by-value的区别" class="headerlink" title="call by name 与 call by value的区别"></a>call by name 与 call by value的区别</h2><p>两者的区别就是调用之前需不需要evaluation，前者不需要，后者需要。例如一个函数$f(x, y) = x$，我们分别调用$f(1+1, 2 )$，call by name 直接引用1+1，再计算出为2，而 call by value是先算出函数参数的值，再去调用$f(2, 2 )$，scala默认是call by value，但是可以在需要call by name 的参数加箭头如<code>=&gt;</code>。</p><p>scala里面定义变量<code>def</code>和<code>val</code>的区别即在此，前者是call by name，例如我们分别定义两个函数：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span></span>: <span class="type">Boolean</span> = loop</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">x</span> </span>= loop</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> y = loop</span><br></pre></td></tr></table></figure><p>函数x可以被成功定义，而后者不行，因为在call by name 的参数evaluation的时候就进入死循环了。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/scala/">scala</category>
      
      
      <comments>http://example.com/2017/08/22/scala-note/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>详解Coursera 奖学金申请步骤</title>
      <link>http://example.com/2017/08/21/coursera-scholarship/</link>
      <guid>http://example.com/2017/08/21/coursera-scholarship/</guid>
      <pubDate>Mon, 21 Aug 2017 04:06:29 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/15046037829976.jpg&quot;&gt;&lt;br&gt;最新Coursera 奖学金申请步骤！成功率100%🏆&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/15046037829976.jpg"><br>最新Coursera 奖学金申请步骤！成功率100%🏆</p><span id="more"></span><p>以这门<a href="https://www.coursera.org/learn/progfun1">Scala 函数式程序设计原理 | Coursera</a>为例：</p><p><img src="/images/Screen%20Shot%202017-08-21%20at%2012.09.20.png" alt="Screen Shot 2017-08-21 at 12.09.20"><br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.16.21.png" alt="Screen Shot 2017-08-21 at 12.16.21"><br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.17.47.png" alt="Screen Shot 2017-08-21 at 12.17.47"><br>以下问题必须填写英文，必须大于等于150字，从我的申请记录来看，基本不会审核你究竟填写了什么，这只是为免费用户设置一个门槛，吸引你氪金😂😎<br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.19.16.png" alt="Screen Shot 2017-08-21 at 12.19.16"><br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.19.26.png" alt="Screen Shot 2017-08-21 at 12.19.26"><br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.19.30.png" alt="Screen Shot 2017-08-21 at 12.19.30"></p><p>之前是立即可以获得证书，现在需要等待十五天即可。<br><img src="/images/Screen%20Shot%202017-08-21%20at%2012.20.21.png" alt="Screen Shot 2017-08-21 at 12.20.21"></p><p>关于上面的三个问题回复提供一模板：</p><blockquote><p>I am a graduate student in mainland China, was born in a peasant family, the family has four people, my father, my mother, my brother and I, we four and grandparents living in the same home. Mom and Dad did not work, can only rely on two acres of the family to be barely subsistence income is very meager, good for my brother and I can learn, the family live frugally money supply year my brother and I go to school Reading used. The family also owe a lot of money, so my brother and I grew to know two people not to spend money.</p></blockquote><blockquote><p>Dad, Mom no cultural knowledge, they know the importance of knowledge, so small they are strict requirements of our brothers and both learn to be good in the future to test a good university, find a good job, do not like them, did not work in the countryside. We two brothers are also very competitive, it has been among the best in school, in our view, only with honors in order to make my parents happy, to return to their pains. Monthly income of around one hundred US dollars to pay tuition for this course certificate will be spent half of my cost of living, it will bring a lot of economic pressure to my normal life, and this course is the first door I finished on the site class, have a special meaning for me, I wanted to get this certificate course, this will inspire my passion for learning and motivation.</p></blockquote><blockquote></blockquote><blockquote><p>1, many people have recommended this course for the learning experience to enhance learning method above, I think learning is a lifelong, this course I will gain the knowledge of my lifetime. All the copyright.</p></blockquote><blockquote><p>This door exercise logic and thinking about Coursera course is one of the most popular courses, course descriptions and practical reasoning methods and common logical fallacies, teach you how to properly reasoning, learning a few simple but critical general rules apply to all topics, while avoiding prone to problems when reasoning. 2, almost all individuals can enhance the quality of life of the curriculum to enhance areas of interest I have, I will continue to follow up. 3. Harvest course certificate for me is a recognition of my pay, my motivation for future learning enhance the effect is self-evident, thank you!</p></blockquote><blockquote></blockquote><blockquote><p>1, I guarantee independence to complete a full course, to ensure that all academic tasks independently myself by myself.</p></blockquote><blockquote><p>2, actively participate in discussions and course work, upload your own achievement, strive to contribute their efforts for curriculum community.</p></blockquote><blockquote><p>3, actively publicize the site to friends and relatives, for future expansion of community development programs and make a contribution.</p></blockquote><blockquote><p>4, to participate in and complete the course more sites to learn more new knowledge.</p></blockquote>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Coursera/">Coursera</category>
      
      
      <comments>http://example.com/2017/08/21/coursera-scholarship/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>server certificate verification failed solution</title>
      <link>http://example.com/2017/08/15/server-certificate-verification-failed-solution/</link>
      <guid>http://example.com/2017/08/15/server-certificate-verification-failed-solution/</guid>
      <pubDate>Tue, 15 Aug 2017 10:23:03 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none 的正确解决方法。&lt;/p&gt;
&lt;p&gt;出现此错误时，问题出在证书的缺失，不可用如&lt;co</description>
        
      
      
      
      <content:encoded><![CDATA[<p>server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none 的正确解决方法。</p><p>出现此错误时，问题出在证书的缺失，不可用如<code>export GIT_SSL_NO_VERIFY=1</code>方法去解除安全限制，正确方法是下载证书，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hostname=XXX</span><br><span class="line">port=443</span><br><span class="line">trust_cert_file_location=`curl-config --ca`</span><br><span class="line">sudo bash -c <span class="string">&quot;echo -n | openssl s_client -showcerts -connect <span class="variable">$hostname</span>:<span class="variable">$port</span> 2&gt;/dev/null  | sed -ne &#x27;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#x27; &gt;&gt; <span class="variable">$trust_cert_file_location</span>&quot;</span></span><br></pre></td></tr></table></figure><p>若不起作用，可用IP代替真实hostname。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/08/15/server-certificate-verification-failed-solution/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>nginx 反向代理 REST API</title>
      <link>http://example.com/2017/08/04/nginx-reverse-proxy-for-rest-API/</link>
      <guid>http://example.com/2017/08/04/nginx-reverse-proxy-for-rest-API/</guid>
      <pubDate>Fri, 04 Aug 2017 08:31:16 GMT</pubDate>
      
      <description>&lt;p&gt;利用nginx 为REST API提供负载均衡。利用nginx的负载均衡可以极大提升API服务的稳定性，本文简述此过程配置方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>利用nginx 为REST API提供负载均衡。利用nginx的负载均衡可以极大提升API服务的稳定性，本文简述此过程配置方法。</p><span id="more"></span><p><code>sudo apt install nginx</code>安装nginx，接下来找出nginx配置地址，使用代码<code>nginx -V </code>可打印出一系列配置信息，不同平台和发行版可能不同，我这边是<code>--prefix=/usr/share/nginx</code>，即为nginx根目录，<code>--conf-path=/etc/nginx/nginx.conf</code>即为配置目录。</p><p><code>vim /etc/nginx/nginx.conf</code><br>注意其中的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">61         include /etc/nginx/conf.d/*.conf;</span><br><span class="line">62         include /etc/nginx/sites-enabled/*;</span><br></pre></td></tr></table></figure><p>在<code>/etc/nginx/conf.d/</code>新建<code>service.conf</code>，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">upstream tornadoes &#123;</span><br><span class="line">    server 127.0.0.1:6001;</span><br><span class="line">    server 127.0.0.1:6002;</span><br><span class="line">    server 127.0.0.1:6003;</span><br><span class="line">    server 127.0.0.1:6004;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">listen 5000;</span><br><span class="line">    ## Individual nginx logs</span><br><span class="line">    access_log  /var/log/nginx/web_proxy_access.log;</span><br><span class="line">    error_log   /var/log/nginx/web_proxy_error.log;</span><br><span class="line">    location / &#123;</span><br><span class="line">proxy_pass http://tornadoes; ## 和upstream 名称组对应即可</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们将本地的5000端口负载均衡到四个REST Tornado服务上。<br><code>service nginx restart</code>即可。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/%E8%BF%90%E7%BB%B4/">运维</category>
      
      <category domain="http://example.com/tags/nginx/">nginx</category>
      
      
      <comments>http://example.com/2017/08/04/nginx-reverse-proxy-for-rest-API/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Personal Tips on Mac &amp; Linux &amp; Iphone</title>
      <link>http://example.com/2017/07/18/All_kinds_of_TIPS/</link>
      <guid>http://example.com/2017/07/18/All_kinds_of_TIPS/</guid>
      <pubDate>Tue, 18 Jul 2017 02:43:17 GMT</pubDate>
      
      <description>&lt;p&gt;随手记录自己在用Mac开发上随时发现的各种Tips。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>随手记录自己在用Mac开发上随时发现的各种Tips。</p><span id="more"></span><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><h3 id="别用Bash啦用zsh！🈲"><a href="#别用Bash啦用zsh！🈲" class="headerlink" title="别用Bash啦用zsh！🈲"></a>别用Bash啦用zsh！🈲</h3><p>zsh的自动补全功能各种神奇，可以补齐路径，补齐命令，补齐参数等，再也不用<a href="https://zh.wikipedia.org/zh/RTFM">RTFM</a>了。按下连按Tap还有二级菜单。<br><img src="/images/Screen%20Shot%202017-07-19%20at%2023.44.06.png" alt="Screen Shot 2017-07-19 at 23.44.06"><br><img src="/images/Screen%20Shot%202017-07-19%20at%2023.42.56.png" alt="Screen Shot 2017-07-19 at 23.42.56"></p><p>kill命令不需<code>ps aux | grep xxx</code>，只需<code>kill xxx</code>然后tap即可，如，这里我需要kill jupyter notebook只需要<code>kill python</code>再tap，非常方便。</p><p><img src="/images/Screen%20Shot%202017-07-19%20at%2023.47.58.png" alt="Screen Shot 2017-07-19 at 23.47.58"></p><p>跳转时，只需<code>..</code>即可不需<code>cd</code>，而<code>...</code>等于<code>../../</code>。</p><p>输入d，将列出当前 session 访问过的所有目录，再按提示的数字即可进入相应目录。</p><p><img src="/images/Screen%20Shot%202017-07-19%20at%2023.52.08.png" alt="Screen Shot 2017-07-19 at 23.52.08"></p><p>查找：zsh 的历史记录跨 session，可以共享。历史记录支持受限查找。比如，输入git，再按向上箭头，会搜索用过的所有 git 命令。搭配<a href="https://github.com/robbyrussell/oh-my-zsh">oh-my-zsh</a>更佳哦😎</p><h2 id="工具篇"><a href="#工具篇" class="headerlink" title="工具篇"></a>工具篇</h2><h3 id="MWeb-目前体验最好的markdown编辑器"><a href="#MWeb-目前体验最好的markdown编辑器" class="headerlink" title="MWeb 目前体验最好的markdown编辑器"></a>MWeb 目前体验最好的markdown编辑器</h3><p><a href="http://zh.mweb.im/">MWeb - 专业的Markdown写作、记笔记、静态博客生成软件 - MWeb</a>，各种markdown编辑器都用过，什么Mou、Macdown等等，都是远不如这个MWeb的。个人最喜欢图片拖入功能，在此处设置好后<br><img src="/images/Screen%20Shot%202017-07-19%20at%2023.58.33.png" alt="Screen Shot 2017-07-19 at 23.58.33"></p><p>之间拖入图片，即可自动写入路径并实时预览（我用的hexo搭的博客）😘<strong>杀手级功能，效率神器！</strong>，除此之外其他的功能也是各种方便，这只需要￥98，还在等什么，赶快行动吧！<br><img src="/images/Screen%20Shot%202017-07-20%20at%2000.00.06.png" alt="Screen Shot 2017-07-20 at 00.00.06"></p><h3 id="Transserra"><a href="#Transserra" class="headerlink" title="Transserra"></a>Transserra</h3><p>iOS App，可以离线下载Coursera课程，杀手功能：<strong>翻译字幕！！！</strong>，看公开课实在是太方便啦！不过需要注意，不要在还有下载任务的时候开启cellular（蜂窝网络）下使用，本人就是这样在月初被烧完了整个月的流量！！！👻， 翻译功能需要付费，不过不贵。<br><img src="/images/IMG_1750.png" alt="IMG_1750"></p><h3 id="Iterm2"><a href="#Iterm2" class="headerlink" title="Iterm2"></a>Iterm2</h3><p><a href="https://www.iterm2.com/">iTerm2 - macOS Terminal Replacement</a>是一款Mac上体验极佳的终端软件，拥有许多出色特性，如拖动字符串、多Tap广播输入等等<img src="/images/Screen%20Shot%202017-08-10%20at%2012.49.06.png" alt="Screen Shot 2017-08-10 at 12.49.06"><br>按住⌘键:</p><ul><li>可以拖拽选中的字符串；</li><li>点击 url：调用默认浏览器访问该网址；</li><li>点击文件：调用默认程序打开文件；</li><li>如果文件名是filename:42，且默认文本编辑器是 Macvim、Textmate或BBEdit，将会直接打开到这一行；</li><li>点击文件夹：在 finder 中打开该文件夹；</li><li>同时按住option键，可以以矩形选中，类似于vim中的ctrl v操作。</li></ul><p>常用快捷键</p><ul><li>切换 tab：⌘+←, ⌘+→, ⌘+{, ⌘+}。⌘+数字直接定位到该 tab；</li><li>新建 tab：⌘+t；</li><li>顺序切换 pane：⌘+[, ⌘+]；</li><li>按方向切换 pane：⌘+Option+方向键；</li><li>切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分；</li><li>智能查找，支持正则查找：⌘+f。</li></ul><p>iTerm2 可以自动补齐命令，输入若干字符，按⌘+;弹出自动补齐窗口，列出曾经使用过的命令。iTerm2 也可以使用历史记录，按⌘+Shift+h弹出历史粘贴记录窗口，<br><img src="/images/Screen%20Shot%202017-08-21%20at%2011.29.29.png" alt="Screen Shot 2017-08-21 at 11.29.29"></p><p>⌘+Shift+;弹出历史命令记录窗口。⌘+Option+e全屏展示所有的 tab，可以搜索。<br>一个标签页中开的窗口太多，有时候会找不到当前的鼠标，⌘+/找到它。</p><p><a href="http://iterm2colorschemes.com/">这里</a>收集了大量 iTerm2 的主题，你可以选择使用。我用的是Zenburn。在其 github repo 里下载对应的xxx.itermcolors文件，双击安装使用。<br><img src="/images/15023408306576.jpg"></p><p>更新：</p><ul><li>取消鼠标滚轮浏览历史记录的设置：<a href="https://gxnotes.com/article/48116.html">如何关闭iTerm2中的“scrolling the history” - 共享笔记</a></li></ul><h3 id="Mosh"><a href="#Mosh" class="headerlink" title="Mosh"></a>Mosh</h3><p> 替代SSH的<a href="https://mosh.org/">Mosh: the mobile shell</a>，极大降低ssh延迟，并且持续时间极佳。<br> <img src="/images/15023407365562.jpg"></p><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><h3 id="表情符号"><a href="#表情符号" class="headerlink" title="表情符号"></a>表情符号</h3><p>按 Control-Command-空格键。此时会显示“字符显示程序”弹出窗口：<br><img src="/images/15004806123652.jpg"></p><h3 id="Linux-终端快速清行"><a href="#Linux-终端快速清行" class="headerlink" title="Linux 终端快速清行"></a>Linux 终端快速清行</h3><p>有时候我们在终端里打出了一个很长很长的命令，这时候我们需要清空重新输入，有个快捷键就是ctr+p，即可快速清除当前输入。</p><h3 id="Linux-切到上一个目录"><a href="#Linux-切到上一个目录" class="headerlink" title="Linux 切到上一个目录"></a>Linux 切到上一个目录</h3><p><code>cd -</code>即可：<br><img src="/images/Screen%20Shot%202017-07-21%20at%2011.24.53.png" alt="Screen Shot 2017-07-21 at 11.24.53"></p><h3 id="截图"><a href="#截图" class="headerlink" title="截图"></a>截图</h3><ul><li>Command(⌘)-Shift-3 对整个屏幕拍摄屏幕快照</li><li>Command(⌘)-Shift-4 对屏幕的某个部分拍摄屏幕快照，可以选择截图区域</li><li>Command(⌘)-Shift-4-空格键 对某个窗口拍摄屏幕快照</li><li>Command(⌘)-Ctrl-Shift-4 对选定区域进行截屏，屏幕截图，文件保存在剪贴板</li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Mac/">Mac</category>
      
      
      <comments>http://example.com/2017/07/18/All_kinds_of_TIPS/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive install on Ubuntu，并以Mysql作为Metastore</title>
      <link>http://example.com/2017/07/07/Hive-install-on-Ubuntu/</link>
      <guid>http://example.com/2017/07/07/Hive-install-on-Ubuntu/</guid>
      <pubDate>Fri, 07 Jul 2017 02:43:17 GMT</pubDate>
      
      <description>&lt;p&gt;安装配置Hive虽然比较简单，但是网上的资料各种坑，总结下来写下本文作为成功后的记录。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>安装配置Hive虽然比较简单，但是网上的资料各种坑，总结下来写下本文作为成功后的记录。</p><span id="more"></span><h2 id="下载与放置"><a href="#下载与放置" class="headerlink" title="下载与放置"></a>下载与放置</h2><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><p><a href="http://www.apache.org/dyn/closer.cgi/hive/">Hive下载地址</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo tar xzvf apache-hive-2.1.1-bin.tar.gz -C /usr/<span class="built_in">local</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /usr/<span class="built_in">local</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mv apache-hive-2.1.1-bin/ hive</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo chown hadoop@hadoop -R hive</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> </span></span><br></pre></td></tr></table></figure><h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><p><code>$ sudo apt-get install mysql-server</code></p><h3 id="mysql-Java连接"><a href="#mysql-Java连接" class="headerlink" title="mysql Java连接"></a>mysql Java连接</h3><p><code>$ sudo apt-get install libmysql-java</code><br>并创建软连接<br><code>$ ln -s /usr/share/java/mysql-connector-java.jar $HIVE_HOME/lib/mysql-connector-java.jar</code></p><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>在<code>~/.profile</code>里添加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><p>并<code>source ~/.profile</code></p><h2 id="建表与连接"><a href="#建表与连接" class="headerlink" title="建表与连接"></a>建表与连接</h2><h3 id="初始表格"><a href="#初始表格" class="headerlink" title="初始表格"></a>初始表格</h3><p>在mysql里创建数据库，格式同<code>hive-schema-2.1.0.mysql.sql</code> ，这里依据你的版本号来</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mysql <span class="operator">-</span>u root <span class="operator">-</span>p</span><br><span class="line">Enter password:</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> DATABASE metastore;</span><br><span class="line">mysql<span class="operator">&gt;</span> USE metastore;</span><br><span class="line">mysql<span class="operator">&gt;</span> SOURCE <span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>hive<span class="operator">/</span>scripts<span class="operator">/</span>metastore<span class="operator">/</span>upgrade<span class="operator">/</span>mysql<span class="operator">/</span>hive<span class="operator">-</span>schema<span class="number">-2.1</span><span class="number">.0</span>.mysql.sql;;</span><br></pre></td></tr></table></figure><h3 id="创建用户并给予权限"><a href="#创建用户并给予权限" class="headerlink" title="创建用户并给予权限"></a>创建用户并给予权限</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;hiveuser&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;hivepassword&#x27;</span>; </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">all</span> <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">&#x27;hiveuser&#x27;</span><span class="variable">@localhost</span> identified <span class="keyword">by</span> <span class="string">&#x27;hivepassword&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span>  flush privileges;</span><br></pre></td></tr></table></figure><h3 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h3><p>在<code>$HIVE_HOME/conf</code>文件夹创建<code>hive-site.xml</code>文件，配置如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">description</span>&gt;</span>metadata is stored in a MySQL server<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">description</span>&gt;</span>MySQL JDBC driver class<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hiveuser<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">description</span>&gt;</span>user name for connecting to mysql server<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hivepassword<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">description</span>&gt;</span>password for connecting to mysql server<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="OK，启动Hive-Shell试试看吧"><a href="#OK，启动Hive-Shell试试看吧" class="headerlink" title="OK，启动Hive Shell试试看吧"></a>OK，启动Hive Shell试试看吧</h3><p>测试一下，在hive shell里建表<br><code>hive&gt; create table saurzcode(id int, name string);</code></p><p>再在mysql里查看</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql <span class="operator">-</span>u root <span class="operator">-</span>p</span><br><span class="line">Enter password:                                                             </span><br><span class="line">mysql<span class="operator">&gt;</span> use metastore;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> tables ;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> TBLS;</span><br></pre></td></tr></table></figure><p>若可以看见上面在hive里建的表<code>saurzcode</code>，恭喜你大功告成！😆😎🤠</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/Hive/">Hive</category>
      
      <category domain="http://example.com/tags/Hadoop/">Hadoop</category>
      
      
      <comments>http://example.com/2017/07/07/Hive-install-on-Ubuntu/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ssh 建立本地localhost与远程服务器localhost的连接</title>
      <link>http://example.com/2017/07/06/ssh-web-tunnel/</link>
      <guid>http://example.com/2017/07/06/ssh-web-tunnel/</guid>
      <pubDate>Thu, 06 Jul 2017 06:23:29 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;远程连接服务器开发时，经常需要连接到服务器的localhost的web界面查看，如深度学习服务器的jupyter notebook、服务器上的hadoop的hdfs和yarn以及spark的web界面，还有Supervisor等等，很多时候服务器都没有图形界面，很多时候用服</description>
        
      
      
      
      <content:encoded><![CDATA[<p>远程连接服务器开发时，经常需要连接到服务器的localhost的web界面查看，如深度学习服务器的jupyter notebook、服务器上的hadoop的hdfs和yarn以及spark的web界面，还有Supervisor等等，很多时候服务器都没有图形界面，很多时候用服务器IP在本地查看又因为防火墙的原因被阻挡，那么这里有一个很简单的方法即可达到目的：即<strong>从本地建立一个ssh通道</strong>，如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh username@address_of_remote -L 127.0.0.1:1234:127.0.0.1:8888</span><br></pre></td></tr></table></figure><p>即可在本地的1234端口访问远程服务器的<code>127.0.0.1:8888</code>地址了！</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/07/06/ssh-web-tunnel/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>使用supervisor支持Python3程序</title>
      <link>http://example.com/2017/07/06/Use-supervisor-support-Python3-program/</link>
      <guid>http://example.com/2017/07/06/Use-supervisor-support-Python3-program/</guid>
      <pubDate>Thu, 06 Jul 2017 03:23:07 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;a href=&quot;http://supervisord.org/index.html&quot;&gt;Supervisor&lt;/a&gt;是python2写就的一款强大的运维工具，众所周知，&lt;br&gt;目前Supervisor还不支持python3，那么怎么利用Supervisor监控python3程序呢？本文主要讲述Supervisor在&lt;br&gt;Ubuntu下的安装部署以及上述问题的解决。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><a href="http://supervisord.org/index.html">Supervisor</a>是python2写就的一款强大的运维工具，众所周知，<br>目前Supervisor还不支持python3，那么怎么利用Supervisor监控python3程序呢？本文主要讲述Supervisor在<br>Ubuntu下的安装部署以及上述问题的解决。</p><span id="more"></span><h2 id="安装及设置"><a href="#安装及设置" class="headerlink" title="安装及设置"></a>安装及设置</h2><p>可通过pip安装，如果你已经是python3的pip，会安装失败，那么可以用<code>sudo apt-get install supervisor</code>来安装，默认由Ubuntu自带的<code> /usr/bin/python2.7</code>驱动。</p><p>运行<code>echo_supervisord_conf  &gt; /etc/supervisor/supervisord.conf</code>来产生设置，未避免产生非root用户的权限错误，将<code>/etc/supervisor/supervisord.conf</code>内<code>[unix_http_server]</code>这项改为（<code>;</code>即是注释）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[unix_http_server]</span><br><span class="line">file=/tmp/supervisor.sock   ; (the path to the socket file)</span><br><span class="line">chmod=0766                 ; socket file mode (default 0700)</span><br><span class="line">;chown=nobody:nogroup       ; socket file uid:gid owner</span><br><span class="line">;username=user              ; (default is no username (open server))</span><br><span class="line">;password=123               ; (default is no password (open server))</span><br></pre></td></tr></table></figure><p>再将末尾的<code>[include]</code>部分改为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[include]</span><br><span class="line">files = /etc/supervisor/*.conf</span><br><span class="line">files = /etc/supervisor/conf.d/*.conf</span><br></pre></td></tr></table></figure><p>这样方便为每个app单独设置conf文件而不必全部写在全局设置里面。<br> <a href="https://stackoverflow.com/questions/18859063/supervisor-socket-error-issue">在启动<code>supervisorctl</code>须先启动<code>supervisord</code></a>，否则会出现<code>error: &lt;class &#39;socket.error&#39;&gt;, [Errno 99] Cannot assign requested address: file: /usr/lib/python2.7/socket.py line: 575</code>错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo supervisord -c /etc/supervisor/supervisord.conf</span><br><span class="line">sudo supervisorctl -c /etc/supervisor/supervisord.conf</span><br></pre></td></tr></table></figure><p>在<code>/etc/supervisor/conf.d/</code>里新建<code>app.conf</code>文件，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[program:app]</span><br><span class="line">directory = ~/su/ ; 程序的启动目录</span><br><span class="line"><span class="built_in">command</span> = /home/hadoop/anaconda3/bin/python /home/hadoop/su/app.py  ; 启动命令，可以看出与手动在命令行启动的命令是一样的，注意这里home不可用~代替</span><br><span class="line">autostart = <span class="literal">true</span>     ; 在 supervisord 启动的时候也自动启动</span><br><span class="line">startsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了</span><br><span class="line">autorestart = <span class="literal">true</span>   ; 程序异常退出后自动重启</span><br><span class="line">startretries = 3     ; 启动失败自动重试次数，默认是 3</span><br><span class="line">user = hadoop          ; 用哪个用户启动</span><br><span class="line">redirect_stderr = <span class="literal">true</span>  ; 把 stderr 重定向到 stdout，默认 <span class="literal">false</span></span><br><span class="line">stdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB</span><br><span class="line">stdout_logfile_backups = 20     ; stdout 日志文件备份数</span><br><span class="line">; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）</span><br><span class="line">stdout_logfile = /tmp/app.log</span><br></pre></td></tr></table></figure><p>再介绍两个有用的配置项<code>stopasgroup</code>和<code>killasgroup</code>，如果我们用Flask等Rest服务，通常其会开启几个进程，那么如果<code>stopasgroup</code>不启用的话，supervisor无法重启此服务（关闭主进程时其子进程没有关闭，再开启主进程时会提示端口被占用等错误信息）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">; 默认为 false，如果设置为 true，当进程收到 stop 信号时，会自动将该信号发给该进程的子进程。如果这个配置项为 true，那么也隐含 killasgroup 为 true。例如在 Debug 模式使用 Flask 时，Flask 不会将接收到的 stop 信号也传递给它的子进程，因此就需要设置这个配置项。</span><br><span class="line">stopasgroup=false             ; send stop signal to the UNIX process </span><br><span class="line">; 默认为 false，如果设置为 true，当进程收到 kill 信号时，会自动将该信号发给该进程的子进程。如果这个程序使用了 python 的 multiprocessing 时，就能自动停止它的子线程。</span><br><span class="line">killasgroup=false             ; SIGKILL the UNIX process group (def false)</span><br></pre></td></tr></table></figure><p>这里我们可以看出，虽然supervisor是python2写的，但只要我们指定运行的python3解释器去运行程序就行了。</p><p>运行<code>supervisorctl</code>，即可在shell里面方便的操作，如<code>start app</code>、<code>restart app</code>等。</p><p>若需要web界面，可在<code>/etc/supervisor/supervisord.conf</code>内修改，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[inet_http_server]         ; inet (TCP) server disabled by default</span><br><span class="line">port=127.0.0.1:9001        ; (ip_address:port specifier, *:port <span class="keyword">for</span> all iface, 若的形式*:port则开放外网访问 )</span><br><span class="line">;username=user              ; (default is no username (open server))</span><br><span class="line">;password=123               ; (default is no password (open server))</span><br></pre></td></tr></table></figure><p>重启<code>supervisorctl</code>后即可在<code>127.0.0.1:9001</code>见到web界面，</p><p>![](/images/2017/07/Screenshot from 2017-07-06 11-49-21.png)</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>如果修改了 /etc/supervisord.conf ,需要执行 supervisorctl reload 来重新加载配置文件，否则不会生效。。。</li><li>很多时候用supervisor管理后台进程容易失败，如<code>hbase/bin/hbase-daemon.sh start thrift</code>，这时候可以改用前台进程如<code>/usr/local/hbase/bin/hbase thrift start</code>。</li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/%E8%BF%90%E7%BB%B4/">运维</category>
      
      
      <comments>http://example.com/2017/07/06/Use-supervisor-support-Python3-program/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Ubuntu16.04 固定IP与设置DNS</title>
      <link>http://example.com/2017/06/20/Ubuntu-16-04-static-IP/</link>
      <guid>http://example.com/2017/06/20/Ubuntu-16-04-static-IP/</guid>
      <pubDate>Tue, 20 Jun 2017 07:13:31 GMT</pubDate>
      
      <description>&lt;p&gt;设置Hadoop集群的第一步很可能就是设置固定IP于DNS，而网上这一做法由于Ubuntu版本及桌面版服务器版的不同导致残差不齐，本文记录一下Ubuntu16.04在非图形界面固定IP与设置DNS的过程。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>设置Hadoop集群的第一步很可能就是设置固定IP于DNS，而网上这一做法由于Ubuntu版本及桌面版服务器版的不同导致残差不齐，本文记录一下Ubuntu16.04在非图形界面固定IP与设置DNS的过程。</p><span id="more"></span><h2 id="Ubuntu16-04-固定IP"><a href="#Ubuntu16-04-固定IP" class="headerlink" title="Ubuntu16.04 固定IP"></a>Ubuntu16.04 固定IP</h2><h3 id="Step-One【Ubuntu-server不需，跳过即可】"><a href="#Step-One【Ubuntu-server不需，跳过即可】" class="headerlink" title="Step-One【Ubuntu-server不需，跳过即可】"></a>Step-One【Ubuntu-server不需，跳过即可】</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/NetworkManager/NetworkManager.conf</span><br><span class="line"><span class="comment"># 将`managed=false`修改成`managed=true`</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h3 id="Step-Two"><a href="#Step-Two" class="headerlink" title="Step-Two"></a>Step-Two</h3><p>如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改配置文件</span></span><br><span class="line">sudo vim /etc/network/interfaces</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># interfaces(5) file used by ifup(8) and ifdown(8)</span></span><br><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"></span><br><span class="line">auto enp0s31f6</span><br><span class="line">iface enp0s31f6 inet static</span><br><span class="line">address 192.168.1.109</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line"><span class="comment">#network 192.168.1.0</span></span><br><span class="line"><span class="comment">#broadcast 192.168.1.255</span></span><br><span class="line">gateway 192.168.1.254</span><br></pre></td></tr></table></figure><p>其中‘enp0s31f6’就是<code>ifconfig</code>中以太网名称。</p><p>附Linux下查看网关gateway方法：</p><ol><li>route -n</li><li>ip route show</li><li>traceroute <a href="http://www.baidu.com/">www.baidu.com</a> -s 100 【第一行就是自己的网关】</li><li>netstat -r</li><li>more /etc/network/interfaces 【Debian/Ubuntu Linux】</li><li>more /etc/sysconfig/network-scripts/ifcfg-eth0 【Red Hat Linux】</li></ol><p>如不清楚网关和子网掩码等参数，可在Ubuntu设置里将network里的ipv4先设置为DHCP（自动获取网络），再利用<code>ifconfig</code>和上述方法查看参数后更改固定参数。</p><h3 id="Step-Three"><a href="#Step-Three" class="headerlink" title="Step-Three"></a>Step-Three</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启networking服务</span></span><br><span class="line">sudo systemctl restart networking.service</span><br></pre></td></tr></table></figure><h2 id="Ubuntu16-04-设置DNS"><a href="#Ubuntu16-04-设置DNS" class="headerlink" title="Ubuntu16.04 设置DNS"></a>Ubuntu16.04 设置DNS</h2><p>但是固定IP使得电脑很可能无法上网，那么需要手动设置DNS。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认文件不存在</span></span><br><span class="line">sudo vim /etc/resolvconf/resolv.conf.d/base</span><br></pre></td></tr></table></figure><p>添加下面内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">meserver 8.8.8.8</span><br><span class="line">nameserver 8.8.4.4</span><br><span class="line"></span><br><span class="line">nameserver 192.168.1.254</span><br><span class="line">nameserver 114.114.114.114</span><br></pre></td></tr></table></figure><p>其中114.114.114.114是国内移动、电信和联通通用的DNS，8.8.8.8和8.8.4.4是GOOGLE公司提供的DNS，192.168.1.254是网关地址。</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="http://www.jianshu.com/p/ea4bca38e5d7">ubuntu16.04固定IP与设置DNS - 简书</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/06/20/Ubuntu-16-04-static-IP/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Learning Something from Fluent Python</title>
      <link>http://example.com/2017/06/18/Learning-Something-from-Fluent-Python/</link>
      <guid>http://example.com/2017/06/18/Learning-Something-from-Fluent-Python/</guid>
      <pubDate>Sun, 18 Jun 2017 11:42:32 GMT</pubDate>
      
      <description>&lt;p&gt;“Fluent Python” 真是一本不可多得的进阶Python神书！读时感觉就像一个老司机讲他的经历，而你情不自禁的喊“666~”。本文记录一些从书里看到的精彩片段与心得。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>“Fluent Python” 真是一本不可多得的进阶Python神书！读时感觉就像一个老司机讲他的经历，而你情不自禁的喊“666~”。本文记录一些从书里看到的精彩片段与心得。</p><span id="more"></span><h2 id="singledispatch装饰器"><a href="#singledispatch装饰器" class="headerlink" title="singledispatch装饰器"></a>singledispatch装饰器</h2><p>functools.singledispatch 装饰器是在Python 3.4中引入的新特性，类似java 的方法重载，可以让你方便的为不同的类型参数调用不同函数。书中举的一个场景是比如，我们需要为不同的参数生成不同格式的HTML tag，那么如果用一个函数来表达这个逻辑，可能需要非常多的if-else逻辑的跳转，这不仅很繁杂，而且不利于后期的维护与迭代，那么singledispatch 装饰器就可以让你从这个局面里解放出来，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf8 -*-</span></span><br><span class="line"><span class="comment"># Created by frank at 18/06/2017</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> singledispatch</span><br><span class="line"></span><br><span class="line"><span class="meta">@singledispatch</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myprint</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@myprint.register(<span class="params"><span class="built_in">str</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;FUCKING STRING! &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(text))</span><br><span class="line"></span><br><span class="line"><span class="meta">@myprint.register(<span class="params"><span class="built_in">int</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;FUCKING INT! &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(n))</span><br><span class="line"></span><br><span class="line"><span class="meta">@myprint.register(<span class="params"><span class="built_in">float</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_</span>(<span class="params">f</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;FUCKING FLOAT! &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(f))</span><br><span class="line"></span><br><span class="line"><span class="meta">@myprint.register(<span class="params"><span class="built_in">tuple</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_</span>(<span class="params">seq</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;FUCKING TUPLE!&quot;</span> + <span class="built_in">str</span>([item <span class="keyword">for</span> item <span class="keyword">in</span> seq]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    myprint(<span class="number">1</span>)</span><br><span class="line">    myprint(<span class="number">0.5</span>)</span><br><span class="line">    myprint(<span class="string">&#x27;frank&#x27;</span>)</span><br><span class="line">    myprint((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure><p>结果是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FUCK INT! 1</span><br><span class="line">FUCK FLOAT! 0.5</span><br><span class="line">FUCK STRING! frank</span><br><span class="line">FUCK tuple![1, 2, 3]</span><br></pre></td></tr></table></figure><p>以上的简单的例子中，singledispatch装饰器为myprint函数的不同参数选择了不同的调用。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2017/06/18/Learning-Something-from-Fluent-Python/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>programmer humor week 4</title>
      <link>http://example.com/2017/06/18/programmer-humor-week-4/</link>
      <guid>http://example.com/2017/06/18/programmer-humor-week-4/</guid>
      <pubDate>Sun, 18 Jun 2017 11:28:36 GMT</pubDate>
      
      <description>&lt;p&gt;programmer humor from reddit 🤣😂😜&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>programmer humor from reddit 🤣😂😜</p><span id="more"></span><h3 id="Passwords"><a href="#Passwords" class="headerlink" title="Passwords"></a>Passwords</h3><p><img src="/images/2017/06/00.png"></p><h3 id="Haters-will-say-he-she-doesn’t-even-code"><a href="#Haters-will-say-he-she-doesn’t-even-code" class="headerlink" title="Haters will say he/she doesn’t even code"></a>Haters will say he/she doesn’t even code</h3><p><img src="/images/2017/06/01.jpg"></p><h3 id="Just-a-bit"><a href="#Just-a-bit" class="headerlink" title="Just a bit."></a>Just a bit.</h3><p><img src="/images/2017/06/02.jpg"></p><h3 id="Happy-Birthday-Linux"><a href="#Happy-Birthday-Linux" class="headerlink" title="Happy Birthday Linux!"></a>Happy Birthday Linux!</h3><p><img src="/images/2017/06/03.jpg"></p><h3 id="How-to-get-tomorrow’s-date"><a href="#How-to-get-tomorrow’s-date" class="headerlink" title="How to get tomorrow’s date"></a>How to get tomorrow’s date</h3><p><img src="/images/2017/06/04.png"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><p><a href="https://www.reddit.com/r/ProgrammerHumor/">Programmer Humor</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Funny/">Funny</category>
      
      
      <comments>http://example.com/2017/06/18/programmer-humor-week-4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Python PATH是怎么一回事？从“import pyspark”报错说起</title>
      <link>http://example.com/2017/06/15/About-Python-PATH/</link>
      <guid>http://example.com/2017/06/15/About-Python-PATH/</guid>
      <pubDate>Wed, 14 Jun 2017 18:57:57 GMT</pubDate>
      
      <description>&lt;p&gt;为何import pyspark报错？让我们从捋一捋Python的环境变量PATH开始！&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>为何import pyspark报错？让我们从捋一捋Python的环境变量PATH开始！</p><span id="more"></span><p>Spark装好后直接在代码开头<code>import pyspark</code>不出意外是要报错的，没有这个模块？当然不是，只是python找不到这个地址而已，有很quick and dirty的解决方法，就是利用包<code>findspark</code>，只要在开头</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> findspark</span><br><span class="line">findspark.init()</span><br></pre></td></tr></table></figure><p>接下来即可顺利<code>import pyspark</code>，不过这个在“import其他依赖之前先运行函数”实在是有碍观赏性。。。什么是“优雅的解决方法”呢？别急，我们先来看看<code>import findspark</code>做了什么吧：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ensure SPARK_HOME is defined</span></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = spark_home</span><br><span class="line"></span><br><span class="line"><span class="comment"># ensure PYSPARK_PYTHON is defined</span></span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_PYTHON&#x27;</span>] = python_path</span><br><span class="line"></span><br><span class="line"><span class="comment"># add pyspark to sys.path</span></span><br><span class="line">spark_python = os.path.join(spark_home, <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line">py4j = glob(os.path.join(spark_python, <span class="string">&#x27;lib&#x27;</span>, <span class="string">&#x27;py4j-*.zip&#x27;</span>))[<span class="number">0</span>]</span><br><span class="line">sys.path[:<span class="number">0</span>] = [spark_python, py4j]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> edit_rc:</span><br><span class="line">    change_rc(spark_home, spark_python, py4j) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> edit_profile:</span><br><span class="line">    edit_ipython_profile(spark_home, spark_python, py4j)</span><br></pre></td></tr></table></figure><p>debug一下，原来init()的作用即是将如’/usr/local/spark/python’和’/usr/local/spark/python/lib/py4j-0.9-src.zip’写入 sys.path内，其中可选是否写入’~/.bashrc’或者IPython profile里。再通过查阅一些资料，我们开始验证想法，比如，我们在桌面建立’fuck.py’文件：</p><p><code>echo &quot;print(&#39;FUCK&#39;)&quot; &gt; fuck.py</code><br>那么，只要我们import fuck 成功即打印此文字，我们在Desktop下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">frank@mac:Desktop$ python -c <span class="string">&quot;import fuck&quot;</span></span><br><span class="line">FUCK</span><br><span class="line">frank@mac:Desktop$ python -c <span class="string">&quot;import sys; print(sys.path)&quot;</span></span><br><span class="line">[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;/Users/frank/Desktop&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python36.zip&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/lib-dynload&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/Sphinx-1.5.1-py3.6.egg&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/aeosa&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg&#x27;</span>]</span><br></pre></td></tr></table></figure><p>没问题，因为<code>sys.path</code>虽不包括当前目录，但是buildin函数import默认寻找当前目录。</p><p>那我们切到其他文件夹？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">frank@mac:tmp$ python</span><br><span class="line"></span><br><span class="line">frank@mac:tmp$ python -c <span class="string">&quot;import fuck&quot;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;string&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ModuleNotFoundError: No module named <span class="string">&#x27;fuck&#x27;</span></span><br><span class="line">frank@mac:tmp$ python -c <span class="string">&quot;import sys; print(sys.path)&quot;</span></span><br><span class="line">[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python36.zip&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/lib-dynload&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/Sphinx-1.5.1-py3.6.egg&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/aeosa&#x27;</span>, <span class="string">&#x27;/Users/frank/anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg&#x27;</span>]</span><br></pre></td></tr></table></figure><p><code>fuck.py</code>既不在当前目录也不在<code>sys.path</code>，那么如何添加呢？有两种方法：一是添加进<code>sys.path</code>里：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; sys.path.append(<span class="string">&#x27;/Users/frank/Desktop&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; import fuck</span><br><span class="line">FUCK</span><br></pre></td></tr></table></figure><p>不过这个只对当前程序起作用，想要持久效果的话，通过查阅<a href="https://docs.python.org/3/library/sys.html#sys.path">29.1. sys — System-specific parameters and functions — Python 3.6.1 documentation</a>可得，<code>sys.path</code>是通过PYTHONPATH环境变量起作用的，那么把需要的目录添加到PYTHONPATH即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frank@mac:~$ <span class="built_in">echo</span> <span class="string">&quot;export PYTHONPATH=/Users/frank/Desktop:<span class="variable">$PYTHONPATH</span>&quot;</span> &gt;&gt; ~/.profile &amp;&amp; <span class="built_in">source</span>  ~/.profile</span><br></pre></td></tr></table></figure><p>再import即可成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frank@mac:tmp$ python -c <span class="string">&quot;import fuck&quot;</span></span><br><span class="line">FUCK</span><br></pre></td></tr></table></figure><p>综上，需要一劳永逸解决<code>import pyspark</code>失败的问题，那么在`~/.profile’内添加如下即可（py4j-0.10.4-部分版本号可能不同））：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure><p>在<code>source  ~/.profile</code>即可。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2017/06/15/About-Python-PATH/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>programmer humor week 3</title>
      <link>http://example.com/2017/05/27/programmer-humor-week-3/</link>
      <guid>http://example.com/2017/05/27/programmer-humor-week-3/</guid>
      <pubDate>Sat, 27 May 2017 09:58:39 GMT</pubDate>
      
      <description>&lt;p&gt;programmer humor from reddit 🤣😂😜&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>programmer humor from reddit 🤣😂😜</p><span id="more"></span><h3 id="“what-sales-does”"><a href="#“what-sales-does”" class="headerlink" title="“what sales does”"></a>“what sales does”</h3><p><img src="/images/2017/05/00.png"></p><h3 id="Harry-Potter-can-code-Python"><a href="#Harry-Potter-can-code-Python" class="headerlink" title="Harry Potter can code Python"></a>Harry Potter can code Python</h3><p><img src="/images/2017/05/01.jpg"></p><h3 id="The-neverending-story"><a href="#The-neverending-story" class="headerlink" title="The neverending story."></a>The neverending story.</h3><p><img src="/images/2017/05/02.png"></p><h3 id="relationship"><a href="#relationship" class="headerlink" title="relationship"></a>relationship</h3><p><img src="/images/2017/05/03.jpg"></p><h3 id="Functional-Programming-For-Beginners"><a href="#Functional-Programming-For-Beginners" class="headerlink" title="Functional Programming For Beginners"></a>Functional Programming For Beginners</h3><p><img src="/images/2017/05/04.png"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><p><a href="https://www.reddit.com/r/ProgrammerHumor/">Programmer Humor</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Funny/">Funny</category>
      
      
      <comments>http://example.com/2017/05/27/programmer-humor-week-3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Ubuntu 16.04 搭建 Spark &amp; Hadoop集群的详细步骤及报错填坑</title>
      <link>http://example.com/2017/05/27/Ubuntu-16-04-install-Spark-Hadoop/</link>
      <guid>http://example.com/2017/05/27/Ubuntu-16-04-install-Spark-Hadoop/</guid>
      <pubDate>Sat, 27 May 2017 08:13:04 GMT</pubDate>
      
      <description>&lt;p&gt;在Ubuntu 16.04 安装 Spark &amp;amp; Hadoop分布式集群的记录&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在Ubuntu 16.04 安装 Spark &amp; Hadoop分布式集群的记录</p><span id="more"></span><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>如下设置默认都在每一台机器上都要进行。</p><h3 id="配置hadoop用户"><a href="#配置hadoop用户" class="headerlink" title="配置hadoop用户"></a>配置hadoop用户</h3><p>首先是在每个机器上创建hadoop用户，设置密码（方便起见建议都设置一样的），并赋予其root权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br><span class="line">sudo passwd hadoop</span><br><span class="line">sudo adduser hadoop sudo</span><br></pre></td></tr></table></figure><h3 id="固定IP"><a href="#固定IP" class="headerlink" title="固定IP"></a>固定IP</h3><p>为防止重启导致IP变化，需要固定Ip方法参考<a href="http://frankchen.xyz/2017/06/20/Ubuntu-16-04-static-IP/">Ubuntu16.04 固定IP与设置DNS | 不正经数据科学家</a></p><h3 id="配置hosts"><a href="#配置hosts" class="headerlink" title="配置hosts"></a>配置hosts</h3><p>为方便部署，可配置hosts名，方便输入地址，如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line">192.168.1.113      czn.shise.com</span><br><span class="line">192.168.1.102      czm.shise.com</span><br><span class="line">192.168.1.120      wwj.shise.com</span><br><span class="line">192.168.1.123      bas.shise.com</span><br></pre></td></tr></table></figure><p>测试能否ping通<br><code>ping czn.shise.com -c 3</code></p><h3 id="配置-ssh-无密码访问集群机器"><a href="#配置-ssh-无密码访问集群机器" class="headerlink" title="配置 ssh 无密码访问集群机器"></a>配置 ssh 无密码访问集群机器</h3><p>每台机器之间以及每台机器与自己的localhost都需配置ssh免密码登录。<br>如未安装ssh需 <code>sudo apt install openssh-server</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost</span><br><span class="line"><span class="built_in">exit</span>                           <span class="comment"># 退出刚才的 ssh localhost</span></span><br><span class="line"><span class="built_in">cd</span> ~/.ssh/                     <span class="comment"># 若没有该目录，请先执行一次ssh localhost</span></span><br><span class="line">ssh-keygen -t rsa              <span class="comment"># 会有提示，都按回车就可以</span></span><br></pre></td></tr></table></figure><p>再用<code>ssh-copy-id</code>来设置免密码登录，如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id localhost</span><br><span class="line">ssh-copy-id czn.shise.com</span><br><span class="line">ssh-copy-id czm.shise.com</span><br><span class="line">ssh-copy-id bas.shise.com</span><br></pre></td></tr></table></figure><p>在每个机器上都如此设置与其它机器的免密码登录。<br>这里默认都是<code>hadoop</code>用户，所以不需带用户名，如果不是则需要带用户名如<br><code>ssh-copy-id hadoop@czn.shise.com</code></p><h3 id="Java环境"><a href="#Java环境" class="headerlink" title="Java环境"></a>Java环境</h3><p>统一使用openjdk-8，<code>sudo apt-get install openjdk-8-jre openjdk-8-jdk</code><br>会默认安装在<code>/usr/lib/jvm/java-8-openjdk-amd64</code></p><h2 id="Hadoop集群配置"><a href="#Hadoop集群配置" class="headerlink" title="Hadoop集群配置"></a>Hadoop集群配置</h2><p>我们先登录至作为master的机器，配置好之后再将hadoop环境复制至各slave即可，非常方便。<br>首先是Hadoop集群的配置，下载<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/">Index of /apache/hadoop/common</a>，我们选择2.7.3版本。<br>放置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxf ~/Downloads/hadoop-2.7.3.tar.gz -C /usr/<span class="built_in">local</span>    <span class="comment"># 解压到/usr/local中</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">sudo mv ./hadoop-2.7.3/ ./hadoop            <span class="comment"># 将文件夹名改为hadoop</span></span><br><span class="line">sudo chown -R hadoop:hadoop ./hadoop       <span class="comment"># 修改文件权限</span></span><br></pre></td></tr></table></figure><h3 id="各文件配置"><a href="#各文件配置" class="headerlink" title="各文件配置"></a>各文件配置</h3><p>配置<code>hadoop/etc/hadoop</code>文件夹下的各文件，</p><p>在<code>hadoop-env.sh</code>里添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure><p>在<code>core-site.xml</code>里添加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://wwj.shise.com:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>在<code>yarn-site.xml</code>里添加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;wwj.shise.com&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>改写<code>slaves</code>为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">czn.shise.com</span><br><span class="line">czm.shise.com</span><br><span class="line">wwj.shise.com</span><br><span class="line">bas.shise.com</span><br></pre></td></tr></table></figure><p>改写<code>mapred-site.xml</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;wwj.shise.com:10020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;wwj.shise.com:19888&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p><code>hdfs-site.xml</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;wwj.shise.com:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h3 id="复制配置好的hadoop至各机器"><a href="#复制配置好的hadoop至各机器" class="headerlink" title="复制配置好的hadoop至各机器"></a>复制配置好的hadoop至各机器</h3><p>在master上压缩文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo rm -r ./hadoop/tmp     <span class="comment"># 删除 Hadoop 临时文件</span></span><br><span class="line">sudo rm -r ./hadoop/logs/*   <span class="comment"># 删除日志文件</span></span><br><span class="line">tar -zcf ~/hadoop.master.tar.gz ./hadoop   <span class="comment"># 先压缩再复制</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">scp ./hadoop.master.tar.gz czn.shise.com:/home/hadoop <span class="comment"># 复制至各机器</span></span><br><span class="line">scp ./hadoop.master.tar.gz czm.shise.com:/home/hadoop</span><br><span class="line">scp ./hadoop.master.tar.gz bas.shise.com:/home/hadoop</span><br></pre></td></tr></table></figure><p>再登录至复制过去的每个slave</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -r /usr/<span class="built_in">local</span>/hadoop    <span class="comment"># 删掉旧的（如果存在）</span></span><br><span class="line">sudo tar -zxf ~/hadoop.master.tar.gz -C /usr/<span class="built_in">local</span></span><br><span class="line">sudo chown -R hadoop /usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure><h3 id="各机器环境变量"><a href="#各机器环境变量" class="headerlink" title="各机器环境变量"></a>各机器环境变量</h3><p><code>sudo vim ~/.profile</code><br>我的环境变量设置如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Java Env</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=<span class="variable">$JAVA_HOME</span>/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JRE_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hadoop Env</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p><code>source ~/.profile</code></p><h3 id="启动检查"><a href="#启动检查" class="headerlink" title="启动检查"></a>启动检查</h3><p>登录master机器，执行 NameNode 的格式化：<code>hdfs namenode -format </code><br>先dfs、再yarn</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure><h3 id="验证hadoop安装"><a href="#验证hadoop安装" class="headerlink" title="验证hadoop安装"></a>验证hadoop安装</h3><p>可以通过jps命令查看各个节点启动的进程是否正常。在 master 上应该有以下几个进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ jps  <span class="comment">#run on master</span></span><br><span class="line">3407 SecondaryNameNode</span><br><span class="line">3218 NameNode</span><br><span class="line">3552 ResourceManager</span><br><span class="line">3910 Jps</span><br></pre></td></tr></table></figure><p>在每个slave上应该有以下几个进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ jps   <span class="comment">#run on slaves</span></span><br><span class="line">2072 NodeManager</span><br><span class="line">2213 Jps</span><br><span class="line">1962 DataNode</span><br></pre></td></tr></table></figure><h2 id="Spark分布式配置"><a href="#Spark分布式配置" class="headerlink" title="Spark分布式配置"></a>Spark分布式配置</h2><h3 id="下载及安置"><a href="#下载及安置" class="headerlink" title="下载及安置"></a>下载及安置</h3><p>官网下载，<a href="http://spark.apache.org/downloads.html">Downloads | Apache Spark</a> ，这里我们选择2.2.1版本， 及Pre-build with user-provided Apache Hadoop，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxf ~/Downloads/spark-2.1.1-bin-without-hadoop.tgz -C /usr/<span class="built_in">local</span>/</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo mv ./spark-2.1.1-bin-without-hadoop/ ./spark</span><br><span class="line">sudo chown -R hadoop:hadoop ./spark          <span class="comment"># 此处的 hadoop 为你的用户名</span></span><br></pre></td></tr></table></figure><h3 id="配置Spark"><a href="#配置Spark" class="headerlink" title="配置Spark"></a>配置Spark</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/conf    <span class="comment">#进入spark配置目录</span></span><br><span class="line">cp spark-env.sh.template spark-env.sh   <span class="comment">#从配置模板复制</span></span><br><span class="line">vim spark-env.sh     <span class="comment">#添加配置内容</span></span><br></pre></td></tr></table></figure><p>在<code>spark-env.sh</code>末尾添加以下内容（这是我的配置，你可以自行修改）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export SCALA_HOME=/home/spark/workspace/scala-2.10.4</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">SPARK_MASTER_IP=wwj.shise.com</span><br><span class="line">SPARK_LOCAL_DIRS=/usr/<span class="built_in">local</span>/spark</span><br><span class="line">SPARK_DRIVER_MEMORY=1G</span><br></pre></td></tr></table></figure><p>参考<a href="https://spark.apache.org/docs/latest/hadoop-provided.html">Using Spark’s “Hadoop Free” Build - Spark 2.2.0 Documentation</a>，<code>spark-env.sh</code>还需加上<br><code>export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</code>。</p><p><code>vim slaves</code>在slaves文件下填上slave主机名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">czn.shise.com</span><br><span class="line">czm.shise.com</span><br><span class="line">wwj.shise.com</span><br><span class="line">bas.shise.com</span><br></pre></td></tr></table></figure><h3 id="复制配置好的Spark至各机器"><a href="#复制配置好的Spark至各机器" class="headerlink" title="复制配置好的Spark至各机器"></a>复制配置好的Spark至各机器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zcf ~/spark.master.tar.gz ./spark   <span class="comment"># 先压缩再复制</span></span><br><span class="line"><span class="built_in">cd</span> ~/</span><br><span class="line">scp ./spark.master.tar.gz czn.shise.com:/home/hadoop  <span class="comment">#传输数据</span></span><br><span class="line">scp ./spark.master.tar.gz czm.shise.com:/home/hadoop  <span class="comment">#传输数据</span></span><br><span class="line">scp ./spark.master.tar.gz bas.shise.com:/home/hadoop  <span class="comment">#传输数据</span></span><br></pre></td></tr></table></figure><h3 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h3><p><code>sbin/start-all.sh</code><br>用jps检查，在 master 上应该有以下几个进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">7949 Jps</span><br><span class="line">7328 SecondaryNameNode</span><br><span class="line">7805 Master</span><br><span class="line">7137 NameNode</span><br><span class="line">7475 ResourceManager</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在 slave 上应该有以下几个进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$jps</span></span><br><span class="line">3132 DataNode</span><br><span class="line">3759 Worker</span><br><span class="line">3858 Jps</span><br><span class="line">3231 NodeManager</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="报错及解决"><a href="#报错及解决" class="headerlink" title="报错及解决"></a>报错及解决</h2><blockquote><p>Python in worker has different version 2.7 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.<br>出现这个错误的原因是为worker与driver设置了不同的Python版本，解决方法是（以anaconda3.6为例）：</p></blockquote><p><code>vim /usr/local/spark/conf/spark-env.sh</code>，<br>添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ANACONDA_ROOT=/home/hadoop/anaconda3</span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="variable">$ANACONDA_ROOT</span>/bin/python</span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=<span class="variable">$ANACONDA_ROOT</span>/bin/pythonexport PYSPARK_PYTHON=<span class="variable">$ANACONDA_ROOT</span>/bin/python</span><br></pre></td></tr></table></figure><p>值得注意的是，很多教程会让你在<code>.bashrc</code>里设置，这不是推荐的方法。参考自<a href="https://stackoverflow.com/questions/30518362/how-do-i-set-the-drivers-python-version-in-spark">pyspark - How do I set the driver’s python version in spark? - Stack Overflow</a>。</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="http://wuchong.me/blog/2015/04/04/spark-on-yarn-cluster-deploy/">Spark On YARN 集群安装部署 | Jark’s Blog</a></li><li><a href="http://dblab.xmu.edu.cn/blog/install-hadoop-cluster/">Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS_厦大数据库实验室博客</a></li><li><a href="http://blog.csdn.net/zhshulin/article/details/50413240">Hadoop集群完全分布式搭建教程-CentOS - 在路上 - 博客频道 - CSDN.NET</a></li><li><a href="https://my.oschina.net/jackieyeah/blog/657750">Hadoop 2.6.4分布式集群环境搭建 - JackieYeah的个人空间</a></li><li><a href="http://www.jianshu.com/p/2f6a85fe7b92">Spark On YARN 集群安装部署 - 简书</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Hadoop/">Hadoop</category>
      
      <category domain="http://example.com/tags/Spark/">Spark</category>
      
      
      <comments>http://example.com/2017/05/27/Ubuntu-16-04-install-Spark-Hadoop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>解决Excel长数字被转为科学计数法的问题</title>
      <link>http://example.com/2017/05/12/examples-for-processing-excel-and-time-series/</link>
      <guid>http://example.com/2017/05/12/examples-for-processing-excel-and-time-series/</guid>
      <pubDate>Fri, 12 May 2017 03:43:34 GMT</pubDate>
      
      <description>&lt;p&gt;记录一些利用Pandas处理Excel和时间戳的例子。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>记录一些利用Pandas处理Excel和时间戳的例子。</p><span id="more"></span><h3 id="读取和保存Excel"><a href="#读取和保存Excel" class="headerlink" title="读取和保存Excel"></a>读取和保存Excel</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sheetname指定读取子表</span></span><br><span class="line">dfs = pd.read_excel(<span class="string">&#x27;/Users/frank/Desktop/hebing.xlsx&#x27;</span>, sheetname=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">c.to_excel(<span class="string">&#x27;/Users/frank/Desktop/result.xlsx&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="DataFrame合并及排序"><a href="#DataFrame合并及排序" class="headerlink" title="DataFrame合并及排序"></a>DataFrame合并及排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfs_group = dfs.groupby(by=<span class="string">&#x27;订单号&#x27;</span>).<span class="built_in">sum</span>()</span><br><span class="line">dfs_group.sort_values(ascending=<span class="literal">False</span>, by=<span class="string">&#x27;子订单金额&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="时间段切片"><a href="#时间段切片" class="headerlink" title="时间段切片"></a>时间段切片</h3><p>这个我暂时没发现如何用一行表达式完成，暂时用的这种low方式🤣</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = dfs.loc[dfs[<span class="string">&quot;付款时间&quot;</span>] &lt; <span class="string">&#x27;2017-05-10 09:00:00&#x27;</span>]</span><br><span class="line">b = a.loc[a[<span class="string">&quot;付款时间&quot;</span>] &gt; <span class="string">&#x27;2017-05-08 10:00:00&#x27;</span>]</span><br></pre></td></tr></table></figure><h3 id="解决长数字被转为科学计数法的问题"><a href="#解决长数字被转为科学计数法的问题" class="headerlink" title="解决长数字被转为科学计数法的问题"></a>解决长数字被转为科学计数法的问题</h3><p>比如好好的订单号，</p><img src="/images/2017/05/Screen Shot 2017-05-12 at 11.50.35.png" width="200" />保存为xlsx或者csv就变成了这样，这是什么玩意儿，完全不能忍啊！🤡🤓🤑<img src="/images/2017/05/Screen Shot 2017-05-12 at 11.51.26.png" width="100" />如何解决呢？如下<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c[<span class="string">&#x27;订单号&#x27;</span>] = c[<span class="string">&#x27;订单号&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="string">&#x27;&#123;:.0f&#125;&#x27;</span>.<span class="built_in">format</span>(x))</span><br></pre></td></tr></table></figure><p>即将其长数字转为不带小数点的浮点数形式即可😎</p><img src="/images/2017/05/Screen Shot 2017-05-12 at 12.02.33.png" width="200" />]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Pandas/">Pandas</category>
      
      
      <comments>http://example.com/2017/05/12/examples-for-processing-excel-and-time-series/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>面试常见基础算法:排序/查找/树的遍历等（python版）</title>
      <link>http://example.com/2017/05/04/Basic-Algorithms-in-Python/</link>
      <guid>http://example.com/2017/05/04/Basic-Algorithms-in-Python/</guid>
      <pubDate>Thu, 04 May 2017 06:08:10 GMT</pubDate>
      
      <description>&lt;p&gt;总结一下基本算法，以备忘，以复习。&lt;br&gt;当然，你别指望考官会直接考你这些，太基础，但是，当他知道你这些都写不出来的时候，你面试绝对没希望了。&lt;/p&gt;
&lt;p&gt;PS: 真的有面试官会考啊，至少Baidu会考…………&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>总结一下基本算法，以备忘，以复习。<br>当然，你别指望考官会直接考你这些，太基础，但是，当他知道你这些都写不出来的时候，你面试绝对没希望了。</p><p>PS: 真的有面试官会考啊，至少Baidu会考…………</p><span id="more"></span><h2 id="8大排序"><a href="#8大排序" class="headerlink" title="8大排序"></a>8大排序</h2><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p> 稳定排序，简单易于实现，复杂度$Ο(n ^2)$ </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    length = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, length):</span><br><span class="line">            <span class="keyword">if</span> arr[i] &gt; arr[j]:</span><br><span class="line">                arr[i], arr[j] = arr[j], arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure><h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><p> 不稳定排序，复杂度$Ο(n ^2)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    length = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">        _<span class="built_in">min</span> = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, length):</span><br><span class="line">            <span class="keyword">if</span> arr[_<span class="built_in">min</span>] &gt; arr[j]:</span><br><span class="line">                _<span class="built_in">min</span> = j</span><br><span class="line">        arr[i], arr[_<span class="built_in">min</span>] = arr[_<span class="built_in">min</span>], arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure><h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span>(<span class="params">alist</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;插入排序&quot;&quot;&quot;</span></span><br><span class="line">    n = <span class="built_in">len</span>(alist)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        <span class="comment"># 控制将拿到的元素放到前面有序序列中正确位置的过程</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(j, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 如果比前面的元素小，则往前移动</span></span><br><span class="line">            <span class="keyword">if</span> alist[i] &lt; alist[i - <span class="number">1</span>]:</span><br><span class="line">                alist[i], alist[i - <span class="number">1</span>] = alist[i - <span class="number">1</span>], alist[i]</span><br><span class="line">            <span class="comment"># 否则代表比前面的所有元素都小，不需要再移动</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h3 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span>(<span class="params">alist</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;希尔排序&quot;&quot;&quot;</span></span><br><span class="line">    n = <span class="built_in">len</span>(alist)</span><br><span class="line">    gap = n // <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> gap &gt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(gap, n):</span><br><span class="line">            i = j</span><br><span class="line">            <span class="keyword">while</span> (i - gap) &gt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> alist[i] &lt; alist[i - gap]:</span><br><span class="line">                    alist[i], alist[i - gap] = alist[i - gap], alist[i]</span><br><span class="line">                    i -= gap</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        gap //= <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>稳定排序，复杂度 $Ο(n log n)$ ，该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">msort2</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(x) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    result = []          </span><br><span class="line">    mid = <span class="built_in">int</span>(<span class="built_in">len</span>(x) / <span class="number">2</span>)</span><br><span class="line">    y = msort2(x[:mid])</span><br><span class="line">    z = msort2(x[mid:])</span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">len</span>(y) &gt; <span class="number">0</span>) <span class="keyword">and</span> (<span class="built_in">len</span>(z) &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="keyword">if</span> y[<span class="number">0</span>] &gt; z[<span class="number">0</span>]:</span><br><span class="line">            result.append(z[<span class="number">0</span>])</span><br><span class="line">            z.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(y[<span class="number">0</span>])</span><br><span class="line">            y.pop(<span class="number">0</span>)</span><br><span class="line">    result += y</span><br><span class="line">    result += z</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="快速排序-QuickSort"><a href="#快速排序-QuickSort" class="headerlink" title="快速排序 QuickSort"></a>快速排序 QuickSort</h3><p>为不稳定排序，快速排序通常明显比同为 $Ο(n log n)$ 的其他算法更快，因此常被采用，而且快排采用了分治法的思想，所以在很多笔试面试中能经常看到快排的影子。可见掌握快排的重要性.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quicksort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>: <span class="keyword">return</span> arr</span><br><span class="line">    </span><br><span class="line">    pivot = arr[<span class="built_in">len</span>(arr) // <span class="number">2</span>]</span><br><span class="line">    left = [i <span class="keyword">for</span> i <span class="keyword">in</span> arr <span class="keyword">if</span> i&lt;pivot]    </span><br><span class="line">    middle = [i <span class="keyword">for</span> i <span class="keyword">in</span> arr <span class="keyword">if</span> i==pivot]</span><br><span class="line">    right = [i <span class="keyword">for</span> i <span class="keyword">in</span> arr <span class="keyword">if</span> i&gt;pivot]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> quicksort(left) + middle + quicksort(right)</span><br></pre></td></tr></table></figure><h3 id="堆排序-HeapSort"><a href="#堆排序-HeapSort" class="headerlink" title="堆排序 HeapSort"></a>堆排序 HeapSort</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MAX_Heapify</span>(<span class="params">heap,HeapSize,root</span>):</span><span class="comment">#在堆中做结构调整使得父节点的值大于子节点</span></span><br><span class="line"></span><br><span class="line">    left = <span class="number">2</span>*root + <span class="number">1</span></span><br><span class="line">    right = left + <span class="number">1</span></span><br><span class="line">    larger = root</span><br><span class="line">    <span class="keyword">if</span> left &lt; HeapSize <span class="keyword">and</span> heap[larger] &lt; heap[left]:</span><br><span class="line">        larger = left</span><br><span class="line">    <span class="keyword">if</span> right &lt; HeapSize <span class="keyword">and</span> heap[larger] &lt; heap[right]:</span><br><span class="line">        larger = right</span><br><span class="line">    <span class="keyword">if</span> larger != root:<span class="comment">#如果做了堆调整则larger的值等于左节点或者右节点的，这个时候做对调值操作</span></span><br><span class="line">        heap[larger],heap[root] = heap[root],heap[larger]</span><br><span class="line">        MAX_Heapify(heap, HeapSize, larger)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Build_MAX_Heap</span>(<span class="params">heap</span>):</span><span class="comment">#构造一个堆，将堆中所有数据重新排序</span></span><br><span class="line">    HeapSize = <span class="built_in">len</span>(heap)<span class="comment">#将堆的长度当独拿出来方便</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange((HeapSize -<span class="number">2</span>)//<span class="number">2</span>,-<span class="number">1</span>,-<span class="number">1</span>):<span class="comment">#从后往前出数</span></span><br><span class="line">        MAX_Heapify(heap,HeapSize,i)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">HeapSort</span>(<span class="params">heap</span>):</span><span class="comment">#将根节点取出与最后一位做对调，对前面len-1个节点继续进行对调整过程。</span></span><br><span class="line">    Build_MAX_Heap(heap)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(heap)-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">        heap[<span class="number">0</span>],heap[i] = heap[i],heap[<span class="number">0</span>]</span><br><span class="line">        MAX_Heapify(heap, i, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> heap</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">radixSort</span>():</span></span><br><span class="line">    A=[random.randint(<span class="number">1</span>,<span class="number">9999</span>) <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10000</span>)]   </span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> xrange(<span class="number">4</span>):  <span class="comment">#4轮排序       </span></span><br><span class="line">        s=[[] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> A:</span><br><span class="line">            s[i/(<span class="number">10</span>**k)%<span class="number">10</span>].append(i)</span><br><span class="line">        A=[a <span class="keyword">for</span> b <span class="keyword">in</span> s <span class="keyword">for</span> a <span class="keyword">in</span> b]</span><br><span class="line">    <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure><h2 id="查找："><a href="#查找：" class="headerlink" title="查找："></a>查找：</h2><h3 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h3><p>只适用于有序数组，复杂度$Ο(log n)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">arr, key</span>):</span></span><br><span class="line">    low = <span class="number">0</span></span><br><span class="line">    high = <span class="built_in">len</span>(arr) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> low &lt;= high:</span><br><span class="line">        mid = (low + high) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> arr[mid] == key: <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">elif</span> arr[mid] &lt; key: </span><br><span class="line">            low = mid + <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> arr[mid] &gt; key:</span><br><span class="line">            high = mid - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;节点类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, elem=-<span class="number">1</span>, lchild=<span class="literal">None</span>, rchild=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.elem = elem</span><br><span class="line">        self.lchild = lchild</span><br><span class="line">        self.rchild = rchild</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tree</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;树类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.root = Node()</span><br><span class="line">        self.myQueue = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self, elem</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;为树添加节点&quot;&quot;&quot;</span></span><br><span class="line">        node = Node(elem)</span><br><span class="line">        <span class="keyword">if</span> self.root.elem == -<span class="number">1</span>:  <span class="comment"># 如果树是空的，则对根节点赋值</span></span><br><span class="line">            self.root = node</span><br><span class="line">            self.myQueue.append(self.root)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            treeNode = self.myQueue[<span class="number">0</span>]  <span class="comment"># 此结点的子树还没有齐。</span></span><br><span class="line">            <span class="keyword">if</span> treeNode.lchild == <span class="literal">None</span>:</span><br><span class="line">                treeNode.lchild = node</span><br><span class="line">                self.myQueue.append(treeNode.lchild)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                treeNode.rchild = node</span><br><span class="line">                self.myQueue.append(treeNode.rchild)</span><br><span class="line">                self.myQueue.pop(<span class="number">0</span>)  <span class="comment"># 如果该结点存在右子树，将此结点丢弃。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">front_digui</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用递归实现树的先序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="built_in">print</span> root.elem,</span><br><span class="line">        self.front_digui(root.lchild)</span><br><span class="line">        self.front_digui(root.rchild)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">middle_digui</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用递归实现树的中序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.middle_digui(root.lchild)</span><br><span class="line">        <span class="built_in">print</span> root.elem,</span><br><span class="line">        self.middle_digui(root.rchild)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">later_digui</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用递归实现树的后序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.later_digui(root.lchild)</span><br><span class="line">        self.later_digui(root.rchild)</span><br><span class="line">        <span class="built_in">print</span> root.elem,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">front_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用堆栈实现树的先序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        myStack = []</span><br><span class="line">        node = root</span><br><span class="line">        <span class="keyword">while</span> node <span class="keyword">or</span> myStack:</span><br><span class="line">            <span class="keyword">while</span> node:                     <span class="comment">#从根节点开始，一直找它的左子树</span></span><br><span class="line">                <span class="built_in">print</span> node.elem,</span><br><span class="line">                myStack.append(node)</span><br><span class="line">                node = node.lchild</span><br><span class="line">            node = myStack.pop()            <span class="comment">#while结束表示当前节点node为空，即前一个节点没有左子树了</span></span><br><span class="line">            node = node.rchild                  <span class="comment">#开始查看它的右子树</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">middle_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用堆栈实现树的中序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        myStack = []</span><br><span class="line">        node = root</span><br><span class="line">        <span class="keyword">while</span> node <span class="keyword">or</span> myStack:</span><br><span class="line">            <span class="keyword">while</span> node:                     <span class="comment">#从根节点开始，一直找它的左子树</span></span><br><span class="line">                myStack.append(node)</span><br><span class="line">                node = node.lchild</span><br><span class="line">            node = myStack.pop()            <span class="comment">#while结束表示当前节点node为空，即前一个节点没有左子树了</span></span><br><span class="line">            <span class="built_in">print</span> node.elem,</span><br><span class="line">            node = node.rchild                  <span class="comment">#开始查看它的右子树</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">later_stack</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用堆栈实现树的后序遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        myStack1 = []</span><br><span class="line">        myStack2 = []</span><br><span class="line">        node = root</span><br><span class="line">        myStack1.append(node)</span><br><span class="line">        <span class="keyword">while</span> myStack1:                   <span class="comment">#这个while循环的功能是找出后序遍历的逆序，存在myStack2里面</span></span><br><span class="line">            node = myStack1.pop()</span><br><span class="line">            <span class="keyword">if</span> node.lchild:</span><br><span class="line">                myStack1.append(node.lchild)</span><br><span class="line">            <span class="keyword">if</span> node.rchild:</span><br><span class="line">                myStack1.append(node.rchild)</span><br><span class="line">            myStack2.append(node)</span><br><span class="line">        <span class="keyword">while</span> myStack2:                         <span class="comment">#将myStack2中的元素出栈，即为后序遍历次序</span></span><br><span class="line">            <span class="built_in">print</span> myStack2.pop().elem,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">level_queue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;利用队列实现树的层次遍历&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        myQueue = []</span><br><span class="line">        node = root</span><br><span class="line">        myQueue.append(node)</span><br><span class="line">        <span class="keyword">while</span> myQueue:</span><br><span class="line">            node = myQueue.pop(<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">print</span> node.elem,</span><br><span class="line">            <span class="keyword">if</span> node.lchild != <span class="literal">None</span>:</span><br><span class="line">                myQueue.append(node.lchild)</span><br><span class="line">            <span class="keyword">if</span> node.rchild != <span class="literal">None</span>:</span><br><span class="line">                myQueue.append(node.rchild)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;主函数&quot;&quot;&quot;</span></span><br><span class="line">    elems = <span class="built_in">range</span>(<span class="number">10</span>)           <span class="comment">#生成十个数据作为树节点</span></span><br><span class="line">    tree = Tree()          <span class="comment">#新建一个树对象</span></span><br><span class="line">    <span class="keyword">for</span> elem <span class="keyword">in</span> elems:                  </span><br><span class="line">        tree.add(elem)           <span class="comment">#逐个添加树的节点</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;队列实现层次遍历:&#x27;</span></span><br><span class="line">    tree.level_queue(tree.root)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n\n递归实现先序遍历:&#x27;</span></span><br><span class="line">    tree.front_digui(tree.root)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n递归实现中序遍历:&#x27;</span> </span><br><span class="line">    tree.middle_digui(tree.root)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n递归实现后序遍历:&#x27;</span></span><br><span class="line">    tree.later_digui(tree.root)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n\n堆栈实现先序遍历:&#x27;</span></span><br><span class="line">    tree.front_stack(tree.root)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n堆栈实现中序遍历:&#x27;</span></span><br><span class="line">    tree.middle_stack(tree.root)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n堆栈实现后序遍历:&#x27;</span></span><br><span class="line">    tree.later_stack(tree.root)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2017/05/04/Basic-Algorithms-in-Python/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>个人面经（百度、腾讯、鹏元数据、行云智能数据岗）</title>
      <link>http://example.com/2017/04/22/%E4%B8%AA%E4%BA%BA%E9%9D%A2%E7%BB%8F/</link>
      <guid>http://example.com/2017/04/22/%E4%B8%AA%E4%BA%BA%E9%9D%A2%E7%BB%8F/</guid>
      <pubDate>Sat, 22 Apr 2017 06:51:17 GMT</pubDate>
      
      <description>&lt;p&gt;记录自找工作以来个人的面试经历与一些思考。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>记录自找工作以来个人的面试经历与一些思考。</p><span id="more"></span><h2 id="百度数据挖掘一面（电话面）"><a href="#百度数据挖掘一面（电话面）" class="headerlink" title="百度数据挖掘一面（电话面）"></a>百度数据挖掘一面（电话面）</h2><ol><li>介绍项目</li><li>问题</li><li>基础知识：java的多态、map和垃圾回收</li><li>如何用网络知识让抢火车票更快</li><li>快排的思想、时间和空间复杂度、如果是整数排序有没有O(n)的解法</li><li>逻辑回归线性回归区别</li><li>linux怎么查看某文件当前被哪些进程访问</li><li>vim如何查找替换</li></ol><h2 id="百度运维一面（电话面）"><a href="#百度运维一面（电话面）" class="headerlink" title="百度运维一面（电话面）"></a>百度运维一面（电话面）</h2><ol><li>聊项目</li><li>python字符串的替换</li><li>SQL的优化</li><li>LInux 如何找进程杀进程</li></ol><h2 id="百度运维二面（现场面）"><a href="#百度运维二面（现场面）" class="headerlink" title="百度运维二面（现场面）"></a>百度运维二面（现场面）</h2><ol><li>聊项目</li><li>手写冒泡</li></ol><h2 id="行云智能一面（现场面）"><a href="#行云智能一面（现场面）" class="headerlink" title="行云智能一面（现场面）"></a>行云智能一面（现场面）</h2><p>遇到面试官是西电校友</p><ol><li>聊项目</li><li>CNN的思想：pooling的方式、卷积的思想</li><li>设计模式有什么了解</li><li>多线程多进程的了解</li><li>快排的思想</li><li>手写代码二叉树删除</li></ol><h2 id="中科乐创一面（现场面）"><a href="#中科乐创一面（现场面）" class="headerlink" title="中科乐创一面（现场面）"></a>中科乐创一面（现场面）</h2><p>最尴尬的一次，面试官是南洋理工的，聊了聊我的项目就似乎对我不感兴趣，就开始和我聊家常。。。</p><h2 id="鹏元数据一面（现场面）"><a href="#鹏元数据一面（现场面）" class="headerlink" title="鹏元数据一面（现场面）"></a>鹏元数据一面（现场面）</h2><ol><li>聊项目</li><li>做了张试卷如 </li></ol><ul><li>推导极大似然估计</li><li>聚类与分类区别，列举常用聚类算法及程序包</li><li>一些简单的SQL命令</li><li>编程题：列举一串数字内奇偶数出现次数及引申出的结合他们业务的评级转换矩阵的打印</li></ul><h2 id="腾讯基础研究一面（现场面）"><a href="#腾讯基础研究一面（现场面）" class="headerlink" title="腾讯基础研究一面（现场面）"></a>腾讯基础研究一面（现场面）</h2><ol><li>聊项目</li><li>聚类与分类区别，常用聚类算法<br>思考：诸如此类列举算法的问题，最好是迅速流利的列举出多个，不要有迟疑，不过对于其基本含义要有了解。</li><li>场景题，两个含有数字的文件，找出同时出现在两个文件内的数字；若文件太大放不进内存该怎么办？<br>思考：这种问题可小可大，可难可易。因为哪怕再小的问题在规模变大也就是涉及到大数据都是不简单的，这个问题，对于小文件，两三行代码即可搞定，那么你写出来之后，面试官基本上就会进一步问你：如果文件很大，无法同时把这两个文件装进内存，怎么办？我当时回答的是用Pandas的read_csv分块读取，这是个很不好的回答，因为掉包不是基本功。我回头想了想，也许这个答案是用generator比较好。</li></ol>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Interview/">Interview</category>
      
      
      <comments>http://example.com/2017/04/22/%E4%B8%AA%E4%BA%BA%E9%9D%A2%E7%BB%8F/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Ubuntu 16.04下为TITAN 1080 显卡安装驱动(Cuda&amp;CudNN)及Gpu版TensorFlow</title>
      <link>http://example.com/2017/04/20/Ubuntu-16-04%E4%B8%8B%E4%B8%BATITAN-1080-%E6%98%BE%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8-Cuda-CudNN-%E5%8F%8AGpu%E7%89%88TensorFlow/</link>
      <guid>http://example.com/2017/04/20/Ubuntu-16-04%E4%B8%8B%E4%B8%BATITAN-1080-%E6%98%BE%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8-Cuda-CudNN-%E5%8F%8AGpu%E7%89%88TensorFlow/</guid>
      <pubDate>Thu, 20 Apr 2017 01:29:22 GMT</pubDate>
      
      <description>&lt;p&gt;近来入坑了TITAN 1080显卡，在Ubuntu 16.04下为装好驱动以使用Gpu版TensorFlow可不简单，踩了许多坑之后写下此篇为记录。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>近来入坑了TITAN 1080显卡，在Ubuntu 16.04下为装好驱动以使用Gpu版TensorFlow可不简单，踩了许多坑之后写下此篇为记录。</p><span id="more"></span><h1 id="下载Cuda"><a href="#下载Cuda" class="headerlink" title="下载Cuda"></a>下载Cuda</h1><p>按装官方教程，我们可以应该安装Cuda8.0和Cudnn V5.1，在此下载<a href="https://developer.nvidia.com/cuda-downloads">CUDA 8.0 Downloads | NVIDIA Developer</a></p><p><img src="/images/2017/04/3864914136-589146eda380f_articlex.png"></p><p>在这里最好选runfile local，因为选deb的话会遇到apt get的源损坏问题。</p><h1 id="降级gcc和g"><a href="#降级gcc和g" class="headerlink" title="降级gcc和g++"></a>降级gcc和g++</h1><p>由于Cuda不支持新版本的gcc和g++，所以如果建议先降级到4版本，方法见<a href="http://m.blog.csdn.net/article/details?id=48135125">ubuntu 中 gcc/g++版本降级</a></p><h1 id="安装显卡驱动"><a href="#安装显卡驱动" class="headerlink" title="安装显卡驱动"></a>安装显卡驱动</h1><p><code>sudo apt-get install nvidia-367</code></p><h1 id="安装Cuda"><a href="#安装Cuda" class="headerlink" title="安装Cuda"></a>安装Cuda</h1><h2 id="关闭你的图形界面"><a href="#关闭你的图形界面" class="headerlink" title="关闭你的图形界面"></a>关闭你的图形界面</h2><p><code>sudo service lightdm stop</code></p><p>此时电脑应该会黑屏，</p><p><code>CTRL + ALT + F1</code>进入命令行，登录，cd 到你存放下载的目录，执行</p><p><code>sudo bash cuda_8.0.44_linux.run</code></p><p>然后你会看到如<br><code>Do you accept the previously read EULA?accept/decline/quit: </code> 输入<code>accept</code></p><p><code>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 3xx.xx?</code> 输入 <code>no</code></p><p>之后还会问你是否安装<code>X configuration</code> 输入<code>no</code></p><p>安装好了之后，再用命令<code>sudo bash cuda_8.0.44_linux.run -slient -driver</code> 来安装驱动。</p><p>最后<code>sudo service lightdm start</code>或者重启。</p><h2 id="设置Cuda环境变量"><a href="#设置Cuda环境变量" class="headerlink" title="设置Cuda环境变量"></a>设置Cuda环境变量</h2><p><code>sudo vi ~/.bashrc</code></p><p>添加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=&quot;$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64&quot;</span><br><span class="line">export CUDA_HOME=/usr/local/cuda-8.0</span><br></pre></td></tr></table></figure><p>保存退出</p><p>再<code>source  .bashrc</code></p><h1 id="Cudnn-安装"><a href="#Cudnn-安装" class="headerlink" title="Cudnn 安装"></a>Cudnn 安装</h1><h2 id="下载Cudnn"><a href="#下载Cudnn" class="headerlink" title="下载Cudnn"></a>下载Cudnn</h2><p>在此处下载：<a href="https://developer.nvidia.com/rdp/cudnn-download">Membership Required | NVIDIA Developer</a>，这里你先得注册一个NVIDA账号，填写一堆问卷。<br>有两种方法，一是deb安装包，二是下载tar</p><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>选择 Download cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0下载<br>cuDNN v5.1 Runtime Library for Ubuntu16.04 Power8 (Deb)安装</p><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>二是下载tar，解压后会得到一个Cuda文件夹，复制到Cuda-8.0文件夹中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda-8.0/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda-8.0/lib64</span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn*</span><br></pre></td></tr></table></figure><h1 id="安装TensorFlow"><a href="#安装TensorFlow" class="headerlink" title="安装TensorFlow"></a>安装TensorFlow</h1><p>这里我们使用Anaconda装Python3，</p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>下载好安装脚本之后，<br><code>bash ~/Downloads/Anaconda3-4.3.0-Linux-x86_64.sh</code>安装，记得在询问是否添加PATH时选择<code>yes</code></p><p><code>pip install tensorflow-gpu</code></p><h2 id="建立虚拟环境"><a href="#建立虚拟环境" class="headerlink" title="建立虚拟环境"></a>建立虚拟环境</h2><p>新建环境<code>conda create -n tensorflow</code><br>激活环境<code>source activate tensorflow</code><br>此时已处于此环境下</p><h2 id="安装TensorFlow-1"><a href="#安装TensorFlow-1" class="headerlink" title="安装TensorFlow"></a>安装TensorFlow</h2><p><code>conda install tensorflow-gpu</code><br>这里Anaconda会自动安装依赖，直到全部完成</p><h1 id="测试TF"><a href="#测试TF" class="headerlink" title="测试TF"></a>测试TF</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello = tf.constant(<span class="string">&#x27;Hello, TensorFlow!&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sess = tf.Session()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sess.run(hello))</span><br><span class="line">Hello, TensorFlow!</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = tf.constant(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = tf.constant(<span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sess.run(a + b))</span><br><span class="line"><span class="number">42</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p>若打印一系列包含Gpu信息的说明，恭喜你，安装成功！！！</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/TensorFlow/">TensorFlow</category>
      
      
      <comments>http://example.com/2017/04/20/Ubuntu-16-04%E4%B8%8B%E4%B8%BATITAN-1080-%E6%98%BE%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8-Cuda-CudNN-%E5%8F%8AGpu%E7%89%88TensorFlow/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>创建双击可执行的sh脚本</title>
      <link>http://example.com/2017/04/19/%E5%88%9B%E5%BB%BA%E5%8F%8C%E5%87%BB%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9A%84sh%E8%84%9A%E6%9C%AC/</link>
      <guid>http://example.com/2017/04/19/%E5%88%9B%E5%BB%BA%E5%8F%8C%E5%87%BB%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9A%84sh%E8%84%9A%E6%9C%AC/</guid>
      <pubDate>Wed, 19 Apr 2017 01:36:49 GMT</pubDate>
      
      <description>&lt;p&gt;在Mac&amp;amp;Linux上创建双击可执行的sh脚本的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在Mac&amp;Linux上创建双击可执行的sh脚本的方法。</p><span id="more"></span><h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><p>首先创建测试脚本<br><code>touch clickexe.sh</code><br><code>open -e clickexe.sh</code><br>在脚本中输入内容<br><code>echo &quot;hello world&quot;</code></p><p>再执行命令<br><code>chmod +x clickexe.sh</code></p><p>然后在取景器右键单击文件，并选择“get<br> info”，然后选择“Open with” </p><p>这里你可以选择你想要的文件执行到应用程序中，为了能够选择你需要从“推荐应用”到“所有应用程序”选中“Terminal”即可。</p><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>在Ubuntu中，自从13.04以后，双击sh脚本文件就已经默认是geidt打开了，要想运行，从文件管理器–&gt;文件–&gt;首选项–&gt;行为–&gt;可执行文件</p><p>有三个选项，默认是第二个，如果想要直接运行，选第一个，而每次询问就是弹出一个窗口，问你是运行，在终端中运行，还是用gedit查看。</p><p>记得在脚本文件右键–&gt;属性–&gt;权限：允许以程序执行文件</p><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="http://www.cnblogs.com/Findxiaoxun/p/3558994.html">ubuntu sh脚本双击运行 - Findxiaoxun - 博客园</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      <category domain="http://example.com/tags/Mac/">Mac</category>
      
      <category domain="http://example.com/tags/bash/">bash</category>
      
      
      <comments>http://example.com/2017/04/19/%E5%88%9B%E5%BB%BA%E5%8F%8C%E5%87%BB%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%9A%84sh%E8%84%9A%E6%9C%AC/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Python2 Python3的各种冲突及解决方法</title>
      <link>http://example.com/2017/04/18/Python3-%E5%AE%89%E8%A3%85opencv%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95/</link>
      <guid>http://example.com/2017/04/18/Python3-%E5%AE%89%E8%A3%85opencv%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95/</guid>
      <pubDate>Tue, 18 Apr 2017 09:52:06 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要记录Python2 Python3的各种冲突及解决方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要记录Python2 Python3的各种冲突及解决方法。</p><span id="more"></span><h2 id="Opencv在Python3下的安装"><a href="#Opencv在Python3下的安装" class="headerlink" title="Opencv在Python3下的安装"></a>Opencv在Python3下的安装</h2><p>目前opencv对于Python2.7支持不错，我折腾了许久才弄好Python3下的安装方法，最简单的既是利用Anaconda<br>来安装，步骤如</p><ol><li>安装Anaconda下载对应平台的安装包<a href="https://www.continuum.io/downloads">Download Anaconda Now! | Continuum</a></li><li>下载完毕，用终端命令安装刚下的包<code>bash Anaconda3-4.3.0-MacOSX-x86_64.sh</code></li><li>命令行会询问是否需要添加PATH如<code>.bash_profile &gt;&gt; </code>填<code> yes</code></li><li>刷新 <code>cd &amp;&amp; source .bash_profile</code></li><li>检测安装位置<code>check python</code>，结果若是<code>$ which python $ /.../anaconda/bin/python</code>则OK</li><li>最后用这条命令安装<code>pip install opencv-pyhton</code>（不需要pip3）</li></ol><h2 id="urlparse"><a href="#urlparse" class="headerlink" title="urlparse"></a>urlparse</h2><p><code>import urlparse</code> 需要变为 <code>import urllib.parse as urlparse</code></p><h2 id="整数相除"><a href="#整数相除" class="headerlink" title="整数相除"></a>整数相除</h2><p>python2的 <code>/</code> 等价于3里的 <code>//</code></p><h2 id="map-与-zip"><a href="#map-与-zip" class="headerlink" title="map 与 zip"></a>map 与 zip</h2><p>Python3里的map与zip返回生成器，所以需要将list(map(func, b))， list(zip(a,b))之后才可以按下标访问。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2017/04/18/Python3-%E5%AE%89%E8%A3%85opencv%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>programmer humor week 2</title>
      <link>http://example.com/2017/04/17/programmer-humor-week-2/</link>
      <guid>http://example.com/2017/04/17/programmer-humor-week-2/</guid>
      <pubDate>Mon, 17 Apr 2017 09:58:39 GMT</pubDate>
      
      <description>&lt;p&gt;programmer humor from reddit 🤣😂😜&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>programmer humor from reddit 🤣😂😜</p><span id="more"></span><h3 id="“Hey-you-know-Binary-Search-Trees-”-“Say-no-more-”"><a href="#“Hey-you-know-Binary-Search-Trees-”-“Say-no-more-”" class="headerlink" title="“Hey, you know Binary Search Trees?” “Say no more.”"></a>“Hey, you know Binary Search Trees?” “Say no more.”</h3><p><img src="/images/2017/04/05.jpg"></p><h3 id="After-setting-up-a-new-floor-on-campus…"><a href="#After-setting-up-a-new-floor-on-campus…" class="headerlink" title="After setting up a new floor on campus…"></a>After setting up a new floor on campus…</h3><p><img src="/images/2017/04/06.jpg"></p><h3 id="Logins-should-be-unique"><a href="#Logins-should-be-unique" class="headerlink" title="Logins should be unique"></a>Logins should be unique</h3><p><img src="/images/2017/04/07.png"></p><h3 id="Cringe-How-to-do-coding"><a href="#Cringe-How-to-do-coding" class="headerlink" title="[Cringe] How to do coding"></a>[Cringe] How to do coding</h3><p><img src="/images/2017/04/08.jpg"></p><h3 id="How-to-learn-coding-in-a-single-night"><a href="#How-to-learn-coding-in-a-single-night" class="headerlink" title="How to learn coding in a single night."></a>How to learn coding in a single night.</h3><p><img src="/images/2017/04/09.jpg"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><p><a href="https://www.reddit.com/r/ProgrammerHumor/">Programmer Humor</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Funny/">Funny</category>
      
      
      <comments>http://example.com/2017/04/17/programmer-humor-week-2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>利用git 同步本地与服务器代码</title>
      <link>http://example.com/2017/04/13/%E5%88%A9%E7%94%A8git-%E5%90%8C%E6%AD%A5%E6%9C%AC%E5%9C%B0%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%A0%81/</link>
      <guid>http://example.com/2017/04/13/%E5%88%A9%E7%94%A8git-%E5%90%8C%E6%AD%A5%E6%9C%AC%E5%9C%B0%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%A0%81/</guid>
      <pubDate>Wed, 12 Apr 2017 16:53:49 GMT</pubDate>
      
      <description>&lt;p&gt;在服务器端直接用vim写代码固然不是个好体验，本文介绍用git在两者之间同步的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在服务器端直接用vim写代码固然不是个好体验，本文介绍用git在两者之间同步的方法。</p><span id="more"></span><h2 id="免认证登录"><a href="#免认证登录" class="headerlink" title="免认证登录"></a>免认证登录</h2><p>先设置ssh公钥私钥来免密码登录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/.ssh</span><br><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;mail@domain.com&quot;</span></span><br></pre></td></tr></table></figure><p>复制过去</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub user@vps:./</span><br><span class="line">ssh user@vps</span><br><span class="line">cat id_rsa.pub &gt;&gt; /home/user/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>注意cat 后是&gt;&gt; 不是&gt;，前者是追加，后者是覆盖。<br>若22端口不能使用，可以通过<code>-P port_number</code>指定使用的端口号</p><h2 id="进入服务器项目"><a href="#进入服务器项目" class="headerlink" title="进入服务器项目"></a>进入服务器项目</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ssh user@vps  </span><br><span class="line">cd /home/project</span><br><span class="line">git init</span><br><span class="line">echo &quot;hello&quot; &gt;&gt; README</span><br><span class="line">git add README</span><br><span class="line">git commit -m &quot;add README&quot;</span><br><span class="line">exit</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在本机上把项目 Clone 下来：</p><p>git clone user@vps:/home/project</p><p>若22端口不能使用，可以执行：</p><p>git clone ssh://user@vps:1280/home/project</p><h2 id="修改钩子使其接受push"><a href="#修改钩子使其接受push" class="headerlink" title="修改钩子使其接受push"></a>修改钩子使其接受push</h2><p>在服务器端<br><code>git config receive.denyCurrentBranch ignore</code></p><p>编辑 VPS 端 Git 钩子.git/hooks/post-receive 文件，内容为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">cd ..</span><br><span class="line">env -i git reset --hard</span><br></pre></td></tr></table></figure><p>最后将文件设置为可执行：<br><code>chmod a+x .git/hooks/post-receive</code></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/04/13/%E5%88%A9%E7%94%A8git-%E5%90%8C%E6%AD%A5%E6%9C%AC%E5%9C%B0%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BB%A3%E7%A0%81/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>利用Pandas读取远程mysql数据库</title>
      <link>http://example.com/2017/04/11/%E5%88%A9%E7%94%A8Pandas%E8%AF%BB%E5%8F%96%E8%BF%9C%E7%A8%8Bmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <guid>http://example.com/2017/04/11/%E5%88%A9%E7%94%A8Pandas%E8%AF%BB%E5%8F%96%E8%BF%9C%E7%A8%8Bmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <pubDate>Tue, 11 Apr 2017 09:31:49 GMT</pubDate>
      
      <description>&lt;p&gt;利用pymysql与Pandas读取远程数据库上的表格，并存储为本地csv文件。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>利用pymysql与Pandas读取远程数据库上的表格，并存储为本地csv文件。</p><span id="more"></span><p>因为业务需要读取服务器上的数据进行分析，能连接到sql服务器，但是当我企图用mysqldump备份（复制）database到本地却经常出现<code>mysqldump: Error 2013: Lost connection to MySQL server during query when dumping table</code>错误，这个需要改<code>net_write_timeout</code>来增加等待时长来解决，苦于我的账号并没有权限，难不成只好之间上sql用odbs大法直接做数据分析？我的天，那得多麻烦，经过几番思考，我的解决方案是：用sql的python接口包pymysql进行sql登录以及操作，再用Pandas以DataFrame格式接受table数据，最后存为csv文件。</p><h2 id="登录模块"><a href="#登录模块" class="headerlink" title="登录模块"></a>登录模块</h2><p>注意，若数据库含有中文，需要<code>use_unicode=True</code>避免乱码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*_coding:utf8-*-</span></span><br><span class="line"><span class="comment"># Created by frank at 07/04/2017</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line">host = <span class="string">&#x27;#########&#x27;</span></span><br><span class="line">port = <span class="comment">####</span></span><br><span class="line">user = <span class="string">&#x27;########&#x27;</span></span><br><span class="line">password = <span class="string">&#x27;#######&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_database</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: return the pre-connect database</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    connection = pymysql.connect(host=host,</span><br><span class="line">                         user=user,</span><br><span class="line">                         password=password,</span><br><span class="line">                         port=port,</span><br><span class="line">                         charset=<span class="string">&#x27;utf8mb4&#x27;</span>,</span><br><span class="line">                         use_unicode=<span class="literal">True</span>,)</span><br><span class="line">    <span class="keyword">return</span> connection</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="处理模块"><a href="#处理模块" class="headerlink" title="处理模块"></a>处理模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*_coding:utf8-*-</span></span><br><span class="line"><span class="comment"># Created by frank at 07/04/2017</span></span><br><span class="line"><span class="comment"># 连接数据库</span></span><br><span class="line"><span class="keyword">from</span> connection <span class="keyword">import</span> get_database</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行sql命令，打印返回结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">sql_command</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> connection.cursor() <span class="keyword">as</span> cursor:</span><br><span class="line">            cursor.execute(sql_command)</span><br><span class="line">            result = cursor.fetchall()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;COMMAND: &quot;</span>, sql_command)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;RESULT: &quot;</span>, result)         </span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line">            dic[sql_command] = result</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Command %s failed!&quot;</span> % sql_command)</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立连接</span></span><br><span class="line">connection = get_database()</span><br><span class="line">connection.commit()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存放命令与对应结果，便于之后调试</span></span><br><span class="line">dic = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL 查询语句</span></span><br><span class="line">sql_commands = [</span><br><span class="line"><span class="comment"># &quot;SHOW DATABASES;&quot;,</span></span><br><span class="line"><span class="string">&quot;use wind_data;&quot;</span>,</span><br><span class="line"><span class="comment"># &quot;show tables;&quot;,</span></span><br><span class="line"><span class="comment"># &quot;SHOW COLUMNS FROM absdescription;&quot;,</span></span><br><span class="line"><span class="comment"># &quot;SHOW COLUMNS FROM absdescription2;&quot;,</span></span><br><span class="line"><span class="comment"># &quot;SHOW COLUMNS FROM ashareagency;&quot;</span></span><br><span class="line"><span class="comment"># &quot;select * from absdescription;&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;select count(*) from absdescription;&quot;</span></span><br><span class="line"><span class="comment">#     &quot;SHOW COLUMNS FROM xcashflow;&quot;,</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sql_command <span class="keyword">in</span> sql_commands:</span><br><span class="line">    execute(sql_command)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有table名字存于list</span></span><br><span class="line">tables = []</span><br><span class="line">l = <span class="built_in">list</span>(dic[<span class="string">&quot;show tables;&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> l:</span><br><span class="line">    tables.append(i[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取得所有table，分别存放于csv文件</span></span><br><span class="line"><span class="keyword">for</span> table <span class="keyword">in</span> tables:</span><br><span class="line"><span class="comment">#     table = &#x27;absdescription&#x27;</span></span><br><span class="line">    sql_cmd = <span class="string">&quot;select * from %s&quot;</span> % table</span><br><span class="line"></span><br><span class="line">    df = pd.read_sql(sql=sql_cmd, con=connection)</span><br><span class="line"></span><br><span class="line">    df.to_csv(<span class="string">&quot;data/%s.csv&quot;</span> % table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 断开连接</span></span><br><span class="line">connection.close()       </span><br></pre></td></tr></table></figure><h2 id="参考自"><a href="#参考自" class="headerlink" title="参考自"></a>参考自</h2><ul><li><a href="http://www.jianshu.com/p/2dbf454a386e">mysqldump 错误2013 Lost connection - 简书</a></li><li><a href="http://www.ttlsa.com/mysql/mysql-common-error-analysis-and-solution-methods/">MySQL常见错误分析与解决方法总结 - 运维生存时间</a></li><li><a href="http://www.cnblogs.com/arkenstone/p/6271923.html">Python中从SQL型数据库读写dataframe型数据 - Arkenstone - 博客园</a></li><li><a href="http://jingyan.baidu.com/article/eae0782785a4c21fec548525.html">pandas教程：[19]读写sql数据库_百度经验</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/SQL/">SQL</category>
      
      <category domain="http://example.com/tags/Pandas/">Pandas</category>
      
      
      <comments>http://example.com/2017/04/11/%E5%88%A9%E7%94%A8Pandas%E8%AF%BB%E5%8F%96%E8%BF%9C%E7%A8%8Bmysql%E6%95%B0%E6%8D%AE%E5%BA%93/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Data Science cheatsheet</title>
      <link>http://example.com/2017/04/05/machine-learning-cheat-sheet/</link>
      <guid>http://example.com/2017/04/05/machine-learning-cheat-sheet/</guid>
      <pubDate>Wed, 05 Apr 2017 08:45:56 GMT</pubDate>
      
      <description>&lt;p&gt;记录若干关于数据科学的cheatsheet&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>记录若干关于数据科学的cheatsheet</p><span id="more"></span><h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><p><img src="/images/2017/04/Pandas_Cheat_Sheet/Slide1.bmp"><br><img src="/images/2017/04/Pandas_Cheat_Sheet/Slide2.bmp"></p><h2 id="Sklearn"><a href="#Sklearn" class="headerlink" title="Sklearn"></a>Sklearn</h2><p><img src="/images/2017/04/drop_shadows_background.png"></p><h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p><img src="/images/2017/04/conda-cheatsheet-1/conda-cheatsheet-1.jpg"><br><img src="/images/2017/04/conda-cheatsheet-1/conda-cheatsheet-2.jpg"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><ul><li><p><a href="https://github.com/scikit-learn/scikit-learn/blob/4d9a12d175a38f2bcb720389ad2213f71a3d7697/doc/themes/scikit-learn/static/ML_MAPS_README.rst">scikit-learn/ML_MAPS_README.rst at 4d9a12d175a38f2bcb720389ad2213f71a3d7697 · scikit-learn/scikit-learn</a></p></li><li><p><a href="https://github.com/pandas-dev/pandas/tree/master/doc/cheatsheet">pandas/doc/cheatsheet at master · pandas-dev/pandas</a></p></li><li><p><a href="https://conda.io/docs/using/cheatsheet.html">Conda cheat sheet — Conda documentation</a></p></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Machine-Learning/">Machine Learning</category>
      
      
      <comments>http://example.com/2017/04/05/machine-learning-cheat-sheet/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>programmer humor week 1</title>
      <link>http://example.com/2017/04/01/programmer-humor-week-1/</link>
      <guid>http://example.com/2017/04/01/programmer-humor-week-1/</guid>
      <pubDate>Sat, 01 Apr 2017 09:58:39 GMT</pubDate>
      
      <description>&lt;p&gt;programmer humor from reddit 🤣😂😜&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>programmer humor from reddit 🤣😂😜</p><span id="more"></span><h3 id="How-OS-fanboys-and-girls-meet"><a href="#How-OS-fanboys-and-girls-meet" class="headerlink" title="How OS fanboys (and girls) meet"></a>How OS fanboys (and girls) meet</h3><p><img src="/images/2017/04/00.jpg"></p><h3 id="The-doors-at-work-are-version-controlled"><a href="#The-doors-at-work-are-version-controlled" class="headerlink" title="The doors at work are version-controlled."></a>The doors at work are version-controlled.</h3><p><img src="/images/2017/04/01.jpg"></p><h3 id="5-word-horror-story"><a href="#5-word-horror-story" class="headerlink" title="5 word horror story"></a>5 word horror story</h3><p><img src="/images/2017/04/02.png"></p><h3 id="Windows-has-a-built-in-java-code-optimizer-with-a-simple-drag-and-drop-interface"><a href="#Windows-has-a-built-in-java-code-optimizer-with-a-simple-drag-and-drop-interface" class="headerlink" title="Windows has a built-in java code optimizer with a simple drag-and-drop interface"></a>Windows has a built-in java code optimizer with a simple drag-and-drop interface</h3><p><img src="/images/2017/04/03.png"></p><h3 id="GitHub-The-place-where-I-fork"><a href="#GitHub-The-place-where-I-fork" class="headerlink" title="GitHub. The place where I fork."></a>GitHub. The place where I fork.</h3><p><img src="/images/2017/04/04.png"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><p><a href="https://www.reddit.com/r/ProgrammerHumor/">Programmer Humor</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Funny/">Funny</category>
      
      
      <comments>http://example.com/2017/04/01/programmer-humor-week-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Learn More,Study Less</title>
      <link>http://example.com/2017/03/26/learn%20more%20study%20less/</link>
      <guid>http://example.com/2017/03/26/learn%20more%20study%20less/</guid>
      <pubDate>Sun, 26 Mar 2017 07:11:56 GMT</pubDate>
      
      <description>&lt;p&gt;关于learn more study less 的思维导图  &lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>关于learn more study less 的思维导图  </p><span id="more"></span><p>![](/images/2017/03/learn more study less 15.45.08.png)</p><h2 id="holistic-learning-的流程"><a href="#holistic-learning-的流程" class="headerlink" title="holistic learning 的流程"></a>holistic learning 的流程</h2><h3 id="Acquire-获取"><a href="#Acquire-获取" class="headerlink" title="Acquire 获取"></a>Acquire 获取</h3><ul><li>准确、精炼地得到信息  </li><li>简化  <ul><li>提取精华、略去无用信息  </li></ul></li><li>容量  <ul><li>知道的信息越多越好  </li></ul></li><li>速度  <ul><li>尽快完成获取阶段  </li></ul></li></ul><h3 id="Understand-理解"><a href="#Understand-理解" class="headerlink" title="Understand 理解"></a>Understand 理解</h3><ul><li>了解信息的基本意思，并联系上下文来理解  </li><li>理解信息的第一阶段：理解信息的表层含义  <ul><li>当遇到不明白之处，应该分解问题，找到真正不明白之处  </li></ul></li></ul><h3 id="Explore-扩展"><a href="#Explore-扩展" class="headerlink" title="Explore 扩展"></a>Explore 扩展</h3><ul><li>形成高速公路、模型及内部联系良好的结构  </li><li>深度扩展  <ul><li>知识的由来、背景的探究  </li></ul></li><li>横向扩展  <ul><li>构造模型：寻找类似的知识的联系  </li></ul></li><li>纵向扩展  <ul><li>创建高速公路：跨学科、跨领域的知识联系  <ul><li>最重要、最有挑战性的扩展方法，有益于创造性思考  </li><li>比喻metaphor  </li><li>内在法visceralization  <ul><li><a href="https://www.scotthyoung.com/learnonsteroids/grab/Visceralization-GettingStarted.pdf"> Getting Started with Visceralization </a>  </li></ul></li></ul></li></ul></li></ul><h3 id="Test-测试"><a href="#Test-测试" class="headerlink" title="Test 测试"></a>Test 测试</h3><h3 id="Debug纠错"><a href="#Debug纠错" class="headerlink" title="Debug纠错"></a>Debug纠错</h3><ul><li>在模型和高速公路中寻找改正错误  </li><li>知识网络的修剪，添加特殊例子，删减错误的联系等  <ul><li>阅读与你观点相反的书籍  </li><li>将你的知识放入现实世界来观察等  </li></ul></li></ul><h3 id="Apply-应用"><a href="#Apply-应用" class="headerlink" title="Apply 应用"></a>Apply 应用</h3><ul><li>创造新途径，将所学知识知识应用起来，这是学习的最终目的  </li><li>通过比较知识如何在现实中应用来调整，防止成为“书呆子”  </li></ul><h2 id="找出自己的薄弱环节"><a href="#找出自己的薄弱环节" class="headerlink" title="找出自己的薄弱环节"></a>找出自己的薄弱环节</h2><h3 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h3><ul><li>症状  <ul><li>阅读和听讲速度慢  </li><li>需要反复阅读  </li></ul></li><li>原因  <ul><li>阅读/学习习惯不好  </li><li>记笔记习惯不好  </li><li>不理解基本概念、术语  </li></ul></li><li>解决  <ul><li>养成良好的学习、阅读和记笔记的习惯  </li></ul></li></ul><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><ul><li>表现  <ul><li>阅读时不明白作者意思  </li><li>笔记很完善，却不明白其含义  </li></ul></li><li>解决  <ul><li>放慢阅读速度，寻找其他资料，以求得更加详细，另一角度的阐述  <ul><li>基本的理解是后续高级技巧的基石  </li></ul></li></ul></li></ul><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul><li>表现  <ul><li>缺少灵活性  <ul><li>已经掌握了一个新东西，但是没有或不会将 它与其他学过的知识联系起来，假如让你用这个新的知识去解决一个非常规问题，就常常束手无策。  </li></ul></li></ul></li></ul><h3 id="纠错"><a href="#纠错" class="headerlink" title="纠错"></a>纠错</h3><ul><li>表现  <ul><li>错误联系太多  </li><li>在课堂上很少出现，而在实际世界中却很普遍  <ul><li>课堂上人们很少去扩展：发生错误机会少  </li><li>实际中人们经常想出各种联系，却不验证这些联系是否正确：各种迷信的产生  </li></ul></li></ul></li></ul><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ul><li>表现  <ul><li>不能在真实世界中很好地运用知识  </li></ul></li><li>解决  <ul><li>更多的实践，抛开书本，走出去，去做实验，去接触生活，去融入社会  </li></ul></li></ul><h2 id="holistic-learning-techniques"><a href="#holistic-learning-techniques" class="headerlink" title="holistic  learning techniques"></a>holistic  learning techniques</h2><h3 id="获取知识"><a href="#获取知识" class="headerlink" title="获取知识"></a>获取知识</h3><ul><li>快速阅读法  <ul><li>指读法  <ul><li>用食指放在你要读的那一行下面，不断移动食指  </li></ul></li><li>练习阅读  <ul><li>对比指读法与常规读法，测试阅读速度提高潜力  </li><li>对比先读后记与边读边记来测试理解能力  </li></ul></li><li>积极阅读  <ul><li>边读边记笔记  <ul><li>这一节中主要点是什么？  <ul><li>是否完整地获取信息  </li></ul></li><li>我怎样才能记住主要点？  <ul><li>联系信息，视觉化和比喻法  </li></ul></li><li>我要怎样将主要点拓展开以及应用它  <ul><li>将信息应用在不同的情境中  </li></ul></li></ul></li></ul></li></ul></li><li>流笔记法  <ul><li>重点在于提取主要信息，删减次要信息，重点记录联系和按照你理解的方式给信息分类  </li><li>用很短的单词来记下最主要的观点  </li><li>在相联系的观点之间划上一些箭头  </li></ul></li></ul><h3 id="理解与扩展"><a href="#理解与扩展" class="headerlink" title="理解与扩展"></a>理解与扩展</h3><ul><li><p>关键信息  </p><ul><li><p>学习其他知识的基础，与之后的信息关系极强，对于之后的理解至关重要  </p></li><li><p>比喻  </p><ul><li>要点：不熟悉的知识和熟悉的知识联系起来  <ul><li>确定你要深入理解和记忆信息  </li><li>在你的个人经验中寻找与信息部分相似的东西，不求达到完全符合，可找到多个部分符合的“不完美比喻”。  </li><li>重复上述过程，检查比喻不恰当的地方  </li></ul></li><li>运用技巧：要有寻找比喻的欲望  <ul><li>遇到有理解困难的知识，首先应想到比喻  </li><li>注意第一个出现在脑海中的念头  </li><li>优化和测试你的比喻  <ul><li>多找几个不同角度的比喻  </li></ul></li></ul></li><li>抽象信息较适合比喻  </li></ul></li><li><p>内在化  </p><ul><li>调动更多的感知、情感与知识联系在一起，形成强联系  <ul><li>视觉  </li><li>听觉  </li><li>运动  </li><li>情感  </li></ul></li><li>步骤  <ul><li>明确要内在化概念  </li><li>从建立脑海中的静态图像开始  </li><li>将脑海中的静态图像转换为栩栩如生的动态场景  </li><li>加上其他感官，试着用手去拿，去摸，去打它，去嗅它的味道，去听它的声音，动用你身体的所有感官，将所有的感觉与运动的图像相联系。  </li><li>加入更多的感觉或情感  </li><li>不断重复和优化图像  </li></ul></li><li>具体信息较适合内在化  </li></ul></li><li><p>简图法  </p><ul><li><p>简图与比喻和内在化结合在一起  </p><p>  简图可以和比喻及内在化混合在一起，以加深对知识的理解  </p></li><li><p>流简图  </p><ul><li>从一个简单的元素开始，然后在这个成分及与之相联系的不同知识之间 画出联系箭头  </li></ul></li><li><p>概念图  </p><ul><li>将观点联系在一起，与流笔记密切相关。概念图里的关系观点之间的内在关系，在不同观点之间画上箭头， 箭头上还需要加上一些简单的话语  </li></ul></li><li><p>图像简图  </p><ul><li>粗糙简单的涂鸦来代替文字  </li></ul></li></ul></li></ul></li><li><p>困难信息  </p><ul><li>联想法  <ul><li>将一系列观点串在一起，就像链条  </li><li>步骤  <ul><li>创造顺序  <ul><li>先在纸上写下你打算记住的很多信息，在你能理解的前提下，迅速地将信息分成几个类 别  </li></ul></li><li>设计符号  <ul><li>要能迅速让你联想到原始的知识  </li></ul></li><li>创建属于自己的联想  <ul><li>发挥想象力，把符号之间连接起来  </li></ul></li></ul></li><li>难点  <ul><li>符号重复  <ul><li>可以尝试不同颜色来区分  </li></ul></li><li>断裂的联系  <ul><li>符号串不宜太长  </li></ul></li><li>难以辨认的符号  <ul><li>用只有自己能懂的很好，但是一定不能让自己迷惑  </li></ul></li><li>触发物丢失  <ul><li>防止记不起第一个：增加中第一项和触发物之间的联想  </li></ul></li></ul></li></ul></li><li>抽象信息、随意信息，关联程度不强  </li></ul></li></ul><h2 id="信息的结构"><a href="#信息的结构" class="headerlink" title="信息的结构"></a>信息的结构</h2><h3 id="随意信息"><a href="#随意信息" class="headerlink" title="随意信息"></a>随意信息</h3><ul><li>特点  <ul><li>缺少内在逻辑联系，需要死记硬背的知识  </li></ul></li><li>方法  <ul><li>着力去寻找知识点之间的联系  </li></ul></li></ul><h3 id="观点信息"><a href="#观点信息" class="headerlink" title="观点信息"></a>观点信息</h3><ul><li>特点  <ul><li>存在争议的信息  </li></ul></li><li>方法  <ul><li>在获取阶段，快速检索大量信息：找寻其中的模式（不记忆具体细节）  <ul><li>速读  </li><li>图示：以加强对比以提取模式，增进理解  </li></ul></li></ul></li></ul><h3 id="大多数学科都是这几种信息不同比例的组合"><a href="#大多数学科都是这几种信息不同比例的组合" class="headerlink" title="大多数学科都是这几种信息不同比例的组合"></a>大多数学科都是这几种信息不同比例的组合</h3><h3 id="过程信息"><a href="#过程信息" class="headerlink" title="过程信息"></a>过程信息</h3><ul><li>特点  <ul><li>教导如何行动，一系列操作的集合  </li></ul></li><li>方法  <ul><li>打造良好的结构与模型：加速过程信息的学习  <ul><li>需要大量时间投入练习  </li></ul></li></ul></li></ul><h3 id="具体信息"><a href="#具体信息" class="headerlink" title="具体信息"></a>具体信息</h3><ul><li>特点  <ul><li>能与感官、实际相联系的信息  </li></ul></li><li>方法  <ul><li>内在化：有助于你将信息与多个感 官相联系  </li></ul></li></ul><h3 id="运用各种方法找寻信息之间的联系：以把弱结构的信息转化为强结构的信息"><a href="#运用各种方法找寻信息之间的联系：以把弱结构的信息转化为强结构的信息" class="headerlink" title="运用各种方法找寻信息之间的联系：以把弱结构的信息转化为强结构的信息"></a>运用各种方法找寻信息之间的联系：以把弱结构的信息转化为强结构的信息</h3><h3 id="抽象信息"><a href="#抽象信息" class="headerlink" title="抽象信息"></a>抽象信息</h3><ul><li>特点  <ul><li>缺少与感官的直接联系  </li></ul></li><li>方法  <ul><li>运用方法将抽象信息降低到一个基本的级别  <ul><li>内在法  </li><li>比喻  </li></ul></li></ul></li></ul><h2 id="三个基本概念"><a href="#三个基本概念" class="headerlink" title="三个基本概念"></a>三个基本概念</h2><h3 id="Constructs"><a href="#Constructs" class="headerlink" title="Constructs"></a>Constructs</h3><ul><li>Familiar Constructs  <ul><li>感官结构  <ul><li>来自人类的感官知觉，是最熟悉、最生动的结构  </li></ul></li><li>关系结构  <ul><li>来自人类生活经验中人与事务、事物之间的联系  </li></ul></li><li>基本数学结构  <ul><li>来自我们以掌握的简单的基本数学概念  </li></ul></li></ul></li><li>结构：就是一系列联系紧密的知识，一个知识点与越多的其它的知识点相联系，则你对于这个知识点的掌握就越牢固，应用起来也就越简单明了。  </li></ul><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><ul><li>模型是对结构的索引，是对于结构的形象化的抽象，它将关键的结构压缩和概括，  </li></ul><h3 id="Highway"><a href="#Highway" class="headerlink" title="Highway"></a>Highway</h3><ul><li>高速公路是不同结构之间的联系，这种联系是跨学科的，也即是我们可以把A领域的知识迁移到B领域。  </li></ul><h1 id="将每个-知识点都要经过整体性学习里的明白、拓展和应用三个阶段"><a href="#将每个-知识点都要经过整体性学习里的明白、拓展和应用三个阶段" class="headerlink" title="将每个 知识点都要经过整体性学习里的明白、拓展和应用三个阶段"></a>将每个 知识点都要经过整体性学习里的明白、拓展和应用三个阶段</h1><h1 id="比喻法、图表法以及信息压-缩技术"><a href="#比喻法、图表法以及信息压-缩技术" class="headerlink" title="比喻法、图表法以及信息压 缩技术"></a>比喻法、图表法以及信息压 缩技术</h1>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Time-Management/">Time Management</category>
      
      <category domain="http://example.com/tags/Life/">Life</category>
      
      
      <comments>http://example.com/2017/03/26/learn%20more%20study%20less/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Basic Linux/Unix command Interview Questions</title>
      <link>http://example.com/2017/03/19/Basic-Linux-Unix-command-Interview-Questions/</link>
      <guid>http://example.com/2017/03/19/Basic-Linux-Unix-command-Interview-Questions/</guid>
      <pubDate>Sat, 18 Mar 2017 16:53:08 GMT</pubDate>
      
      <description>&lt;p&gt;Overview of Basic Linux/Unix command Interview Questions: 常见Linux命令的概述记录&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Overview of Basic Linux/Unix command Interview Questions: 常见Linux命令的概述记录</p><span id="more"></span><h2 id="初级问题"><a href="#初级问题" class="headerlink" title="初级问题"></a>初级问题</h2><ul><li>列出目录内所有的软链接文件</li></ul><p><code>ls -la | grep &quot;^l&quot;</code></p><p><code>ls -la</code>会以ASCII列出所有文件，而软链接文件都是以<code>l</code>开头的，<code>grep &quot;^l&quot;</code>会找出它们。关于grep的正则pattern可以见此：<a href="https://www.digitalocean.com/community/tutorials/using-grep-regular-expressions-to-search-for-text-patterns-in-linux#regular-expressions">Using Grep &amp; Regular Expressions to Search for Text Patterns in Linux | DigitalOcean</a></p><ul><li>创建一个只读的文件？</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch file</span><br><span class="line">chmod 400 file</span><br></pre></td></tr></table></figure><p>更多可见：<a href="http://javarevisited.blogspot.com/2011/11/file-permissions-in-unix-linux-example.html">File permissions in UNIX Linux with Example &gt;&gt; Unix Tutorial</a></p><ul><li>如何将一个进程在后端运行？如何将其返回前端？如何杀死进程？</li></ul><p>分别是在命令后加上<code>&amp;</code>；<code>fg jobid</code>(用<code>jobs</code>来看jobid)；<code>kill -KILL PID</code> 可见<a href="https://kb.iu.edu/d/afnz">How do I run a Unix process in the background?</a></p><ul><li>测试远程链接？</li></ul><p>用<code>ping</code>或<code>telnet</code>即可</p><ul><li>找寻历史命令？</li></ul><p><code>history | grep &quot;Pattern&quot;</code></p><ul><li>远程复制文件？</li></ul><p><code>scp</code>，或者<code>rsync</code>，<code>sftp</code></p><ul><li>进程的CPU占用？</li></ul><p><code>top</code></p><ul><li>当前磁盘用量？</li></ul><p><code>df -h</code></p><ul><li>Swapping交换和Paging分页的区别？</li></ul><p>paging指的是以页为单位的交换，<br>swapping指的是以整个进程为单位的交换。</p><p>paging机制是进程内外交换的主流，某些情况下仍然会使用swapping机制，比如：<br>1、系统内存严重短缺，paging机制的速度已经不足以满足需要。<br>2、进程处于完全非激活状态超过10秒钟。<br>swapping会把整个进程移出主存，而不像paging那样只弄点页面出去。</p><p>swapping和paging都是内存与磁盘(虚拟内存)之间的交互方式当内存不够用时，为了加载急需的程序进内存，需要将一部分暂时不用的内存存到磁盘上，两者对比swapping更快更粗暴，paging更慢更flexibly，<br>更多可见此<a href="http://blog.sina.com.cn/s/blog_5b68591b0102v1q7.html">[转载]内存的分页与交换_流苏_新浪博客</a></p><h2 id="中级问题"><a href="#中级问题" class="headerlink" title="中级问题"></a>中级问题</h2><ul><li><code>ps -ef</code> 和 <code>ps -auxwww</code>有什么区别？</li></ul><p><code>ps -auxwww</code>可以打印死进程？？</p><ul><li>cpu信息？</li></ul><p><code>cat /proc/cpuinfo</code></p><ul><li>软链接与硬链接区别</li></ul><p><a href="http://javarevisited.blogspot.com/2011/04/symbolic-link-or-symlink-in-unix-linux.html">How to Create, Update and Remove Soft link in UNIX</a></p><ul><li>什么是僵尸进程？如何找到僵尸进程？</li></ul><p>When a program forks and the child finishes before the parent, the kernel still keeps some of its information about the child in case the parent might need it - for example, the parent may need to check the child’s exit status. To be able to get this information, the parent calls ‘wait()’; In the interval between the child terminating and the parent calling ‘wait()’, the child is said to be a ‘zombie’</p><p><code>ps</code>中，僵尸进程的状态将带有’Z’</p><ul><li>如何统计一个文件内字符”Unix”出现次数？</li></ul><p><code>grep -c &quot;Unix&quot; filename</code></p><ul><li>chmod是什么意思？<code>r-- -w- --x</code>代表着什么？</li></ul><p><code>chmod</code>用于改变一个文件或者目录在Linux里的权限，rwx分别代表读写执行，而字符顺序代表着用户 组 以及 其他， 那么这里的意思就是这个文件用户可读，组内用户可写，其他只能执行。</p><ul><li>系统内有个文件包含字符”UnixCommandInterviewQuestions”，如何找到？</li></ul><p>见此<a href="http://javarevisited.blogspot.com/2011/03/10-find-command-in-unix-examples-basic.html">10 Example of find command in Unix and Linux</a></p><ul><li>如何检查是否某进程在监听某端口？</li></ul><p><code>telnet hostname port</code> <a href="http://javarevisited.blogspot.com/2010/10/basic-networking-commands-in-linuxunix.html">Top 10 basic networking commands in linux/unix</a></p><h3 id="高级问题"><a href="#高级问题" class="headerlink" title="高级问题"></a>高级问题</h3><ul><li>怎么知道某个文件被哪些进程使用？</li></ul><p><code>lsof</code>，尼玛呀，这就是我baidu电话面试时碰到的问题。。</p><ul><li>查看你的某个端口被什么远程服务器连接？</li></ul><p><code>netstat -a | grep &quot;port&quot;</code></p><ul><li>nohup是什么？</li></ul><p>用于在后端运行程序，但是和<code>&amp;</code>不同，<code>nohup</code>在用户log off 时不会停止运行，而<code>&amp;</code>会终止。</p><ul><li>ephemeral port？</li></ul><p>临时端口也叫做暂时端口。通常存在于客户机中。它在客户端应用程序需要连接到服务器时建立而在客户端应用程序终止时取消。它的端口号是随机选取的，数值大于1023。</p><ul><li>如果一个进程正在往MYSQL里写数据，如何管查它写入的速度？</li></ul><p><code>watch</code></p><ul><li>替换某文件内所有某字符？</li></ul><p><code>sed s/Unix/UNIX/g fileName</code></p><ul><li>某文件包含以tab分隔的Name, Address and Phone Number，如何提取所有的Phone Number？</li></ul><p><code>cut -f3 filename</code></p><ul><li>服务器运行时间？</li></ul><p><code>uptime</code></p><ul><li>IP 与 hostname互转？</li></ul><p><code>nslookup</code></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2017/03/19/Basic-Linux-Unix-command-Interview-Questions/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>python源码解析0：趣事</title>
      <link>http://example.com/2017/03/18/python-source-code-reading-0/</link>
      <guid>http://example.com/2017/03/18/python-source-code-reading-0/</guid>
      <pubDate>Fri, 17 Mar 2017 19:56:23 GMT</pubDate>
      
      <description>&lt;p&gt;About 两处python源码的趣味解读。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>About 两处python源码的趣味解读。</p><span id="more"></span><h3 id="The-Zen-of-Python"><a href="#The-Zen-of-Python" class="headerlink" title="The Zen of Python"></a>The Zen of Python</h3><p>我们知道，<code>import this</code>会打印如下“蟒蛇之禅”：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">The Zen of Python, by Tim Peters</span><br><span class="line"></span><br><span class="line">Beautiful <span class="keyword">is</span> better than ugly.</span><br><span class="line">Explicit <span class="keyword">is</span> better than implicit.</span><br><span class="line">Simple <span class="keyword">is</span> better than <span class="built_in">complex</span>.</span><br><span class="line">Complex <span class="keyword">is</span> better than complicated.</span><br><span class="line">Flat <span class="keyword">is</span> better than nested.</span><br><span class="line">Sparse <span class="keyword">is</span> better than dense.</span><br><span class="line">Readability counts.</span><br><span class="line">Special cases aren<span class="string">&#x27;t special enough to break the rules.</span></span><br><span class="line"><span class="string">Although practicality beats purity.</span></span><br><span class="line"><span class="string">Errors should never pass silently.</span></span><br><span class="line"><span class="string">Unless explicitly silenced.</span></span><br><span class="line"><span class="string">In the face of ambiguity, refuse the temptation to guess.</span></span><br><span class="line"><span class="string">There should be one-- and preferably only one --obvious way to do it.</span></span><br><span class="line"><span class="string">Although that way may not be obvious at first unless you&#x27;</span>re Dutch.</span><br><span class="line">Now <span class="keyword">is</span> better than never.</span><br><span class="line">Although never <span class="keyword">is</span> often better than *right* now.</span><br><span class="line">If the implementation <span class="keyword">is</span> hard to explain, it<span class="string">&#x27;s a bad idea.</span></span><br><span class="line"><span class="string">If the implementation is easy to explain, it may be a good idea.</span></span><br><span class="line"><span class="string">Namespaces are one honking great idea -- let&#x27;</span>s do more of those!</span><br></pre></td></tr></table></figure><p>但是在source里面也就是<code>2.7/Lib/this.py</code>里，是这样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&quot;&quot;&quot;Gur Mra bs Clguba, ol Gvz Crgref</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Ornhgvshy vf orggre guna htyl.</span></span><br><span class="line"><span class="string">Rkcyvpvg vf orggre guna vzcyvpvg.</span></span><br><span class="line"><span class="string">Fvzcyr vf orggre guna pbzcyrk.</span></span><br><span class="line"><span class="string">Pbzcyrk vf orggre guna pbzcyvpngrq.</span></span><br><span class="line"><span class="string">Syng vf orggre guna arfgrq.</span></span><br><span class="line"><span class="string">Fcnefr vf orggre guna qrafr.</span></span><br><span class="line"><span class="string">Ernqnovyvgl pbhagf.</span></span><br><span class="line"><span class="string">Fcrpvny pnfrf nera&#x27;g fcrpvny rabhtu gb oernx gur ehyrf.</span></span><br><span class="line"><span class="string">Nygubhtu cenpgvpnyvgl orngf chevgl.</span></span><br><span class="line"><span class="string">Reebef fubhyq arire cnff fvyragyl.</span></span><br><span class="line"><span class="string">Hayrff rkcyvpvgyl fvyraprq.</span></span><br><span class="line"><span class="string">Va gur snpr bs nzovthvgl, ershfr gur grzcgngvba gb thrff.</span></span><br><span class="line"><span class="string">Gurer fubhyq or bar-- naq cersrenoyl bayl bar --boivbhf jnl gb qb vg.</span></span><br><span class="line"><span class="string">Nygubhtu gung jnl znl abg or boivbhf ng svefg hayrff lbh&#x27;er Qhgpu.</span></span><br><span class="line"><span class="string">Abj vf orggre guna arire.</span></span><br><span class="line"><span class="string">Nygubhtu arire vf bsgra orggre guna *evtug* abj.</span></span><br><span class="line"><span class="string">Vs gur vzcyrzragngvba vf uneq gb rkcynva, vg&#x27;f n onq vqrn.</span></span><br><span class="line"><span class="string">Vs gur vzcyrzragngvba vf rnfl gb rkcynva, vg znl or n tbbq vqrn.</span></span><br><span class="line"><span class="string">Anzrfcnprf ner bar ubaxvat terng vqrn -- yrg&#x27;f qb zber bs gubfr!&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> (<span class="number">65</span>, <span class="number">97</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">26</span>):</span><br><span class="line">        d[<span class="built_in">chr</span>(i+c)] = <span class="built_in">chr</span>((i+<span class="number">13</span>) % <span class="number">26</span> + c)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;&quot;</span>.join([d.get(c, c) <span class="keyword">for</span> c <span class="keyword">in</span> s])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>哈哈，这不就是<a href="https://zh.wikipedia.org/wiki/%E5%87%B1%E6%92%92%E5%AF%86%E7%A2%BC">凯撒密码</a>么。。。每个字母分大小写(65:A, 97:a)都被对应到ASCII 表后13个位置，于是就有</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;A&#x27;</span>: <span class="string">&#x27;N&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;B&#x27;</span>: <span class="string">&#x27;O&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;C&#x27;</span>: <span class="string">&#x27;P&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;D&#x27;</span>: <span class="string">&#x27;Q&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;E&#x27;</span>: <span class="string">&#x27;R&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;F&#x27;</span>: <span class="string">&#x27;S&#x27;</span>,</span><br><span class="line">....</span><br><span class="line"><span class="string">&#x27;s&#x27;</span>: <span class="string">&#x27;f&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;t&#x27;</span>: <span class="string">&#x27;g&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;u&#x27;</span>: <span class="string">&#x27;h&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;v&#x27;</span>: <span class="string">&#x27;i&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;w&#x27;</span>: <span class="string">&#x27;j&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;x&#x27;</span>: <span class="string">&#x27;k&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;y&#x27;</span>: <span class="string">&#x27;l&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;z&#x27;</span>: <span class="string">&#x27;m&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p> 所以，原作者应该是这样写出来的密码的</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">&quot;&quot;&quot;The Zen of Python, by Tim Peters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Beautiful is better than ugly.</span></span><br><span class="line"><span class="string">Explicit is better than implicit.</span></span><br><span class="line"><span class="string">Simple is better than complex.</span></span><br><span class="line"><span class="string">Complex is better than complicated.</span></span><br><span class="line"><span class="string">Flat is better than nested.</span></span><br><span class="line"><span class="string">Sparse is better than dense.</span></span><br><span class="line"><span class="string">Readability counts.</span></span><br><span class="line"><span class="string">Special cases aren&#x27;t special enough to break the rules.</span></span><br><span class="line"><span class="string">Although practicality beats purity.</span></span><br><span class="line"><span class="string">Errors should never pass silently.</span></span><br><span class="line"><span class="string">Unless explicitly silenced.</span></span><br><span class="line"><span class="string">In the face of ambiguity, refuse the temptation to guess.</span></span><br><span class="line"><span class="string">There should be one-- and preferably only one --obvious way to do it.</span></span><br><span class="line"><span class="string">Although that way may not be obvious at first unless you&#x27;re Dutch.</span></span><br><span class="line"><span class="string">Now is better than never.</span></span><br><span class="line"><span class="string">Although never is often better than *right* now.</span></span><br><span class="line"><span class="string">If the implementation is hard to explain, it&#x27;s a bad idea.</span></span><br><span class="line"><span class="string">If the implementation is easy to explain, it may be a good idea.</span></span><br><span class="line"><span class="string">Namespaces are one honking great idea -- let&#x27;s do more of those!&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> (<span class="number">65</span>, <span class="number">97</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">26</span>):</span><br><span class="line">        d[<span class="built_in">chr</span>(i+c)] = <span class="built_in">chr</span>((i-<span class="number">13</span>) % <span class="number">26</span> + c)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>.join([d.get(c, c) <span class="keyword">for</span> c <span class="keyword">in</span> s]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p> 很神奇吧？哈哈，其实就是逆向一下就ok😎</p><h3 id="antigravity"><a href="#antigravity" class="headerlink" title="antigravity"></a>antigravity</h3><p> 我们知道，在python里，<code>import antigravity</code>会让我们弹到一个<a href="https://xkcd.com/353/">网站</a>，里面有这幅著名的图画</p><p> <img src="/images/2017/03/python.png"></p><p> python带我们飞！那么为什么会这样呢？</p><p> 看看源码，</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> webbrowser</span><br><span class="line"></span><br><span class="line">webbrowser.<span class="built_in">open</span>(<span class="string">&quot;http://xkcd.com/353/&quot;</span>)</span><br></pre></td></tr></table></figure><p> 哈哈，原来就这两行，Are you kidding me?</p><p> 关于这个的来龙去脉，可以看看这里：<a href="http://python-history.blogspot.com/2010/06/import-antigravity.html">The History of Python: import antigravity</a>以及这里：<a href="http://sciyoshi.com/2008/12/import-antigravity/">import antigravity | sciyoshi.com</a>，大意是源自google的一个复活节彩蛋。值得注意的是，python3的antigravity彩蛋升级了！不信你看</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> webbrowser</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line">webbrowser.<span class="built_in">open</span>(<span class="string">&quot;https://xkcd.com/353/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geohash</span>(<span class="params">latitude, longitude, datedow</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Compute geohash() using the Munroe algorithm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; geohash(37.421542, -122.085589, b&#x27;2005-05-26-10458.68&#x27;)</span></span><br><span class="line"><span class="string">    37.857713 -122.544543</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># http://xkcd.com/426/</span></span><br><span class="line">    h = hashlib.md5(datedow).hexdigest()</span><br><span class="line">    p, q = [(<span class="string">&#x27;%f&#x27;</span> % <span class="built_in">float</span>.fromhex(<span class="string">&#x27;0.&#x27;</span> + x)) <span class="keyword">for</span> x <span class="keyword">in</span> (h[:<span class="number">16</span>], h[<span class="number">16</span>:<span class="number">32</span>])]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%d%s %d%s&#x27;</span> % (latitude, p[<span class="number">1</span>:], longitude, q[<span class="number">1</span>:]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p> 里面隐藏了一个计算<a href="https://en.wikipedia.org/wiki/Geohashing">Geohashing</a>的算法，可以根据给定点坐标的经纬度以及当前时间计算一个随机的新的点坐标。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2017/03/18/python-source-code-reading-0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>programmer humor week 0</title>
      <link>http://example.com/2017/03/15/programmer-humor-week-0/</link>
      <guid>http://example.com/2017/03/15/programmer-humor-week-0/</guid>
      <pubDate>Wed, 15 Mar 2017 10:33:39 GMT</pubDate>
      
      <description>&lt;p&gt;programmer humor from reddit 🤣😂😜&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>programmer humor from reddit 🤣😂😜</p><span id="more"></span><h3 id="Huge-improvements-in-both-code-quality-and-performance"><a href="#Huge-improvements-in-both-code-quality-and-performance" class="headerlink" title="Huge improvements in both code quality and performance"></a>Huge improvements in both code quality and performance</h3><p><img src="/images/2017/03/16.png"></p><h3 id="Coding-in-MS-Paint"><a href="#Coding-in-MS-Paint" class="headerlink" title="Coding in MS Paint"></a>Coding in MS Paint</h3><p><img src="/images/2017/03/17.gif"></p><h3 id="What-debuggers-actually-do"><a href="#What-debuggers-actually-do" class="headerlink" title="What debuggers actually do"></a>What debuggers actually do</h3><p><img src="/images/2017/03/18.png"></p><h3 id="Every-time"><a href="#Every-time" class="headerlink" title="Every time"></a>Every time</h3><p><img src="/images/2017/03/19.png"></p><h3 id="One-last-compilation"><a href="#One-last-compilation" class="headerlink" title="One last compilation"></a>One last compilation</h3><p><img src="/images/2017/03/20.jpg"></p><h2 id="引用自"><a href="#引用自" class="headerlink" title="引用自"></a>引用自</h2><p><a href="https://www.reddit.com/r/ProgrammerHumor/">Programmer Humor</a></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Funny/">Funny</category>
      
      
      <comments>http://example.com/2017/03/15/programmer-humor-week-0/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>数据挖掘流程：数据可视化与预处理</title>
      <link>http://example.com/2017/03/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%B5%81%E7%A8%8B%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86/</link>
      <guid>http://example.com/2017/03/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%B5%81%E7%A8%8B%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86/</guid>
      <pubDate>Wed, 15 Mar 2017 03:14:11 GMT</pubDate>
      
      <description>&lt;p&gt;数据挖掘的第一步，当我们手中拿到一份数据，当然是对数据进行观察与预处理了。本文主要对这两个方面做一个个人的总结。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>数据挖掘的第一步，当我们手中拿到一份数据，当然是对数据进行观察与预处理了。本文主要对这两个方面做一个个人的总结。</p><span id="more"></span><h2 id="import-掉包？"><a href="#import-掉包？" class="headerlink" title="import 掉包？"></a>import 掉包？</h2><p>第0步，调包。。</p><p>通常numpy、pandas、scipy、seaborn已经matplotlib是必须的</p><p>为防止烦人的warning，还需要</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&#x27;ignore&#x27;)</span><br></pre></td></tr></table></figure><p>因为我们不管warning只管error，哈哈😂</p><p>seaborn的设置颜色格式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(&#x27;whitegrid&#x27;)</span><br></pre></td></tr></table></figure><p>以及</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="观察与可视化"><a href="#观察与可视化" class="headerlink" title="观察与可视化"></a>观察与可视化</h2><p>一般来说，我们应该首先观察<strong>标签的分布</strong>以及<strong>特征的分布</strong>，对于前者通常使用pandas Dataframe的<code>columns</code>，对于后者则是<code>value_counts()</code>和<code>describe()</code>来展示。如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train.columns</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int_level = train_df[&#x27;interest_level&#x27;].value_counts()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train[&#x27;SalePrice&#x27;].describe()</span><br></pre></td></tr></table></figure><p><code>describe()</code>会给出标签的各种数值信息，如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count      1460.000000</span><br><span class="line">mean     180921.195890</span><br><span class="line">std       79442.502883</span><br><span class="line">min       34900.000000</span><br><span class="line">25%      129975.000000</span><br><span class="line">50%      163000.000000</span><br><span class="line">75%      214000.000000</span><br><span class="line">max      755000.000000</span><br><span class="line">Name: SalePrice, dtype: float64</span><br></pre></td></tr></table></figure><p>同时也可以借助于seaborn图来显示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(df_train[&#x27;SalePrice&#x27;]);</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/1.png"></p><p>接下来可以看看标签的偏度和峰度(skewness and kurtosis)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;Skewness: %f&quot; % df_train[&#x27;SalePrice&#x27;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % df_train[&#x27;SalePrice&#x27;].kurt())</span><br></pre></td></tr></table></figure><h3 id="特征与标签关系"><a href="#特征与标签关系" class="headerlink" title="特征与标签关系"></a>特征与标签关系</h3><p>对于数值特征可用散点图来展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var = <span class="string">&#x27;GrLivArea&#x27;</span></span><br><span class="line">data = pd.concat([df_train[<span class="string">&#x27;SalePrice&#x27;</span>], df_train[var]], axis=<span class="number">1</span>)</span><br><span class="line">data.plot.scatter(x=var, y=<span class="string">&#x27;SalePrice&#x27;</span>, ylim=(<span class="number">0</span>,<span class="number">800000</span>));</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/03.png"></p><p>对于类别特征，则可用箱型图</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var = &#x27;OverallQual&#x27;</span><br><span class="line">data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)</span><br><span class="line">f, ax = plt.subplots(figsize=(8, 6))</span><br><span class="line">fig = sns.boxplot(x=var, y=&quot;SalePrice&quot;, data=data)</span><br><span class="line">fig.axis(ymin=0, ymax=800000);</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/04.png"></p><p>时间特征类似</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var = &#x27;YearBuilt&#x27;</span><br><span class="line">data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)</span><br><span class="line">f, ax = plt.subplots(figsize=(16, 8))</span><br><span class="line">fig = sns.boxplot(x=var, y=&quot;SalePrice&quot;, data=data)</span><br><span class="line">fig.axis(ymin=0, ymax=800000);</span><br><span class="line">plt.xticks(rotation=90);</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/05.png"></p><h3 id="特征与特征的关系"><a href="#特征与特征的关系" class="headerlink" title="特征与特征的关系"></a>特征与特征的关系</h3><p>用关联矩阵Correlation matrix的heatmap类型可以展示所有特征与特征的关系</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#correlation matrix</span><br><span class="line">corrmat = df_train.corr()</span><br><span class="line">f, ax = plt.subplots(figsize=(12, 9))</span><br><span class="line">sns.heatmap(corrmat, vmax=.8, square=True);</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/06.png"></p><p>从关联矩阵我们可以对特征的总体关系有个认识，那么进一步可以用zoomed heatmap来筛选几个特征进行观察其之间的关系</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#saleprice correlation matrix</span><br><span class="line">k = 10 #number of variables for heatmap</span><br><span class="line">cols = corrmat.nlargest(k, &#x27;SalePrice&#x27;)[&#x27;SalePrice&#x27;].index</span><br><span class="line">cm = np.corrcoef(df_train[cols].values.T)</span><br><span class="line">sns.set(font_scale=1.25)</span><br><span class="line">hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt=&#x27;.2f&#x27;, annot_kws=&#123;&#x27;size&#x27;: 10&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/07.png"></p><p>大杀器则是scatterplot，如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#scatterplot</span><br><span class="line">sns.set()</span><br><span class="line">cols = [&#x27;SalePrice&#x27;, &#x27;OverallQual&#x27;, &#x27;GrLivArea&#x27;, &#x27;GarageCars&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;FullBath&#x27;, &#x27;YearBuilt&#x27;]</span><br><span class="line">sns.pairplot(df_train[cols], size = 2.5)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/08.png"></p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><h3 id="缺失值-Missing-data¶"><a href="#缺失值-Missing-data¶" class="headerlink" title="缺失值 Missing data¶"></a>缺失值 Missing data¶</h3><p>首先观察包含缺失值的特征</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#missing data</span><br><span class="line">total = df_train.isnull().sum().sort_values(ascending=False)</span><br><span class="line">percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)</span><br><span class="line">missing_data = pd.concat([total, percent], axis=1, keys=[&#x27;Total&#x27;, &#x27;Percent&#x27;])</span><br><span class="line">missing_data.head(20)</span><br></pre></td></tr></table></figure><p>以上将打印包含缺失值的特征的缺失个数和比例</p><p>当然对于缺失值，不同情况有不同的处理方法，例如</p><p><img src="/images/2017/03/09.jpg"></p><p>这里我们简单的将missing超过1的feature丢弃，再将missing值为1的样本删去，其他方法有待之后补充。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#dealing with missing data</span><br><span class="line">df_train = df_train.drop((missing_data[missing_data[&#x27;Total&#x27;] &gt; 1]).index,1)</span><br><span class="line">df_train = df_train.drop(df_train.loc[df_train[&#x27;Electrical&#x27;].isnull()].index)</span><br><span class="line">df_train.isnull().sum().max()</span><br></pre></td></tr></table></figure><h3 id="离群点"><a href="#离群点" class="headerlink" title="离群点"></a>离群点</h3><p>单特征情况，可以以如下形式观察</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#standardizing data</span><br><span class="line">saleprice_scaled = StandardScaler().fit_transform(df_train[&#x27;SalePrice&#x27;][:,np.newaxis]);</span><br><span class="line">low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]</span><br><span class="line">high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]</span><br><span class="line">print(&#x27;outer range (low) of the distribution:&#x27;)</span><br><span class="line">print(low_range)</span><br><span class="line">print(&#x27;\nouter range (high) of the distribution:&#x27;)</span><br><span class="line">print(high_range)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">outer range (low) of the distribution:</span><br><span class="line">[[-1.83820775]</span><br><span class="line"> [-1.83303414]</span><br><span class="line"> [-1.80044422]</span><br><span class="line"> [-1.78282123]</span><br><span class="line"> [-1.77400974]</span><br><span class="line"> [-1.62295562]</span><br><span class="line"> [-1.6166617 ]</span><br><span class="line"> [-1.58519209]</span><br><span class="line"> [-1.58519209]</span><br><span class="line"> [-1.57269236]]</span><br><span class="line"></span><br><span class="line">outer range (high) of the distribution:</span><br><span class="line">[[ 3.82758058]</span><br><span class="line"> [ 4.0395221 ]</span><br><span class="line"> [ 4.49473628]</span><br><span class="line"> [ 4.70872962]</span><br><span class="line"> [ 4.728631  ]</span><br><span class="line"> [ 5.06034585]</span><br><span class="line"> [ 5.42191907]</span><br><span class="line"> [ 5.58987866]</span><br><span class="line"> [ 7.10041987]</span><br><span class="line"> [ 7.22629831]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>双特征关系如特征标签关系那样，先concat再scatter</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#bivariate analysis saleprice/grlivarea</span><br><span class="line">var = &#x27;GrLivArea&#x27;</span><br><span class="line">data = pd.concat([df_train[&#x27;SalePrice&#x27;], df_train[var]], axis=1)</span><br><span class="line">data.plot.scatter(x=var, y=&#x27;SalePrice&#x27;, ylim=(0,800000));</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/11.png"></p><p>离群点可以简单删去，如</p><p><img src="/images/2017/03/10.png"></p><h3 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h3><p>用histogram 和 normal probability可以观察数据的峰度偏度以及是否符合正态分布</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(df_train[&#x27;SalePrice&#x27;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[&#x27;SalePrice&#x27;], plot=plt)</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/12.png"><br><img src="/images/2017/03/13.png"></p><p>对于正偏度，取log通常不错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#applying log transformation</span><br><span class="line">df_train[&#x27;SalePrice&#x27;] = np.log(df_train[&#x27;SalePrice&#x27;])</span><br><span class="line">In [22]:</span><br><span class="line">#transformed histogram and normal probability plot</span><br><span class="line">sns.distplot(df_train[&#x27;SalePrice&#x27;], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[&#x27;SalePrice&#x27;], plot=plt)</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/14.png"><br><img src="/images/2017/03/15.png"></p><p>有时我们会遇到具有许多0值得特征，而从istogram 和 normal probability可以看出其具有偏度，那么可以使用如下方法：将非零点取log保留零点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#create column for new variable (one is enough because it&#x27;s a binary categorical feature)</span><br><span class="line">#if area&gt;0 it gets 1, for area==0 it gets 0</span><br><span class="line">df_train[&#x27;HasBsmt&#x27;] = pd.Series(len(df_train[&#x27;TotalBsmtSF&#x27;]), index=df_train.index)</span><br><span class="line">df_train[&#x27;HasBsmt&#x27;] = 0</span><br><span class="line">df_train.loc[df_train[&#x27;TotalBsmtSF&#x27;]&gt;0,&#x27;HasBsmt&#x27;] = 1</span><br><span class="line">In [28]:</span><br><span class="line">#transform data</span><br><span class="line">df_train.loc[df_train[&#x27;HasBsmt&#x27;]==1,&#x27;TotalBsmtSF&#x27;] = np.log(df_train[&#x27;TotalBsmtSF&#x27;])</span><br></pre></td></tr></table></figure><p>对于标签，如果偏度太大，可以使用<code>log1p</code>来处理，并对比前后的差距</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">matplotlib.rcParams[&#x27;figure.figsize&#x27;] = (12.0, 6.0)</span><br><span class="line">prices = pd.DataFrame(&#123;&quot;price&quot;:train[&quot;SalePrice&quot;],</span><br><span class="line">                       &quot;log(price + 1)&quot;:np.log1p(train[&quot;SalePrice&quot;])</span><br><span class="line">                      &#125;)</span><br><span class="line">prices.hist()</span><br></pre></td></tr></table></figure><p><img src="/images/2017/03/02.png"></p><p>对全部Dataframe处理需要concat test与train，一并处理，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_data = pd.concat((train.loc[:,&quot;MSSubClass&quot;: &quot;SaleCondition&quot;], test.loc[:,&quot;MSSubClass&quot;: &quot;SaleCondition&quot;]))</span><br></pre></td></tr></table></figure><p>最后需要将预测的标签值放大还原，如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lasso_preds = np.expm1(model_lasso.predict(X_test))</span><br></pre></td></tr></table></figure><h2 id="参考出处"><a href="#参考出处" class="headerlink" title="参考出处"></a>参考出处</h2><ul><li><a href="https://www.kaggle.com/pmarcelino/house-prices-advanced-regression-techniques/comprehensive-data-exploration-with-python/notebook">House Prices: Advanced Regression Techniques | Kaggle</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      
      <comments>http://example.com/2017/03/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%B5%81%E7%A8%8B%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Amdahl&#39;s law</title>
      <link>http://example.com/2017/02/22/Amdahl-s-law/</link>
      <guid>http://example.com/2017/02/22/Amdahl-s-law/</guid>
      <pubDate>Wed, 22 Feb 2017 10:03:29 GMT</pubDate>
      
      <description>&lt;p&gt;关于Amdahl’s law。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>关于Amdahl’s law。</p><span id="more"></span><p>Amdahl’s law，又叫做阿姆达尔定律，其意义在于表示了计算机并行计算处理任务的加速的极限。</p><h2 id="简略证明"><a href="#简略证明" class="headerlink" title="简略证明"></a>简略证明</h2><p>解释如下，假设一个任务需要时间$T$来完成，而其中可以被并行处理加速的部分比例为$p$，那么不能被并行计算加速的部分就为$1-p$，比如从磁盘上读取程序段就不能并行加速，而读取完成到内存中就可以开多个进程或者利用分布式的方法并行处理来加速。</p><p>$$<br>T = (1-p)T + pT<br>$$</p><p>开启加速后，可以加速的部分时间减少至原来的 $\frac {p} {s}$</p><p>$$<br>T’ = (1-p)T + \frac p s T<br>$$</p><p>则加速比就为</p><p>$$<br>S_{\text{latency}}(s) = \frac {T} {T’} = \frac{1}{1 - p + \frac p s}<br>$$</p><h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>Amdahl’s law揭示了不管如何的进行并行计算，只要任务包含无法被并行加速的部分，那么加速比是有上限的，因为</p><p>$$<br>\lim_{s \rightarrow \infty} S_{\text{latency}}(s) = \frac {T} {T’} = \frac{1}{1 - p}<br>$$</p><p>例如如下图中的例子，如果任务的95%可以并行，那么加速的极限约为20倍。</p><p><img src="/images/2017/02/AmdahlsLaw.svg.png"></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      
      <comments>http://example.com/2017/02/22/Amdahl-s-law/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Deep Learning Interview</title>
      <link>http://example.com/2017/02/18/Deep-Learning-Interview/</link>
      <guid>http://example.com/2017/02/18/Deep-Learning-Interview/</guid>
      <pubDate>Sat, 18 Feb 2017 02:25:31 GMT</pubDate>
      
      <description>&lt;p&gt;整理一些关于Deep Learning的面试问题。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>整理一些关于Deep Learning的面试问题。</p><span id="more"></span><h2 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h2><ul><li><p>CNN最成功的应用是在CV，那为什么NLP和Speech的很多问题也可以用CNN解出来？为什么AlphaGo里也用了CNN？这几个不相关的问题的相似性在哪里？CNN通过什么手段抓住了这个共性？</p><ul><li>以上几个不相关问题的相关性在于，都存在局部与整体的关系，由低层次的特征经过组合，组成高层次的特征，并且得到不同特征之间的空间相关性。如下图：低层次的直线／曲线等特征，组合成为不同的形状，最后得到汽车的表示。<br><img src="/images/2017/02/v2-8555de443211e31f6e3967fe0fab83b3_b.png"></li><li><em>CNN抓住此共性的手段主要有四个：局部连接／权值共享／池化操作／多层次结构。</em><ul><li>局部连接使网络可以提取数据的局部特征；</li><li>权值共享大大降低了网络的训练难度，一个Filter只提取一个特征，在整个图片（或者语音／文本） 中进行卷积；</li><li>池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。</li></ul></li></ul></li><li><p>为什么很多做人脸的Paper会最后加入一个Local Connected Conv？</p><ul><li>如果每一个点的处理使用相同的Filter，则为全卷积，如果使用不同的Filter，则为Local-Conv。</li><li>后接了3个Local-Conv层，这里是用Local-Conv的原因是，人脸在不同的区域存在不同的特征（眼睛／鼻子／嘴的分布位置相对固定），当不存在全局的局部特征分布时，Local-Conv更适合特征的提取。</li></ul></li><li><p>什么样的资料集不适合用深度学习?</p><ul><li>数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。</li><li>数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。</li></ul></li><li><p>对所有优化问题来说, 有没有可能找到比現在已知算法更好的算法?</p><ul><li>No Free Lunch定律：不存在一个通用普适的模型，对于所有的学习问题都能做到性能最佳。<br><img src="/images/2017/02/v2-ee269730f637849151525ab8ac299840_b.png"></li><li>对于训练样本（黑点），不同的算法A/B在不同的测试样本（白点）中有不同的表现，这表示：对于一个学习算法A，若它在某些问题上比学习算法 B更好，则必然存在一些问题，在那里B比A好。</li><li>也就是说：对于所有问题，无论学习算法A多聪明，学习算法 B多笨拙，它们的期望性能相同。</li><li>但是：没有免费午餐定力假设所有问题出现几率相同，实际应用中，不同的场景，会有不同的问题分布，所以，在优化算法时，针对具体问题进行分析，是算法优化的核心所在。</li></ul></li><li><p>用贝叶斯机率说明Dropout的原理</p><ul><li><a href="http://mlg.eng.cam.ac.uk/yarin/PDFs/Dropout_as_a_Bayesian_approximation.pdf">Dropout as a Bayesian Approximation: Insights and Applications</a></li></ul></li><li><p>何为共线性, 跟过拟合有啥关联?</p><ul><li><a href="https://en.wikipedia.org/wiki/Multicollinearity">Multicollinearity－Wikipedia</a></li><li>共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。</li><li>共线性会造成冗余，导致过拟合。</li><li>解决方法：排除变量的相关性／加入权重正则。</li></ul></li><li><p>说明如何用支持向量机实现深度学习(列出相关数学公式)</p></li><li><p>广义线性模型是怎被应用在深度学习中?</p><ul><li><a href="http://blog.shakirm.com/2015/01/a-statistical-view-of-deep-learning-i-recursive-glms/">A Statistical View of Deep Learning (I): Recursive GLMs ← The Spectator</a></li><li>深度学习从统计学角度，可以看做递归的广义线性模型。</li><li>广义线性模型相对于经典的线性模型(y=wx+b)，核心在于引入了连接函数g(.)，形式变为：y=g−1(wx+b)。</li><li>深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻辑回归（广义线性模型的一种）的Logistic函数即为神经元激活函数中的Sigmoid函数，很多类似的方法在统计学和神经网络中的名称不一样，容易引起初学者的困惑。下图是一个对照表：<br><img src="/images/2017/02/v2-29d9d42212fd2294e71c2f3e760791d4_b.png"></li></ul></li><li><p>什么造成梯度消失问题? 推导一下</p><ul><li><a href="https://www.quora.com/How-does-the-ReLu-solve-the-vanishing-gradient-problem">How does the ReLu solve the vanishing gradient problem? - Quora</a></li><li><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.nq9lr4sdn">Yes you should understand backprop – Medium</a></li><li>神经网络的训练中，通过改变神经元的权重，使网络的输出值尽可能逼近标签以降低误差值，训练普遍使用BP算法，核心思想是，计算出输出与标签间的损失函数值，然后计算其相对于每个神经元的梯度，进行权值的迭代。梯度消失会造成权值更新缓慢，模型训练难度增加。造成梯度消失的一个原因是，许多激活函数将输出值挤压在很小的区间内，在激活函数两端较大范围的定义域内梯度为0。造成学习停止<br><img src="/images/2017/02/v2-d081992735ff19112770f8aa8e273c13_b.png"></li></ul></li><li><p>Weights Initialization. 不同的方式，造成的后果。为什么会造成这样的结果。</p><ul><li>几种主要的权值初始化方法：lecun_uniform /  glorot_normal / he_normal / batch_normal</li><li>lecun_uniform：<a href="https://www.researchgate.net/publication/2811922_Efficient_BackProp">Efficient BackProp (PDF Download Available)</a></li><li>glorot_normal：<a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a></li><li>he_normal：<a href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers:Surpassing Human-Level Performance on ImageNet Classification</a></li><li>batch_normal：<a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li></ul></li><li><p>为什么网络够深(Neurons 足够多)的时候，总是可以避开较差Local Optima？</p><ul><li><a href="https://arxiv.org/abs/1412.0233">[1412.0233] The Loss Surfaces of Multilayer Networks</a></li></ul></li><li><p>Loss. 有哪些定义方式（基于什么？）， 有哪些优化方式，怎么优化，各自的好处，以及解释。</p><ul><li>Cross-Entropy / MSE / K-L散度</li></ul></li><li><p>Dropout。 怎么做，有什么用处，解释。</p><ul><li><a href="https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning">How does the dropout method work in deep learning? - Quora</a></li><li><a href="https://arxiv.org/pdf/1312.6197.pdf">An empirical analysis of dropout in piecewise linear networks</a></li><li><a href="https://arxiv.org/pdf/1207.0580.pdf">Improving neural networks by preventing co-adaptation of feature detectors</a></li></ul></li><li><p>Activation Function. 选用什么，有什么好处，为什么会有这样的好处。</p><ul><li>几种主要的激活函数：Sigmond / ReLU ／PReLU</li><li><a href="http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf">Deep Sparse Rectifier Neural Networks</a></li><li><a href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li></ul></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.zhihu.com/question/41233373">如果你是面试官，你怎么去判断一个面试者的深度学习水平？ - 知乎</a></li><li><a href="https://www.zhihu.com/question/54308150">深度学习相关的职位面试时一般会问什么？会问一些传统的机器学习算法吗？ - 知乎</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      
      <comments>http://example.com/2017/02/18/Deep-Learning-Interview/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>在Windows上安装并加速拉取Docker镜像的方法</title>
      <link>http://example.com/2017/02/17/Docker-Windows-Speed-up/</link>
      <guid>http://example.com/2017/02/17/Docker-Windows-Speed-up/</guid>
      <pubDate>Fri, 17 Feb 2017 06:38:44 GMT</pubDate>
      
      <description>&lt;p&gt;Docker容器服务近来可谓是一日千里爆炸式的发展，但是在国内安装Docker或者拉取庞大的Docker镜像都不可避免的遇到蜗牛式速度的问题，本文主要关于加速下载DockerWindows客户端和镜像的方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Docker容器服务近来可谓是一日千里爆炸式的发展，但是在国内安装Docker或者拉取庞大的Docker镜像都不可避免的遇到蜗牛式速度的问题，本文主要关于加速下载DockerWindows客户端和镜像的方法。</p><span id="more"></span><h2 id="下载Docker-Windows客户端"><a href="#下载Docker-Windows客户端" class="headerlink" title="下载Docker Windows客户端"></a>下载Docker Windows客户端</h2><p>使用Daocloud提供的<a href="https://get.daocloud.io/docker-install/windows">下载地址</a>，基本上几分钟即可下载完100Mb左右的Docker Windows客户端，而用Docker官网的下载地址可谓几乎没有速度。</p><h2 id="加速拉取Docker镜像"><a href="#加速拉取Docker镜像" class="headerlink" title="加速拉取Docker镜像"></a>加速拉取Docker镜像</h2><p>不挂VPN直接拉取Docker镜像绝对是灾难性的体验，不仅慢如狗而且极容易中断连接。这里我们同样使用Daocloud提供的镜像站如<a href="https://www.daocloud.io/mirror#accelerator-doc">这里</a>，使用方法为在Docker右键菜单的设置选项内的DockerDaemon里面，加上一段地址改为如下形式，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;http://59dcc468.m.daocloud.io&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;insecure-registries&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后Docker会自动重启，之后再Pool镜像即可享受火箭加速般的提升！</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Docker/">Docker</category>
      
      
      <comments>http://example.com/2017/02/17/Docker-Windows-Speed-up/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Explanation of Convolutional Neural Networks</title>
      <link>http://example.com/2017/02/16/Explanation-of-Convolutional-Neural-Networks/</link>
      <guid>http://example.com/2017/02/16/Explanation-of-Convolutional-Neural-Networks/</guid>
      <pubDate>Thu, 16 Feb 2017 06:56:16 GMT</pubDate>
      
      <description>&lt;p&gt;卷积神经网络(Convolutional Neural Network)，简称CNN，是机器视觉领域的主要神经网络模型。本文主要对CNN做一个简明全面的介绍。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>卷积神经网络(Convolutional Neural Network)，简称CNN，是机器视觉领域的主要神经网络模型。本文主要对CNN做一个简明全面的介绍。</p><span id="more"></span><p><img src="/images/2017/02/screen-shot-2016-08-07-at-4-59-29-pm.png"></p><p>上图是90年代的LeNet的结构，当时主要用于字符的识别，当前有许多的新的CNN结构，但是大体上都是采用了与LeNet类似的主要思想。本文主要以LeNet为例来做讲解。</p><p>LeNet的主要组成部分：</p><ul><li>卷积层</li><li>非线性变换(ReLU)</li><li>池化层或者下采样</li><li>分类(全连接)</li></ul><h2 id="图片就是矩阵"><a href="#图片就是矩阵" class="headerlink" title="图片就是矩阵"></a>图片就是矩阵</h2><p>在讲卷积与卷积层之前，我们首先介绍一下图片的相关的概念。本质上，每张图片都是像素值的矩阵。</p><p><img src="/images/2017/02/8-gif.gif"></p><p>彩色图片具有三个<strong>通道</strong>，所谓的RGB图片，也就是在红色、绿色和蓝色三个颜色的矩阵，每个像素值都是[0,255]的值。灰度图片只有一个通道，所以只有一个矩阵。</p><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>CNN由卷积而得名，那么什么是卷积呢？先来看图片</p><p>首先我们有如下的5*5的矩阵，它的每个像素值都由0或者1组成</p><p><img src="/images/2017/02/screen-shot-2016-07-24-at-11-25-13-pm.png"></p><p>再来一张如下的3*3的矩阵</p><p><img src="/images/2017/02/screen-shot-2016-07-24-at-11-25-24-pm.png"></p><p>用这个3<em>3的矩阵对以上5</em>5的矩阵进行卷积，可以表示为如下的过程，</p><p><img src="/images/2017/02/convolution_schematic.gif"></p><p>上述过程可以描述成，3<em>3的矩阵首先定位到5</em>5的矩阵的左上角，两者覆盖重叠到的部位进行点乘再求和，得到的值是新的矩阵的左上角第一个元素，接着3<em>3矩阵向右移动一个像素，也叫一个stride，进行下一次卷积操作，知道遍历完毕，得到一个新的矩阵。在CNN中，这个3</em>3的矩阵叫做<em>滤波器</em>或者<em>卷积核</em>，得到的新的矩阵叫做<em>特征映射</em>。可以说，卷积核的作用就是从原图片中发现特征。所以对于同一张图片，我们可以用不同的卷积核去操作，得到完全不同的特征映射。考虑如下的图片，</p><p><img src="/images/2017/02/111.png"></p><p>我们用不同的卷积核进行操作，得到的结果如下，</p><p><img src="/images/2017/02/screen-shot-2016-08-05-at-11-03-00-pm.png"></p><p>另一个例子如下，</p><p><img src="/images/2017/02/giphy.gif"></p><p>如图，两个非常相似但是方向不同的卷积核对同一张图片进行卷积，得到的不同的结果。在训练过程中，CNN会自动学习到这些卷积核的参数，但是我们还有一些超参数需要手动确定，如卷积核个数、大小以及网络的结构等等。而特征映射的大小由三个参数来确定，</p><ul><li><em>Depth</em>：也就是卷积核的个数，我们用几个卷积核进行操作，那么就可以得到多少个重叠着的特征映射，也就是特征映射的深度。</li><li><em>Stride</em>：卷积时每步移动的大小，容易得知，步子越大，那么卷积的次数也就越小，那么特征映射矩阵也就越小。</li><li><em>Zero-Padding</em>：指的是是否在原图像周围补上零再进行卷积，，这样也是控制特征映射大小的方法，带有Padding和不带有Padding的卷积分别叫做宽卷积和窄卷积。</li></ul><h2 id="非线性映射-ReLU"><a href="#非线性映射-ReLU" class="headerlink" title="非线性映射(ReLU)"></a>非线性映射(ReLU)</h2><p>ReLU函数是什么？初一看它的全称Rectified Linear Unit好像特别高大上，其实它的函数形式非常简单，就是</p><p>$$output = max(0, input)$$</p><p>也就是将原输入的负值全部替换为0。顺便一说，深度学习业界充斥着这种现象，如多层感知机与神经网络、甚至是Deep Learning这个称号本身都是这样改过来的“好名字”，不得不说，起个好名字对于成功也是非常主要的啊！</p><p>话说回来，用ReLU处理过的图片的效果如下：</p><p><img src="/images/2017/02/screen-shot-2016-08-07-at-6-18-19-pm.png"></p><p>除ReLU之外，还有sigmoid函数和tanh双曲函数等非线性变换，但是ReLU被证明表现更加，所以也就更常用。</p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化(pooling)也就是信号处理领域的下采样Downsampling，其作用是对特征映射保留主要信息的同时进行降维。根据计算方式的不同可以有Max、Average、Sum等多种pooling方式。</p><p><img src="/images/2017/02/screen-shot-2016-08-10-at-3-38-39-am.png"></p><p>以上展示了使用2*2的窗口对经过卷积和非线性映射的矩阵的Max pooling操作。这里的stride是2个像素，对每个区域采用最大值。在网络中，pooling是对每个特征映射单独操作的，于是我们会得到相同数目的输出。</p><p><img src="/images/2017/02/screen-shot-2016-08-07-at-6-19-37-pm.png"></p><p>下图展示了pooling操作，</p><p><img src="/images/2017/02/screen-shot-2016-08-07-at-6-11-53-pm.png"></p><p>pooling操作显著地减小了输入的空间大小，除此之外，</p><ul><li>使得输入更加小，更加容易计算</li><li>减小网络的复杂程度，有利于对抗过拟合</li><li>使得网络对于扰动等噪音更加鲁棒，因为微小的扰动对于pooling结果没有影响</li><li>有益于物体探测的准确性</li></ul><h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>经过两轮的卷积-ReLU-pooling操作，接下来就是标准的全连接神经网络结构了，所谓全连接，也就是上一层的每个神经元都与下一层的每个神经元有连接，倒数第二层的输出是每个类的概率，再经过一个softmax层进行归一化处理，我们得到了最终的输出：和为1的每个分类的概率。</p><p><img src="/images/2017/02/screen-shot-2016-08-06-at-12-34-02-am.png"></p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>上面把CNN拆开了讲，接下来我们把各个组件合起来看一下CNN的训练过程。比如我们的输入是一张船的图片，而输出则是属于船的概率是1，如[0,0,1,0]。</p><p><img src="/images/2017/02/screen-shot-2016-08-07-at-9-15-21-pm.png"></p><p>那么训练过程如下</p><ul><li>步骤1：以随机值初始化卷积核和权重参数</li><li>步骤2：网络得到输入，进行前向的计算（卷积、ReLU和pooling）得到最终各分类的概率，假设是[0.1, 0.3, 0.2, 0.4]，因为参数都是随机的，那么结果肯定也是随机的</li><li>步骤3：利用平方误差计算错误的损失函数大小</li><li>步骤4：反向传播计算error对于各个参数的梯度，对参数进行更新，以减小错误程度<ul><li>注意到我们只更新卷积核的参数以及全连接的权重，其余的参数已经在训练之前指定</li><li>在训练过程中，网络逐渐“学习”到如何正确分类图片，这是通过逐渐修改更新参数得到的</li></ul></li><li>步骤5：对于所有训练集内的图片重复步骤2-4</li></ul><h2 id="CNN的可视化"><a href="#CNN的可视化" class="headerlink" title="CNN的可视化"></a>CNN的可视化</h2><p><img src="/images/2017/02/screen-shot-2016-08-10-at-12-58-30-pm.png"></p><p>CNN在人脸识别内的应用，如上图所示。对于CNN的原理，结合上图我们可以进行如下的解释：CNN的卷积核由下到上是逐渐探测复杂的特征的，比如第一层卷积核的特征映射是简单的明暗线段纹理，第二层就可以得到曲线等复杂一些的特征，到了第三层探测的特征已经是人脸的形状轮廓了，后面的层对于前面层的特征进行组合变化而得到更加复杂的组合。这就类似单层感知机连异或函数都无法表示，多层感知机组合起来也就是神经网络却可以拟合任意复杂的函数的原理一样。</p><p><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html">这里</a>有一个很棒的关于CNN原理的展示demo，如图</p><p><img src="/images/2017/02/conv_all.png"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">An Intuitive Explanation of Convolutional Neural Networks</a></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/CNN/">CNN</category>
      
      
      <comments>http://example.com/2017/02/16/Explanation-of-Convolutional-Neural-Networks/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mac上安装Kaggle Docker 镜像的方法</title>
      <link>http://example.com/2017/02/13/Install-Kaggle-Docker-on-Mac/</link>
      <guid>http://example.com/2017/02/13/Install-Kaggle-Docker-on-Mac/</guid>
      <pubDate>Sun, 12 Feb 2017 18:31:56 GMT</pubDate>
      
      <description>&lt;p&gt;作为数据科学业界独占鳌头的竞赛网站Kaggle为我们提供了简便的一键安装的Docker镜像，使得我们可以方便的在本地&lt;br&gt;使用与Kaggle网站在线完全一致的环境，那么在Mac上如何安装和使用Kaggle的Docker镜像呢？&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>作为数据科学业界独占鳌头的竞赛网站Kaggle为我们提供了简便的一键安装的Docker镜像，使得我们可以方便的在本地<br>使用与Kaggle网站在线完全一致的环境，那么在Mac上如何安装和使用Kaggle的Docker镜像呢？</p><span id="more"></span><h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><p>参考<a href="https://www.docker.com/">Docker官网</a>的教程可以方便的下载安装Docker在Mac上。</p><h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><p>安装好Docker并运行成功后，参考<a href="https://github.com/kaggle/docker-python">这里</a>，在终端用如下这行命令<code>docker run --rm -it kaggle/python</code>，就会下载kaggle的python环境Docker镜像到本地，大小数G，如果出现握手失败等提示可以尝试挂VPN或者用Daocloud的服务来加速。</p><h2 id="jupyter-notebook设置"><a href="#jupyter-notebook设置" class="headerlink" title="jupyter notebook设置"></a>jupyter notebook设置</h2><p>我们装好环境后当然不是只是为了在命令行内使用python环境，必须用jupyter notebook！那么怎么设置才能在本地的浏览器上连接容器内运行的内核呢？<br>参考<a href="http://blog.kaggle.com/2016/02/05/how-to-get-started-with-data-science-in-containers/">这里</a>，在你的<code>.bashrc</code>或者<code>.bash_profile</code>文件内添加如下数行，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kpython()&#123;</span><br><span class="line">  docker run -v $PWD:/tmp/working -w=/tmp/working --rm -it kaggle/python python &quot;$@&quot;</span><br><span class="line">&#125;</span><br><span class="line">ikpython() &#123;</span><br><span class="line">  docker run -v $PWD:/tmp/working -w=/tmp/working --rm -it kaggle/python ipython</span><br><span class="line">&#125;</span><br><span class="line">kjupyter() &#123;</span><br><span class="line">  (sleep 3 &amp;&amp; open &quot;http://$(docker-machine ip docker):8888&quot;)&amp;</span><br><span class="line">  docker run -v $PWD:/tmp/working -w=/tmp/working -p 8888:8888 --rm -it kaggle/python jupyter notebook --no-browser --ip=&quot;0.0.0.0&quot; --notebook-dir=/tmp/working</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>别忘了<code>source .bashrc</code>，之后就可以用<code>kjupyter</code>命令来运行<code>jupyter notebook</code>，只要进入命令行中提供的网址如<code>http://0.0.0.0:8888/?token=16185adf197d30dc82e9b88508a5ac585e6fa072c682117d</code>就可进入<code>jupyter notebook</code>。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Data-Science/">Data Science</category>
      
      <category domain="http://example.com/tags/Docker/">Docker</category>
      
      
      <comments>http://example.com/2017/02/13/Install-Kaggle-Docker-on-Mac/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Note for SoloLearn SQL</title>
      <link>http://example.com/2017/01/17/Note-for-SoloLearn-SQL/</link>
      <guid>http://example.com/2017/01/17/Note-for-SoloLearn-SQL/</guid>
      <pubDate>Tue, 17 Jan 2017 08:11:48 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要关于SQL的基本语法的笔记，来自SoloLearn。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要关于SQL的基本语法的笔记，来自SoloLearn。</p><span id="more"></span><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="介绍数据库"><a href="#介绍数据库" class="headerlink" title="介绍数据库"></a>介绍数据库</h3><h4 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h4><p>数据库是指以利于容易地连接、有效管理和更新的方式来管理的一系列的数据。数据库由储存相关联的信息的表格组成，举例来说，假设我们需要建立一个如YouTube的网站，那么我们需要数据库来存储视频信息、用户名与密码以及评论等等。</p><h4 id="数据库表格"><a href="#数据库表格" class="headerlink" title="数据库表格"></a>数据库表格</h4><p>数据库表格用类似Excel的方式存储和展示数据，数据库通常由许多的表格构成，例如想象一个由名字和电话号码构成的表格。</p><p><img src="/%5Cimages%5C2017%5C01%5C1.png"></p><h4 id="primary-key"><a href="#primary-key" class="headerlink" title="primary key"></a>primary key</h4><p>primary key是表格中特殊的一列，主要特性是</p><ul><li>每行都有独特的primary key</li><li>不能为null</li></ul><p>例如下图中，ID是个primary key的好选择，因为可能会有重名的情况。</p><p><img src="/%5Cimages%5C2017%5C01%5C2.png"></p><h4 id="什么是SQL"><a href="#什么是SQL" class="headerlink" title="什么是SQL"></a>什么是SQL</h4><p>我们已经理解了什么是数据库，那么理解什么是SQL就很简单了。SQL 全称是结构化序列语言（Structured Query Language）。SQL用于连接和操作数据库，而MySQL指的是一种能理解SQL的程序语言。可以这么说，SQL是一种标准，而有许多遵循这个版本却自带许多特性的程序语言的实现。</p><p>SQL可以：</p><ul><li>插入、更新、删除数据库里的记录</li><li>创建新的数据库、表格、存储程序和外观</li><li>从数据库取回数据</li></ul><h3 id="SQL语句-SELECT"><a href="#SQL语句-SELECT" class="headerlink" title="SQL语句 SELECT"></a>SQL语句 SELECT</h3><h4 id="基本SQL语句"><a href="#基本SQL语句" class="headerlink" title="基本SQL语句"></a>基本SQL语句</h4><p><code>SHOW DATABASES</code>：返回服务器上所有数据库的序列</p><p><code>SHOW TABLES</code>：返回当前数据库上的所有表格</p><p><code>SHOW COLUMNS FROM customers</code>：返回选定表格内的列信息</p><h4 id="SELECT-语句"><a href="#SELECT-语句" class="headerlink" title="SELECT 语句"></a>SELECT 语句</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> column_list</span><br><span class="line"><span class="keyword">FROM</span> table_name</span><br></pre></td></tr></table></figure><p>在制定表格内选中一列或者多列</p><h3 id="语法规则"><a href="#语法规则" class="headerlink" title="语法规则"></a>语法规则</h3><h4 id="多行语句"><a href="#多行语句" class="headerlink" title="多行语句"></a>多行语句</h4><p>SQL允许同时运行多句语句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT FirstName FROM customers;</span><br><span class="line">SELECT City FROM customers;</span><br></pre></td></tr></table></figure><h4 id="大小写不敏感"><a href="#大小写不敏感" class="headerlink" title="大小写不敏感"></a>大小写不敏感</h4><p>SQL是大小写不敏感的，如下三行是同样的效果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select City from customers;</span><br><span class="line">SELECT City FROM customers;</span><br><span class="line">sElEct City From customers;</span><br></pre></td></tr></table></figure><h4 id="忽略空白"><a href="#忽略空白" class="headerlink" title="忽略空白"></a>忽略空白</h4><p>whitespace和多行被忽略，以下语句是ok的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT        City</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FROM customers;</span><br></pre></td></tr></table></figure><h3 id="选择多列"><a href="#选择多列" class="headerlink" title="选择多列"></a>选择多列</h3><h4 id="选择多列-1"><a href="#选择多列-1" class="headerlink" title="选择多列"></a>选择多列</h4><p>以逗号分隔，可以同时选择多列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT FirstName, LastName, City</span><br><span class="line">FROM customers;</span><br></pre></td></tr></table></figure><h4 id="选择所有列"><a href="#选择所有列" class="headerlink" title="选择所有列"></a>选择所有列</h4><p><code>SELECT * FROM customers; </code></p><h3 id="DISTINCT和LIMIT"><a href="#DISTINCT和LIMIT" class="headerlink" title="DISTINCT和LIMIT"></a>DISTINCT和LIMIT</h3><h4 id="DISTINCT关键词"><a href="#DISTINCT关键词" class="headerlink" title="DISTINCT关键词"></a>DISTINCT关键词</h4><p>DISTINCT关键词指排除重复项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT DISTINCT column_name1, column_name2</span><br><span class="line">FROM table_name;</span><br></pre></td></tr></table></figure><h4 id="LIMIT关键词"><a href="#LIMIT关键词" class="headerlink" title="LIMIT关键词"></a>LIMIT关键词</h4><p>指定返回的子集大小</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT column list</span><br><span class="line">FROM table_name</span><br><span class="line">LIMIT [number of records];</span><br></pre></td></tr></table></figure><p>如选择前五项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, City</span><br><span class="line">FROM customers LIMIT 5;</span><br></pre></td></tr></table></figure><p>选择从3<strong>后面</strong>的4项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, City</span><br><span class="line"> FROM customers LIMIT 3, 4;</span><br></pre></td></tr></table></figure><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><h4 id="全名"><a href="#全名" class="headerlink" title="全名"></a>全名</h4><p>当要操作拥有相同列名字的多个表格时，可以使用全名如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT City FROM customers;</span><br><span class="line"></span><br><span class="line">SELECT customers.City FROM customers;</span><br></pre></td></tr></table></figure><h4 id="Order-By"><a href="#Order-By" class="headerlink" title="Order By"></a>Order By</h4><p>Order By用于与SELECT来排序数据<br>用 Firstname排序</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">ORDER BY FirstName;</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C3.png"></p><h4 id="多列排序"><a href="#多列排序" class="headerlink" title="多列排序"></a>多列排序</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">ORDER BY LastName, Age;</span><br></pre></td></tr></table></figure><p>先用LastName排序，在LastName相同的情况下，用Age排序</p><h2 id="Filtering-Functions-Subqueries"><a href="#Filtering-Functions-Subqueries" class="headerlink" title="Filtering, Functions, Subqueries"></a>Filtering, Functions, Subqueries</h2><h3 id="WHERE语句"><a href="#WHERE语句" class="headerlink" title="WHERE语句"></a>WHERE语句</h3><h4 id="WHERE语句-1"><a href="#WHERE语句-1" class="headerlink" title="WHERE语句"></a>WHERE语句</h4><p>WHERE语句类似一个过滤器的作用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_list</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE condition;</span><br></pre></td></tr></table></figure><h4 id="SQL操作符"><a href="#SQL操作符" class="headerlink" title="SQL操作符"></a>SQL操作符</h4><p>比较操作符和逻辑操作符用于WHERE语句内</p><p><img src="/%5Cimages%5C2017%5C01%5C4.png"></p><h4 id="BETWEEN-操作符"><a href="#BETWEEN-操作符" class="headerlink" title="BETWEEN 操作符"></a>BETWEEN 操作符</h4><p>用于选中一定范围内的值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name BETWEEN value1 AND value2;</span><br></pre></td></tr></table></figure><h4 id="Text-值"><a href="#Text-值" class="headerlink" title="Text 值"></a>Text 值</h4><p>需要用单引号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, City</span><br><span class="line">FROM customers</span><br><span class="line">WHERE City = &#x27;New York&#x27;;</span><br></pre></td></tr></table></figure><h3 id="AND-OR逻辑操作符"><a href="#AND-OR逻辑操作符" class="headerlink" title="AND OR逻辑操作符"></a>AND OR逻辑操作符</h3><p>逻辑操作符用于操作两个布尔值，返回true、false、或者null</p><p><img src="/%5Cimages%5C2017%5C01%5C5.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, Age</span><br><span class="line">FROM customers</span><br><span class="line">WHERE Age &gt;= 30 AND Age &lt;= 40;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE City = &#x27;New York&#x27; OR City = &#x27;Chicago&#x27;;</span><br></pre></td></tr></table></figure><h4 id="结合AND-amp-OR"><a href="#结合AND-amp-OR" class="headerlink" title="结合AND &amp; OR"></a>结合AND &amp; OR</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE City = &#x27;New York&#x27;</span><br><span class="line">AND (Age=30 OR Age=35);</span><br></pre></td></tr></table></figure><h3 id="IN-NOT-IN"><a href="#IN-NOT-IN" class="headerlink" title="IN NOT IN"></a>IN NOT IN</h3><p>IN操作符用于需要将一列与许多值比较的情况，如用OR语句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE City = &#x27;New York&#x27;</span><br><span class="line">OR City = &#x27;Los Angeles&#x27;</span><br><span class="line">OR City = &#x27;Chicago&#x27;;</span><br></pre></td></tr></table></figure><p>用IN语句替代可简写为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE City IN (&#x27;New York&#x27;, &#x27;Los Angeles&#x27;, &#x27;Chicago&#x27;);</span><br></pre></td></tr></table></figure><p>NOT IN就是反面情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM customers</span><br><span class="line">WHERE City NOT IN (&#x27;New York&#x27;, &#x27;Los Angeles&#x27;, &#x27;Chicago&#x27;);</span><br></pre></td></tr></table></figure><h3 id="Custom-列"><a href="#Custom-列" class="headerlink" title="Custom 列"></a>Custom 列</h3><h4 id="CONCAT语句"><a href="#CONCAT语句" class="headerlink" title="CONCAT语句"></a>CONCAT语句</h4><p>CONCAT语句用于联合多个Text值，返回字符串</p><p><code>SELECT CONCAT(FirstName, &#39;, &#39; , City) FROM customers; </code><br><img src="/%5Cimages%5C2017%5C01%5C6.png"></p><h4 id="AS-操作符"><a href="#AS-操作符" class="headerlink" title="AS 操作符"></a>AS 操作符</h4><p>AS 操作符用于生成新的列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT CONCAT(FirstName,&#x27;, &#x27;, City) AS new_column</span><br><span class="line">FROM customers;</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C7.png"></p><h4 id="算数操作符"><a href="#算数操作符" class="headerlink" title="算数操作符"></a>算数操作符</h4><ul><li><ul><li><ul><li>/</li></ul></li></ul></li></ul><p>如将Salary自增500</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, Salary+500 AS Salary</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><h4 id="UPPER-LOWER函数"><a href="#UPPER-LOWER函数" class="headerlink" title="UPPER LOWER函数"></a>UPPER LOWER函数</h4><p>用于转换为大小写格式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT FirstName, UPPER(LastName) AS LastName</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure><h4 id="SQRT-、-AVG"><a href="#SQRT-、-AVG" class="headerlink" title="SQRT 、 AVG"></a>SQRT 、 AVG</h4><p>SQRT返回平方根</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT Salary, SQRT(Salary)</span><br><span class="line">FROM employees;</span><br></pre></td></tr></table></figure><p>AVG返回均值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT AVG(Salary) FROM employees;</span><br></pre></td></tr></table></figure><h4 id="SUM函数"><a href="#SUM函数" class="headerlink" title="SUM函数"></a>SUM函数</h4><p>返回列的加和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT SUM(Salary) FROM employees;</span><br></pre></td></tr></table></figure><h3 id="子语句"><a href="#子语句" class="headerlink" title="子语句"></a>子语句</h3><p>子语句是指含有其他语句的语句，假设我们需要选中全部薪水大于均值的人，那么可能需要先获取均值</p><p><code>SELECT AVG(Salary) FROM employees;</code></p><p>再</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT FirstName, Salary FROM employees</span><br><span class="line">WHERE  Salary &gt; 3100</span><br><span class="line">ORDER BY Salary DESC;</span><br></pre></td></tr></table></figure><p>其实可以结合起来</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT FirstName, Salary FROM employees</span><br><span class="line">WHERE  Salary &gt; (SELECT AVG(Salary) FROM employees)</span><br><span class="line">ORDER BY Salary DESC;</span><br></pre></td></tr></table></figure><h3 id="LIKE和MIN"><a href="#LIKE和MIN" class="headerlink" title="LIKE和MIN"></a>LIKE和MIN</h3><h4 id="LIKE函数"><a href="#LIKE函数" class="headerlink" title="LIKE函数"></a>LIKE函数</h4><p>LIKE用于在WHERE里指定条件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE column_name LIKE pattern;</span><br></pre></td></tr></table></figure><p>例如，选择所有A开头的人</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM employees</span><br><span class="line">WHERE FirstName LIKE &#x27;A%&#x27;;</span><br></pre></td></tr></table></figure><p>选择所有s结尾名字的人</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM employees</span><br><span class="line">WHERE LastName LIKE &#x27;%s&#x27;;</span><br></pre></td></tr></table></figure><h4 id="MIN函数"><a href="#MIN函数" class="headerlink" title="MIN函数"></a>MIN函数</h4><p>用于选择最小值</p><p><code>SELECT MIN(Salary) AS Salary FROM employees;</code></p><h2 id="JOIN、表操作"><a href="#JOIN、表操作" class="headerlink" title="JOIN、表操作"></a>JOIN、表操作</h2><h3 id="合并表格"><a href="#合并表格" class="headerlink" title="合并表格"></a>合并表格</h3><p>对于以下两个表格</p><p><img src="/%5Cimages%5C2017%5C01%5C8.png"></p><p><img src="/%5Cimages%5C2017%5C01%5C9.png"></p><p>可用以下语句结合</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT customers.ID, customers.Name, orders.Name, orders.Amount</span><br><span class="line">FROM customers, orders</span><br><span class="line">WHERE customers.ID=orders.Customer_ID</span><br><span class="line">ORDER BY customers.ID;</span><br></pre></td></tr></table></figure><p>结果</p><p><img src="/%5Cimages%5C2017%5C01%5C10.png"></p><h3 id="Join的类型"><a href="#Join的类型" class="headerlink" title="Join的类型"></a>Join的类型</h3><p>可以用“小名”来简化join操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT ct.ID, ct.Name, ord.Name, ord.Amount</span><br><span class="line">FROM customers AS ct, orders AS ord</span><br><span class="line">WHERE ct.ID=ord.Customer_ID</span><br><span class="line">ORDER BY ct.ID;</span><br></pre></td></tr></table></figure><h4 id="JOIN类型"><a href="#JOIN类型" class="headerlink" title="JOIN类型"></a>JOIN类型</h4><ul><li>INNER JOIN</li><li>LEFT JOIN</li><li>RIGHT JOIN</li></ul><p>INNER JOIN等同于JOIN</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table1 INNER JOIN table2</span><br><span class="line">ON table1.column_name=table2.column_name;</span><br></pre></td></tr></table></figure><p>关系如图</p><p><img src="/%5Cimages%5C2017%5C01%5C11.png"></p><p>LEFT JOIN 返回所有左边表格的行，甚至是在右边表格没有符合的也是如此。</p><p>基本语法为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT table1.column1, table2.column2...</span><br><span class="line">FROM table1 LEFT OUTER JOIN table2</span><br><span class="line">ON table1.column_name = table2.column_name;</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C12.png"></p><p>举例来说，考虑以下两个依次是customers和items，<br><img src="/%5Cimages%5C2017%5C01%5C13.png"></p><p><img src="/%5Cimages%5C2017%5C01%5C14.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT customers.Name, items.Name</span><br><span class="line">FROM customers LEFT OUTER JOIN items</span><br><span class="line">ON customers.ID=items.Seller_id;</span><br></pre></td></tr></table></figure><p>结果</p><p><img src="/%5Cimages%5C2017%5C01%5C15.png"></p><p>如果用RIGHT JOIN</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT table1.column1, table2.column2...</span><br><span class="line">FROM table1 RIGHT OUTER JOIN table2</span><br><span class="line">ON table1.column_name = table2.column_name;</span><br></pre></td></tr></table></figure><p>结果是</p><p><img src="/%5Cimages%5C2017%5C01%5C16.png"></p><h3 id="UNION"><a href="#UNION" class="headerlink" title="UNION"></a>UNION</h3><p>当需要合并相似的表格时，可以用到UNION and UNION ALL，两者主要区别是前者会丢弃重复项。</p><p>如考虑以下两个表格</p><p><img src="/%5Cimages%5C2017%5C01%5C17.png"></p><p><img src="/%5Cimages%5C2017%5C01%5C18.png"></p><p>使用语句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, City FROM First</span><br><span class="line">UNION</span><br><span class="line">SELECT ID, FirstName, LastName, City FROM Second;</span><br></pre></td></tr></table></figure><p>结果为</p><p><img src="/%5Cimages%5C2017%5C01%5C19.png"></p><p>而使用UNION ALL</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID, FirstName, LastName, City FROM First</span><br><span class="line">UNION ALL</span><br><span class="line">SELECT ID, FirstName, LastName, City FROM Second;</span><br></pre></td></tr></table></figure><p>结果为</p><p><img src="/%5Cimages%5C2017%5C01%5C20.png"></p><h3 id="INSERT语句"><a href="#INSERT语句" class="headerlink" title="INSERT语句"></a>INSERT语句</h3><h4 id="插入语句"><a href="#插入语句" class="headerlink" title="插入语句"></a>插入语句</h4><p>INSERT语句用于在表格插入一条数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO table_name</span><br><span class="line">VALUES (value1, value2, value3,...);</span><br></pre></td></tr></table></figure><p>也可以指定插入列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO table_name (column1, column2, column3, ...,columnN)  </span><br><span class="line">VALUES (value1, value2, value3,...valueN);</span><br></pre></td></tr></table></figure><p>亦可只插入指定列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO table_name (column1, column2, column3, ...,columnN)  </span><br><span class="line">VALUES (value1, value2, value3,...valueN);</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C21.png"></p><h3 id="UPDATE、DELETE语句"><a href="#UPDATE、DELETE语句" class="headerlink" title="UPDATE、DELETE语句"></a>UPDATE、DELETE语句</h3><p>UPDATE语句用于更改表格</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE table_name</span><br><span class="line">SET column1=value1, column2=value2, ...</span><br><span class="line">WHERE condition;</span><br></pre></td></tr></table></figure><p>例如</p><p><img src="/%5Cimages%5C2017%5C01%5C22.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Employees</span><br><span class="line">SET Salary=5000</span><br><span class="line">WHERE ID=1;</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C23.png"></p><p>也可以同时更改数项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Employees</span><br><span class="line">SET Salary=5000, FirstName=&#x27;Robert&#x27;</span><br><span class="line">WHERE ID=1;</span><br></pre></td></tr></table></figure><p>DELETE用于删除数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM table_name</span><br><span class="line">WHERE condition;</span><br></pre></td></tr></table></figure><h3 id="创建表格"><a href="#创建表格" class="headerlink" title="创建表格"></a>创建表格</h3><p>CREATE TABLE 用于创建表格</p><p>基本语法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table_name</span><br><span class="line">(</span><br><span class="line">column_name1 data_type(size),</span><br><span class="line">column_name2 data_type(size),</span><br><span class="line">column_name3 data_type(size),</span><br><span class="line">....</span><br><span class="line">columnN data_type(size)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul><li>column_names指定列名</li><li>data_type指定存储数据的类型如int</li><li>size指定最大长度</li></ul><p>如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Users</span><br><span class="line">(</span><br><span class="line">   UserID int,</span><br><span class="line">   FirstName varchar(100),</span><br><span class="line">   LastName varchar(100),</span><br><span class="line">   City varchar(100)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>varchar指的是字符类型</p><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>数值<br>INT - 带符号或者非符号integer<br>FLOAT(M,D) - 带符号浮点数M是展示长度，D是小数点位<br>DOUBLE(M,D) - 带符号long类型浮点数M是展示长度，D是小数点位</p><p>日期和时间<br>DATE - YYYY-MM-DD 格式<br>DATETIME - YYYY-MM-DD HH:MM:SS 格式<br>TIMESTAMP - 从 1970年1月1日午夜开始计算的时间长度<br>TIME - Stores the time in HH:MM:SS format.</p><p>字符串<br>CHAR(M) - 固定长度的字符串，M是长度，最大为255 byte.<br>VARCHAR(M) - 可变长度字符串，M是最大长度<br>BLOB - “二进制大型对象” Binary Large Objects， 用于存储图片等<br>TEXT - 大规模的text数据</p><p>指定primary key</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Users</span><br><span class="line">(</span><br><span class="line">   UserID int,</span><br><span class="line">   FirstName varchar(100),</span><br><span class="line">   LastName varchar(100),</span><br><span class="line">   City varchar(100),</span><br><span class="line">   PRIMARY KEY(UserID)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="NOT-NULL-和-AUTO-INCREMENT"><a href="#NOT-NULL-和-AUTO-INCREMENT" class="headerlink" title="NOT NULL 和 AUTO_INCREMENT"></a>NOT NULL 和 AUTO_INCREMENT</h3><h4 id="SQL约束"><a href="#SQL约束" class="headerlink" title="SQL约束"></a>SQL约束</h4><p>NOT NULL -  强制列不能含有NULL<br>UNIQUE - 不允许列中出现重复值<br>PRIMARY KEY - 强制表格对于特定的列接受数据并创建单独的加速索引<br>CHECK - 通过逻辑表达式来判断值是否有效<br>DEFAULT - 往表格插入数据时，若某列未指定值，则自动插入默认值</p><p>例如，如下语句指name列不允许出现NULL</p><p><code>name varchar(100) NOT NULL</code></p><h4 id="AUTO-INCREMENT"><a href="#AUTO-INCREMENT" class="headerlink" title="AUTO INCREMENT"></a>AUTO INCREMENT</h4><p>当新一条记录加入时，自动生成某数，通常从1开始，每次新纪录加入，自增1。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UserID int NOT NULL AUTO_INCREMENT,</span><br><span class="line">PRIMARY KEY (UserID)</span><br></pre></td></tr></table></figure><h3 id="ALTER-DROP-RANAME"><a href="#ALTER-DROP-RANAME" class="headerlink" title="ALTER DROP RANAME"></a>ALTER DROP RANAME</h3><p>ALTER用于对表格中的列进行添加、删除和编辑操作，也可以对表格的约束进行添加或移除。</p><p><img src="/%5Cimages%5C2017%5C01%5C24.png"></p><p><code>ALTER TABLE People ADD DateOfBirth date;</code></p><p><img src="/%5Cimages%5C2017%5C01%5C25.png"></p><p>DROP用于删除整列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE People</span><br><span class="line">DROP COLUMN DateOfBirth;</span><br></pre></td></tr></table></figure><p>要删除整个表格</p><p><code>DROP TABLE People;</code></p><p>RENAME用于列改名或者对表格改名</p><p>将People的FirstName列改名为name</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE People</span><br><span class="line">CHANGE FirstName name varchar(100);</span><br></pre></td></tr></table></figure><p>将整个表格改名</p><p><code>RENAME TABLE People TO Users;</code></p><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><p>为了更加方便的组织和操作数据库，经常需要使用视图。视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的真实的表中的字段。我们可以向视图添加 SQL 函数、WHERE 以及 JOIN 语句，我们也可以提交数据，就像这些来自于某个单一的表。</p><p>创建语句如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE VIEW view_name AS</span><br><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE condition;</span><br></pre></td></tr></table></figure><p>假设一表格，如<br><img src="/%5Cimages%5C2017%5C01%5C26.png"></p><p>我们要创建一个视图来展示职工的名字和薪水</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE VIEW List AS</span><br><span class="line">SELECT FirstName, Salary</span><br><span class="line">FROM  Employees;</span><br></pre></td></tr></table></figure><p>接下来可以类似展示表格一样展示视图</p><p><code>SELECT * FROM List;</code></p><p><img src="/%5Cimages%5C2017%5C01%5C27.png"></p><p>可以用以下语句来更新视图</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE OR REPLACE VIEW view_name AS</span><br><span class="line">SELECT column_name(s)</span><br><span class="line">FROM table_name</span><br><span class="line">WHERE condition;</span><br></pre></td></tr></table></figure><p>例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE OR REPLACE VIEW List AS</span><br><span class="line">SELECT FirstName, LastName, Salary</span><br><span class="line">FROM  Employees;</span><br></pre></td></tr></table></figure><p><img src="/%5Cimages%5C2017%5C01%5C28.png"></p><p>丢弃视图<br><code>DROP VIEW List;</code></p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/SQL/">SQL</category>
      
      <category domain="http://example.com/tags/Note/">Note</category>
      
      
      <comments>http://example.com/2017/01/17/Note-for-SoloLearn-SQL/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Note of Recommendation System in Action</title>
      <link>http://example.com/2017/01/16/Action/</link>
      <guid>http://example.com/2017/01/16/Action/</guid>
      <pubDate>Sun, 15 Jan 2017 16:19:00 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要关于项亮的《推荐系统实践》的笔记。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要关于项亮的《推荐系统实践》的笔记。</p><span id="more"></span><h2 id="推荐系统的评测方式"><a href="#推荐系统的评测方式" class="headerlink" title="推荐系统的评测方式"></a>推荐系统的评测方式</h2><p>以下也是一项最终能上线的推荐算法的依次测试顺序，</p><ul><li>离线评测<ul><li>将数据集分为训练集和测试集，离线对算法进行评测</li></ul></li><li>用户调查<ul><li>在上线之前通过调查得到用户满意度的信息</li></ul></li><li>在线评测<ul><li>进行AB测试，对比推荐算法指标</li></ul></li></ul><h2 id="推荐系统的评测指标"><a href="#推荐系统的评测指标" class="headerlink" title="推荐系统的评测指标"></a>推荐系统的评测指标</h2><ul><li>满意度<ul><li>是推荐系统的最重要标准</li><li>无法离线计算，只能通过用户调查和在线实验得到</li><li>可通过停留时间、点击率和转化率来统计</li></ul></li><li>预测准确度<ul><li>最重要的离线测试标准</li><li>主要方法是，在离线数据集内的训练集训练的结果与测试集对比，比较重合度。</li><li>又分为评分预测和Top N推荐</li><li>对于评分预测，有均方根误差（RMSE）和平均绝对误差（MAE）计算两种方式，相差不大，前者对于偏离项惩罚大，后者对于评分取整的情况会降低误差。</li><li>对于Top N推荐，通常通过准确率和招呼率来评测<ul><li>假设$R(u)$和$T(u)$分别是训练集和测试集上的推荐，那么两者的交集长度除以$R(u)$的长度就是precision，交集长度除以$T(u)$就是recall。</li></ul></li><li>评分预测关注预测用户看了电影后会给电影什么样的评分，而Top N是找到用户最有可能感兴趣的电影</li></ul></li><li>覆盖率coverage<ul><li>粗略定义为推荐系统发掘的物品占全部物品的比率，精确定义为物品流行度与全部物品流行度的比率</li><li>可通过信息熵和基尼系数来计算</li><li>两者都是计算不同物品流行度之间的平衡度</li><li>推荐系统一般具有马太效应：强者更强</li></ul></li><li>多样性<ul><li>要覆盖满足用户广大的兴趣，可以用不同的物品相似度度量函数来定义不同的多样性</li><li>多样性和相似性是trade off的，需要达到一定的平衡，让推荐效果最好</li></ul></li><li>新颖性<ul><li>推荐用户未见过的物品，最简单的是推荐流行度低的物品</li><li>难点在于不牺牲精度的前提下提高多样性和新颖性</li></ul></li><li>惊喜度<ul><li>推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。</li></ul></li><li>信任度<ul><li>用户对推荐系统的信任度高，能增加用户与推荐系统的交互</li><li>提升用户对推荐系统的信任度的方法<ul><li>增加推荐系统的透明度：对用户的推荐需要进行解释</li><li>提高用户的社交关系进行推荐</li></ul></li></ul></li><li>实时性<ul><li>实时更新追踪用户的行为和状态的变化</li><li>能够将新加入的物品推荐给用户</li></ul></li><li>鲁棒性<ul><li>反作弊性</li><li>作弊方法<ul><li>行为注入攻击</li><li>评分系统攻击：大批给某物品打高分</li></ul></li><li>如何对抗作弊<ul><li>采用作弊代价高的行为作为推荐系统采纳的数据</li><li>使用数据前进行检测、清理</li></ul></li></ul></li><li>商业目标<ul><li>不同利益方关注不同</li></ul></li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Recommendation-System/">Recommendation System</category>
      
      
      <comments>http://example.com/2017/01/16/Action/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Sort Algorithms of Linear Time Complexity</title>
      <link>http://example.com/2017/01/13/Sort-Algorithms-of-Linear-Time-Complexity/</link>
      <guid>http://example.com/2017/01/13/Sort-Algorithms-of-Linear-Time-Complexity/</guid>
      <pubDate>Fri, 13 Jan 2017 12:05:31 GMT</pubDate>
      
      <description>&lt;p&gt;常用排序算法如归并、快排、堆排序等基于比较的排序方法都是不能突破$O(n \log n)$时间复杂度的，本文着重介绍几种线性时间复杂度的排序方法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>常用排序算法如归并、快排、堆排序等基于比较的排序方法都是不能突破$O(n \log n)$时间复杂度的，本文着重介绍几种线性时间复杂度的排序方法。</p><span id="more"></span><p>基于比较的排序为何不能突破$O(n \log n)$时间复杂度？因为$N$个数有$N!$个可能的排列情况，也就是说基于比较的排序算法的判定树有$N!$个叶子结点，比较次数至少为$\log(N!)= O(N \log N)$ (斯特林公式)</p><p>而线性复杂度的排序方法通常来说有计数排序、桶排序和基数排序三种。</p><h2 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h2><p>计数排序（Counting sort）是一种稳定的线性时间排序算法，Θ(n + k)的时间复杂度。n 是待排序数组的大小，k 是辅助数组 count 的大小。</p><p>因为它并不是基于比较的的排序算法，所以它没有O(NlogN)的下限。并且在一定的条件下，使用该算法比使用快排能带来更好的效率。例如在基数排序中就运用了计数排序，因为它只需要额外的10个元素大小的辅助数组，线性的效率，并保证了稳定性。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>计数排序的主要思想是将待排序元素的值作为下标，利用辅助数组 count 记录所有的元素出现的次数。即 count[i] 的值代表元素 i 在原始数组中出现的次数。这样，原始数组的所有元素就被有有序地记录下来。</p><p>当然，只知道某个元素出现的次数是不足以排序的。仔细观察 count 数组，发现对 count 数组进行累加（count[i] += count[i-1]）后，count[i] 的含义就变成了原始数组 i 前面有 count[i]个数是不大于它的。最后就可以根据 count 数组中的排名去构造一个已排序的数组了。</p><p>下面以原始数组d = {8, 13, 0, 3, 20, 16, 9, 7, 11, 5} 去演示上述的过程：</p><p>![](\images\2017\01\Screen Shot 2017-01-13 at 23.06.23.png)</p><p>或者是数组中有重复元素的情况：</p><p>![](\images\2017\01\Screen Shot 2017-01-13 at 23.06.41.png)</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>计数排序虽然效率高，却有其受限的条件。</p><p>只能对[0, K]区间的非负整数进行排序。<br>当 K 很大时，空间复杂度会变得很大。<br>所以，如果是对于[0, 100]这样的区间，计数排序是个好的选择。考虑到空间复杂度的优化，也可以用原始数组中的 (最大值 - 最小值 + 1) 作为 count 数组的大小。</p><h3 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    数组 d 的元素只能位于[0, K)区间的非负整数，O(n + K)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">counting_sort</span><span class="params">(<span class="keyword">int</span> d[], <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> max = <span class="number">0</span>, min = Integer.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (max &lt; d[i])</span><br><span class="line">            max = d[i];</span><br><span class="line">        <span class="keyword">if</span> (min &gt; d[i])</span><br><span class="line">            min = d[i];</span><br><span class="line">    &#125;</span><br><span class="line">    max++;</span><br><span class="line">    <span class="keyword">int</span>[]  count = <span class="keyword">new</span> <span class="keyword">int</span>[max - min; <span class="comment">//优化空间</span></span><br><span class="line">    <span class="keyword">int</span>[] ans = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; max; ++i) count[i] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) count[d[i] - min]++;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; max; ++i) count[i] += count[i - <span class="number">1</span>];</span><br><span class="line">    <span class="comment">//这里必须逆序循环，不然会造成排序结果失去稳定性。</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = n - <span class="number">1</span>; i &gt;= <span class="number">0</span>; --i)</span><br><span class="line">      ans[ --count[d[i]- min] ] = d[i];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h2><h2 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h2>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      <category domain="http://example.com/tags/Java/">Java</category>
      
      
      <comments>http://example.com/2017/01/13/Sort-Algorithms-of-Linear-Time-Complexity/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Polymorphism of Java</title>
      <link>http://example.com/2017/01/13/Polymorphism-of-Java/</link>
      <guid>http://example.com/2017/01/13/Polymorphism-of-Java/</guid>
      <pubDate>Fri, 13 Jan 2017 10:15:27 GMT</pubDate>
      
      <description>&lt;p&gt;最近面试被问到Java的多态怎么理解，自己含含糊糊的感觉自己知道点含义可是就是具体怎么说打不出来，尴尬死。接下来打算把三大特性：封装、继承、多态都好好的写下来，以参考。本文先写关于Java的多态吧。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>最近面试被问到Java的多态怎么理解，自己含含糊糊的感觉自己知道点含义可是就是具体怎么说打不出来，尴尬死。接下来打算把三大特性：封装、继承、多态都好好的写下来，以参考。本文先写关于Java的多态吧。</p><span id="more"></span><p>多态，用一句话来说，就是<strong>事物在运行过程中存在不同的状态</strong>。多态的存在有三个前提:</p><ol><li>要有继承关系</li><li>子类要重写父类的方法</li><li>父类引用指向子类对</li></ol><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>我们先定义一个父类Animal</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> num = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">int</span> age = <span class="number">20</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;动物在吃饭&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> stastic <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;动物在睡觉&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;动物在奔跑&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再定义一个子类Cat</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> num = <span class="number">30</span>;</span><br><span class="line">  <span class="keyword">int</span> age = <span class="number">40</span>;</span><br><span class="line">  String name = <span class="string">&quot;Tom&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;猫在吃饭&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> stastic <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;猫在睡觉&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">catchMouse</span><span class="params">()</span></span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;猫在抓老鼠&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再来一个测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo_Test</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> stastic <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">    Animal am = <span class="keyword">new</span> Cat();</span><br><span class="line">    am.eat();</span><br><span class="line">    am.sleep();</span><br><span class="line">    am.run();</span><br><span class="line">    System.out.println(am.num);</span><br><span class="line">    System.out.println(am.age);</span><br><span class="line"></span><br><span class="line">    am.catchMouse();</span><br><span class="line">    System.out.println(am.name);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先来看看上面是否满足三个条件：</p><ol><li>子类Cat继承了父类Animal；</li><li>子类重写了父类的eat()、sleep()方法，其中前者是非静态，后者是静态方法；</li><li>在堆内存中开辟了子类Cat()对象，并把存在于栈内存中的Animal()引用指向这个对象。</li></ol><p>然后我们看一下运行结果，应该是</p><p>猫在吃饭<br>动物在睡觉<br>动物在奔跑<br>10<br>20</p><p>那么为什么呢？</p><ul><li>子类重写了父类的非静态成员方法，对象am.eat()的输出结果是“猫在吃饭”；</li><li>子类重写了父类的静态成员方法，对象am.sleep()的输出结果是“动物在睡觉”；</li><li>未被子类重写的方法am.run()的输出结果是“动物在奔跑”。</li></ul><p>那么可以总结出多态成员访问的特点：</p><ul><li>成员变量：编译看左边(父类),运行看左边(父类)</li><li>成员方法：编译看左边(父类)，运行看右边(子类)。动态绑定</li><li>静态方法：编译看左边(父类)，运行看左边(父类)(静态和类相关，算不上重写，所以，访问还是左边的)</li></ul><p>只有非静态的成员方法,编译看左边,运行看右边，而以上的这个过程就叫做<strong>多态的向上转型</strong>。</p><h2 id="多态的缺点"><a href="#多态的缺点" class="headerlink" title="多态的缺点"></a>多态的缺点</h2><p>多态也存在缺点，也就是无法尝试调用子类特有的方法，如上面未展示am.catchMouse();<br>System.out.println(am.name);两行代码都是会报错的，因为这是子类特有的成员方法和成员属性。</p><p>如果我们需要调用子类的特有成员方法和成员属性，那么应该将这个父类强制转换为子类类型，如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo_Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">Animal am = <span class="keyword">new</span> Cat();</span><br><span class="line">am.eat();</span><br><span class="line">am.sleep();</span><br><span class="line">am.run();</span><br><span class="line"><span class="comment">//am.catchMouse();</span></span><br><span class="line"><span class="comment">//System.out.println(am.name);</span></span><br><span class="line">System.out.println(am.num);</span><br><span class="line">System.out.println(am.age);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;------------------------------&quot;</span>);</span><br><span class="line">Cat ct = (Cat)am;</span><br><span class="line">ct.eat();</span><br><span class="line">ct.sleep();</span><br><span class="line">ct.run();</span><br><span class="line">ct.catchMouse();</span><br><span class="line">&#125;        </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>执行强制类型转换<code>Cat ct = (Cat)am</code>后，这时ct就指向堆里最先创建的Cat()对象了，自然能使用Cat类的一切成员方法和成员属性了。这也是多态的魅力，为了使用子类的某些方法不需要重新再开辟内存。以上就是<strong>多态中的向下转型</strong>。</p><h2 id="通俗解释"><a href="#通俗解释" class="headerlink" title="通俗解释"></a>通俗解释</h2><p>花木兰替父从军<br>大家都知道花木兰替父从军的例子，花木兰替父亲花弧从军。那么这时候花木兰是子类，花弧是父类。花弧有自己的成员属性年龄，姓名，性别。花木兰也有这些属性，但是很明显二者的属性完全不一样。花弧有自己的非静态成员方法‘骑马杀敌’，同样花木兰也遗传了父亲一样的方法‘骑马杀敌’。花弧还有一个静态方法‘自我介绍’，每个人都可以问花弧姓甚名谁。同时花木兰还有一个自己特有的非静态成员方法‘涂脂抹粉’。但是，现在花木兰替父从军，女扮男装。这时候相当于父类的引用（花弧这个名字）指向了子类对象（花木兰这个人），那么在其他类（其他的人）中访问子类对象（花木兰这个人）的成员属性（姓名，年龄，性别）时，其实看到的都是花木兰她父亲的名字（花弧）、年龄（60岁）、性别（男）。当访问子类对象（花木兰这个人）的非静态成员方法（骑马打仗）时，其实都是看到花木兰自己运用十八般武艺在骑马打仗。当访问花木兰的静态方法时（自我介绍），花木兰自己都是用她父亲的名字信息在向别人作自我介绍。并且这时候花木兰不能使用自己特有的成员方法‘涂脂抹粉’。—–多态中的向上转型<br>那么终于一将功成万骨枯，打仗旗开得胜了，花木兰告别了战争生活。有一天，遇到了自己心爱的男人，这时候爱情的力量将父类对象的引用（花弧这个名字）强制转换为子类对象本来的引用（花木兰这个名字），那么花木兰又从新成为了她自己，这时候她完全是她自己了。名字是花木兰，年龄是28，性别是女，打仗依然那样生猛女汉子，自我介绍则堂堂正正地告诉别人我叫花木兰。OMG！终于，终于可以使用自己特有的成员方法‘涂脂抹粉’了。从此，花木兰完全回到了替父从军前的那个花木兰了。并且和自己心爱的男人幸福的过完了一生。—–多态中的向下转型<br>。</p><h2 id="参考出处"><a href="#参考出处" class="headerlink" title="参考出处"></a>参考出处</h2><ul><li>作者：程序狗<br>链接：<a href="https://www.zhihu.com/question/30082151/answer/120520568">https://www.zhihu.com/question/30082151/answer/120520568</a><br>来源：知乎</li></ul>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Java/">Java</category>
      
      <category domain="http://example.com/tags/OOP/">OOP</category>
      
      
      <comments>http://example.com/2017/01/13/Polymorphism-of-Java/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Map 0f Java</title>
      <link>http://example.com/2017/01/13/Map-0f-Java/</link>
      <guid>http://example.com/2017/01/13/Map-0f-Java/</guid>
      <pubDate>Fri, 13 Jan 2017 05:53:14 GMT</pubDate>
      
      <description>&lt;p&gt;整理关于Java的Map相关的知识，最近面试有被问到关于此类数据结构的知识，故写下来总结一番。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>整理关于Java的Map相关的知识，最近面试有被问到关于此类数据结构的知识，故写下来总结一番。</p><span id="more"></span><p>List和Map都是java.util里面有关集合的数据结构类。Map主要的功能是元素对（键值对）的形式，每个键都映射到一个类。接下来我们介绍Map的分类、初始化、遍历的方式、排序方法以及常用API。</p><h2 id="Map类"><a href="#Map类" class="headerlink" title="Map类"></a>Map类</h2><p>Java中的Map类可分为三种：</p><ul><li>通用Map：用于在应用程序内管理映射，通常在java.utils内<ul><li>HashMap、</li><li>Hashtable、</li><li>Properties、</li><li>LinkedHashMap、</li><li>IdentityHashMap、</li><li>TreeMap、WeakHashMap、</li><li>ConcurrentHashMap</li></ul></li><li>专用Map：不必我们自己创建，而是通过其他应用程序访问<ul><li>java.util.jar.Attribute、javax.print.attribute.standard.PrinterStateReasons、java.security.Provider、java.awt.RenderingHints、javax.swing.UIDefaults</li></ul></li><li>自定义Map</li></ul><h2 id="常用类型的区别"><a href="#常用类型的区别" class="headerlink" title="常用类型的区别"></a>常用类型的区别</h2><ul><li>HashMap<ul><li>最常用的Map，速度快，非同步（不支持线程同步）</li><li>允许一条键为null：多了覆盖</li><li>允许多条值为null</li></ul></li><li>TreeMap<ul><li>用Iterator遍历的时候返回以key为序的序列</li><li>故不允许key为空</li><li>非同步</li></ul></li><li>HashTable<ul><li>类似HashMap，但是写入速度慢</li><li>因为支持线程同步：同一时刻只能有一线程能写HashTable</li></ul></li><li>LinkedHashMap<ul><li>保持了插入顺序，Iterator遍历时先进先出</li><li>key、value都允许为空</li></ul></li></ul><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//建立</span></span><br><span class="line">HashMap&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line"><span class="comment">//寻值</span></span><br><span class="line">map.get(<span class="string">&quot;key1&quot;</span>);</span><br><span class="line"><span class="comment">//插入</span></span><br><span class="line">map.put(<span class="string">&quot;key2&quot;</span>, <span class="string">&quot;value2&quot;</span>);</span><br><span class="line"><span class="comment">//移除</span></span><br><span class="line">map.remove(<span class="string">&quot;key1&quot;</span>);</span><br><span class="line"><span class="comment">//清空</span></span><br><span class="line">map.clear();</span><br><span class="line"><span class="comment">//</span></span><br></pre></td></tr></table></figure><h2 id="Map的遍历"><a href="#Map的遍历" class="headerlink" title="Map的遍历"></a>Map的遍历</h2><p>初始化</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">map.put(<span class="string">&quot;key1&quot;</span>, <span class="string">&quot;value1&quot;</span>);</span><br><span class="line">map.put(<span class="string">&quot;key2&quot;</span>, <span class="string">&quot;value2&quot;</span>);</span><br></pre></td></tr></table></figure><p>分别使用增强for循环和Iterator来遍历</p><h3 id="增强for循环遍历"><a href="#增强for循环遍历" class="headerlink" title="增强for循环遍历"></a>增强for循环遍历</h3><h4 id="KeySet遍历"><a href="#KeySet遍历" class="headerlink" title="KeySet遍历"></a>KeySet遍历</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (String key: map.keySet())&#123;</span><br><span class="line">  System.out.println(key + <span class="string">&quot;: &quot;</span> + map.get(key));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="entrySet遍历"><a href="#entrySet遍历" class="headerlink" title="entrySet遍历"></a>entrySet遍历</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry: map.entrySet())&#123;</span><br><span class="line">  System.out.println(entry.getKey() + <span class="string">&quot;: &quot;</span> + entry.getValue());</span><br></pre></td></tr></table></figure><h3 id="Iterator遍历"><a href="#Iterator遍历" class="headerlink" title="Iterator遍历"></a>Iterator遍历</h3><h4 id="KeySet遍历-1"><a href="#KeySet遍历-1" class="headerlink" title="KeySet遍历"></a>KeySet遍历</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;String&gt; iterator = map.keySet().iterator();</span><br><span class="line"><span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">  String key = iterator.next();</span><br><span class="line">  System.out.println(key + <span class="string">&quot;: &quot;</span> + map.get(key));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="entrySet遍历-1"><a href="#entrySet遍历-1" class="headerlink" title="entrySet遍历"></a>entrySet遍历</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = map.entrySet().iterator();</span><br><span class="line"><span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">    Map.Entry&lt;String, String&gt; entry = iterator.next();</span><br><span class="line">    System.out.println(entry.getKey() + <span class="string">&quot;：&quot;</span> + entry.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="遍历性能"><a href="#遍历性能" class="headerlink" title="遍历性能"></a>遍历性能</h3><p>就实验比较，</p><ul><li><p>增强for循环使用方便，但性能较差，不适合处理超大量级的数据。</p></li><li><p>迭代器的遍历速度要比增强for循环快很多，是增强for循环的2倍左右。</p></li><li><p>使用entrySet遍历的速度要比keySet快很多，是keySet的1.5倍左右。</p></li></ul><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>TreeMap排序，若是升序只需要按序输出即可，降序需要改写比较器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; map = <span class="keyword">new</span> TreeMap&lt;String, String&gt;(<span class="keyword">new</span> Comparator&lt;String&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(String obj1, String obj2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> obj2.compareTo(obj1);<span class="comment">// 降序排序</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">map.put(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">map.put(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;b&quot;</span>);</span><br><span class="line">map.put(<span class="string">&quot;c&quot;</span>, <span class="string">&quot;a&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (String key : map.keySet()) &#123;</span><br><span class="line">    System.out.println(key + <span class="string">&quot; ：&quot;</span> + map.get(key));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>HashMap\HashTable\LinkedHashMap排序</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">map.put(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">map.put(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;b&quot;</span>);</span><br><span class="line">map.put(<span class="string">&quot;c&quot;</span>, <span class="string">&quot;a&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过ArrayList构造函数把map.entrySet()转换成list</span></span><br><span class="line">List&lt;Map.Entry&lt;String, String&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;Map.Entry&lt;String, String&gt;&gt;(map.entrySet());</span><br><span class="line"><span class="comment">// 通过比较器实现比较排序</span></span><br><span class="line">Collections.sort(list, <span class="keyword">new</span> Comparator&lt;Map.Entry&lt;String, String&gt;&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Map.Entry&lt;String, String&gt; mapping1, Map.Entry&lt;String, String&gt; mapping2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapping1.getKey().compareTo(mapping2.getKey());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;String, String&gt; mapping : list) &#123;</span><br><span class="line">    System.out.println(mapping.getKey() + <span class="string">&quot; ：&quot;</span> + mapping.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常用API"><a href="#常用API" class="headerlink" title="常用API"></a>常用API</h2><table><thead><tr><th>method</th><th>作用</th></tr></thead><tbody><tr><td>clear()</td><td>从 Map 中删除所有映射</td></tr><tr><td>remove(Object key)</td><td>从 Map 中删除键和关联的值</td></tr><tr><td>put(Object key, Object value)</td><td>将指定值与指定键相关联</td></tr><tr><td>putAll(Map t)</td><td>将指定 Map 中的所有映射复制到此 map</td></tr><tr><td>entrySet()</td><td>返回 Map 中所包含映射的 Set 视图。Set 中的每个元素都是一个 Map.Entry 对象，可以使用 getKey() 和 getValue() 方法（还有一个 setValue() 方法）访问后者的键元素和值元素</td></tr><tr><td>keySet()</td><td>返回 Map 中所包含键的 Set 视图。删除 Set 中的元素还将删除 Map 中相应的映射（键和值）</td></tr><tr><td>values()</td><td>返回 map 中所包含值的 Collection 视图。删除 Collection 中的元素还将删除 Map 中相应的映射（键和值）</td></tr><tr><td>get(Object key)</td><td>返回与指定键关联的值</td></tr><tr><td>containsKey(Object key)</td><td>如果 Map 包含指定键的映射，则返回 true</td></tr><tr><td>containsValue(Object value)</td><td>如果此 Map 将一个或多个键映射到指定值，则返回 true</td></tr><tr><td>isEmpty()</td><td>如果 Map 不包含键-值映射，则返回 true</td></tr><tr><td>size()</td><td>返回 Map 中的键-值映射的数目</td></tr></tbody></table>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Java/">Java</category>
      
      <category domain="http://example.com/tags/Data-Structure/">Data Structure</category>
      
      
      <comments>http://example.com/2017/01/13/Map-0f-Java/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>To be a great commander</title>
      <link>http://example.com/2017/01/11/good%20commander/</link>
      <guid>http://example.com/2017/01/11/good%20commander/</guid>
      <pubDate>Wed, 11 Jan 2017 07:19:05 GMT</pubDate>
      
      <description>&lt;p&gt;近来偶然读到林彪元帅关于如何进行军事工作写的工作总结，不光是军事，应用到日常工作、做事也是很好的指导，这是林彪不到30岁时候写下的文字，顿时明白为何人家23岁就可以当军长的原因。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>近来偶然读到林彪元帅关于如何进行军事工作写的工作总结，不光是军事，应用到日常工作、做事也是很好的指导，这是林彪不到30岁时候写下的文字，顿时明白为何人家23岁就可以当军长的原因。</p><span id="more"></span><p>杨成武回忆：1936年12月,西安事变爆发，红军大学第一期毕业。即将奔赴前线，林彪找我谈话，给我留下很深的印象。我过去当政委，还想干老本行。但军 委经过全面考虑,确定我当师长。林彪说毛主席要我和你谈一次话，讲一下怎样当好师长的问题。谈话时罗瑞卿也在场,杨成武认真作了记录。林彪讲了九条,这也 是他自己在战争中的体会：</p><p>一、要勤快。不勤快的人办不好事情，不能当好军事指挥员。应该自己干的事情一定要亲自过目，亲自动手。比如，应该上去看的山头就要爬上去，应该了解的情况 就要及时了解，应该检查的问题就要严格检查。不能懒，军事指挥员切忌懒，因为懒会带来危险，带来失败。比方说，一个军事指挥员，到了宿营地就进房子，搞水 洗脸洗脚，搞鸡蛋煮面吃，吃饱了就睡大觉。他对住的村子有多大，在什么位置，附近有几个山头周围有几条道路，敌情怎么样，群众条件怎么样，可能发生什么情 况，部队到齐了没有，哨位在什么地方，发生紧急情况时的处置预案如何，都不过问，都不知道。这样，如果半夜三更发生了情况，敌人来个突然袭击，就没有办法 了。到那种时候，即使平时很勇敢的指挥员，也会束手无策，只好三十六计，跑为上计，结果，变成一个机会主义者。机会主义和打败仗，常常是因为没有思想准 备，没有组织准备，工作没有做到家，懒的结果。因此，不论大小指挥员都要勤快，要不惜走路，不怕劳累，要多用脑子，要做到心到、眼到、口到、脚到、手到。 事情没有做好以前，不能贪闲。贪闲就隐伏着犯错误的根子。什么事都要心中有底，“凡事预则立，不预则废”。雷打不动的干部，牛皮糖式的干部，不管有多大本 事，都不是好干部。</p><p>　　二、要摸清上级的意图。对上级的意图要真正理解，真正融会贯通，真正认识自己所受领的任务在战役、战斗全局中的 地位和作用。这样，才能充分发挥自己的主观能动性；才能打破框框，有敢于和善于在新情况中找到新办法的创造性；才能有大勇，才能决心强、决心狠，敢于彻底 胜利，有强烈的吞掉敌人的企图和雄心。指挥员的勇敢集中表现在歼敌决心的坚定顽强上面。指挥员的大勇建立在革命的最高自觉性和正确理解上级意图的基础上 面。</p><p>　　三、要调查研究。对于敌情、地形、部队的情况和社会情况，要经常做到心中有数。要天天摸，天天琢磨，不能间断。这样做，不能看 作是重复，实际上这不是重复，而是不断深化不断提高的过程，是取得正确认识的必不可少的手段。平时积累掌握的情况越多，越系统，在战时，特别是在紧张复杂 的情况下，就越沉着，越有办法。急中生智的“智”，才有基础。因此，调查研究工作要贯串在各项工作中，要贯串在每一次战役、战斗的整个过程，反对打莽撞 仗、糊涂仗，反对急性病，反对不亲自动手做调查研究的懒汉作风。特别是敌情，必须切实摸透。因为敌情是活的，敌人必然会极力隐蔽、伪装他们的真实企图和行 动。要尽一切可能不间断地侦察，查清敌人的部署和动向，看他扮演什么角色？是主角还是配角？是主力还是非主力？是骄兵还是败兵？能集中多大兵力向我们进攻 和阻挡我们的进攻。查明敌主官的特性，看他惯用和擅长用什么战法，根据他当前的企图判断他可能采用什么打法，等等。只要摸清了敌情、我情、地形的底，决心 就快，就硬，就坚定。就不会被任何假象所迷惑，就不会被任何困难所吓住。如果情况不清，就会犹豫不决，举棋不定，坐失良机，或者勉强下了决心，一遇风吹草 动，听到畏难叫苦和不正确的建议，就容易动摇，可能一念之差，前功尽弃。</p><p>　　四、要有个活地图。指挥员和参谋必须熟悉地图，要经常读地 图。熟读地图可以产生见解，产生智慧，产生办法，产生信心。读的方法是把图挂起来，搬个凳子坐下来，对着地图看，从大的方向到活动地区，从地区全貌到每一 地段的地形特点，从粗读到细读，逐块逐块地读，用红蓝铅笔把主要的山脉、河流、城镇、村庄、道路标划出来，边读，边划，等到地图差不多快划烂了，也就差不 多把地图背熟了，背出来了。在熟读地图的基础上，要亲自组织有关指挥员和参谋对作战地区和战场进行实地勘察，核正地图，把战场的地形情况和敌我双方的兵力 部署都装至脑子里去，做到闭上眼睛面前就有一幅鲜明的战场图影，离开地图也能指挥作战。这样，在你死我活、瞬息万变的战斗情况下，可以比敌人来得快，争取 先机，先敌一着，掌握主动，稳操胜券。</p><p>　　五、要把各方面的问题想够想透。每一次战役、战斗的组织，要让大家提出各种可能出现的问题， 要让大家来找答案，而且要从最坏的最严重的情况来找答案。把所有提出来的问题都回答了，再没有问题没有回答的了，这样，打起仗来才不会犯大错误，万一犯了 错误，也比较容易纠正。没有得到答案的问题，不能因为想了很久想不出来就把它丢开，留下一个疙瘩。如果这样，是很危险的，在紧要关头，这个疙瘩很可能冒出 来，就会使你们心中无数，措手不及。当然，在战争环境中，要考虑的问题很多，不可能一次都提完，也不可能一次都回答完，整个战役、战斗的过程，就是不断提 出问题和不断回答问题的过程。有时脑子很疲劳，有的问题可能立即回答不了。这时，除了好好地和别人商量以外，就好好地睡一觉，睡好了，睡醒了，头脑清醒 了，再躺在床上好好想一想，就可能开窍，可能想通了，回答了，解决了。总之，对每一个问题不能含糊了事。问题回答完了，战役、战斗的组织才算完成。</p><p>　 　六、要及时下达决心。在什么样的情况下可以下决心打呢？指挥员必须以最大努力组织战役、战斗的准备工作，力求确有把握才动手，不打无把握之仗。但是任何 一次战斗都不可能完全具备各种条件，不可能有百分之百的把握。一般说有百分之七十左右的把握，就很不错了，就要坚决地打，放手地打。不足的条件，要通过充 分发挥人的因素的作用，依靠人民群众的力量，充分发挥人民军队特有的政治上的优势，充分发挥指战员的智慧和英勇顽强的战斗作风来弥补，以主观努力来创造条 件，化冒险性为创造性，取得胜利。</p><p>　　七、要有一个很好的很团结的班子。领导班子思想认识要一致，行动要协调、合拍，要雷厉风行，要有革命英雄主义的气概。都要勤快，都千方百计地办好事情，完成任务。不互相扯皮，不互相干扰，不抱旁观者的态度。如果领导班子不好，人多不但无用，反而有害。</p><p>　 　八、要有一个很好的战斗作风。有好的战斗作风的部队才能打好仗，打胜仗。好的战斗作风首先是不叫苦，抢着去担负最艰巨的任务，英勇顽强，不怕牺牲，猛打 猛冲猛追。特别是要勇于穷追。因为把敌人打垮以后，追击是解决战斗、扩大战果、彻底歼灭敌人最关键的一招。在追击时，要跑步追，快步追，走不动的扶着拐棍 追，就是爬、滚，也要往前追，只有抓住敌人，才能吃掉敌人。好的战斗作风要靠平时养成，要靠实际锻炼，要在紧张、残酷的战斗中才能锻炼出来。不敢打硬仗、 恶仗的部队，让他打几次就打出来了，因为已经见识过硬仗、恶仗的场面，有了体会，有了经验，知道怎么打了，百炼成钢就是这个道理。做工作也要有好的作风， 说了就要做，说到那里做到那里，要做得干脆利索，要一竿子插到底，一点不含糊，不做好不撒手。好的作风的养成，关键在于干部。强将手下无弱兵，干部的作风 怎么样，部队的作风就会怎么样。因此，首先要抓好干部，要干部做出样子，影响带动部队。只要干部作风好，指挥好战斗，多打胜仗，即使是新建的部队或者原来 基础较弱的部队，也会很快打出好作风来，像铁锤一样，砸到那里，那里就碎。</p><p>　　九、要重视政治，亲自做政治工作。部队战斗力的提高 要靠平时坚强的党的领导、坚强的政治工作。连队的支部一定要建设好，支部的工作要做活，就是要把所有党团员的革命劲头鼓得足足的，充分发挥他们的模范作 用、带头作用，通过他们把全连带动起来，通过他们去做政治工作，提高全体指战员的阶级觉悟。有了坚强的党支部的领导，有了坚强的政治工作，就可以做到一呼 百应，争先恐后，不怕牺牲，前赴后继。战术、技术也要练好，特别是技术，如果枪打不准，战场上就不能消灭敌人，就不能解决战斗。因此，军事训练不能马虎， 党政工作要领导好训练。艺高人胆大，胆大艺更高，部队有了高度的无产阶级觉悟，有了好的战斗作风，再加上过硬的作战本领，就如虎添翼，就可以无敌于天下。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/life/">life</category>
      
      
      <comments>http://example.com/2017/01/11/good%20commander/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>logistic regression的公式手推相关</title>
      <link>http://example.com/2017/01/09/logistic-regression/</link>
      <guid>http://example.com/2017/01/09/logistic-regression/</guid>
      <pubDate>Mon, 09 Jan 2017 07:56:59 GMT</pubDate>
      
      <description>&lt;p&gt;本文有关logistic regression的公式相关的手推，包括假说函数、极大似然估计以及梯度下降算法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文有关logistic regression的公式相关的手推，包括假说函数、极大似然估计以及梯度下降算法。</p><span id="more"></span><h2 id="Hypothesis"><a href="#Hypothesis" class="headerlink" title="Hypothesis"></a>Hypothesis</h2><p>首选我们要明确，logistic regression虽然叫“回归”，但是它却是用来做分类的，也是最最常用的分类机器学习算法。其假说模型为：</p><p>$$<br>h_{\theta}(x) = g(\theta ^T x)<br>$$</p><p>其中$g(z) = \frac{1}{1+e^{-z}}$，so</p><p>$$<br>h_{\theta}(x) = \frac{1}{1+e^{-\theta ^T x}}<br>$$</p><p>可以看到，函数主体和线性回归一样，都是样本与参数的内积，但是逻辑回归是用来打分的，也就是判断样本是正负例的概率，需要$g(z)$也就是sigmoid或者logistics函数来将这个内积映射到一个区间(0,1)，所以实际上</p><p>$$<br>h_{\theta}(x) = p(y=1 | x;\theta)<br>$$</p><p>以上只是得出了样本点是正例的概率，到底预测它是正例还是负例，我们还需要一个decision boundary，例如</p><p>$$<br>h_{\theta}(x) \ge 0.5 \rightarrow y=1 \<br>h_{\theta}(x) \lt 0.5 \rightarrow y=0<br>$$</p><p>由于sigmoid函数的形状我们容易得到</p><p>$$<br>\theta ^T x \ge 0 \rightarrow y=1 \<br>\theta ^T x \lt 0 \rightarrow y=0<br>$$</p><p>当然，decision boundary属于假说函数的一部分，不一定就是0.5.</p><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>二元分类可以看做是一个伯努利分布，又叫做0-1分布，上面提到<br>$$<br>p(y=1 | x;\theta) = h_{\theta}(x)<br>$$</p><p>那么自然有</p><p>$$<br>p(y=0 | x;\theta) = 1 - h_{\theta}(x)<br>$$</p><p>那么总体分布也就是得到一个观测值的概率可以用Trick写成<br>$$<br>p(y | x;\theta) = (h_{\theta}(x))^y (1 - h_{\theta}(x^i))^{(1-y)}<br>$$</p><p>因为每一个样本和其他样本是独立同分布的，把它们的概率相乘得到似然函数，</p><p>$$<br>L(\theta) = \prod_{i=1}^{m}((h_{\theta}(x^i))^{y^i} (1 - h_{\theta}(x^i))^{(1-y^i)})<br>$$<br>为计算方便，取对数，得到</p><p>$$<br>l(\theta) = \sum_{i=1}^{m} (y^i \log(h_{\theta}(x^i)) +<br>(1-y^i) (1 - h_{\theta}(x^i))<br>)<br>$$</p><h2 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h2><p>既然逻辑回归是做预测的，那么损失函数就是预测错了多少的度量咯。比如我们就可以统计到底预测错了多少个，来当做损失函数，但是呢，这样的函数肯定是非凸的，不好优化，所以实际采用的损失函数是这样的</p><p>$$<br>J(\theta) = \frac{1}{m}\sum_{i=1}^{m} (Cost(h_{\theta}(x^i)), y^i)<br>$$</p><p>其中<br>$$<br>Cost(h_{\theta}(x), y) = -\log(h_{\theta}(x)) \ \  if \ \ y=1 \<br>;Cost (h_{\theta}(x), y) = -\log(1 - h_{\theta}(x)) \ \  if \ \ y=0<br>$$</p><p>可简写成：</p><p>$$<br>Cost(h_{\theta}(x), y) = -  y \log(h_{\theta}(x)) - (1-y) \log(1 - h_{\theta}(x))<br>$$</p><p>函数图像如下</p><p><img src="/%5Cimages%5C2017%5C01%5Coctave-workspace.png"></p><p><img src="/%5Cimages%5C2017%5C01%5CUt7vvXnxEead-BJkoDOYOw_f719f2858d78dd66d80c5ec0d8e6b3fa_Logistic_regression_cost_function_negative_class.png"></p><p>可以直观的看到，就是概率预测的和标签越接近惩罚越小，反之越大。当然，这里讲的只是二元分类，标签不是0就是1.</p><p>最后，逻辑回归的损失函数为</p><p>$$<br>J(\theta) = - \frac{1}{m} \sum_{i=1}^{m} (y^i \log(h_{\theta}(x^i)) + (1-y^i) \log (1-h_{\theta}(x^i))<br>$$</p><h2 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h2><p>梯度下降更新算法</p><p>$$<br>\theta_j = \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}<br>$$</p><p>其中，</p><p>$$<br>\frac{\partial J(\theta)}{\partial \theta_j} = - \frac{1}{m} \sum{i=1}^{m} (y^i \log(g(z)) + (1-y^i) \log (1-g(z))<br>$$</p><p>$$<br>= - \frac{1}{m} \sum_{i=1}^{m} ( \frac{y^i}{g(z)} \frac{\partial g(z)}{\theta_j} - \frac{1-y^i}{1-g(z)} \frac{\partial g(z)}{\theta_j})<br>$$</p><p>$$<br>= - \frac{1}{m} \sum_{i=1}^{m}   \frac{y^i - g(z)}{g(z)(1-g(z))}  \frac{\partial g(z)}{\theta_j}<br>$$</p><p>又<br>$$<br>\frac{\partial g(z)}{\theta_j} = g(z)(1-g(z)x_j^i<br>$$</p><p>代入上式可得<br>$$<br>\frac{\partial J(\theta)}{\partial \theta_j} =<br>\frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^i)-y^i)x_j^i<br>$$<br>这就得到了逻辑回归的梯度下降更新式子<br>$$<br>\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^i)-y^i)x_j^i<br>$$<br>是不是感觉和线性回归的式子一模一样？哈哈，很神奇吧！不过注意两者的假说函数$h_{\theta}(x)$是不同的，区别在这儿。</p><h2 id="牛顿法优化"><a href="#牛顿法优化" class="headerlink" title="牛顿法优化"></a>牛顿法优化</h2><p>除了梯度下降，其实还有许多可以对逻辑回归做优化的方法，例如牛顿法，这里有待下次更新。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2017/01/09/logistic-regression/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>linear regression 的公式手推相关</title>
      <link>http://example.com/2017/01/06/linear-regression/</link>
      <guid>http://example.com/2017/01/06/linear-regression/</guid>
      <pubDate>Fri, 06 Jan 2017 13:55:30 GMT</pubDate>
      
      <description>&lt;p&gt;本文有关多元linear Regression的损失函数从极大似然估计的角度的推导以及梯度下降算法。纯手打，^^&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文有关多元linear Regression的损失函数从极大似然估计的角度的推导以及梯度下降算法。纯手打，^^</p><span id="more"></span><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>我们的模型为</p><p>$$<br>h_{\theta}(x) =  \theta_0 + \theta_1x + \theta_2 x^2 … = \theta ^ TX<br>$$</p><p>似然函数为：</p><p>$$y^i = \theta ^ T x^i + \epsilon ^ i$$</p><p>，残差用$\epsilon$表示，对于每一个样本点的残差$\epsilon^i$，（注意以下标号中上标i表示第i个样本点），有：</p><p>$$<br>\epsilon^i = y^i - h_{\theta}(x^i) = y^i - \theta ^ T x^i<br>$$</p><p>那么我们有假设所有的残差根据中心极限定理，其密度函数$p(\epsilon^i)$符合均值为0，方差为$\sigma^2$的高斯分布，即</p><p>$$<br>p(\epsilon^i) = \frac{1}{\sqrt {2\pi} \sigma} \exp (-\frac{(\epsilon^i)^2}{2 \sigma ^2}) \<br>= \frac{1}{\sqrt {2\pi} \sigma} \exp (-\frac{(y^i - \theta ^ T x^i)^2}{2 \sigma ^2})<br>$$</p><p>那么，似然函数就是所有样本点的出现的概率乘积，即</p><p>$$<br>L(\theta) = \prod_{i=1}^{m} p(\epsilon^i) \<br>$$</p><p>$$<br>= \prod_{i=1}^{m} \frac{1}{\sqrt {2\pi} \sigma} \exp (-\frac{(y^i - \theta ^ T x^i)^2}{2 \sigma ^2})<br>$$</p><p>我们最终是求$\theta$的最优解，于是对似然函数取对数，</p><p>$$<br>l(\theta) = \log \left(\prod_{i=1}^{m} \frac{1}{\sqrt {2\pi} \sigma} \exp (-\frac{(y^i - \theta ^ T x^i)^2}{2 \sigma ^2})\right) \<br>$$</p><p>$$<br>= m \log \frac{1}{\sqrt {2\pi} \sigma} - \frac{1}{2 \sigma ^2} \sum _{i=1}^{m} (y^i - \theta ^ T x^i)^2<br>$$</p><p>扔掉常数项，就得到了线性回归的目标函数或error function，</p><p>$$<br>J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_{\theta}(x^i) - y^i) ^ 2<br>$$</p><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>以上可以把目标函数写成这样的形式：</p><p>$$<br>J(\theta) = \frac{1}{2} (X \theta - y)^T (X \theta - y)<br>$$</p><p>对向量$\theta$求导，</p><p>$$<br>\frac{\partial J(\theta)}{\partial \theta} =  X^T(X \theta - y)<br>$$</p><p>直接令上式为零，得到</p><p>$$<br>\theta = (X^TX)^{-1} X^Ty<br>$$</p><p>最小二乘法解线性回归理论很漂亮，但是因为复杂度的原因实际上不常用。因为矩阵求逆的复杂度为$O(n^3)$，很慢。另外一种解释是通常X不是满秩的，譬如生物学科里面的数据，特征有成千上万个，数据却少得可怜，这种通常是解不出特定的解的。</p><h2 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h2><p>常用的还是梯度下降法。以上得到了损失函数为</p><p>$$<br>J(\theta) = \frac{1}{2} \sum_{i=1}^m (h_{\theta}(x^i) - y^i) ^ 2<br>$$</p><p>那么，通过对$\theta$的各分量$\theta_i$根据梯度更新其值即可</p><p>$$<br>\theta_j = \theta_j -  \alpha \frac{\partial J(\theta)}{\partial \theta_j}<br>$$</p><p>而上式中</p><p>$$<br>\frac {\partial J(\theta)}{\partial \theta_i} =<br>$$</p><p>$$<br>\frac{1}{2m} \sum_{i=1}^m \frac{\partial(h_{\theta}(x^i) - y^i) ^ 2}{\partial \theta_j}<br>$$</p><p>$$<br>= \frac{2}{2m} \sum_{i=1}^m (h_{\theta}(x^i) - y^i)  \frac{\partial h_{\theta}(x^i)}{\partial \theta_j}<br>$$</p><p>又上式中</p><p>$$<br>\frac{\partial h_{\theta}(x^i)}{\partial \theta_j} =<br>\frac{\partial (\theta_0 x_0^i + \theta_1 x_1^i + \cdots+ \theta_j x_j^i + \cdots)}{\partial \theta_j} \<br>= \frac{\partial ( \theta_j x_j^i )}{\partial \theta_j}<br>= x_j^i<br>$$</p><p>一步步代上去可得</p><p>$$<br>\theta_j = \theta_j -  \alpha \frac{1}{m} \sum_{i=1}^m {(h_{\theta}(x^i) - y^i)} x_j^i<br>$$</p><p>这就是梯度下降法更新多元线性回归的公式啦！^_^</p><p>PS：有细心的同学可能发现上面的式子中添加了$\frac{1}{m}$，可能有疑惑，想问有什么区别。回答：其实是一样的，因为在机器学习中，我们并不关心最优化的时候，目标函数的极值是多少，而我们只关注，目标函数取极值的时候，参数的值是多少。所以因为这个原因，我们经常为了式子简便而对目标函数做缩放，比如上面的取对数，对数的底是e还是2根本没有区别。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2017/01/06/linear-regression/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>AliPay RedEnvelope Hacker</title>
      <link>http://example.com/2016/12/25/AliPay-RedEnvelope-Hacker/</link>
      <guid>http://example.com/2016/12/25/AliPay-RedEnvelope-Hacker/</guid>
      <pubDate>Sun, 25 Dec 2016 15:16:53 GMT</pubDate>
      
      <description>&lt;p&gt; 最近支付宝继续其逆天改命的追赶超越微信的社交梦之路，上线了狂拽酷炫吊炸天的AR红包玩法，顿时刷爆了一波朋友圈，但是这热闹后面也隐藏着一些问题甚至是致命Bug或者危机。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p> 最近支付宝继续其逆天改命的追赶超越微信的社交梦之路，上线了狂拽酷炫吊炸天的AR红包玩法，顿时刷爆了一波朋友圈，但是这热闹后面也隐藏着一些问题甚至是致命Bug或者危机。</p><span id="more"></span><p>AR红包一上线，毁誉参半，有媒体人产品方面人士表示“这是支付宝在对抗微信的战场上，难得的漂亮反击”，但是。。。同时很快有天才找到了作弊的方法，所谓实现了“早上试了一下，现在已经实现在家收红包的局面了”，方法其实类似我之后提到的，只是他用的是PS。。。方法是：</p><ul><li>截图放到ps里，建立和黑色条纹等宽的长条若干；</li><li>黑色条纹然后往上移动一点，覆盖住显示图片的区域，再复制一张截图置于顶层建立剪贴蒙板，把位置错来来看；</li><li>扫一下就可以领取红包了</li></ul><p> 以上来自知乎用户@Chain</p><p>很快我又找到了代码版本，是用php实现的，数行代码即可搞定（为了跑成功花了半小时学习如何安装并跑出php的Hello World，囧~）：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">imagecropper</span>(<span class="params"><span class="variable">$source_path</span></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="variable">$source_info</span>   = getimagesize(<span class="variable">$source_path</span>);</span><br><span class="line"><span class="variable">$source_width</span>  = <span class="variable">$source_info</span>[<span class="number">0</span>];</span><br><span class="line"><span class="variable">$source_height</span> = <span class="variable">$source_info</span>[<span class="number">1</span>];</span><br><span class="line"><span class="variable">$source_mime</span>   = <span class="variable">$source_info</span>[<span class="string">&#x27;mime&#x27;</span>];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$oldimg</span> = imagecreatefrompng(<span class="variable">$source_path</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$base_width</span>=<span class="number">340</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable">$base_height</span>=<span class="number">6</span>;</span><br><span class="line"><span class="variable">$baseimage</span> = imagecreatetruecolor(<span class="variable">$base_width</span>, <span class="variable">$base_width</span>);<span class="comment">// 苹果图啊</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$beginx</span> = <span class="number">150</span>;</span><br><span class="line"><span class="variable">$beginy</span> = <span class="number">444</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable">$thisimage</span> = imagecreatetruecolor(<span class="variable">$base_width</span>, <span class="variable">$base_height</span>);</span><br><span class="line">imagecopy(<span class="variable">$baseimage</span>, <span class="variable">$oldimg</span>, <span class="number">0</span>, <span class="number">0</span>,       <span class="variable">$beginx</span>,      <span class="variable">$beginy</span>, <span class="variable">$base_width</span>, <span class="variable">$base_height</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="variable">$i</span>=<span class="number">0</span>;<span class="variable">$i</span>&lt;<span class="number">30</span>;<span class="variable">$i</span>++)&#123;</span><br><span class="line">imagecopy(<span class="variable">$baseimage</span>, <span class="variable">$oldimg</span>, <span class="number">0</span>, <span class="variable">$i</span>*(<span class="variable">$base_height</span>*<span class="number">2</span>)-<span class="variable">$base_height</span>, <span class="variable">$beginx</span>, (<span class="variable">$beginy</span>+(<span class="variable">$i</span>*(<span class="variable">$base_height</span>*<span class="number">2</span>))),  <span class="variable">$base_width</span>, <span class="variable">$base_height</span>);</span><br><span class="line">imagecopy(<span class="variable">$baseimage</span>, <span class="variable">$oldimg</span>, <span class="number">0</span>, <span class="variable">$i</span>*(<span class="variable">$base_height</span>*<span class="number">2</span>), <span class="variable">$beginx</span>, (<span class="variable">$beginy</span>+(<span class="variable">$i</span>*(<span class="variable">$base_height</span>*<span class="number">2</span>))),  <span class="variable">$base_width</span>, <span class="variable">$base_height</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">header(<span class="string">&#x27;Content-Type: image/png&#x27;</span>);</span><br><span class="line">imagepng(<span class="variable">$baseimage</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">imagecropper(<span class="string">&quot;http://127.0.0.1/frank/img/IMG_0734.png&quot;</span>)</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>效果如下图：</p><p><img src="/images/2016/12/IMG_0723.PNG"></p><p><img src="/images/2016/12/IMG_0725.PNG"></p><p>算法的原理是：使用imagecreatetruecolor创建的新图像，利用imagecopy将指定坐标（截图中的线索图片的方框的左上角）开始的横条部分逐步依次由上到下复制到新图像上，以此达到用黑色条纹上下方的相似图像遮盖条纹的目的。当然原作者的iPhone肯定不是我这个型号，所以很显然这个开始复制的点需要测量手机截图的实际像素距离才可以确定（又花了半个小时测量我手机的截图的线索图片方框左上角的坐标，囧~）。</p><p>从这个实验的过程我也看到php作为与浏览器息息相关的语言的优势，上面的程序是每次运行都把新图片显示在浏览器里面，所以每次收到新截图都可以只需刷新一下浏览器就可以在屏幕上显示出处理后的图片了。</p><p>运行此php脚本的方法是将其放在xampp的htdocs目录下，开启Apache服务，再在浏览器中访问127.0.0.1/index.php 即可（index.php即脚本名）。</p><p>其实从AR红包上线以来就有许多问题，譬如</p><ul><li><p>如果线索图片是工卡、校园卡或者桌椅、纸巾等附近的人也可以拍到类似的物品或者含有类似logo物品的图片也是可以领取的，这就涉及到定位精准度等问题，不过我认为这也是玩法的乐趣所在，让人民群众喜闻乐见的作弊也是买点之一</p></li><li><p>而像上面提到的直接处理图片就可以作弊肯定就是大问题了，这说明阿里哦不，是蚂蚁金服对于图片的处理的算法急需改进，肯定不可能是这种错位一下图片就可以作弊的程度，这里我有个想法是加入类似于人脸识别里的判断是真人还是相片的模块，通过这个排除不是真实物品的利用屏幕上的图片来作弊的行为。</p></li></ul><p>好了，暂时先写这么多，祝圣诞快乐！</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/shenzhenjinma/aliredenvelope">支付宝红包破解算法</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2016/12/25/AliPay-RedEnvelope-Hacker/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>pointer and ++--</title>
      <link>http://example.com/2016/12/11/pointer-and/</link>
      <guid>http://example.com/2016/12/11/pointer-and/</guid>
      <pubDate>Sun, 11 Dec 2016 08:50:45 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要关于演示指针与自增自减运算符结合的时候的运算顺序。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要关于演示指针与自增自减运算符结合的时候的运算顺序。</p><span id="more"></span><table><thead><tr><th align="center">表达式</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center"><code>*p++</code>或<code>*(p++)</code></td><td align="center">自增前表达式的值是<code>*p</code>，然后自增<code>p</code></td></tr><tr><td align="center"><code>(*p)++</code></td><td align="center">自增前表达式的值是<code>*p</code>，然后自增<code>*p</code></td></tr><tr><td align="center"><code>*++p</code>或<code>*(++p)</code></td><td align="center">先自增<code>p</code>，自增后表达式的值是<code>*p</code></td></tr><tr><td align="center"><code>++*p</code>或<code>++(*p)</code></td><td align="center">先自增<code>*p</code>，自增后表达式的值是<code>*p</code></td></tr></tbody></table><p>原理是自增和<code>*</code>在一起时结合顺序由右到左，比如<code>*p++</code>，先运算<code>p++</code>，也就是<code>p</code>当前的值，再运算<code>*p</code>对寻址，再对<code>p</code>自增。</p><p>注意以上所有的表达式返回的值都是<code>*p</code>，只不过对分别是对<code>p</code>和<code>*p</code>的自增操作。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/C/">C++</category>
      
      
      <comments>http://example.com/2016/12/11/pointer-and/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>QuickSort in C &amp; Python</title>
      <link>http://example.com/2016/12/02/QuickSort-in-C/</link>
      <guid>http://example.com/2016/12/02/QuickSort-in-C/</guid>
      <pubDate>Fri, 02 Dec 2016 11:55:35 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要关于演示C语言中的快排算法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要关于演示C语言中的快排算法。</p><span id="more"></span><p>大名鼎鼎的QuickSort–快速排序算法，如此的高效、快速而优雅，今天让我们用图片和文字形象地展示一下它吧！</p><p>快排是一种分治算法，其主要思想在于通过选取一个基准Pivot将序列分为左右两个子序列，其中左序列的数都小于等于Pivot，右边的都大于等于Pivot，再在这两个子序列上递归调用快排算法即可。</p><p>而理解快排算法的核心就在于分解这个步骤，这里我们先给出代码，再用图片展示步骤。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  main.c</span></span><br><span class="line"><span class="comment">//  QuickSort</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  Created by frankchen on 12/2/16.</span></span><br><span class="line"><span class="comment">//  Copyright © 2016 frankchen. All rights reserved.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">QuickSort</span><span class="params">(<span class="keyword">int</span> s[],<span class="keyword">int</span> low,<span class="keyword">int</span> high)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> s[],<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a[N], i;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Enter %d numbers to be sorted: &quot;</span>, N);</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;N; i++)</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;a[i]);</span><br><span class="line">    </span><br><span class="line">    QuickSort(a, <span class="number">0</span>, N<span class="number">-1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;In sorted order: \n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;N; i++)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, a[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//交换数组中的两个元素</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> s[],<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> temp;</span><br><span class="line">    temp=s[i];</span><br><span class="line">    s[i]=s[j];</span><br><span class="line">    s[j]=temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">QuickSort</span><span class="params">(<span class="keyword">int</span> s[], <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, pivot;<span class="comment">//记录界限的位置</span></span><br><span class="line">    <span class="keyword">if</span>(low &lt; high)<span class="comment">//只有数组中元素大于1时才操作</span></span><br><span class="line">    &#123;</span><br><span class="line">        pivot = low;<span class="comment">//选取第一个元素作为基准</span></span><br><span class="line">        <span class="keyword">for</span>(i=low+<span class="number">1</span>; i&lt;=high; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (s[i] &lt; s[low])</span><br><span class="line">                swap(s, ++pivot, i);</span><br><span class="line">        &#125;</span><br><span class="line">        swap(s, low, pivot);<span class="comment">//基准元与界限交换</span></span><br><span class="line">        QuickSort(s, low, pivot<span class="number">-1</span>);</span><br><span class="line">        QuickSort(s, pivot+<span class="number">1</span>, high);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是Python版本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuickSort</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, l</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.l = l</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        打印排序后的list</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;list\t:%s&#x27;</span> % (self.l)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">swap</span>(<span class="params">self, s, i, j</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        交换位置</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        tmp = s[i]</span><br><span class="line">        s[i] = s[j]</span><br><span class="line">        s[j] = tmp</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">QuickSort</span>(<span class="params">self, s, low, high</span>):</span></span><br><span class="line">        i = <span class="number">0</span>; pivot = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> low &lt; high:</span><br><span class="line">            pivot = low</span><br><span class="line">            i = low + <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(i, high+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> s[i] &lt; s[low]:</span><br><span class="line">                    pivot += <span class="number">1</span></span><br><span class="line">                    self.swap(s, pivot, i)</span><br><span class="line">            self.swap(s, low, pivot)</span><br><span class="line">            self.QuickSort(s, low, pivot-<span class="number">1</span>)</span><br><span class="line">            self.QuickSort(s, pivot+<span class="number">1</span>, high)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getList</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    读取文件内的数存入数组</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    MyFile = <span class="string">&quot;QuickSort.txt&quot;</span></span><br><span class="line">    l = []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(MyFile) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            l.append(<span class="built_in">int</span>(line))</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Sort</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    排序</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 创建QuickSort对象</span></span><br><span class="line">    l = getList()</span><br><span class="line">    p = QuickSort(l)</span><br><span class="line">    N = <span class="built_in">len</span>(l)</span><br><span class="line">    p.QuickSort(l, <span class="number">0</span>, N-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    p = Sort()</span><br><span class="line">    <span class="built_in">print</span> p</span><br></pre></td></tr></table></figure><ul><li>为了排序整个序列，只需要调用QuickSort(R，0，n-1)即可完成对R[0..n-1]的排序。</li><li>这里选取了第一个元素作为基准，如果输入是随机序列，那么没什么大碍，但是如果输入是预排序或者逆序的，那么会产生坏的排序，使得时间复杂度提高，随机选取基准是一种可行的方法，另外一种是选取开头、中间点和末位点的中位数。</li></ul><pre><code>![image](/images/2016/12/QuickSort/QuickSort.001.jpeg)![image](/images/2016/12/QuickSort/QuickSort.002.jpeg)![image](/images/2016/12/QuickSort/QuickSort.003.jpeg)![image](/images/2016/12/QuickSort/QuickSort.004.jpeg)![image](/images/2016/12/QuickSort/QuickSort.005.jpeg)![image](/images/2016/12/QuickSort/QuickSort.006.jpeg)![image](/images/2016/12/QuickSort/QuickSort.007.jpeg)![image](/images/2016/12/QuickSort/QuickSort.008.jpeg)![image](/images/2016/12/QuickSort/QuickSort.009.jpeg)![image](/images/2016/12/QuickSort/QuickSort.010.jpeg)</code></pre>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2016/12/02/QuickSort-in-C/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Workflow for automatic extract and jump to the true URL of 91porn.com</title>
      <link>http://example.com/2016/11/28/Workflow-for-automatic-extract-and-jump-to-the-true-URL-of-91porn-com/</link>
      <guid>http://example.com/2016/11/28/Workflow-for-automatic-extract-and-jump-to-the-true-URL-of-91porn-com/</guid>
      <pubDate>Sun, 27 Nov 2016 16:41:22 GMT</pubDate>
      
      <description>&lt;p&gt;主要讲述自己开发的Alfred Workflow 91url：自动获取某网站的真实视频地址并跳转的应用。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>主要讲述自己开发的Alfred Workflow 91url：自动获取某网站的真实视频地址并跳转的应用。</p><span id="more"></span><p>相信许多朋友都爱看91的视频，但是免费用户的每日有限的观看次数总是让人意犹未尽。。。于是<a href="http://freeget.vip/">FreeGet 免费福利资讯</a>应运而生。。。但是重复的从浏览器窗口点击复制url，切换窗口、粘贴再点击。。。有什么办法可以让众狼友的双手解放出来呢？作为程序员的我当然不能忍，所以耗费一下午的时间开发了这个Workflow：91url，能够自动获取当前的浏览器窗口的网址并提交到FreeGet网站，并用火狐浏览器打开真实视频网址（抱歉是0.1版本，功能受限，不足之处待之后版本解决）。使用方法非常简单，只要在我的<a href="https://github.com/frankchen0130/91url">Github</a>下载并拖到Alfred 的Workflow即可，另外还需要安装Python的自动化网页测试工具包selenium：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure><p>然后浏览器处于91视频的页面的时候，用command + 空格 输入91url并enter即可(当然也可以修改HotKey来触发)：</p><p><img src="/images/2016/11/9.png" alt="image"></p><p>之后91url将自动打开火狐浏览器并跳转至FreeGet获取真实网址，</p><p><img src="/images/2016/11/10.png" alt="image"></p><p>如上图，点击即可播放或者下载，so，enjoy！</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Old-Driver/">Old Driver</category>
      
      
      <comments>http://example.com/2016/11/28/Workflow-for-automatic-extract-and-jump-to-the-true-URL-of-91porn-com/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Devide and Conquer Counting Inversions with Python</title>
      <link>http://example.com/2016/11/25/Devide-and-Conquer-Counting-Inversions-with-Python/</link>
      <guid>http://example.com/2016/11/25/Devide-and-Conquer-Counting-Inversions-with-Python/</guid>
      <pubDate>Fri, 25 Nov 2016 08:55:15 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要内容关于python归并排序求逆序数的算法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要内容关于python归并排序求逆序数的算法。</p><span id="more"></span><p>解决问题：给定有限长度的无重复乱序数组，求其逆序数个数。简单来说我们可以用两个循环来解决，但是复杂度为$O(N^2)$，若利用归并排序，复杂度就降为了$O(N \log(N))$。以下给出一个实现，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ivrs_num</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filename</span>):</span></span><br><span class="line">        self.count = <span class="number">0</span></span><br><span class="line">        self.filename = filename</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_txt</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;载入txt文件保存为list&#x27;&#x27;&#x27;</span></span><br><span class="line">        int_list = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(self.filename) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                int_list.append(<span class="built_in">int</span>(line))</span><br><span class="line">        <span class="keyword">return</span> int_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">self, ListA, ListB</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;将两个已经排序好的数组合并成新的排序好的数组</span></span><br><span class="line"><span class="string">        顺便计算逆序数&#x27;&#x27;&#x27;</span></span><br><span class="line">        newList = []</span><br><span class="line">        <span class="keyword">while</span> ListA <span class="keyword">and</span> ListB:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">int</span>(ListA[<span class="number">0</span>]) &gt; <span class="built_in">int</span>(ListB[<span class="number">0</span>]):</span><br><span class="line">                self.count += <span class="built_in">len</span>(ListA)</span><br><span class="line">                newList.append(ListB.pop(<span class="number">0</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                newList.append(ListA.pop(<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> newList + ListA + ListB</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span>(<span class="params">self, A</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;归并排序&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(A) == <span class="number">1</span>: <span class="keyword">return</span> A</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            middle = <span class="built_in">len</span>(A) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">return</span> self.merge(self.merge_sort(A[:middle]), self.merge_sort(A[middle:]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">count_ivrs</span>(<span class="params">self</span>):</span></span><br><span class="line">        data = self.load_txt()</span><br><span class="line">        self.merge_sort(data)</span><br><span class="line">        <span class="keyword">return</span> self.count</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    ivrs = Ivrs_num(<span class="string">&quot;IntegerArray.txt&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> ivrs.count_ivrs()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      <category domain="http://example.com/tags/Algorithm/">Algorithm</category>
      
      
      <comments>http://example.com/2016/11/25/Devide-and-Conquer-Counting-Inversions-with-Python/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Understanding EM algorithm</title>
      <link>http://example.com/2016/11/18/Understanding-EM-algorithm/</link>
      <guid>http://example.com/2016/11/18/Understanding-EM-algorithm/</guid>
      <pubDate>Fri, 18 Nov 2016 13:54:19 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要内容为用一个简短的例子解释EM算法。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要内容为用一个简短的例子解释EM算法。</p><span id="more"></span><p>EM算法是聚类中常用的机器学习算法，但是相比喜闻乐见的k-means算法，大家可能对于EM算法的了解可能没有那么直观深入，所以本文主要利用一个简单的例子，在对比k-means算法的过程中，帮助大家建立一个清晰明确的对EM算法的理解。</p><p>当我们在聚类的领域谈论k-means算法时，分组的概念是非常清晰直观的–每个样本点只属于它离得最近的那个中心点所属的分组。如果给出一些样本点和中心，那么我们很容易给这些点打标签。</p><p>但是对于EM算法而言，分组的概念就么那么直观了（因为EM算法考虑每个样本点都有一定的概率属于所有的分组）。在我们介=引入EM算法之前，我们先复习一下k-means里面的分组概念。</p><h2 id="k-means里面的分组概念"><a href="#k-means里面的分组概念" class="headerlink" title="k-means里面的分组概念"></a>k-means里面的分组概念</h2><p>假设我们有如下的三个样本点（2D平面情况下的点）：</p><table><thead><tr><th align="center">数据集</th><th align="center">X</th><th align="center">Y</th></tr></thead><tbody><tr><td align="center">点0</td><td align="center">10</td><td align="center">5</td></tr><tr><td align="center">点1</td><td align="center">2</td><td align="center">1</td></tr><tr><td align="center">点2</td><td align="center">3</td><td align="center">7</td></tr></tbody></table><p><img src="/images/2016/11/1.png" alt="image"></p><p>如果在上面的数据集上跑k-means算法，假定中心点如下：</p><table><thead><tr><th align="center">中心</th><th align="center">X</th><th align="center">Y</th></tr></thead><tbody><tr><td align="center">A</td><td align="center">3</td><td align="center">4</td></tr><tr><td align="center">B</td><td align="center">6</td><td align="center">3</td></tr><tr><td align="center">C</td><td align="center">4</td><td align="center">6</td></tr></tbody></table><p><img src="/images/2016/11/2.png" alt="image"></p><p>使用欧几里得距离，可以分配聚类如下</p><table><thead><tr><th>距离</th><th>群组A中心</th><th>群组B中心</th><th>群组C中心</th><th>群组分配</th></tr></thead><tbody><tr><td>点0</td><td>7.071</td><td><strong>4.472</strong></td><td>6.083</td><td>群组B</td></tr><tr><td>点1</td><td><strong>3.162</strong></td><td>4.472</td><td>5.385</td><td>群组A</td></tr><tr><td>点2</td><td>3.000</td><td>5.000</td><td><strong>1.414</strong></td><td>群组C</td></tr></tbody></table><p><img src="/images/2016/11/3.png" alt="image"></p><p>到此，我们可以给出一个回答：到底把一个点归类到一个群组意味着什么？举例来说，点1只被分配到分组A，也就是点1的100%属于群组A并且0%属于群组B和群组C。那么根据这个定义，我们可以得到如下表格，</p><table><thead><tr><th></th><th align="right">群组A</th><th align="center">群组B</th><th>群组C</th></tr></thead><tbody><tr><td>点0</td><td align="right">0</td><td align="center"><strong>1</strong></td><td>0</td></tr><tr><td>点1</td><td align="right"><strong>1</strong></td><td align="center">0</td><td>0</td></tr><tr><td>点2</td><td align="right">0</td><td align="center">0</td><td><strong>1</strong></td></tr><tr><td>成员个数</td><td align="right">1</td><td align="center">1</td><td>1</td></tr></tbody></table><p>注意到，对于一个群组来说，其得到的每一行的和都是1（因为一个点的百分比就是之和就是1）；另外，每一列的和就是这个群组的成员点的个数。推而广之：</p><ul><li>每一行的和总是1，因为一个点的百分比之和是1</li><li>每一列的和就是分配到这个群组的点的个数</li></ul><h2 id="EM算法中的群组分配"><a href="#EM算法中的群组分配" class="headerlink" title="EM算法中的群组分配"></a>EM算法中的群组分配</h2><p>到此为止，我们做的似乎不错，但是存在一个问题，我们这里每个点都只能属于一个群组，不过这一点有时候不是那么合理，比如点0分配到群组B似乎没什么问题，但是比如点1距离群组A和群组B的距离差别不那么大，那么只因为距离群组A近那么一点点就只把它分配到群组A，难道没什么问题吗？我们可能更加想表达这样一种概念：点1更可能属于群组A，但是我们也想保留点1也有一些可能属于群组B的不确定性。</p><table><thead><tr><th>距离</th><th>群组A中心</th><th>群组B中心</th><th>群组C中心</th><th>群组分配</th></tr></thead><tbody><tr><td>点0</td><td>7.071</td><td>4.472</td><td>6.083</td><td>群组B</td></tr><tr><td>点1</td><td>3.162</td><td>4.472</td><td>5.385</td><td>群组A</td></tr><tr><td>点2</td><td>3.000</td><td>5.000</td><td>1.414</td><td>群组C</td></tr></tbody></table><p>我们如何表述这种不确定性呢？这就是<strong>分组权重</strong>的由来。分组权重表达了一个点有多可能属于某个群组。比如之前的形式是这样的，</p><table><thead><tr><th></th><th align="right">群组A</th><th align="center">群组B</th><th>群组C</th></tr></thead><tbody><tr><td>点0</td><td align="right">0</td><td align="center">1</td><td>0</td></tr><tr><td>点1</td><td align="right">1</td><td align="center">0</td><td>0</td></tr><tr><td>点2</td><td align="right">0</td><td align="center">0</td><td>1</td></tr><tr><td>成员个数</td><td align="right">1</td><td align="center">1</td><td>1</td></tr></tbody></table><p>把上表的0和1换成分数（不要质疑这些分数怎么来的，等下会给出合理解释，：））</p><table><thead><tr><th></th><th align="right">群组A</th><th align="center">群组B</th><th>群组C</th></tr></thead><tbody><tr><td>点0</td><td align="right">0.007</td><td align="center">0.938</td><td>0.055</td></tr><tr><td>点1</td><td align="right">0.812</td><td align="center">0.154</td><td>0.034</td></tr><tr><td>点2</td><td align="right">0.234</td><td align="center">0.016</td><td>0.750</td></tr><tr><td>软计数</td><td align="right">1.053</td><td align="center">1.108</td><td>0.839</td></tr></tbody></table><p>上表中，点0以93.8%的概率属于群组B，同时下一行中，点1以81.2%的概率属于群组A。这些分数也就是<strong>分组权重</strong>。比如，点0属于分组A的权重就是0.7%。</p><p><strong>和k-means算法中每个点只能属于一个群组不同，这里每个点都以某种程度地属于每一个群组。</strong>例如，93.8%的点0属于群组，其余的属于其他的群组。</p><p><img src="/images/2016/11/4.png" alt="image"></p><p>那么，在上面的分配矩阵里面，每一行和每一列的含义如下，</p><ul><li>每一行的和都是1，因为每个点都100%属于所有的群组，将这一些部分加起来和必定是1</li><li>每一列的和是这个群组的“软计数”，它代表着所有的点属于这个群组的百分比之和</li><li>所有的群组的软计数之和就是样本点的总数</li></ul><h2 id="步骤E：给定分组参数计算分组权重"><a href="#步骤E：给定分组参数计算分组权重" class="headerlink" title="步骤E：给定分组参数计算分组权重"></a>步骤E：给定分组参数计算分组权重</h2><p>分组权重是怎么来的？来自给定分组的分布的时候，我们观察样本点可能是什么。而EM算法中的每一个群组都由一个<strong>分组权重</strong>，一个<strong>均值向量</strong>，一个<strong>协方差矩阵</strong>构成。其中，均值表示群组的中心，协方差体现群组的范围，而分组权重体现了样本点与此分组的关联程度。所有，每个群组都由一个多变量高斯分布所定义。</p><p>回顾上面的例子，加上一个不确定度的椭圆，如下，</p><p><img src="/images/2016/11/5.png" alt="image"></p><p>图中每个椭圆表示着协方差矩阵，在这个例子中，每个群组都是用的是对角协方差矩阵[[3,0],[0,3]]。因为对角线外元素都是0，所有图中的椭圆实际上看起来是圆。并且，由于并没有什么理由认为哪个群组比其他群组更加重要，那么我们定义每个群组的分组权重都是1/3。</p><p>那么，点0属于群组A的概率是多少？这里用来衡量潜在的高斯分布的标准是概率密度函数（probability density function，PDF），使用<code>scipy.stats.multivariate_normal.pdf</code>可计算出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">3</span>,<span class="number">4</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1.275199678019219e-05</span></span><br></pre></td></tr></table></figure><p>我们还要将这个概率乘以分组权重才行，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">3</span>,<span class="number">4</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">4.2506655934e-06</span></span><br></pre></td></tr></table></figure><p>点0属于群组A的似然值是4.251e-6。单看看不出什么，我们还要依次计算群组B和群组C的值。分别计算B和C的PDF并且乘以分组权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">6</span>,<span class="number">3</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.000630854709005</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="number">1</span>/<span class="number">3.</span>*multivariate_normal.pdf([<span class="number">10</span>,<span class="number">5</span>], mean=[<span class="number">4</span>,<span class="number">6</span>], cov=[[<span class="number">3</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">3.71046481027e-05</span></span><br></pre></td></tr></table></figure><p>那么，总结一下，</p><table><thead><tr><th></th><th>群组A</th><th>群组B</th><th>群组C</th></tr></thead><tbody><tr><td>点(10,5)的PDF乘以分组权重</td><td>4.251e-6</td><td>6.309e-4</td><td>3.710e-5</td></tr></tbody></table><p>很明显，群组B的似然值是最高的，这容易理解因为点0距离群组B中心的距离最近。</p><p><img src="/images/2016/11/6.png" alt="image"></p><p>似然值看起来太小了，我么可以对其做一个归一化：都除以所有群组的似然值的和得到百分比值。</p><table><thead><tr><th>点0</th><th>群组A</th><th>群组B</th><th>群组C</th><th>总和</th></tr></thead><tbody><tr><td>似然值</td><td>4.251e-6</td><td>6.309e-4</td><td>3.710e-5</td><td>6.722e-4</td></tr><tr><td>似然值，处以总和</td><td>4.251e-6 / 6.722e-4 = 0.007</td><td>6.309e-4 / 6.722e-4 = 0.938</td><td>3.710e-5 / 6.722e-4 = 0.055</td><td>-</td></tr></tbody></table><p>最下一行就是点0分组责任！注意到因为归一化，这一行的总和是1。小结一下：</p><ul><li>对于每一个点我们计算了其高斯分布的PDF值，通过使用高斯分布的均值和协方差计算得到</li><li>将PDF乘以分组权重，得到似然度</li><li>将似然程度归一化</li></ul><p>依次，我们可以得到点1和点2的矩阵，这里略去不表，最后将三个点的矩阵汇总得到以下，</p><table><thead><tr><th>Responsibility matrix</th><th>Cluster A</th><th>Cluster B</th><th>Cluster C</th></tr></thead><tbody><tr><td>Data point 0</td><td>0.007</td><td>0.938</td><td>0.055</td></tr><tr><td>Data point 1</td><td>0.812</td><td>0.154</td><td>0.034</td></tr><tr><td>Data point 2</td><td>0.234</td><td>0.016</td><td>0.750</td></tr><tr><td>Soft counts</td><td>1.053</td><td>1.108</td><td>0.839</td></tr></tbody></table><h2 id="步骤M：给定分组责任计算分组参数"><a href="#步骤M：给定分组责任计算分组参数" class="headerlink" title="步骤M：给定分组责任计算分组参数"></a>步骤M：给定分组责任计算分组参数</h2><p>现在我们手里已经有了分组的责任了，我们可以依据这些重新更新参数：分组权重、均值和协方差。虽然我们开始是乱猜的这些参数，但是通过更新我们可以得到一些更好的估计。</p><p><strong>分组权重。</strong>群组的相对重要程度由它的软计数来决定。由于分组权重必须和为1，所有这里也需要做归一化，</p><p>|    |Cluster A    |Cluster B    |Cluster C    |Sum|<br>|-|-|-|-|<br>|Soft counts    |1.053|    1.108|    0.839|    3.000|<br>|Soft counts, divided by the sum    |1.053 / 3.000 = 0.351|    1.108 / 3.000 = 0.369    |0.839 / 3.000 = 0.280|-|</p><p>归一化后的软计数，就是分组权重的新的估计。</p><p><strong>均值。</strong>使用分组责任计算所有点坐标的百分比，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[Weighted <span class="built_in">sum</span> of data points <span class="keyword">for</span> cluster A]</span><br><span class="line">= [Fraction of data point <span class="number">0</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">0</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">1</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">1</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">2</span> represented <span class="keyword">in</span> cluster A] * [data point <span class="number">2</span>]</span><br><span class="line">= <span class="number">0.007</span>*[data point <span class="number">0</span>] + <span class="number">0.812</span>*[data point <span class="number">1</span>] + <span class="number">0.234</span>*[data point <span class="number">2</span>]</span><br><span class="line">= <span class="number">0.007</span>*(<span class="number">10</span>,<span class="number">5</span>) + <span class="number">0.812</span>*(<span class="number">2</span>,<span class="number">1</span>)  + <span class="number">0.234</span>*(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">= (<span class="number">0.063</span>,<span class="number">0.035</span>) + (<span class="number">1.624</span>,<span class="number">0.812</span>) + (<span class="number">0.702</span>,<span class="number">1.638</span>)</span><br><span class="line">= (<span class="number">2.396</span>,<span class="number">2.485</span>)</span><br></pre></td></tr></table></figure><p>再除以软计数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[mean of cluster A]</span><br><span class="line">= (<span class="number">2.396</span>,<span class="number">2.485</span>)/<span class="number">1.053</span></span><br><span class="line">= (<span class="number">2.275</span>,<span class="number">2.360</span>)</span><br></pre></td></tr></table></figure><p>类似地计算B和C的均值，得到如下，</p><table><thead><tr><th>New means</th><th>X</th><th>Y</th></tr></thead><tbody><tr><td>Cluster A</td><td>2.275</td><td>2.360</td></tr><tr><td>Cluster B</td><td>8.787</td><td>4.473</td></tr><tr><td>Cluster C</td><td>3.418</td><td>6.626</td></tr></tbody></table><p>让我们画出均值的之前和之后的估计。注意到群组A的均值移动地更加靠近点1，因为群组A是主要的，类似的也发生在B和C上，</p><p><img src="/images/2016/11/7.png" alt="image"></p><p><strong>协方差。</strong> 协方差也是由分数来计算的，但是这里需要矩阵形式，所以实际上是由向量叉乘得到的，</p><p>$$x_i - \hat{\mu}_k$$</p><p>假设上面是d维向量，计算其与自身的内积，</p><p>$$(x_i - \hat{\mu}_k)(x_i - \hat{\mu}_k)^T$$</p><p>对012每个点都根据其坐标和A的均值计算协方差矩阵，与分组责任相乘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[Weighted <span class="built_in">sum</span> of outer products]</span><br><span class="line">= [Fraction of data point <span class="number">0</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">0</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">1</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">1</span>]</span><br><span class="line">  + [Fraction of data point <span class="number">2</span> represented <span class="keyword">in</span> cluster A] * [outer product <span class="keyword">for</span> data point <span class="number">2</span>]</span><br><span class="line">=  <span class="number">0.007</span>*[[<span class="number">59.676</span>,<span class="number">20.394</span>], [<span class="number">20.394</span>,<span class="number">6.970</span>]]</span><br><span class="line">  + <span class="number">0.812</span>*[[<span class="number">0.076</span>,<span class="number">0.374</span>], [<span class="number">0.374</span>,<span class="number">1.850</span>]]</span><br><span class="line">  + <span class="number">0.234</span>*[[<span class="number">0.526</span>,<span class="number">3.364</span>], [<span class="number">3.364</span>,<span class="number">21.530</span>]]</span><br><span class="line">= [[<span class="number">0.602</span>, <span class="number">1.234</span>], [<span class="number">1.234</span>, <span class="number">6.589</span>]]</span><br><span class="line"></span><br><span class="line">[New covariance <span class="keyword">for</span> cluster A]</span><br><span class="line">= [[<span class="number">0.602</span>,<span class="number">1.234</span>], [<span class="number">1.234</span>,<span class="number">6.589</span>]]/<span class="number">1.053</span></span><br><span class="line">= [[<span class="number">0.572</span>,<span class="number">1.172</span>], [<span class="number">1.172</span>,<span class="number">6.257</span>]]</span><br></pre></td></tr></table></figure><p>对于BC重复以上，得到，</p><table><thead><tr><th>New covariances</th><th></th></tr></thead><tbody><tr><td>Cluster A</td><td>[[0.572,1.172], [1.172,6.257]]</td></tr><tr><td>Cluster B</td><td>[[8.132,3.606], [3.606,2.004]]</td></tr><tr><td>Cluster C</td><td>[[3.078,-0.518], [-0.518,1.581]]</td></tr></tbody></table><p><img src="/images/2016/11/8.png" alt="image"></p><p>长于一口气！这么多的计算，我们到底更新的效果是什么？首先，所有的群组都有了更小的不确定度，从图上来看，椭圆变得更小了；其次，群组改变了形状来适应数据，比如群组B向着点1的方向延长了。总之，每次均值和协方差更新以后，群组都改变形状以更好地表示数据里的模式。</p><h2 id="EM算法：交替步骤E和步骤M"><a href="#EM算法：交替步骤E和步骤M" class="headerlink" title="EM算法：交替步骤E和步骤M"></a>EM算法：交替步骤E和步骤M</h2><p>现在我们对于分组的参数有了更好地估计，那么我们可以回过头去计算分组的责任，于是我们可以得到一个更好的参数的估计。实际上，我们可以交替着使用步骤E和步骤M来逐步提高分组的性能。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.coursera.org/learn/ml-clustering-and-retrieval/supplement/s9OBQ/optional-a-worked-out-example-for-em">华盛顿大学机器学习：聚类与检索</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/Machine-Learning/">Machine Learning</category>
      
      
      <comments>http://example.com/2016/11/18/Understanding-EM-algorithm/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Way to solving the .DS_Store problem of Mac</title>
      <link>http://example.com/2016/11/17/Way-to-solving-the-DS-Store-problem-of-Mac/</link>
      <guid>http://example.com/2016/11/17/Way-to-solving-the-DS-Store-problem-of-Mac/</guid>
      <pubDate>Thu, 17 Nov 2016 07:25:30 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要讲述如何解决Mac OS下面的.DS_Store文件的问题。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要讲述如何解决Mac OS下面的.DS_Store文件的问题。</p><span id="more"></span><p>在Mac OS上，<code>.DS_Store</code>文件 是 <code>Desktop Services Store</code> 的简称，是用来存储文件夹的显示属性的自定义属性的隐藏文件，：比如文件图标的摆放位置，如文件的图标位置或背景色，相当于Windows的desktop.ini，删除以后的副作用就是这些信息的失去，不过总体而言影响不大。</p><p>最近上手的Mac，<code>.DS_Store</code> 第一次烦到我，是在Github上folk了人家的项目自己提交了想Pull Request 的时候出现的问题，我明明只修改了一个文件，为什么在每个文件夹下面都出现了这么些个奇怪的 <code>.DS_Store</code> ？？删除了这些文件以后再第二次提交的时候又会出现（期间我用了Finder），谷歌以后才发现这原来是系统自动生成的，要想它不出现，除非只用Shell不用Finder。。。</p><p>接着找资料发现如下办法，</p><ul><li>安装<a href="http://asepsis.binaryage.com/">ASEPSIS</a><ul><li>OS X 10.11以前的版本直接安装即可</li><li>OS X 10.11需要关闭SIP（System Integrity Protection）再使用命令<code>touch ~/.no-asepsis-os-restriction</code> 新建文件再安装</li></ul></li><li>重启系统</li><li>然后可以用以下指令删除mac上所有的.DS_Store：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">find ~ -name &quot;.DS_Store&quot; -delete</span><br><span class="line">或者</span><br><span class="line">find &lt;your path&gt; -name &quot;.DS_Store&quot; -delete</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://www.zhihu.com/question/20345704">https://www.zhihu.com/question/20345704</a></li><li><a href="https://zh.wikipedia.org/wiki/.DS_Store">https://zh.wikipedia.org/wiki/.DS_Store</a>     </li></ol>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Mac/">Mac</category>
      
      <category domain="http://example.com/tags/DS-Store/">.DS_Store</category>
      
      
      <comments>http://example.com/2016/11/17/Way-to-solving-the-DS-Store-problem-of-Mac/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>A efficiency comparison between while for generator comprehension - Python while、for、生成器、列表推导等语句的执行效率对比</title>
      <link>http://example.com/2016/11/11/2016-11-11-a-efficiency-comparison-between-while-slash-for-slash-generator-slash-comprehension/</link>
      <guid>http://example.com/2016/11/11/2016-11-11-a-efficiency-comparison-between-while-slash-for-slash-generator-slash-comprehension/</guid>
      <pubDate>Fri, 11 Nov 2016 14:43:17 GMT</pubDate>
      
      <description>&lt;p&gt;python中，同一个功能的实现，可以用多种语句来实现，比如说:while语句、for语句、生成器、列表推导、内置函数等实现，然而他们的效率并不一样。这里有一个小程序来测试它们执行的效率。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>python中，同一个功能的实现，可以用多种语句来实现，比如说:while语句、for语句、生成器、列表推导、内置函数等实现，然而他们的效率并不一样。这里有一个小程序来测试它们执行的效率。</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line">nums = <span class="number">100</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment">#每个函数实现的都是从1-100的自然数的绝对值添加进一个list</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">while_Statement</span>():</span>  <span class="comment">#while loop实现</span></span><br><span class="line">    res = []  </span><br><span class="line">    x   = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">while</span> nums &gt; x:  </span><br><span class="line">        x += <span class="number">1</span>  </span><br><span class="line">        res.append(<span class="built_in">abs</span>(x))  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">for_Statement</span>():</span>  <span class="comment">#for loop实现</span></span><br><span class="line">    res = []  </span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(nums):  </span><br><span class="line">        res.append(<span class="built_in">abs</span>(x))  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_Expression</span>():</span>  <span class="comment">#生成器实现</span></span><br><span class="line">    res = <span class="built_in">list</span>(<span class="built_in">abs</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(nums))  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">list_Comprehension</span>():</span>  <span class="comment">#列表解析式实现，对比生成器实现可以发现两者区别只有中括号与小括号</span></span><br><span class="line">    res = [<span class="built_in">abs</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(nums)]  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_Function</span>():</span>  <span class="comment">#map函数（内置函数）实现</span></span><br><span class="line">    res = <span class="built_in">map</span>(<span class="built_in">abs</span>, <span class="built_in">range</span>(nums))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    <span class="keyword">import</span> timeit            <span class="comment">#用timeit模块来测试  </span></span><br><span class="line">    <span class="built_in">print</span> sys.version  </span><br><span class="line">    funcs = [while_Statement, for_Statement, generator_Expression, list_Comprehension, map_Function]  </span><br><span class="line">    <span class="keyword">for</span> func <span class="keyword">in</span> funcs:  </span><br><span class="line">        <span class="built_in">print</span> func.__name__.ljust(<span class="number">20</span>),<span class="string">&#x27;: &#x27;</span>,timeit.timeit(<span class="string">&quot;func()&quot;</span>, setup=<span class="string">&quot;from __main__ import func&quot;</span>)  </span><br><span class="line">测试结果:</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>  </span><br><span class="line"><span class="number">2.7</span><span class="number">.10</span> (default, Oct <span class="number">23</span> <span class="number">2015</span>, <span class="number">19</span>:<span class="number">19</span>:<span class="number">21</span>) </span><br><span class="line">[GCC <span class="number">4.2</span><span class="number">.1</span> Compatible Apple LLVM <span class="number">7.0</span><span class="number">.0</span> (clang-<span class="number">700.0</span><span class="number">.59</span><span class="number">.5</span>)]</span><br><span class="line">while_Statement      :  <span class="number">16.0008671284</span></span><br><span class="line">for_Statement        :  <span class="number">12.9374330044</span></span><br><span class="line">generator_Expression :  <span class="number">10.133701086</span></span><br><span class="line">list_Comprehension   :  <span class="number">7.86516404152</span></span><br><span class="line">map_Function         :  <span class="number">5.24277615547</span></span><br></pre></td></tr></table></figure><p>以上用timeit模块两种测试方式测试了若干组数字，得出的结果是执行内置函数最快，其次就是列表推导，再其次生成器和for循环，while循环最慢。最快的使用内置函数的方法要比使用最慢的while快两倍以上。</p><p>简单分析下原因:</p><ul><li>内置函数比如说map,filter,reduce基本上都是用C语言来实现的,所以速度是最快的，</li><li>列表推导内的迭代在解释器内是以C语言的速度运行的(一般是for循环的两倍,对大型文件操作而言</li><li>列表推导效果尤其明显)，相比较for循环代码是在PVM步进运行要快的多</li><li>for循环里面含range()，相对速度也会快些，</li><li>while语句是纯粹用Python代码写成，所以速度最慢。</li></ul><p>综上，<strong>所以函数式编程最好使用内置函数，然后才考虑使用列表推导或for循环。最好不用while循环。</strong></p><p>##参考资料</p><ol><li><a href="http://m.jb51.net/article/67169.htm">Python while、for、生成器、列表推导等语句的执行效率测试</a></li><li><a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips">PythonSpeed/PerformanceTips</a></li><li><a href="http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue1/python-performance-tips-part-1.html">Python 性能小贴士 (第1部分)</a></li></ol>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/python/">python</category>
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2016/11/11/2016-11-11-a-efficiency-comparison-between-while-slash-for-slash-generator-slash-comprehension/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>精确率、召回率、F1 值、ROC/AUC 、PRC各自的优缺点是什么？</title>
      <link>http://example.com/2016/09/21/metric/</link>
      <guid>http://example.com/2016/09/21/metric/</guid>
      <pubDate>Wed, 21 Sep 2016 14:15:48 GMT</pubDate>
      
      <description>&lt;p&gt;精确率、召回率、F1 值、ROC、AUC、PRC都是机器学习模型的常用评价标准，那么它们的区别和联系以及各自应用场景是什么呢？&lt;/p&gt;
&lt;h2 id=&quot;这些指标的含义&quot;&gt;&lt;a href=&quot;#这些指标的含义&quot; class=&quot;headerlink&quot; title=&quot;这些指标的含义&quot;&gt;&lt;/a&gt;这些指标的含义&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Precision：P=TP/(TP+FP)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Recall：R=TP/(TP+FN)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;F1-score：2/(1/P+1/R)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ROC/AUC：TPR=TP/(TP+FN), FPR=FP/(FP+TN)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;TP —— True Positive （真正, TP）被模型预测为正的正样本；可以称作判断为真的正确率&lt;/p&gt;
&lt;p&gt;TN —— True Negative（真负 , TN）被模型预测为负的负样本 ；可以称作判断为假的正确率&lt;/p&gt;
&lt;p&gt;FP ——False Positive （假正, FP）被模型预测为正的负样本；可以称作误报率&lt;/p&gt;
&lt;p&gt;FN—— False Negative（假负 , FN）被模型预测为负的正样本；可以称作漏报率&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>精确率、召回率、F1 值、ROC、AUC、PRC都是机器学习模型的常用评价标准，那么它们的区别和联系以及各自应用场景是什么呢？</p><h2 id="这些指标的含义"><a href="#这些指标的含义" class="headerlink" title="这些指标的含义"></a>这些指标的含义</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Precision：P=TP/(TP+FP)</span><br><span class="line">Recall：R=TP/(TP+FN)</span><br><span class="line">F1-score：2/(1/P+1/R)</span><br><span class="line">ROC/AUC：TPR=TP/(TP+FN), FPR=FP/(FP+TN)</span><br></pre></td></tr></table></figure><p>TP —— True Positive （真正, TP）被模型预测为正的正样本；可以称作判断为真的正确率</p><p>TN —— True Negative（真负 , TN）被模型预测为负的负样本 ；可以称作判断为假的正确率</p><p>FP ——False Positive （假正, FP）被模型预测为正的负样本；可以称作误报率</p><p>FN—— False Negative（假负 , FN）被模型预测为负的正样本；可以称作漏报率</p><span id="more"></span><p>True Positive Rate（真正率 , TPR）或灵敏度（sensitivity） 也就是<strong>召回率 Recall</strong></p><p>TPR = TP /（TP + FN）</p><p>正样本预测结果数 / 正样本实际数</p><p>True Negative Rate（真负率 , TNR）或特指度（specificity）</p><p>TNR = TN /（TN + FP）</p><p>负样本预测结果数 / 负样本实际数</p><p>False Positive Rate （假正率, FPR）</p><p>FPR = FP /（FP + TN）</p><p>被预测为正的负样本结果数 /负样本实际数</p><p>False Negative Rate（假负率 , FNR）</p><p>FNR = FN /（TP + FN）</p><p>被预测为负的正样本结果数 / 正样本实际数</p><p>假定一个具体场景作为例子：</p><blockquote><p>假如某个班级有男生<strong>80</strong>人,女生<strong>20</strong>人,共计<strong>100</strong>人.目标是找出所有女生.</p><p>现在某人挑选出<strong>50</strong>个人,其中<strong>20</strong>人是女生,另外还错误的把30个男生也当作女生挑选出来了.</p><p>作为评估者的你需要来评估(<strong>evaluation</strong>)下他的工作。</p></blockquote><table><thead><tr><th></th><th><strong>相关(Relevant),正类</strong></th><th><strong>无关(NonRelevant),负类</strong></th></tr></thead><tbody><tr><td><strong>被检索到(Retrieved)</strong></td><td>true positives(TP 正类判定为正类,例子中就是正确的判定”这位是女生”)</td><td>false positives(FP 负类判定为正类,”存伪”,例子中就是分明是男生却判断为女生,当下伪娘横行,这个错常有人犯)</td></tr><tr><td><strong>未被检索到(Not Retrieved)</strong></td><td>false negatives(FN 正类判定为负类,”去真”,例子中就是,分明是女生,这哥们却判断为男生–梁山伯同学犯的错就是这个)</td><td>true negatives(TN 负类判定为负类,也就是一个男生被判断为男生,像我这样的纯爷们一准儿就会在此处)</td></tr></tbody></table><p>通过这张表,我们可以很容易得到这几个值:</p><p>TP=20</p><p>FP=30</p><p>FN=0</p><p>TN=50</p><p>**精确率： **策略命中的所有相关样本/策略命中的所有样本</p><p>Precision = TP / (TP + FP)</p><p><em>注：正确率/准确率（accuracy）和 精度（precision）不是一个概念</em></p><p><em>正确率是我们最常见的评价指标，accuracy = （TP+TN）/(P+N)，这个很容易理解，就是被分对的样本数除以所有的样本数</em></p><p><strong>召回率</strong>：策略命中的所有相关样本/所有的相关样本（包括策略未被命中的）</p><p>Recall =  TP / (TP + FN)</p><p>F1-score(F1-分数)：2×准确率×召回率/（准确率+召回率），是模型准确率和召回率的一种加权平均，它的最大值是1，最小值是0。（详细介绍见下）</p><p>ROC(_receiver operating characteristic curve_):  ROC曲线的横坐标为_false positive rate_（FPR,假正率），纵坐标为_true positive rate_（TPR，真正率，召回率）</p><p>PRC(_precision recall curve_): PRC曲线的横坐标为召回率_Recall_，纵坐标为准确率_Precision_。</p><p>AUC:被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。故AUC与PRC是同一概念。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围一般在0.5和1之间。</p><h2 id="指标的评价标准"><a href="#指标的评价标准" class="headerlink" title="指标的评价标准"></a>指标的评价标准</h2><h3 id="ROC与AUC"><a href="#ROC与AUC" class="headerlink" title="ROC与AUC"></a>ROC与AUC</h3><p>ROC（receiver operating characteristic curve）也就是下图中的曲线，其关注两个指标</p><p> True Positive Rate ( TPR ) = TP / [ TP + FN] ，TPR代表能将正例分对的概率</p><p> False Positive Rate( FPR ) = FP / [ FP + TN] ，FPR代表将负例错分为正例的概率</p><p>在ROC 空间中，每个点的横坐标是FPR，纵坐标是TPR，这也就描绘了分类器在TP（真正的正例）和FP（错误的正例）间的trade-off。ROC的主要分析工具是一个画在ROC空间的曲线——ROC curve。我们知道，对于二值分类问题，实例的值往往是连续值，我们通过设定一个阈值，将实例分类到正类或者负类（比如大于阈值划分为正类）。因此我们可以变化阈值，根据不同的阈值进行分类，根据分类结果计算得到ROC空间中相应的点，连接这些点就形成ROC curve。ROC curve经过（0,0）（1,1），实际上(0, 0)和(1, 1)连线形成的ROC curve实际上代表的是一个随机分类器。一般情况下，这个曲线都应该处于(0, 0)和(1, 1)连线的上方。如图所示。</p><p>用ROC curve来表示分类器的performance很直观好用。可是，人们总是希望能有一个数值来标志分类器的好坏。</p><p>于是**Area Under roc Curve(AUC)**就出现了。顾名思义，AUC的值就是处于ROC curve下方的那部分面积的大小。通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的Performance。</p><p>同时我们也看里面也上了AUC也就是是面积。一般来说，如果ROC是光滑的，那么基本可以判断没有太大的overfitting（比如图中0.2到0.4可能就有问题，但是样本太少了），这个时候调模型可以只看AUC，面积越大一般认为模型越好。</p><p><img src="/images/2016/09/efd0feae0d18367a7d666328ae674ab1_b.jpg"></p><h3 id="PRC"><a href="#PRC" class="headerlink" title="PRC"></a>PRC</h3><p>再说PRC， precision recall curve。和ROC一样，先看平滑不平滑（蓝线明显好些），在看谁上谁下（同一测试集上），一般来说，上面的比下面的好（绿线比红线好）。F1（下面介绍）当P和R接近就也越大，一般会画连接(0,0)和(1,1)的线，线和PRC重合的地方的F1是这条线最大的F1（光滑的情况下），此时的F1对于PRC就好象AUC对于ROC一样。<strong>一个数字比一条线更方便调模型。</strong></p><p><img src="/images/2016/09/3378a75e33245f6e0aac33717b19512c_b.jpg"></p><p>以上两个指标用来<strong>判断模型好坏</strong>，但是有时候模型没有单纯的谁比谁好（比如图二的蓝线和青线），那么选择模型还是要结合具体的使用场景。</p><p>下面是两个场景：</p><ol><li>地震的预测</li></ol><p>对于地震的预测，我们希望的是RECALL非常高，也就是说每次地震我们都希望预测出来。这个时候我们可以牺牲PRECISION。情愿发出1000次警报，把10次地震都预测正确了；也不要预测100次对了8次漏了两次。</p><ol><li>嫌疑人定罪</li></ol><p>基于不错怪一个好人的原则，对于嫌疑人的定罪我们希望是非常准确的。及时有时候放过了一些罪犯（recall低），但也是值得的。</p><p>对于分类器来说，本质上是给一个概率，此时，我们再选择一个CUTOFF点（阀值），高于这个点的判正，低于的判负。那么这个点的选择就需要结合你的具体场景去选择。反过来，场景会决定训练模型时的标准，比如第一个场景中，我们就只看RECALL=99.9999%（地震全中）时的PRECISION，其他指标就变得没有了意义。</p><h3 id="PRC比ROC更有效的特殊情况"><a href="#PRC比ROC更有效的特殊情况" class="headerlink" title="PRC比ROC更有效的特殊情况"></a>PRC比ROC更有效的特殊情况</h3><p>在正负样本分布得极不均匀(highly skewed datasets)的情况下，PRC比ROC能更有效地反应分类器的好坏。<img src="/images/2016/09/fd2c6445290cdf3c863664af155b9dd0_b.png"></p><p>例如上图中图(a)ROC曲线中的两个模型看似非常接近左上角，但是对应着同一点的图(b)中的PRC曲线中我们可以发现，在召回率为0.8时准确率只有0.05之少，这是由于正负样本比例失衡造成的。</p><p>再如下图：</p><p><img src="/images/2016/09/74db397e36eabfb505abedd68f15bd57_b.png"></p><p>在testing set出现imbalance时ROC曲线能保持不变，而PR则会出现大变化。引用图(Fawcett, 2006)，(a)(c)为ROC，(b)(d)为PR，(a)(b)样本比例1:1，(c)(d)为1:10。</p><h3 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h3><p>信息检索、分类、识别、翻译等领域两个最基本指标是**召回率(Recall Rate)<strong>和</strong>准确率(Precision Rate)**，召回率也叫查全率，准确率也叫查准率。</p><p>图表表示如下：</p><p><img src="/images/2016/09/0_1308034676G5GQ.gif"></p><p><strong>准确率和召回率是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下准确率高、召回率就低，召回率低、准确率高，当然如果两者都低，那是什么地方出问题了</strong>。一般情况，用不同的阀值，统计出一组不同阀值下的精确率和召回率，这就是PRC曲线。如下图：</p><p><img src="/images/2016/09/0_1308034738ZLr8.png"></p><p><strong>如果是做搜索，那就是保证召回的情况下提升准确率；如果做疾病监测、反垃圾，则是保准确率的条件下，提升召回。</strong></p><p>所以，在两者都要求高的情况下，可以用F1来衡量。</p><p><code>F1 = 2 * P * R / (P + R)</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>AUC是ROC的积分（曲线下面积），是一个数值，一般认为越大越好，数值相对于曲线而言更容易当做调参的参照。</li><li>ROC相比PRC在正负样本比例悬殊时具有保持单调性的特性，学术论文在假定正负样本均衡的时候多用ROC/AUC。</li><li>实际工程更多存在数据标签倾斜问题一般使用F1。</li></ul>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Machine-Learning/">Machine Learning</category>
      
      
      <comments>http://example.com/2016/09/21/metric/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>PDF click return</title>
      <link>http://example.com/2016/09/07/2016-09-07-pdf-click-return/</link>
      <guid>http://example.com/2016/09/07/2016-09-07-pdf-click-return/</guid>
      <pubDate>Wed, 07 Sep 2016 02:57:05 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;在阅读PDF文档时，如果点击了文档中的链接，跳转到另一页，想再快速返回原来的页面，使用alt+左箭头的组合键即可。&lt;/p&gt;
&lt;p&gt;根据情况的不同，有时需要使用若干次才能返回原来的页面，这个组合键就相当于回退，如果点击了链接到了新的页面，在新的页面上又移动了页面，如向上或向下</description>
        
      
      
      
      <content:encoded><![CDATA[<p>在阅读PDF文档时，如果点击了文档中的链接，跳转到另一页，想再快速返回原来的页面，使用alt+左箭头的组合键即可。</p><p>根据情况的不同，有时需要使用若干次才能返回原来的页面，这个组合键就相当于回退，如果点击了链接到了新的页面，在新的页面上又移动了页面，如向上或向下浏览，那么至少要使用2次或2次以上alt+左箭头组合键才能终点原链接处。</p><p>而想要再次回退就使用alt+右箭头组合进行操作即可。</p>]]></content:encoded>
      
      
      
      <category domain="http://example.com/tags/tips/">tips</category>
      
      
      <comments>http://example.com/2016/09/07/2016-09-07-pdf-click-return/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>如何解决Linux 下 zip 文件解压乱码</title>
      <link>http://example.com/2016/07/16/Linux%20zip%20encoding/</link>
      <guid>http://example.com/2016/07/16/Linux%20zip%20encoding/</guid>
      <pubDate>Sat, 16 Jul 2016 04:11:14 GMT</pubDate>
      
      <description>&lt;p&gt;由于zip格式中并没有指定编码格式，Windows下生成的zip文件中的编码是GBK/GB2312等，因此，导致这些zip文件在Linux下解压时出现乱码问题，因为Linux下的默认编码是UTF8。&lt;br&gt;目前网上流传一种unzip -O cp936的方法，但一些unzip是没有-O这个选项的。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>由于zip格式中并没有指定编码格式，Windows下生成的zip文件中的编码是GBK/GB2312等，因此，导致这些zip文件在Linux下解压时出现乱码问题，因为Linux下的默认编码是UTF8。<br>目前网上流传一种unzip -O cp936的方法，但一些unzip是没有-O这个选项的。</p><span id="more"></span><p>在ubuntu下的安装命令是</p><p><code>sudo apt-get install p7zip convmv</code></p><p>安装完之后，就可以用7za和convmv两个命令完成解压缩任务。</p><p><code>LANG=C 7za x your-zip-file.zip convmv -f GBK -t utf8 --notest -r .</code></p><p>第一条命令用于解压缩，而LANG=C表示以US-ASCII这样的编码输出文件名，如果没有这个语言设置，它同样会输出乱码，只不过是UTF8格式的乱码(convmv会忽略这样的乱码)。<br>第二条命令是将GBK编码的文件名转化为UTF8编码，-r表示递归访问目录，即对当前目录中所有文件进行转换。</p><p>作者：Latm Ake<br>链接：<a href="https://www.zhihu.com/question/20523036/answer/35225920">https://www.zhihu.com/question/20523036/answer/35225920</a><br>来源：知乎<br>著作权归作者所有，转载请联系作者获得授权。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2016/07/16/Linux%20zip%20encoding/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RECURRENT NEURAL NETWORK TUTORIAL, PART 4 – IMPLEMENTING A GRU/LSTM RNN WITH PYTHON AND THEANO</title>
      <link>http://example.com/2016/06/22/2016-06-22-recurrent-neural-network-tutorial-part-4-implementing-a-gru-slash-lstm-rnn-with-python-and-theano/</link>
      <guid>http://example.com/2016/06/22/2016-06-22-recurrent-neural-network-tutorial-part-4-implementing-a-gru-slash-lstm-rnn-with-python-and-theano/</guid>
      <pubDate>Wed, 22 Jun 2016 13:42:51 GMT</pubDate>
      
      <description>&lt;p&gt;本文中，我们将学习关于LSTM (Long Short Term Memory)网络和 GRUs (Gated Recurrent Units)的知识。LSTM最初由&lt;a href=&quot;http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf&quot;&gt;Sepp Hochreiter and Jürgen Schmidhuber于1997年提出&lt;/a&gt;，如今是深度学习自然语言处理领域最流行的模型。GRU，&lt;a href=&quot;http://arxiv.org/pdf/1406.1078v3.pdf&quot;&gt;出现于2014年&lt;/a&gt;，是LSTM的简化版，与LSTM有许多相似的特性。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文中，我们将学习关于LSTM (Long Short Term Memory)网络和 GRUs (Gated Recurrent Units)的知识。LSTM最初由<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf">Sepp Hochreiter and Jürgen Schmidhuber于1997年提出</a>，如今是深度学习自然语言处理领域最流行的模型。GRU，<a href="http://arxiv.org/pdf/1406.1078v3.pdf">出现于2014年</a>，是LSTM的简化版，与LSTM有许多相似的特性。</p><span id="more"></span><p>##LSTM 网络</p><p>在<a href="http://frankchen0130.github.io/2016/06/22/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/">第三部分</a>我们提到了梯度消失问题妨碍了标准的RNN学习长期依赖问题。LSTM被设计于用gate结构解决梯度消失问题。为了理解这个机制，我们来看看LSTM如何计算隐藏状态$$s_t$$（其中小圆圈代表Hadamard product，即同型矩阵各元素对应相乘，不同于矩阵点乘）。</p><p><img src="/images/2016/06/latex7.png"></p><p>式子看起来复杂，一步一步来理解实则简单。首先，LSTM的一层代表的只是另一种计算隐藏层的方法。之前我们计算了隐藏状态$$s_t = tanh(Ux_t + WS_{s-1})$$。对于当前的单元，输入是$$t$$时刻的$$x_t$$，而$$s_{t-1}$$是之前的隐藏状态，输出是新的隐藏状态$$s_t$$。其实，LSTM做的事情是完全一样的，只不过换了种方式，这也是理解LSTM的核心。我们可以把LSTM单元看作是黑盒子，给予其当前输入和之前的隐藏状态，它可以输出下一个隐藏状态。</p><p><img src="/images/2016/06/gru-lstm.png"></p><p>把这个牢记于心，我们开始来阐述LSTM如何计算隐藏状态。关于这一点，详细可看<a href="http://frankchen0130.github.io/2016/06/04/understanding-lstm-networks/">这篇文章</a>，这里我们只作简短描述：</p><ul><li>$$i,f,o$$分别被称为输入门、遗忘门和输出门。注意到，它们具有相同的等式，只是参数矩阵不同。它们之所以被称为“门”，是因为sigmoid函数将向量值压缩到0和1之间，再与另一个向量相乘，我们因此决定向量的多少“通过”。输入门决定当前输入计算出来的状态的多少成分被通过，遗忘门决定之前的状态有多少可以被保留到之后，输出门决定当前的状态有多少被传送到外层的网络（高层网络和下一时刻）。这些门的维度都是$$d_s$$，即隐藏层的大小。</li><li>$$g$$是一个候选的隐藏状态，基于当前的输入和之前的隐藏状态计算而出。其与vanilla RNN的计算等式相同，只是把参数$$U,W$$改名为$$U^g,W^g$$。和RNN的直接将$$g$$作为心的隐藏状态不同，我们将其通过一个输入门来决定保留它的多少成分。</li><li>$$c_t$$是单元的内部的记忆，它由之前的记忆$$c_{t-1}$$通过遗忘门再加上新计算出来的隐藏状态$$g$$通过输入门计算得出。因此，它代表了旧的记忆与新的输入的结合。我们可以选择全部忽略旧的记忆（遗忘门全部置零），或者忽略全部的计算出的新状态（输入门全部置零），但是通常来说，我们可能更希望介于两者之间。</li><li>给定记忆$$c_t$$，我们最终通过让记忆和输出门相乘计算出输出隐藏层状态$$s_t$$。在网络内，不是所有的内部记忆都与其他单元使用的隐藏状态有关。</li></ul><p><img src="/images/2016/06/Screen-Shot-2015-10-23-at-10.00.55-AM.png"></p><p>换一种说法，我们可以将标准的RNN看作是特殊的LSTM，如果我们将遗忘门全部置零，输入门全部置一，输出门全部置一，我们就几乎得到一个标准的RNN。通过门机制，LSTM可以操作记忆从而解决长期依赖问题。</p><p>注意到，还有许多的LSTM变种，一种添加上“猫眼”结构，它的门同时取决于之前的隐藏状态$$s_{t-1}$$和之前的内部状态$$c_{t-1}$$。<a href="http://arxiv.org/pdf/1503.04069.pdf"> LSTM: A Search Space Odyssey </a>实验观察了许多不同的LSTM机制。</p><p>##GRU网络</p><p>GRU的理念类似于LSTM，其等式如下：</p><p><img src="/images/2016/06/latex8.png"></p><p>GRU拥有两个门，称为重置门$$r$$和更新门$$z$$。直观来说，重置门决定如何联合新的输入和之前的记忆，而更新门决定留下多少之前的记忆。如果将重置门全部置一并且更新门全部置零，那么我们又得到了我们原始的RNN了。GRU的解决长期依赖的理念和LSTM基本类似，以下是一些不同之处：</p><ul><li>两个门VS三个门</li><li>GRU不处理内层记忆$$c_t$$</li><li>输入门和遗忘门被组合成更新门$$z$$,重置门$$r$$直接连接之前的隐藏状态。因此，</li><li>计算输出是不加上第二个非线性变换</li></ul><p><img src="/images/2016/06/Screen-Shot-2015-10-23-at-10.36.51-AM.png"></p><p>##GRU VS LSTM</p><p>如今你认识了两个对抗梯度消失的模型</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/RNN/">RNN</category>
      
      
      <comments>http://example.com/2016/06/22/2016-06-22-recurrent-neural-network-tutorial-part-4-implementing-a-gru-slash-lstm-rnn-with-python-and-theano/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RECURRENT NEURAL NETWORKS TUTORIAL, PART 3 – BACKPROPAGATION THROUGH TIME AND VANISHING GRADIENTS</title>
      <link>http://example.com/2016/06/22/2016-06-22-recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</link>
      <guid>http://example.com/2016/06/22/2016-06-22-recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/</guid>
      <pubDate>Wed, 22 Jun 2016 07:42:14 GMT</pubDate>
      
      <description>&lt;p&gt;在之前的部分我们实现了RNN，但是并未深入探究时间反向传播算法，本文将对这一点作详细说明。我们将了解关于梯度消失问题的知识，它促使了LSTM和GRU的出现，而这两者都是NLP领域非常常见的模型。&lt;/p&gt;
&lt;p&gt;##BACKPROPAGATION THROUGH TIME (BPTT)&lt;/p&gt;
&lt;p&gt;首先我们回顾一下RNN的基本等式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/2016/06/latex.png&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>在之前的部分我们实现了RNN，但是并未深入探究时间反向传播算法，本文将对这一点作详细说明。我们将了解关于梯度消失问题的知识，它促使了LSTM和GRU的出现，而这两者都是NLP领域非常常见的模型。</p><p>##BACKPROPAGATION THROUGH TIME (BPTT)</p><p>首先我们回顾一下RNN的基本等式：</p><p><img src="/images/2016/06/latex.png"></p><span id="more"></span><p>我们也定义了损失函数（交叉熵）：</p><p><img src="/images/2016/06/latex1.png"></p><p>在这里，$$y_t$$是 $$t$$时刻的正确的词语， $$\tilde{y_t}$$ 是我们的预测。因为我们把一整个序列（句子）当做是输入，那么错误等同于每个时间step（词语）的错误的和。</p><p>![](/images/2016/06/rnn-bptt1.png）</p><p>需要注意，我们的目标是计算基于参数$$U, V, W$$错误的梯度，并且通过SGD来学习到好的参数。类似于我们将错误相加的做法，对于一个训练样本，我们将各个时间点的梯度相加。</p><p>$$<br>\frac{\partial{E}}{\partial{W}} = \sum_{t} \frac{\partial{E_t}}{\partial{W}}<br>$$</p><p>我们使用链式求导法则来计算这些梯度，这就是反向传播算法:从错误处反向计算。以下我们使用$$E_3$$作为例子。</p><p><img src="/images/2016/06/latex2.png"></p><p>其中，$$z_3 = V s_3$$，并且$$\otimes$$指的是向量外积。在这里我们需要注意到，$$\frac{\partial{E_3}}{\partial{V}}$$只取决于当前时刻的值$$\tilde{y_3}, y_3, s_3$$。如果你明确了这一点，那么计算$$V$$的梯度只是矩阵计算罢了。</p><p>但是，对于$$\frac{\partial{E_3}}{\partial{W}}$$和$$V$$就不一样了。我们写出链式法则：</p><p><img src="/images/2016/06/latex3.png"></p><p>可以看到，$$s_3 = \tanh(U x_t + W s_2)$$取决于$$s_2$$，而$$s_2$$又取决于$$W$$和$$s_1$$，以此类推。所以我们计算$$W$$的偏导，我们不能把$$s_2$$当做一个常量，相反我们需要一遍遍的应用链式法则：</p><p><img src="/images/2016/06/latex4.png"></p><p>我们把每个时间点对于梯度贡献综合起来。换句话说，因为$$W$$在直到我们需要输出的时刻都被用到，所以我们需要计算$$t=3$$时刻直到$$t=0$$时刻：</p><p><img src="/images/2016/06/rnn-bptt-with-gradients.png"></p><p>这其实和深度前馈神经网络里的标准的反向传播算法是类似的。主要的不同点在于我们把每个时间点的$$W$$的梯度综合起来。传统的神经网络的不同层之间不共享参数，于是我们也不需要综合什么。但是在我看来，BPTT只不过是在没有展开的RNN上的标准BP算法的别名罢了。类似于标准的BP算法，你也可以定义一个徳塔项来表示反向传播的内容。例如：$$\delta_{2}^{(3)} = \frac{\partial{E_3}}{\partial{z_2}} = \frac{\partial{E_3}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{s_2}} \frac{\partial{s_2}}{\partial{z_2}}$$，其中$$z_2 = Ux_2 + Ws_1$$。以此类推。</p><p>代码实现BPTT如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bptt</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">    T = <span class="built_in">len</span>(y)</span><br><span class="line">    <span class="comment"># Perform forward propagation</span></span><br><span class="line">    o, s = self.forward_propagation(x)</span><br><span class="line">    <span class="comment"># We accumulate the gradients in these variables</span></span><br><span class="line">    dLdU = np.zeros(self.U.shape)</span><br><span class="line">    dLdV = np.zeros(self.V.shape)</span><br><span class="line">    dLdW = np.zeros(self.W.shape)</span><br><span class="line">    delta_o = o</span><br><span class="line">    delta_o[np.arange(<span class="built_in">len</span>(y)), y] -= <span class="number">1.</span></span><br><span class="line">    <span class="comment"># For each output backwards...</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(T)[::-<span class="number">1</span>]:</span><br><span class="line">        dLdV += np.outer(delta_o[t], s[t].T)</span><br><span class="line">        <span class="comment"># Initial delta calculation: dL/dz</span></span><br><span class="line">        delta_t = self.V.T.dot(delta_o[t]) * (<span class="number">1</span> - (s[t] ** <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># Backpropagation through time (for at most self.bptt_truncate steps)</span></span><br><span class="line">        <span class="keyword">for</span> bptt_step <span class="keyword">in</span> np.arange(<span class="built_in">max</span>(<span class="number">0</span>, t-self.bptt_truncate), t+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># print &quot;Backpropagation step t=%d bptt step=%d &quot; % (t, bptt_step)</span></span><br><span class="line">            <span class="comment"># Add to gradients at each previous step</span></span><br><span class="line">            dLdW += np.outer(delta_t, s[bptt_step-<span class="number">1</span>])</span><br><span class="line">            dLdU[:,x[bptt_step]] += delta_t</span><br><span class="line">            <span class="comment"># Update delta for next step dL/dz at t-1</span></span><br><span class="line">            delta_t = self.W.T.dot(delta_t) * (<span class="number">1</span> - s[bptt_step-<span class="number">1</span>] ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> [dLdU, dLdV, dLdW]</span><br></pre></td></tr></table></figure><p>从代码你也可以观察到RNN不容易训练：由于序列比较长，每次传播需要计算很多层，实践上通常许多人的做法是将传播限制在几步之内。</p><p>##梯度消失问题</p><p>之前的部分我们已经讲述了关于RNN的长期依赖问题。为了解这一点，我们来观察上面我们计算过的梯度。</p><p><img src="/images/2016/06/latex5.png"></p><p>注意到是对于自身的链式法则，如。再注意到，我们这里计算的是向量对向量的偏导，其结果是一个雅可比矩阵。因此可以改写上面的梯度式为：</p><p><img src="/images/2016/06/latex6.png"></p><p>式子中的雅克比矩阵的二范数具有上限1.这导致激活函数tanh（或者sigmoid）映射所有的值到[-1,1]，那么偏导也被限制在1（对于sigmoid是$$\frac{1}{4} $$）。</p><p><img src="/images/2016/06/tanh.png"></p><p>图中我们可以看到，在tanh函数两边，梯度都接近于0.这导致它之前的梯度也接近于0，那么，与矩阵中的数字多次相乘使得梯度迅速减小，直到接近消失。院出的时间点对于现在的影响接近于0，这就是长期依赖问题的原因。但是，长期依赖问题并不只是对于RNN出现，深度神经网络都具有这个问题，只不过RNN经常要处理长序列问题，所以网络层数很多，这个问题就经常出现了。</p><p>容易想到的是，与梯度消失问题对应的是，梯度爆炸问题。当雅克比矩阵中的数值较大时，容易出现这个问题。但是，通常来说，对于梯度爆炸，业界关注并不太多。有两个原因，其一，梯度爆炸发生时通常容易发现，因为可能导致程序崩溃之类的后果；其二，通常为梯度设置上限是应对梯度爆炸的简便做法。</p><p>那么怎么应对梯度弥散问题呢？首先，更好的初始化权重可以减少梯度弥散的效果；其次，使用正则化；更加通用的方法是使用ReLU作为激活函数，其梯度要么是1要么是0，所以更少的可能出现梯度弥散的问题。另外，更加流行的做法则是使用 Long Short-Term Memory (LSTM)或者Gated Recurrent Unit (GRU)，LSTM<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf">出现于1997年</a>，也许是NLP领域近期最流行的网络结构。GRU，<a href="http://arxiv.org/pdf/1406.1078v3.pdf">出现于2014年</a>，是LSTM的简化版本。两种网络都是为了应对梯度弥散和长期依赖问题。我们将会在之后的教程中涉及它们。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/RNN/">RNN</category>
      
      
      <comments>http://example.com/2016/06/22/2016-06-22-recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Vim 练级攻略二</title>
      <link>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-er/</link>
      <guid>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-er/</guid>
      <pubDate>Wed, 22 Jun 2016 02:50:35 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;第三级-–-更好，更强，更快&quot;&gt;&lt;a href=&quot;#第三级-–-更好，更强，更快&quot; class=&quot;headerlink&quot; title=&quot;第三级 – 更好，更强，更快&quot;&gt;&lt;/a&gt;第三级 – 更好，更强，更快&lt;/h2&gt;&lt;p&gt;先恭喜你！你干的很不错。我们可以开始一些更为有趣的事了。在第三级，我们只谈那些和vi可以兼容的命令。&lt;/p&gt;
&lt;h3 id=&quot;更好&quot;&gt;&lt;a href=&quot;#更好&quot; class=&quot;headerlink&quot; title=&quot;更好&quot;&gt;&lt;/a&gt;更好&lt;/h3&gt;&lt;p&gt;下面，让我们看一下vim是怎么重复自己的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;. → (小数点) 可以重复上一次的命令&lt;/li&gt;
&lt;li&gt;N&lt;command&gt; → 重复某个命令N次&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="第三级-–-更好，更强，更快"><a href="#第三级-–-更好，更强，更快" class="headerlink" title="第三级 – 更好，更强，更快"></a>第三级 – 更好，更强，更快</h2><p>先恭喜你！你干的很不错。我们可以开始一些更为有趣的事了。在第三级，我们只谈那些和vi可以兼容的命令。</p><h3 id="更好"><a href="#更好" class="headerlink" title="更好"></a>更好</h3><p>下面，让我们看一下vim是怎么重复自己的：</p><ol><li>. → (小数点) 可以重复上一次的命令</li><li>N<command> → 重复某个命令N次</li></ol><span id="more"></span><p>下面是一个示例，找开一个文件你可以试试下面的命令：</p><blockquote><ul><li>2dd → 删除2行</li></ul></blockquote><ul><li>3p → 粘贴文本3次</li><li>100idesu [ESC] → 会写下 “desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu desu “</li><li>. → 重复上一个命令—— 100 “desu “.</li><li><ol start="3"><li>→ 重复 3 次 “desu” (注意：不是 300，你看，VIM多聪明啊).</li></ol></li></ul><p>###更强</p><p>你要让你的光标移动更有效率，你一定要了解下面的这些命令，千万别跳过。</p><ol><li>NG → 到第 N 行 （注：注意命令中的G是大写的，另我一般使用 : N 到第N行，如 :137 到第137行）</li><li>gg → 到第一行。（注：相当于1G，或 :1）</li><li>G → 到最后一行。</li><li>按单词移动：<ol><li>w → 到下一个单词的开头。</li><li>e → 到下一个单词的结尾。</li></ol></li></ol><pre><code>![](/images/2016/06/word_moves.jpg)&gt; 如果你认为单词是由默认方式，那么就用小写的e和w。默认上来说，一个单词由字母，数字和下划线组成（注：程序变量）&gt; 如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W。（注：程序语句）</code></pre><p>下面，让我来说说最强的光标移动：</p><blockquote><ul><li>% : 匹配括号移动，包括 (, {, [. （注：你需要把光标先移到括号上）</li></ul></blockquote><ul><li>* 和 #:  匹配光标当前所在的单词，移动光标到下一个（或上一个）匹配单词（*是下一个，#是上一个）</li></ul><h3 id="更快"><a href="#更快" class="headerlink" title="更快"></a>更快</h3><p>你一定要记住光标的移动，因为很多命令都可以和这些移动光标的命令连动。很多命令都可以如下来干：</p><p><code>&lt;start position&gt;&lt;command&gt;&lt;end position&gt;</code></p><p>例如 0y$ 命令意味着：</p><ul><li>0 → 先到行头</li><li>y → 从这里开始拷贝</li><li>$ → 拷贝到本行最后一个字符</li></ul><p>你也可以输入 ye，从当前位置拷贝到本单词的最后一个字符。</p><p>你也可以输入 y2/foo 来拷贝2个 “foo” 之间的字符串。</p><p>还有很多时间并不一定你就一定要按y才会拷贝，下面的命令也会被拷贝：</p><ul><li>d (删除 )</li><li>v (可视化的选择)</li><li>gU (变大写)</li><li>gu (变小写)</li><li>等等</li></ul><p>（注：可视化选择是一个很有意思的命令，你可以先按v，然后移动光标，你就会看到文本被选择，然后，你可能d，也可y，也可以变大写等）</p><h2 id="第四级-–-Vim-超能力"><a href="#第四级-–-Vim-超能力" class="headerlink" title="第四级 – Vim 超能力"></a>第四级 – Vim 超能力</h2><p>你只需要掌握前面的命令，你就可以很舒服的使用VIM了。但是，现在，我们向你介绍的是VIM杀手级的功能。下面这些功能是我只用vim的原因。</p><h3 id="在当前行上移动光标-0-f-F-t-T"><a href="#在当前行上移动光标-0-f-F-t-T" class="headerlink" title="在当前行上移动光标: 0 ^ $ f F t T , ;"></a>在当前行上移动光标: 0 ^ $ f F t T , ;</h3><blockquote><ul><li>0 → 到行头</li></ul></blockquote><ul><li>^ → 到本行的第一个非blank字符</li><li>$ → 到行尾</li><li>g_ → 到本行最后一个不是blank字符的位置。</li><li>fa → 到下一个为a的字符处，你也可以fs到下一个为s的字符。</li><li>t, → 到逗号前的第一个字符。逗号可以变成其它字符。</li><li>3fa → 在当前行查找第三个出现的a。</li><li>F 和 T → 和 f 和 t 一样，只不过是相反方向。<br><img src="/images/2016/06/line_moves.jpg"></li></ul><p>还有一个很有用的命令是 dt” → 删除所有的内容，直到遇到双引号—— “。</p><p>###区域选择 <code>&lt;action&gt;a&lt;object&gt;</code> 或 <code>&lt;action&gt;i&lt;object&gt;</code></p><p>在visual 模式下，这些命令很强大，其命令格式为</p><p><code>&lt;action&gt;a&lt;object&gt;</code> 和 <code>&lt;action&gt;i&lt;object&gt;</code></p><ul><li>action可以是任何的命令，如 d (删除), y (拷贝), v (可以视模式选择)。</li><li>object 可能是： w 一个单词， W 一个以空格为分隔的单词， s 一个句字， p 一个段落。也可以是一个特别的字符：”、 ‘、 )、 }、 ]。</li></ul><p>假设你有一个字符串 (map (+) (“foo”)).而光标键在第一个 o 的位置。</p><blockquote><ul><li>vi” → 会选择 foo.</li></ul></blockquote><ul><li>va” → 会选择 “foo”.</li><li>vi) → 会选择 “foo”.</li><li>va) → 会选择(“foo”).</li><li>v2i) → 会选择 map (+) (“foo”)</li><li>v2a) → 会选择 (map (+) (“foo”))</li></ul><p><img src="/images/2016/06/textobjects.png"></p><p>###块操作: <C-v></p><p>块操作，典型的操作： 0 <C-v> <C-d> I– [ESC]</p><ul><li>^ → 到行头</li><li><C-v> → 开始块操作</li><li><C-d> → 向下移动 (你也可以使用hjkl来移动光标，或是使用%，或是别的)</li><li>I– [ESC] → I是插入，插入“–”，按ESC键来为每一行生效。</li></ul><p><img src="/images/2016/06/rectangular-blocks.gif"></p><p>###自动提示： <C-n> 和 <C-p></p><p>在 Insert 模式下，你可以输入一个词的开头，然后按 <C-p>或是<C-n>，自动补齐功能就出现了……</p><p><img src="/images/2016/06/completion.gif"></p><h3 id="宏录制：-qa-操作序列-q-a"><a href="#宏录制：-qa-操作序列-q-a" class="headerlink" title="宏录制： qa 操作序列 q, @a, @@"></a>宏录制： qa 操作序列 <code>q, @a, @@</code></h3><p>如下</p><ul><li>qa 把你的操作记录在寄存器 a。</li><li>于是<code> @a</code> 会replay被录制的宏。</li><li><code>@@</code>是一个快捷键用来replay最新录制的宏。</li></ul><p>示例：<br>在一个只有一行且这一行只有“1”的文本中，键入如下命令：</p><ul><li>qaYp<C-a>q→<ul><li>qa 开始录制</li><li>Yp 复制行.</li><li><C-a> 增加1.</li><li>q 停止录制.</li></ul></li><li>@a → 在1下面写下 2</li><li>@@ → 在2 正面写下3</li><li>现在做 100@@ 会创建新的100行，并把数据增加到 103.</li></ul><p><img src="/images/2016/06/macros.gif"></p><p>###可视化选择： <code>v,V,&lt;C-v&gt;</code></p><p>前面，我们看到了 <C-v>的示例 （在Windows下应该是<C-q>），我们可以使用 v 和 V。一但被选好了，你可以做下面的事：</p><ul><li>J → 把所有的行连接起来（变成一行）</li><li>&lt; 或 &gt; → 左右缩进</li><li>= → 自动给缩进 （注：这个功能相当强大，我太喜欢了）</li></ul><p><img src="/images/2016/06/autoindent.gif"></p><p>在所有被选择的行后加上点东西：</p><ul><li><code>&lt;C-v&gt;</code></li><li>选中相关的行 (可使用 j 或 <C-d> 或是 /pattern 或是 % 等……)</li><li>$ 到行最后</li><li>A, 输入字符串，按 ESC。</li></ul><p><img src="/images/2016/06/append-to-many-lines.gif"></p><p>###分屏: :split 和 vsplit.</p><p>下面是主要的命令，你可以使用VIM的帮助 :help split. 你可以参考本站以前的一篇文章VIM分屏。</p><ul><li>:split → 创建分屏 (:vsplit创建垂直分屏)</li><li><code>&lt;C-w&gt;&lt;dir&gt;</code> : dir就是方向，可以是 hjkl 或是 ←↓↑→ 中的一个，其用来切换分屏。</li><li><C-w>_ (或 <C-w>|) : 最大化尺寸 (<C-w>| 垂直分屏)</li><li><C-w>+ (或 <C-w>-) : 增加尺寸</li></ul><p><img src="/images/2016/06/split.gif"></p><p>##结束语</p><ul><li>上面是作者最常用的90%的命令。</li><li>我建议你每天都学1到2个新的命令。</li><li>在两到三周后，你会感到vim的强大的。</li><li>有时候，学习VIM就像是在死背一些东西。</li><li>幸运的是，vim有很多很不错的工具和优秀的文档。</li><li>运行vimtutor直到你熟悉了那些基本命令。</li><li>其在线帮助文档中你应该要仔细阅读的是 :help usr_02.txt.</li><li>你会学习到诸如  !， 目录，寄存器，插件等很多其它的功能。</li><li>学习vim就像学弹钢琴一样，一旦学会，受益无穷。</li></ul>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Vim/">Vim</category>
      
      
      <category domain="http://example.com/tags/tutorial/">tutorial</category>
      
      
      <comments>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-er/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Vim 练级攻略一</title>
      <link>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-lue-1/</link>
      <guid>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-lue-1/</guid>
      <pubDate>Wed, 22 Jun 2016 02:50:35 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;img src=&quot;/images/2016/06/uber_leet_use_vim.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;你想以最快的速度学习人类史上最好的文本编辑器VIM吗？你先得懂得如何在VIM幸存下来，然后一点一点地学习各种戏法。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.vim.org/&quot;&gt;Vim&lt;/a&gt;: the Six Billion Dollar editor&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Better, Stronger, Faster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习&lt;a href=&quot;http://www.vim.org/&quot;&gt;Vim&lt;/a&gt;并且其会成为你最后一个使用的文本编辑器。没有比这个更好的文本编辑器了，非常地难学，但是却不可思议地好用。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><img src="/images/2016/06/uber_leet_use_vim.jpg"></p><p>你想以最快的速度学习人类史上最好的文本编辑器VIM吗？你先得懂得如何在VIM幸存下来，然后一点一点地学习各种戏法。</p><p><a href="http://www.vim.org/">Vim</a>: the Six Billion Dollar editor</p><blockquote><p>Better, Stronger, Faster.</p></blockquote><p>学习<a href="http://www.vim.org/">Vim</a>并且其会成为你最后一个使用的文本编辑器。没有比这个更好的文本编辑器了，非常地难学，但是却不可思议地好用。</p><span id="more"></span><p>我建议下面这四个步骤：</p><ol><li>存活</li><li>感觉良好</li><li>觉得更好，更强，更快</li><li>使用VIM的超能力</li></ol><p>当你走完这篇文章，你会成为一个vim的 superstar。</p><p>在开始学习以前，我需要给你一些警告：</p><ol><li>学习vim在开始时是痛苦的。</li><li>需要时间</li><li>需要不断地练习，就像你学习一个乐器一样。</li><li>不要期望你能在3天内把vim练得比别的编辑器更有效率。</li></ol><p>事实上，你需要2周时间的苦练，而不是3天。</p><p>##第一级 – 存活</p><ol><li>安装<a href="http://www.vim.org/">Vim</a></li><li>启动Vim</li><li>什么也不干！请先阅读</li></ol><p>当你安装好一个编辑器后，你一定会想在其中输入点什么东西，然后看看这个编辑器是什么样子。但vim不是这样的，请按照下面的命令操作：</p><ul><li>启动Vim后，vim在 Normal 模式下。</li><li>让我们进入 Insert 模式，请按下键 i 。(你会看到vim左下角有一个–insert–字样，表示，你可以以插入的方式输入了）</li><li>此时，你可以输入文本了，就像你用“记事本”一样。</li><li>如果你想返回 Normal 模式，请按 ESC 键。</li></ul><p>现在，你知道如何在 Insert 和 Normal 模式下切换了。下面是一些命令，可以让你在 Normal 模式下幸存下来（箭头不代表按键）：</p><blockquote><ul><li>i → Insert 模式，按 ESC 回到 Normal 模式.</li></ul></blockquote><ul><li>x → 删当前光标所在的一个字符。</li><li>:wq → 存盘 + 退出 (:w 存盘, :q 退出)   （陈皓注：:w 后可以跟文件名）</li><li>dd → 删除当前行，并把删除的行存到剪贴板里</li><li>p → 粘贴剪贴板</li></ul><p>推荐:</p><blockquote><ul><li>hjkl (强例推荐使用其移动光标，但不必需) →你也可以使用光标键 (←↓↑→). 注: j 就像下箭头。</li></ul></blockquote><ul><li>:help <command> → 显示相关命令的帮助。你也可以就输入 :help 而不跟命令。（注：退出帮助需要输入:q）</li></ul><p>你能在vim幸存下来只需要上述的那5个命令，你就可以编辑文本了，你一定要把这些命令练成一种下意识的状态。于是你就可以开始进阶到第二级了。</p><p>当是，在你进入第二级时，需要再说一下 Normal 模式。在一般的编辑器下，当你需要copy一段文字的时候，你需要使用 Ctrl 键，比如：Ctrl-C。也就是说，Ctrl键就好像功能键一样，当你按下了功能键Ctrl后，C就不在是C了，而且就是一个命令或是一个快键键了，在VIM的Normal模式下，所有的键就是功能键了。这个你需要知道。</p><p>标记:</p><ul><li>下面的文字中，如果是 Ctrl-λ我会写成 &lt;C-λ&gt;.</li><li>以 : 开始的命令你需要输入 <enter>回车，例如 — 如果我写成 :q 也就是说你要输入 :q<enter>.</li></ul><p>##第二级 – 感觉良好</p><p>上面的那些命令只能让你存活下来，现在是时候学习一些更多的命令了，下面是我的建议：（注：所有的命令都需要在Normal模式下使用，如果你不知道现在在什么样的模式，你就狂按几次ESC键）</p><ol><li><p>各种插入模式</p><blockquote><ul><li>a → 在光标后插入</li></ul></blockquote><ul><li>o → 在当前行后插入一个新行</li><li>O → 在当前行前插入一个新行</li><li>cw → 替换从光标所在位置后到一个单词结尾的字符</li></ul></li><li><p>简单的移动光标</p><blockquote><ul><li>0 → 数字零，到行头</li></ul></blockquote><ul><li>^ → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）</li><li>$ → 到本行行尾</li><li>g_ → 到本行最后一个不是blank字符的位置。</li><li>/pattern → 搜索 pattern 的字符串（注：如果搜索出多个匹配，可按n键到下一个）</li></ul></li><li><p>拷贝/粘贴 （注：p/P都可以，p是表示在当前位置之后，P表示在当前位置之前）</p><blockquote><ul><li>P → 粘贴</li></ul></blockquote><ul><li>yy → 拷贝当前行当行于 ddP</li></ul></li><li><p>Undo/Redo</p><blockquote><ul><li>u → undo</li></ul></blockquote><ul><li><code>&lt;C-r&gt;</code> → redo</li></ul></li><li><p>打开/保存/退出/改变文件(Buffer)</p><blockquote><ul><li>:e &lt;path/to/file&gt; → 打开一个文件</li></ul></blockquote><ul><li>:w → 存盘</li><li>:saveas &lt;path/to/file&gt; → 另存为 &lt;path/to/file&gt;</li><li>:x， ZZ 或 :wq → 保存并退出 (:x 表示仅在需要时保存，ZZ不需要输入冒号并回车)</li><li>:q! → 退出不保存 :qa! 强行退出所有的正在编辑的文件，就算别的文件有更改。</li><li>:bn 和 :bp → 你可以同时打开很多文件，使用这两个命令来切换下一个或上一个文件。（注：我喜欢使用:n到下一个文件）</li></ul></li></ol><p>花点时间熟悉一下上面的命令，一旦你掌握他们了，你就几乎可以干其它编辑器都能干的事了。但是到现在为止，你还是觉得使用vim还是有点笨拙，不过没关系，你可以进阶到第三级了。<a href="http://frankchen0130.github.io/2016/06/22/vim-lian-ji-gong-er/">下一篇</a>我们将介绍第三个和第四个阶段。</p><p>(注：图片中的U83R 1337指的是德语中的uber leet，合起来就是Super Cool的意思，所以图片中文字指的是Super cool use Vim!)</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Vim/">Vim</category>
      
      
      <category domain="http://example.com/tags/tutorial/">tutorial</category>
      
      
      <comments>http://example.com/2016/06/22/2016-06-22-vim-lian-ji-gong-lue-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RECURRENT NEURAL NETWORKS TUTORIAL, PART 2 – IMPLEMENTING A RNN WITH PYTHON, NUMPY AND THEANO</title>
      <link>http://example.com/2016/06/15/2016-06-15-recurrent-neural-networks-tutorial-part-2-implementing-a-rnn-with-python-numpy-and-theano/</link>
      <guid>http://example.com/2016/06/15/2016-06-15-recurrent-neural-networks-tutorial-part-2-implementing-a-rnn-with-python-numpy-and-theano/</guid>
      <pubDate>Wed, 15 Jun 2016 09:54:18 GMT</pubDate>
      
      <description>&lt;p&gt;本文将用Python实现完整的RNN，并且用Theano来优化。&lt;/p&gt;
&lt;h2 id=&quot;语言模型&quot;&gt;&lt;a href=&quot;#语言模型&quot; class=&quot;headerlink&quot; title=&quot;语言模型&quot;&gt;&lt;/a&gt;语言模型&lt;/h2&gt;&lt;p&gt;我们的目标是使用RNN建立一个语言模型。以下我们举例说明什么是语言模型。例如，你说了一句包括$$m$$个词语的句子，语言模型可以为这句话出现的概率打分：&lt;/p&gt;
&lt;p&gt;$$P(w_1,\cdots,w_m) = \prod_{i=1}^m P(w_i \mid w_1,\cdots,w_{i-1})$$&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文将用Python实现完整的RNN，并且用Theano来优化。</p><h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>我们的目标是使用RNN建立一个语言模型。以下我们举例说明什么是语言模型。例如，你说了一句包括$$m$$个词语的句子，语言模型可以为这句话出现的概率打分：</p><p>$$P(w_1,\cdots,w_m) = \prod_{i=1}^m P(w_i \mid w_1,\cdots,w_{i-1})$$</p><span id="more"></span><p> 每一个词语的概率都取决于它之前的所有的词的概率。</p><p>这样的模型有什么用处呢？</p><ul><li>可以用于机器翻译或者语音识别中的正确句子打分</li><li>以概率生成新的句子</li></ul><p>注意到在上面的公式内，我们使用了所有的之前的词的概率，实际上这在计算和存储时的耗费都是巨大的，通常而言只会取2~4个词左右。</p><h2 id="预处理并训练数据"><a href="#预处理并训练数据" class="headerlink" title="预处理并训练数据"></a>预处理并训练数据</h2><h3 id="1-标记化"><a href="#1-标记化" class="headerlink" title="1.标记化"></a>1.标记化</h3><p>原始的文本需要被标记化，例如需要把文本标记为句子，句子标记为词语，并且还需要处理标点符号。我们将使用NLTK的<code>word_tokenize\sent_tokenize</code>方法。</p><h3 id="2-移除低频词"><a href="#2-移除低频词" class="headerlink" title="2.移除低频词"></a>2.移除低频词</h3><p>移除低频词不管是对于训练和预测都是有帮助的。这里我们设置一个上限<code>vocabulary_size</code>为8000，出现次数少于它的词都会被替换为<code>UNKNOWN_TOKEN</code>输入，而当输出是<code>UNKNOWN_TOKEN</code>时，它将被随机替换为一个不在词表内的词，亦或者持续预测直到不出现<code>UNKNOWN_TOKEN</code>为止。</p><h3 id="3-放置句子开始和结束标记"><a href="#3-放置句子开始和结束标记" class="headerlink" title="3.放置句子开始和结束标记"></a>3.放置句子开始和结束标记</h3><p>为了解句子的开始和结束，我们把<code>SENTENCE_START</code>放置在句子开头，并且把<code>SENTENCE_END</code>放置在句子结尾。</p><h3 id="4-建立训练数据的矩阵"><a href="#4-建立训练数据的矩阵" class="headerlink" title="4.建立训练数据的矩阵"></a>4.建立训练数据的矩阵</h3><p>RNN的输入和输出都是向量而不是字符串，我们需要把词与向量一一对应，通过<code>index_to_word</code>和<code>word_to_index</code>。比如一个训练的例子$$x$$为[0, 179, 341, 416]（注意到其中每个元素都是长度为<code>vocabulary_size</code>的one-hot向量，所以$$x$$实际上是一个矩阵），那么其label-$$y$$为[179, 341, 416, 1]，注意到我们的目标是预测下一个词，所以$$y$$就是$$x$$移动一位，并添加上最后的一个元素（预测词）的结果，其中<code>SENTENCE_START</code>和<code>SENTENCE_END</code>分别为0和1.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">vocabulary_size = <span class="number">8000</span></span><br><span class="line">unknown_token = <span class="string">&quot;UNKNOWN_TOKEN&quot;</span></span><br><span class="line">sentence_start_token = <span class="string">&quot;SENTENCE_START&quot;</span></span><br><span class="line">sentence_end_token = <span class="string">&quot;SENTENCE_END&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read the data and append SENTENCE_START and SENTENCE_END tokens</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Reading CSV file...&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/reddit-comments-2015-08.csv&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    reader = csv.reader(f, skipinitialspace=<span class="literal">True</span>)</span><br><span class="line">    reader.<span class="built_in">next</span>()</span><br><span class="line">    <span class="comment"># Split full comments into sentences</span></span><br><span class="line">    sentences = itertools.chain(*[nltk.sent_tokenize(x[<span class="number">0</span>].decode(<span class="string">&#x27;utf-8&#x27;</span>).lower()) <span class="keyword">for</span> x <span class="keyword">in</span> reader])</span><br><span class="line">    <span class="comment"># Append SENTENCE_START and SENTENCE_END</span></span><br><span class="line">    sentences = [<span class="string">&quot;%s %s %s&quot;</span> % (sentence_start_token, x, sentence_end_token) <span class="keyword">for</span> x <span class="keyword">in</span> sentences]</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Parsed %d sentences.&quot;</span> % (<span class="built_in">len</span>(sentences))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenize the sentences into words</span></span><br><span class="line">tokenized_sentences = [nltk.word_tokenize(sent) <span class="keyword">for</span> sent <span class="keyword">in</span> sentences]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Count the word frequencies</span></span><br><span class="line">word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Found %d unique words tokens.&quot;</span> % <span class="built_in">len</span>(word`_freq.items())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the most common words and build index_to_word and word_to_index vectors</span></span><br><span class="line">vocab = word_freq.most_common(vocabulary_size-<span class="number">1</span>)</span><br><span class="line">index_to_word = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> vocab]</span><br><span class="line">index_to_word.append(unknown_token)</span><br><span class="line">word_to_index = <span class="built_in">dict</span>([(w,i) <span class="keyword">for</span> i,w <span class="keyword">in</span> <span class="built_in">enumerate</span>(index_to_word)])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Using vocabulary size %d.&quot;</span> % vocabulary_size</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;The least frequent word in our vocabulary is &#x27;%s&#x27; and appeared %d times.&quot;</span> % (vocab[-<span class="number">1</span>][<span class="number">0</span>], vocab[-<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Replace all words not in our vocabulary with the unknown token</span></span><br><span class="line"><span class="keyword">for</span> i, sent <span class="keyword">in</span> <span class="built_in">enumerate</span>(tokenized_sentences):</span><br><span class="line">    tokenized_sentences[i] = [w <span class="keyword">if</span> w <span class="keyword">in</span> word_to_index <span class="keyword">else</span> unknown_token <span class="keyword">for</span> w <span class="keyword">in</span> sent]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;\nExample sentence: &#x27;%s&#x27;&quot;</span> % sentences[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;\nExample sentence after Pre-processing: &#x27;%s&#x27;&quot;</span> % tokenized_sentences[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the training data</span></span><br><span class="line">X_train = np.asarray([[word_to_index[w] <span class="keyword">for</span> w <span class="keyword">in</span> sent[:-<span class="number">1</span>]] <span class="keyword">for</span> sent <span class="keyword">in</span> tokenized_sentences])</span><br><span class="line">y_train = np.asarray([[word_to_index[w] <span class="keyword">for</span> w <span class="keyword">in</span> sent[<span class="number">1</span>:]] <span class="keyword">for</span> sent <span class="keyword">in</span> tokenized_sentences])</span><br></pre></td></tr></table></figure><p>以下是一个训练样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x:</span><br><span class="line">SENTENCE_START what are n<span class="string">&#x27;t you understanding about this ? !</span></span><br><span class="line"><span class="string">[0, 51, 27, 16, 10, 856, 53, 25, 34, 69]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">y:</span></span><br><span class="line"><span class="string">what are n&#x27;</span>t you understanding about this ? ! SENTENCE_END</span><br><span class="line">[<span class="number">51</span>, <span class="number">27</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">856</span>, <span class="number">53</span>, <span class="number">25</span>, <span class="number">34</span>, <span class="number">69</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>接下来我们开始建立RNN。</p><p>##建立RNN</p><p><img src="/images/2016/06/rnn.jpg"></p><p>总结一下我们的RNN模型的形式。初始输入$$x$$是一个代表一条句子的矩阵，每一时刻的输入$$x_t$$是一个代表一个词语的向量，每一时刻的输出$$o_t$$也是一个向量，其中每个元素代表词表内每一个词被预测的概率。</p><p>RNN中的等式：<br>$$<br>s_t = tanh(Ux_t + Ws_{t-1})<br>o_t = softmax(Vs_t)<br>$$</p><p>介绍一下各个变量的维度：假设我们的词表大小$$C$$为8000，隐藏层大小$$H$$为100，可以把隐藏层大小理解为网络内存的大小，内存越大，网络能记忆的信息也越多，但是也要耗费更多的代价来计算。综上，我们的模型参数维度为：</p><p>$$<br>x_t \in \Bbb{R}^{8000} \ o_t \in \Bbb{R}^{8000} \ s_t \in \Bbb{R}^{100} \ U_t \in \Bbb{R}^{100 \times 8000} \ V_t \in \Bbb{R}^{8000 \times 100} \ W_t \in \Bbb{R}^{100 \times 100} <br>$$</p><p>其中$$U，V，W$$是网络的参数，根据上面的等式，我们需要学习$$2HC+H^2$$个参数，由于$$x_t$$是稀疏的one-hot向量，所以其与$$U$$的乘积一步即可算出，$$W$$和$$S_t$$的维度都比较小，所以最繁琐的计算就是$$VS_t$$了。</p><p>###初始化</p><p>通过Numpy实现第一个版本，对$$U，V，W$$的初始化比较tricky，通常是把它们的初始值置于$$[-\frac{1}{\sqrt n},\frac{1}{\sqrt n}]$$较好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNNumpy</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, word_dim, hidden_dim=<span class="number">100</span>, bptt_truncate=<span class="number">4</span></span>):</span></span><br><span class="line">        <span class="comment"># Assign instance variables</span></span><br><span class="line">        self.word_dim = word_dim</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.bptt_truncate = bptt_truncate</span><br><span class="line">        <span class="comment"># Randomly initialize the network parameters</span></span><br><span class="line">        self.U = np.random.uniform(-np.sqrt(<span class="number">1.</span>/word_dim), np.sqrt(<span class="number">1.</span>/word_dim), (hidden_dim, word_dim))</span><br><span class="line">        self.V = np.random.uniform(-np.sqrt(<span class="number">1.</span>/hidden_dim), np.sqrt(<span class="number">1.</span>/hidden_dim), (word_dim, hidden_dim))</span><br><span class="line">        self.W = np.random.uniform(-np.sqrt(<span class="number">1.</span>/hidden_dim), np.sqrt(<span class="number">1.</span>/hidden_dim), (hidden_dim, hidden_dim))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中<code>word_dim</code>是词表大小，<code>hidden_dim</code>是隐藏层大小。</p><p>###前向计算</p><p>以下是前向计算（预测词语的概率）的过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_propagation</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="comment"># The total number of time steps</span></span><br><span class="line">    T = <span class="built_in">len</span>(x)</span><br><span class="line">    <span class="comment"># During forward propagation we save all hidden states in s because need them later.</span></span><br><span class="line">    <span class="comment"># We add one additional element for the initial hidden, which we set to 0</span></span><br><span class="line">    s = np.zeros((T + <span class="number">1</span>, self.hidden_dim))</span><br><span class="line">    s[-<span class="number">1</span>] = np.zeros(self.hidden_dim)</span><br><span class="line">    <span class="comment"># The outputs at each time step. Again, we save them for later.</span></span><br><span class="line">    o = np.zeros((T, self.word_dim))</span><br><span class="line">    <span class="comment"># For each time step...</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(T):</span><br><span class="line">        <span class="comment"># Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.</span></span><br><span class="line">        s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-<span class="number">1</span>]))</span><br><span class="line">        o[t] = softmax(self.V.dot(s[t]))</span><br><span class="line">    <span class="keyword">return</span> [o, s]</span><br><span class="line"></span><br><span class="line">RNNNumpy.forward_propagation = forward_propagation</span><br></pre></td></tr></table></figure><p>我们同时返回输出及隐藏层状态，隐藏层状态之后会用于梯度计算。$$o_t$$是词表内每个词的概率，但是有时我们需要直接预测出概率最高的词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="comment"># Perform forward propagation and return index of the highest score</span></span><br><span class="line">    o, s = self.forward_propagation(x)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(o, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">RNNNumpy.predict = predict</span><br></pre></td></tr></table></figure><p>尝试输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">model = RNNNumpy(vocabulary_size)</span><br><span class="line">o, s = model.forward_propagation(X_train[<span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span> o.shape</span><br><span class="line"><span class="built_in">print</span> o</span><br><span class="line">(<span class="number">45</span>, <span class="number">8000</span>)</span><br><span class="line">[[ <span class="number">0.00012408</span>  <span class="number">0.0001244</span>   <span class="number">0.00012603</span> ...,  <span class="number">0.00012515</span>  <span class="number">0.00012488</span></span><br><span class="line">   <span class="number">0.00012508</span>]</span><br><span class="line"> [ <span class="number">0.00012536</span>  <span class="number">0.00012582</span>  <span class="number">0.00012436</span> ...,  <span class="number">0.00012482</span>  <span class="number">0.00012456</span></span><br><span class="line">   <span class="number">0.00012451</span>]</span><br><span class="line"> [ <span class="number">0.00012387</span>  <span class="number">0.0001252</span>   <span class="number">0.00012474</span> ...,  <span class="number">0.00012559</span>  <span class="number">0.00012588</span></span><br><span class="line">   <span class="number">0.00012551</span>]</span><br><span class="line"> ...,</span><br><span class="line"> [ <span class="number">0.00012414</span>  <span class="number">0.00012455</span>  <span class="number">0.0001252</span>  ...,  <span class="number">0.00012487</span>  <span class="number">0.00012494</span></span><br><span class="line">   <span class="number">0.0001263</span> ]</span><br><span class="line"> [ <span class="number">0.0001252</span>   <span class="number">0.00012393</span>  <span class="number">0.00012509</span> ...,  <span class="number">0.00012407</span>  <span class="number">0.00012578</span></span><br><span class="line">   <span class="number">0.00012502</span>]</span><br><span class="line"> [ <span class="number">0.00012472</span>  <span class="number">0.0001253</span>   <span class="number">0.00012487</span> ...,  <span class="number">0.00012463</span>  <span class="number">0.00012536</span></span><br><span class="line">   <span class="number">0.00012665</span>]]</span><br></pre></td></tr></table></figure><p>对上面句子（包括45个单词）中的每个词，模型都预测了8000个概率值。因为模型参数这时候是随机初始值，所以预测也是随机的。接下来我们给出预测的词的位置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict(X_train[<span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span> predictions.shape</span><br><span class="line"><span class="built_in">print</span> predictions</span><br><span class="line">(<span class="number">45</span>,)</span><br><span class="line">[<span class="number">1284</span> <span class="number">5221</span> <span class="number">7653</span> <span class="number">7430</span> <span class="number">1013</span> <span class="number">3562</span> <span class="number">7366</span> <span class="number">4860</span> <span class="number">2212</span> <span class="number">6601</span> <span class="number">7299</span> <span class="number">4556</span> <span class="number">2481</span> <span class="number">238</span> <span class="number">2539</span></span><br><span class="line"> <span class="number">21</span> <span class="number">6548</span> <span class="number">261</span> <span class="number">1780</span> <span class="number">2005</span> <span class="number">1810</span> <span class="number">5376</span> <span class="number">4146</span> <span class="number">477</span> <span class="number">7051</span> <span class="number">4832</span> <span class="number">4991</span> <span class="number">897</span> <span class="number">3485</span> <span class="number">21</span></span><br><span class="line"> <span class="number">7291</span> <span class="number">2007</span> <span class="number">6006</span> <span class="number">760</span> <span class="number">4864</span> <span class="number">2182</span> <span class="number">6569</span> <span class="number">2800</span> <span class="number">2752</span> <span class="number">6821</span> <span class="number">4437</span> <span class="number">7021</span> <span class="number">7875</span> <span class="number">6912</span> <span class="number">3575</span>]</span><br></pre></td></tr></table></figure><p>接下来我们计算损失。</p><p>###计算损失</p><p>我们使用交叉熵函数作为损失函数。若我们有$$N$$个训练样本（text中的词语数），$$C$$个类别（词表大小），预测是$$o$$，label是$$y$$，那么损失计算为：</p><p>$$<br>L(y,o) = - \frac{1}{N} \sum_{n \in N} y_n \log o_n<br>$$</p><p>损失函数计算的是我们的预测oo与正确的词yy的差距的大小。通过以下计算损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_total_loss</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">    L = <span class="number">0</span></span><br><span class="line">    <span class="comment"># For each sentence...</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="built_in">len</span>(y)):</span><br><span class="line">        o, s = self.forward_propagation(x[i])</span><br><span class="line">        <span class="comment"># We only care about our prediction of the &quot;correct&quot; words</span></span><br><span class="line">        correct_word_predictions = o[np.arange(<span class="built_in">len</span>(y[i])), y[i]]</span><br><span class="line">        <span class="comment"># Add to the loss based on how off we were</span></span><br><span class="line">        L += -<span class="number">1</span> * np.<span class="built_in">sum</span>(np.log(correct_word_predictions))</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_loss</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">    <span class="comment"># Divide the total loss by the number of training examples</span></span><br><span class="line">    N = np.<span class="built_in">sum</span>((<span class="built_in">len</span>(y_i) <span class="keyword">for</span> y_i <span class="keyword">in</span> y))</span><br><span class="line">    <span class="keyword">return</span> self.calculate_total_loss(x,y)/N</span><br><span class="line"></span><br><span class="line">RNNNumpy.calculate_total_loss = calculate_total_loss</span><br><span class="line">RNNNumpy.calculate_loss = calculate_loss</span><br></pre></td></tr></table></figure><p>让我们稍微检验一下，如果我们词表大小为$$C$$，那么开始时每个词被随机预测的概率为$$\frac{1}{C}$$，那么损失为$$L = - \frac{1}{C} N \log \ \frac{1}{C} = \log C$$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> Limit to <span class="number">1000</span> examples to save time</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Expected Loss for random predictions: %f&quot;</span> % np.log(vocabulary_size)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Actual loss: %f&quot;</span> % model.calculate_loss(X_train[:<span class="number">1000</span>], y_train[:<span class="number">1000</span>])</span><br></pre></td></tr></table></figure><p>很接近。这里我们应当记住，如果data很大，那么计算损失会变得非常耗费时间。</p><p>###通过SGD和BPTT（BACKPROPAGATION THROUGH TIME ）训练RNN</p><p>给定训练样本$$(x,y)$$我们需要计算梯度$$\frac{\partial L}{\partial {U}},\frac{\partial L}{\partial {V}},\frac{\partial L}{\partial {W}}$$。通过以下代码实现BPTT：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bptt</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">    T = <span class="built_in">len</span>(y)</span><br><span class="line">    <span class="comment"># Perform forward propagation</span></span><br><span class="line">    o, s = self.forward_propagation(x)</span><br><span class="line">    <span class="comment"># We accumulate the gradients in these variables</span></span><br><span class="line">    dLdU = np.zeros(self.U.shape)</span><br><span class="line">    dLdV = np.zeros(self.V.shape)</span><br><span class="line">    dLdW = np.zeros(self.W.shape)</span><br><span class="line">    delta_o = o</span><br><span class="line">    delta_o[np.arange(<span class="built_in">len</span>(y)), y] -= <span class="number">1.</span></span><br><span class="line">    <span class="comment"># For each output backwards...</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(T)[::-<span class="number">1</span>]:</span><br><span class="line">        dLdV += np.outer(delta_o[t], s[t].T)</span><br><span class="line">        <span class="comment"># Initial delta calculation</span></span><br><span class="line">        delta_t = self.V.T.dot(delta_o[t]) * (<span class="number">1</span> - (s[t] ** <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># Backpropagation through time (for at most self.bptt_truncate steps)</span></span><br><span class="line">        <span class="keyword">for</span> bptt_step <span class="keyword">in</span> np.arange(<span class="built_in">max</span>(<span class="number">0</span>, t-self.bptt_truncate), t+<span class="number">1</span>)[::-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># print &quot;Backpropagation step t=%d bptt step=%d &quot; % (t, bptt_step)</span></span><br><span class="line">            dLdW += np.outer(delta_t, s[bptt_step-<span class="number">1</span>])</span><br><span class="line">            dLdU[:,x[bptt_step]] += delta_t</span><br><span class="line">            <span class="comment"># Update delta for next step</span></span><br><span class="line">            delta_t = self.W.T.dot(delta_t) * (<span class="number">1</span> - s[bptt_step-<span class="number">1</span>] ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> [dLdU, dLdV, dLdW]</span><br><span class="line"></span><br><span class="line">RNNNumpy.bptt = bptt</span><br></pre></td></tr></table></figure><p>接下来我们测试梯度。</p><p>###测试梯度</p><p>实现BP算法过程中，测试梯度是一个良好的习惯。通过以下公式：</p><p>$$<br>\frac{\partial L}{\partial{\theta}} \approx \lim_{h \rightarrow0} \frac{J(\theta + h)-J(\theta - h)}{2h}<br>$$</p><p>使用以上的公式来测试梯度，同样，由于需要计算所以的参数，梯度测试也是很耗时间的，在部分数据上测试是比较好的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_check</span>(<span class="params">self, x, y, h=<span class="number">0.001</span>, error_threshold=<span class="number">0.01</span></span>):</span></span><br><span class="line">    <span class="comment"># Calculate the gradients using backpropagation. We want to checker if these are correct.</span></span><br><span class="line">    bptt_gradients = self.bptt(x, y)</span><br><span class="line">    <span class="comment"># List of all parameters we want to check.</span></span><br><span class="line">    model_parameters = [<span class="string">&#x27;U&#x27;</span>, <span class="string">&#x27;V&#x27;</span>, <span class="string">&#x27;W&#x27;</span>]</span><br><span class="line">    <span class="comment"># Gradient check for each parameter</span></span><br><span class="line">    <span class="keyword">for</span> pidx, pname <span class="keyword">in</span> <span class="built_in">enumerate</span>(model_parameters):</span><br><span class="line">        <span class="comment"># Get the actual parameter value from the mode, e.g. model.W</span></span><br><span class="line">        parameter = operator.attrgetter(pname)(self)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Performing gradient check for parameter %s with size %d.&quot;</span> % (pname, np.prod(parameter.shape))</span><br><span class="line">        <span class="comment"># Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...</span></span><br><span class="line">        it = np.nditer(parameter, flags=[<span class="string">&#x27;multi_index&#x27;</span>], op_flags=[<span class="string">&#x27;readwrite&#x27;</span>])</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</span><br><span class="line">            ix = it.multi_index</span><br><span class="line">            <span class="comment"># Save the original value so we can reset it later</span></span><br><span class="line">            original_value = parameter[ix]</span><br><span class="line">            <span class="comment"># Estimate the gradient using (f(x+h) - f(x-h))/(2*h)</span></span><br><span class="line">            parameter[ix] = original_value + h</span><br><span class="line">            gradplus = self.calculate_total_loss([x],[y])</span><br><span class="line">            parameter[ix] = original_value - h</span><br><span class="line">            gradminus = self.calculate_total_loss([x],[y])</span><br><span class="line">            estimated_gradient = (gradplus - gradminus)/(<span class="number">2</span>*h)</span><br><span class="line">            <span class="comment"># Reset parameter to original value</span></span><br><span class="line">            parameter[ix] = original_value</span><br><span class="line">            <span class="comment"># The gradient for this parameter calculated using backpropagation</span></span><br><span class="line">            backprop_gradient = bptt_gradients[pidx][ix]</span><br><span class="line">            <span class="comment"># calculate The relative error: (|x - y|/(|x| + |y|))</span></span><br><span class="line">            relative_error = np.<span class="built_in">abs</span>(backprop_gradient - estimated_gradient)/(np.<span class="built_in">abs</span>(backprop_gradient) + np.<span class="built_in">abs</span>(estimated_gradient))</span><br><span class="line">            <span class="comment"># If the error is to large fail the gradient check</span></span><br><span class="line">            <span class="keyword">if</span> relative_error &gt; error_threshold:</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;Gradient Check ERROR: parameter=%s ix=%s&quot;</span> % (pname, ix)</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;+h Loss: %f&quot;</span> % gradplus</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;-h Loss: %f&quot;</span> % gradminus</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;Estimated_gradient: %f&quot;</span> % estimated_gradient</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;Backpropagation gradient: %f&quot;</span> % backprop_gradient</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;Relative Error: %f&quot;</span> % relative_error</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            it.iternext()</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Gradient check for parameter %s passed.&quot;</span> % (pname)</span><br><span class="line"></span><br><span class="line">RNNNumpy.gradient_check = gradient_check</span><br><span class="line"></span><br><span class="line"><span class="comment"># To avoid performing millions of expensive calculations we use a smaller vocabulary size for checking.</span></span><br><span class="line">grad_check_vocab_size = <span class="number">100</span></span><br><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">model = RNNNumpy(grad_check_vocab_size, <span class="number">10</span>, bptt_truncate=<span class="number">1000</span>)</span><br><span class="line">model.gradient_check([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure><p>接下来我们实现SGD。</p><p>###实现SGD</p><p>通过两步实现：</p><ul><li><code>sdg_step</code>计算计算梯度对每个batch更新</li><li>外部循环迭代整个训练数据并且调整学习率</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numpy_sdg_step</span>(<span class="params">self, x, y, learning_rate</span>):</span></span><br><span class="line">    <span class="comment"># Calculate the gradients</span></span><br><span class="line">    dLdU, dLdV, dLdW = self.bptt(x, y)</span><br><span class="line">    <span class="comment"># Change parameters according to gradients and learning rate</span></span><br><span class="line">    self.U -= learning_rate * dLdU</span><br><span class="line">    self.V -= learning_rate * dLdV</span><br><span class="line">    self.W -= learning_rate * dLdW</span><br><span class="line"></span><br><span class="line">RNNNumpy.sgd_step = numpy_sdg_step</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Outer SGD Loop</span><br><span class="line"><span class="comment"># - model: The RNN model instance</span></span><br><span class="line"><span class="comment"># - X_train: The training data set</span></span><br><span class="line"><span class="comment"># - y_train: The training data labels</span></span><br><span class="line"><span class="comment"># - learning_rate: Initial learning rate for SGD</span></span><br><span class="line"><span class="comment"># - nepoch: Number of times to iterate through the complete dataset</span></span><br><span class="line"><span class="comment"># - evaluate_loss_after: Evaluate the loss after this many epochs</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_with_sgd</span>(<span class="params">model, X_train, y_train, learning_rate=<span class="number">0.005</span>, nepoch=<span class="number">100</span>, evaluate_loss_after=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="comment"># We keep track of the losses so we can plot them later</span></span><br><span class="line">    losses = []</span><br><span class="line">    num_examples_seen = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(nepoch):</span><br><span class="line">        <span class="comment"># Optionally evaluate the loss</span></span><br><span class="line">        <span class="keyword">if</span> (epoch % evaluate_loss_after == <span class="number">0</span>):</span><br><span class="line">            loss = model.calculate_loss(X_train, y_train)</span><br><span class="line">            losses.append((num_examples_seen, loss))</span><br><span class="line">            time = datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;%s: Loss after num_examples_seen=%d epoch=%d: %f&quot;</span> % (time, num_examples_seen, epoch, loss)</span><br><span class="line">            <span class="comment"># Adjust the learning rate if loss increases</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(losses) &gt; <span class="number">1</span> <span class="keyword">and</span> losses[-<span class="number">1</span>][<span class="number">1</span>] &gt; losses[-<span class="number">2</span>][<span class="number">1</span>]):</span><br><span class="line">                learning_rate = learning_rate * <span class="number">0.5</span></span><br><span class="line">                <span class="built_in">print</span> <span class="string">&quot;Setting learning rate to %f&quot;</span> % learning_rate</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">        <span class="comment"># For each training example...</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_train)):</span><br><span class="line">            <span class="comment"># One SGD step</span></span><br><span class="line">            model.sgd_step(X_train[i], y_train[i], learning_rate)</span><br><span class="line">            num_examples_seen += <span class="number">1</span></span><br></pre></td></tr></table></figure><p>完成。我们来测试一下训练耗费多长的时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">model = RNNNumpy(vocabulary_size)</span><br><span class="line">%timeit model.sgd_step(X_train[<span class="number">10</span>], y_train[<span class="number">10</span>], <span class="number">0.005</span>)</span><br></pre></td></tr></table></figure><p>可以看到在我的机器上需要SGD的每一步需要180ms，这代表整个训练将耗费数天甚至更多。我们可以通过许多的方法来加速这一过程，如改善代码和调整模型。这里我们希望使用GPU来加速。在这之前，我们先测试一下SGD的效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># Train on a small subset of the data to see what happens</span></span><br><span class="line">model = RNNNumpy(vocabulary_size)</span><br><span class="line">losses = train_with_sgd(model, X_train[:<span class="number">100</span>], y_train[:<span class="number">100</span>], nepoch=<span class="number">10</span>, evaluate_loss_after=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">16</span>:<span class="number">59</span>:<span class="number">46</span>: Loss after num_examples_seen=<span class="number">0</span> epoch=<span class="number">0</span>: <span class="number">8.987425</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">16</span>:<span class="number">59</span>:<span class="number">56</span>: Loss after num_examples_seen=<span class="number">100</span> epoch=<span class="number">1</span>: <span class="number">8.976270</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:06: Loss after num_examples_seen=<span class="number">200</span> epoch=<span class="number">2</span>: <span class="number">8.960212</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">16</span>: Loss after num_examples_seen=<span class="number">300</span> epoch=<span class="number">3</span>: <span class="number">8.930430</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">26</span>: Loss after num_examples_seen=<span class="number">400</span> epoch=<span class="number">4</span>: <span class="number">8.862264</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">37</span>: Loss after num_examples_seen=<span class="number">500</span> epoch=<span class="number">5</span>: <span class="number">6.913570</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">46</span>: Loss after num_examples_seen=<span class="number">600</span> epoch=<span class="number">6</span>: <span class="number">6.302493</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:<span class="number">00</span>:<span class="number">56</span>: Loss after num_examples_seen=<span class="number">700</span> epoch=<span class="number">7</span>: <span class="number">6.014995</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:01:06: Loss after num_examples_seen=<span class="number">800</span> epoch=<span class="number">8</span>: <span class="number">5.833877</span></span><br><span class="line"><span class="number">2016</span>-06-<span class="number">13</span> <span class="number">17</span>:01:<span class="number">16</span>: Loss after num_examples_seen=<span class="number">900</span> epoch=<span class="number">9</span>: <span class="number">5.710718</span></span><br></pre></td></tr></table></figure><p>看起来，SGD起到了效果。</p><p>##通过Theano和GPU训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">enp.random.seed(<span class="number">10</span>)</span><br><span class="line">model = RNNTheano(vocabulary_size)</span><br><span class="line">%timeit model.sgd_step(X_train[<span class="number">10</span>], y_train[<span class="number">10</span>], <span class="number">0.005</span>)</span><br></pre></td></tr></table></figure><p>这次一次SGD步骤耗费为73.7ms。</p><p>这里我们直接使用训练好的的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_model_parameters_theano, save_model_parameters_theano</span><br><span class="line"></span><br><span class="line">model = RNNTheano(vocabulary_size, hidden_dim=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># losses = train_with_sgd(model, X_train, y_train, nepoch=50)</span></span><br><span class="line"><span class="comment"># save_model_parameters_theano(&#x27;./data/trained-model-theano.npz&#x27;, model)</span></span><br><span class="line">load_model_parameters_theano(<span class="string">&#x27;./data/trained-model-theano.npz&#x27;</span>, model)</span><br></pre></td></tr></table></figure><p>###生成语句</p><p>使用如下生成语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_sentence</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="comment"># We start the sentence with the start token</span></span><br><span class="line">    new_sentence = [word_to_index[sentence_start_token]]</span><br><span class="line">    <span class="comment"># Repeat until we get an end token</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> new_sentence[-<span class="number">1</span>] == word_to_index[sentence_end_token]:</span><br><span class="line">        next_word_probs = model.forward_propagation(new_sentence)</span><br><span class="line">        sampled_word = word_to_index[unknown_token]</span><br><span class="line">        <span class="comment"># We don&#x27;t want to sample unknown words</span></span><br><span class="line">        <span class="keyword">while</span> sampled_word == word_to_index[unknown_token]:</span><br><span class="line">            samples = np.random.multinomial(<span class="number">1</span>, next_word_probs[-<span class="number">1</span>])</span><br><span class="line">            sampled_word = np.argmax(samples)</span><br><span class="line">        new_sentence.append(sampled_word)</span><br><span class="line">    sentence_str = [index_to_word[x] <span class="keyword">for</span> x <span class="keyword">in</span> new_sentence[<span class="number">1</span>:-<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">return</span> sentence_str</span><br><span class="line"></span><br><span class="line">num_sentences = <span class="number">10</span></span><br><span class="line">senten_min_length = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_sentences):</span><br><span class="line">    sent = []</span><br><span class="line">    <span class="comment"># We want long sentences, not sentences with one or two words</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(sent) &lt; senten_min_length:</span><br><span class="line">        sent = generate_sentence(model)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot; &quot;</span>.join(sent)</span><br></pre></td></tr></table></figure><p>得到结果为：</p><ul><li>no to blame their stuff go at all .</li><li>consider via under gear but equal every game .</li><li>no similar work on the ui birth a ce nightmare .</li><li>the challenging what is absolutely hard .</li><li>me do you research getting +2 .</li><li>ugh is much good , no .</li><li>me so many different lines hair .</li><li>probably not very a bot or gain .</li><li>correct this is affected so why ?</li><li>register but a grown gun environment .</li></ul><p>看起来还不错！不过还是有一些缺陷，这些都是由于vanilla RNN不能解决长期依赖问题导致的。下一篇我们将讨论BPTT并且关注梯度消失/爆炸问题。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/RNN/">RNN</category>
      
      
      <comments>http://example.com/2016/06/15/2016-06-15-recurrent-neural-networks-tutorial-part-2-implementing-a-rnn-with-python-numpy-and-theano/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ubuntu下修改DNS并且避免重启失效的方法</title>
      <link>http://example.com/2016/06/07/2016-06-07-edit-dns-of-ubuntu/</link>
      <guid>http://example.com/2016/06/07/2016-06-07-edit-dns-of-ubuntu/</guid>
      <pubDate>Tue, 07 Jun 2016 10:19:51 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;安装好Ubuntu之后设置了静态IP地址，再重启后就无法解析域名。想重新设置一下DNS，打开&lt;code&gt;/etc/resolv.conf&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class</description>
        
      
      
      
      <content:encoded><![CDATA[<p>安装好Ubuntu之后设置了静态IP地址，再重启后就无法解析域名。想重新设置一下DNS，打开<code>/etc/resolv.conf</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/resolv.conf</span><br><span class="line"># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)</span><br><span class="line"># DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN</span><br></pre></td></tr></table></figure><p>也就是说，这个文件是<code>resolvconf</code>程序动态创建的，不要直接手动编辑，修改将被覆盖。</p><p>试了试，重启果然失效了，若不解决每次重启都得修改DNS，那多麻烦啊！</p><p>还好找到如下办法：</p><ol><li>修改<code>/etc/resolvconf/resolv.conf.d/base</code>（这个文件默认是空的），在其内插入：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver 8.8.4.4</span><br></pre></td></tr></table></figure></li><li>保存后执行：<code>[sudo] resolvconf -u</code>,即可。</li></ol>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2016/06/07/2016-06-07-edit-dns-of-ubuntu/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RECURRENT NEURAL NETWORKS TUTORIAL, PART 1 – INTRODUCTION TO RNNS</title>
      <link>http://example.com/2016/06/06/2016-06-06-recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</link>
      <guid>http://example.com/2016/06/06/2016-06-06-recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</guid>
      <pubDate>Mon, 06 Jun 2016 11:18:44 GMT</pubDate>
      
      <description>&lt;p&gt;RNN，也即是递归神经网络，是许多NLP任务的流行处理模型。本部分中将简介RNN。&lt;/p&gt;
&lt;p&gt;本部分主要实现此模型–&lt;a href=&quot;http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf&quot;&gt; recurrent neural network based language model&lt;/a&gt;，模型有两个作用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可以基于出现的概率对句子进行打分，可以对于语法和语义正确性进行评估，从而应用于机器翻译等领域。&lt;/li&gt;
&lt;li&gt;可以依据概率生成新的语料。&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>RNN，也即是递归神经网络，是许多NLP任务的流行处理模型。本部分中将简介RNN。</p><p>本部分主要实现此模型–<a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf"> recurrent neural network based language model</a>，模型有两个作用：</p><ol><li>可以基于出现的概率对句子进行打分，可以对于语法和语义正确性进行评估，从而应用于机器翻译等领域。</li><li>可以依据概率生成新的语料。</li></ol><span id="more"></span><p>##什么是RNN</p><p>RNN背后的核心理念是利用序列的信息。传统的神经网络常常假设输入（输出）是独立于彼此的，这对于某些应用来说是不可行的，例如NLP任务，如果你需要预测下一个单词是什么，你不可能不用到之前的单词的信息。RNN之中的<strong>recurrent</strong>指的就是循环往复的意思，网络对于序列数据的每个元素进行同样的操作，网络的输出取决于之前的计算。另一种理解RNN的方法则是把它们看成是有记忆的网络，记忆收集从开始到现在被考虑的信息。理论上RNN可以利用任意时间长度的信息，但是实际上这比较困难。以下是RNN的典型结构：</p><p><img src="/images/2016/06/rnn.jpg" alt="A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature"></p><p>以上的结构将RNN展开成完整的网络。例如，我们需要处理一个5层的序列，那么就需要展开成5层：每层对应一个词。</p><ul><li>$$x_t$$是$$t$$时刻的输入</li><li>$$s_t$$是$$t$$时刻的隐藏状态，代表网络的“记忆”，计算公式为$$s_t = f(Ux_t + Ws_{t-1})$$，其中$$f$$通常是tanh函数或者RELU函数。</li><li>$$o_t$$是$$t$$时刻的输出，如果我们想预测下一个词，那么计算公式为$$o_t = softmax(Vs_t)$$，指的是在整个词表内词的概率值。</li></ul><p>对于以上有几点需要提示：</p><ul><li>我们可以把隐藏状态$$s_t$$看成是网络的“记忆”，其捕捉到在之前所有时间的信息。输出$$o_t$$只取决于在$$t$$时刻的记忆。而在实际上，由于长期依赖问题，$$s_t$$很难捕捉到很长时间以前的信息。</li><li>RNN每个step中的参数（$$U,V,W$$）是相同的，这使得学习的代价减小许多。</li><li>取决于实际任务，我们可能并不需要每个step都有输入和输出。</li></ul><p>##RNN的实际应用<br>以下是RNN在NLP领域的一些实际应用。</p><p>###语言模型与生成语句<br>在给定之前词语的情况下我们希望产生出下一个词语是什么。语言模型的作用就是让我们可以衡量一个句子的可能性，这对于机器翻译是很重要的（可能性越高的更可能正确）。而语言模型的另一个作用则是预测下一个词语是什么，我们可以通过在输出的概率词汇中采样得到，。对于语言模型，输入是一序列的词语（每一个词语都是one-hot表示），输出则是一序列的预测的词语。在训练时我们设置$$o_t = x_{t + 1}$$，因为这一时刻的输出就是下一时刻的输入。</p><p>关于语言模型与生成语句的论文：</p><ul><li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf">Recurrent neural network based language model</a></li><li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf">Extensions of Recurrent neural network based language model</a></li><li><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf">Generating Text with Recurrent Neural Networks</a></li></ul><p>###机器翻译</p><p>机器翻译类似于语言模型，其输入为需要翻译的句子，输出则是翻译的目标语言的句子。与语言模型不同的是，我们在输入整个句子之后才输出。</p><p><img src="/images/2016/06/Screen-Shot-2015-09-17-at-10.39.06-AM-1024x557.png"></p><p>关于机器翻译的论文：</p><ul><li><a href="http://www.aclweb.org/anthology/P14-1140.pdf">A Recursive Recurrent Neural Network for Statistical Machine Translation</a></li><li><a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">Sequence to Sequence Learning with Neural Networks</a></li><li><a href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf">Joint Language and Translation Modeling with Recurrent Neural Networks</a></li></ul><p>###语言识别</p><p>给予一段说话人语言的声音序列，我们预测出一序列的带有概率的语言成分的序列。</p><p>相关论文：</p><ul><li><a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a></li></ul><p>###生成图片描述</p><p>与CNN结合，RNN可以为无标签的图片生成描述，模型甚至可以排列好这些描述成更加类似人类语言的形式。</p><p><img src="/images/2016/06/Screen-Shot-2015-09-17-at-11.44.24-AM-1024x349.png" alt="Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/"></p><p>##训练RNN</p><p>训练RNN与典型的神经网络类似，值得注意的是Backpropagation Through Time (BPTT)，并且通过BPTT训练的vanilla RNN由于梯度弥散或者梯度爆炸，不能有效的解决长期依赖的问题。</p><p>##其他的一些RNN</p><p>针对vanilla RNN的一些缺陷，近年来许多RNN的变体涌现出来。</p><p><strong>双向RNN</strong>，主要输入不仅与过去的输入，并且与将来的输入有关的理念。例如我们需要预测一个句子中间缺失的词语。双向RNN的结构很简单，只是把两个RNN在顶部<br>结合，其输出取决于了两个RNN的隐藏状态。</p><p><img src="/images/2016/06/bidirectional-rnn-300x196.png"></p><p><strong>深度（双向）RNN</strong>，与双向RNN类似，只是每个step需要训练多层的网络，这使得模型更为强大（也需要更多的数据来训练）。</p><p><img src="/images/2016/06/Screen-Shot-2015-09-16-at-2.21.51-PM-272x300.png"></p><p><strong>LSTM网络</strong>，对RNN的隐藏层做了改进以解决长期依赖问题，是近来流行的RNN类型。LSTM可以通过gate决定网络需要记住和遗忘多长时间之前的记忆，以此联合之前的状态、记忆和输入。对于LSTM的详细知识可以见此：<a href="http://frankchen0130.github.io/2016/06/04/understanding-lstm-networks/">理解LSTM网络</a>。</p><p>##结论</p><p>到此我们对于RNN有了一个基本的认识，之后我们将对其进行代码的实现。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="http://example.com/tags/RNN/">RNN</category>
      
      
      <comments>http://example.com/2016/06/06/2016-06-06-recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>理解LSTM网络</title>
      <link>http://example.com/2016/06/04/2016-06-04-understanding-lstm-networks/</link>
      <guid>http://example.com/2016/06/04/2016-06-04-understanding-lstm-networks/</guid>
      <pubDate>Sat, 04 Jun 2016 09:16:15 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;Recurrent-Neural-Networks-RNN&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Networks-RNN&quot; class=&quot;headerlink&quot; title=&quot;Recurrent Neural Networks(RNN)&quot;&gt;&lt;/a&gt;Recurrent Neural Networks(RNN)&lt;/h2&gt;&lt;p&gt;人类是依靠自己过往的经验来学习，如同我们在读文章时，每一时刻，我们对于当前的概念的理解总要添加上对于之前获取的知识经验，总之，我们的思维是有持续性的。&lt;/p&gt;
&lt;p&gt;传统的神经网络模型无法做到这一点，而这也是它的主要缺陷之一。&lt;/p&gt;
&lt;p&gt;循环神经网络解决了这个难题，所谓循环，简单来说其结构允许信息在网络内留存，也即是，网络是有记忆的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/2016/06/RNN-rolled.png&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="Recurrent-Neural-Networks-RNN"><a href="#Recurrent-Neural-Networks-RNN" class="headerlink" title="Recurrent Neural Networks(RNN)"></a>Recurrent Neural Networks(RNN)</h2><p>人类是依靠自己过往的经验来学习，如同我们在读文章时，每一时刻，我们对于当前的概念的理解总要添加上对于之前获取的知识经验，总之，我们的思维是有持续性的。</p><p>传统的神经网络模型无法做到这一点，而这也是它的主要缺陷之一。</p><p>循环神经网络解决了这个难题，所谓循环，简单来说其结构允许信息在网络内留存，也即是，网络是有记忆的。</p><p><img src="/images/2016/06/RNN-rolled.png"></p><span id="more"></span><p>上图中，表示A表示神经网络的一块，在$$t$$时刻有输入$$X_t$$和输出$$h_t$$，这结构很简单，特别的是中间那一环，表示信息可以在网络内保存和传递。</p><p>以上的循环结构也可以拆解为下面的串列结构来理解：</p><p><img src="/images/2016/06/RNN-unrolled.png"></p><p>我们可以把一个网络块的循环看成是多个相同的网络之间信息的传递，而这样的结构也就意味着，RNN天生就适合处理与序列相关的数据，如时间序列、NLP中的语言模型、音乐等。</p><p>近年来RNN的成功应用是与LSTM划不开联系的。接下来就给大家介绍LSTM网络。</p><p>##长期依赖问题</p><p>RNN能够利用之前的信息来帮助当前的处理，这是我们对于RNN的期待。但是RNN能够做到这一点是有条件的：需要解决<strong>长期依赖问题</strong>。</p><p>举个例子，例如我们需要预测如下句子中的最后一个单词：“the clouds are in the sky”，因为有关的信息与其被需要的位置的距离不远，所以RNN可以轻易解决这个问题。</p><p><img src="/images/2016/06/RNN-shorttermdepdencies.png"></p><p>但是当预测需要更早的信息的时候呢？例如“I grew up in France… I speak fluent French.” 这时候有关的信息与其被需要的位置的距离可能很远。而此时，RNN变得很难处理这个问题。</p><p><img src="/images/2016/06/RNN-longtermdependencies.png"></p><p>理论上，RNN应该可以解决这类“长期依赖问题”，但是实际上却无法做到。<br>幸运的是，LSTM可以解决这个问题！</p><h2 id="LSTM-网络"><a href="#LSTM-网络" class="headerlink" title="LSTM 网络"></a>LSTM 网络</h2><p>Long Short Term Memory networks，简称为LSTM，是一种可以学习长期依赖的RNN。那么，LSTM为何具有这种能力呢？</p><p>我们先来看看标准的RNN形式：</p><p><img src="/images/2016/06/LSTM3-SimpleRNN.png"></p><p>形式很简单，tanh层接受当前时刻的输入$$X_t$$以及上一时刻传来的记忆信息，输出$$h_t$$及记忆信息。</p><p>而LSTM在标准的RNN形式下，网络增加到了四层。</p><p><img src="/images/2016/06/LSTM3-chain.png"></p><p>此图中，黄色的框格代表神经网络层，粉红色的圆圈代表逐点运算，例如向量相加或者相乘，单条黑色的线代表向量的传输，合并的黑色的线代表向量的连接，分叉的黑色线代表向量的复制（同一向量传送到不同的方向）。</p><p>##LSTM网络核心理念</p><p>LSTM的核心就是网络内上面的那条水平线，称为cell state $$C_t$$，类似于传送带的功能，它在整个网络内直线传送，只做一些线性的变动，它代表着的是RNN中不变的信息。</p><p><img src="/images/2016/06/LSTM3-C-line.png"></p><p>LSTM具有对cell state进行增减信息的功能，是靠如下的部件–gate完成的。</p><p><img src="/images/2016/06/LSTM3-gate.png"></p><p>gate由一个sigmoid层和逐点乘操作构成，我们都知道sigmoid函数输出的是一个介于0和1之间的数，那么gate的作用就显而易见了：<strong>通过sigmoid层的输入决定gate的输入有多少能被输入。</strong>而LSTM具有三个gate，都是为了保持和控制cell state。</p><h2 id="分步理解LSTM"><a href="#分步理解LSTM" class="headerlink" title="分步理解LSTM"></a>分步理解LSTM</h2><p>LSTM结构的第一步是决定我们应该把多少信息从cell state里面丢弃。这是有一个叫做“forget gate”的部分完成的。其接收$$h_{t-1}$$和$$x_t$$，输出一个0和1之间的数，再与上一时刻的cell state$$C_{t-1}$$做逐点乘。</p><p><img src="/images/2016/06/LSTM3-focus-f.png"></p><p>下一步则是决定把多少的新信息存储在cell state里面。首先，一个称为“input gate layer”的sigmoid层决定要更新的信息的多少，接下来一个tanh层产生一个称为$$\tilde{C}_t$$的向量，它代表了新的状态值，最后我们整合以上两者，添加到cell state里面去。</p><p><img src="/images/2016/06/LSTM3-focus-i.png"></p><p>决定了要忘记多少信息并添加多少新信息之后，我们就实际来执行这一步：</p><p><img src="/images/2016/06/LSTM3-focus-C.png"></p><p>最后，我们还需要决定输出的内容。输出主要来自于cell state，但是还是要通过一个tanh层并由sigmoid层决定输出多少。</p><p><img src="/images/2016/06/LSTM3-focus-o.png"></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/note/">note</category>
      
      
      <category domain="http://example.com/tags/RNN/">RNN</category>
      
      <category domain="http://example.com/tags/LSTM/">LSTM</category>
      
      
      <comments>http://example.com/2016/06/04/2016-06-04-understanding-lstm-networks/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Rephil和MapReduce： 描述长尾数据的数学模型</title>
      <link>http://example.com/2016/06/04/2016-06-04-rephil-and-mapreduce/</link>
      <guid>http://example.com/2016/06/04/2016-06-04-rephil-and-mapreduce/</guid>
      <pubDate>Sat, 04 Jun 2016 07:02:32 GMT</pubDate>
      
      <description>&lt;p&gt;Google Rephil是Google AdSense背后广告相关性计算的头号秘密武器。但是这个系统没有发表过论文。只是其作者（博士Uri Lerner和工程师Mike Yar）在2002年在湾区举办的几次小规模交流中简要介绍过。所以Kevin Murphy把这些内容写进了他的书《Machine Learning: a Probabilitic Perspecitve》里。在吴军博士的《数学之美》里也提到了Rephil。&lt;/p&gt;
&lt;p&gt;Rephil的模型是一个全新的模型，更像一个神经元网络。这个网络的学习过程从Web scale的文本数据中归纳海量的语义——比如“apple”这个词有多个意思：一个公司的名字、一种水果、以及其他。当一个网页里包含”apple”, “stock”, “ipad”等词汇的时候，Rephil可以告诉我们这个网页是关于apple这个公司的，而不是水果。&lt;/p&gt;
&lt;p&gt;这个功能按说pLSA和LDA也都能实现。为什么需要一个全新的模型呢？ 从2007年至今，国内外很多团队都尝试过并行化pLSA和LDA。心灵手巧的工程师们，成功的开发出能学习数万甚至上十万语义（latent topics）的训练系统。但是不管大家用什么训练数据，都会发现，得到的大部分语义（相关的词的聚类）都是非常类似，或者说“重复”的。如果做一个“去重”处理，几万甚至十万的语义，就只剩下几百几千了。&lt;/p&gt;
&lt;p&gt;这是怎么回事？&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Google Rephil是Google AdSense背后广告相关性计算的头号秘密武器。但是这个系统没有发表过论文。只是其作者（博士Uri Lerner和工程师Mike Yar）在2002年在湾区举办的几次小规模交流中简要介绍过。所以Kevin Murphy把这些内容写进了他的书《Machine Learning: a Probabilitic Perspecitve》里。在吴军博士的《数学之美》里也提到了Rephil。</p><p>Rephil的模型是一个全新的模型，更像一个神经元网络。这个网络的学习过程从Web scale的文本数据中归纳海量的语义——比如“apple”这个词有多个意思：一个公司的名字、一种水果、以及其他。当一个网页里包含”apple”, “stock”, “ipad”等词汇的时候，Rephil可以告诉我们这个网页是关于apple这个公司的，而不是水果。</p><p>这个功能按说pLSA和LDA也都能实现。为什么需要一个全新的模型呢？ 从2007年至今，国内外很多团队都尝试过并行化pLSA和LDA。心灵手巧的工程师们，成功的开发出能学习数万甚至上十万语义（latent topics）的训练系统。但是不管大家用什么训练数据，都会发现，得到的大部分语义（相关的词的聚类）都是非常类似，或者说“重复”的。如果做一个“去重”处理，几万甚至十万的语义，就只剩下几百几千了。</p><p>这是怎么回事？</p><span id="more"></span><p>如果大家尝试着把训练语料中的低频词去掉，会发现训练得到的语义和用全量数据训练得到的差不多。换句话说，pLSA和LDA模型的训练算法没有在意低频数据。</p><p>为什么会这样呢？因为pLSA和LDA这类概率模型的主要构造单元都是指数族分布（exponential family）。比如pLSA假设一个文档中的语义的分布是multinomial的，每个语义中的词的分布也是multinomial的。因为multinomial是一种典型的指数族分布，这样整个模型描述的海量数据的分布，不管哪个维度上的marginalization，都是指数族分布。在LDA中也类似——因为LDA假设各个文档中的语义分布的multinomial distributions的参数是符合Dirichlet分布的，并且各个语义中的词的分布的multinomial distributions的参数也是符合Dirichlet分布的，这样整个模型是假设数据是指数族分布的。</p><p>可是Internet上的实际数据基本都不是指数族分布的——而是长尾分布的。至于为什么是这样？可以参见2006年纽约时报排名畅销书The Long Tail: Why the Future of Business is Selling Less of More。或者看看其作者Chris Anderson的博客<a href="http://www.thelongtail.com/">The Long Tail</a>。</p><p>长尾分布的形状大致如下图所示：</p><p><img src="/images/2016/06/conceptual.jpg"></p><p>其中x轴表示数据的类型，y轴是各种类型的频率，少数类型的频率很高（称为大头，图中红色部分），大部分很低，但是大于0（称为长尾，图中黄色部分）。一个典型的例子是文章中词的分布，有个具体的名字Zipf’s law，就是典型的长尾分布。而指数族分布基本就只有大头部分——换句话说，如果我们假设长尾数据是指数族分布的，我们实际上就把尾巴给割掉了。</p><p>割掉数据的尾巴——这就是pLSA和LDA这样的模型做的——那条长尾巴覆盖的多种多样的数据类型，就是Internet上的人生百态。理解这样的百态是很重要的。比如百度和Google为什么能如此赚钱？因为互联网广告收益。传统广告行业，只有有钱的大企业才有财力联系广告代理公司，一帮西装革履的高富帅聚在一起讨论，竞争电视或者纸媒体上的广告机会。互联网广告里，任何人都可以登录到一个网站上去投放广告，即使每日广告预算只有几十块人民币。这样一来，刘备这样织席贩屡的小业主，也能推销自己做的席子和鞋子。而搜索引擎用户的兴趣也是百花齐放的——从人人爱戴的陈老师苍老师到各种小众需求包括“红酒木瓜汤”（一种丰胸秘方，应该出丰胸广告）或者“苹果大尺度”（在搜索范冰冰主演的《苹果》电影呢）。把各种需求和各种广告通过智能技术匹配起来，就酝酿了互联网广告的革命性力量。这其中，理解各种小众需求、长尾意图就非常重要了。</p><p>实际上，Rephil就是这样一个能理解百态的模型。因为它把Google AdSense的盈利能力大幅提升，最终达到Google收入的一半。两位作者荣获Google的多次大奖，包括Founders’ Award。</p><p>而切掉长尾是一个很糟糕的做法。大家还记得小说《1984》里有这样一个情节吗？老大哥要求发布“新话”——一种新的语言，删掉自然英语中大部分词汇，只留下那些主流的词汇。看看小说里的人们生活的世界，让人浑身发毛，咱们就能体会“割尾巴”的恶果了。没有看过《1984》的朋友可以想象一下水木首页上只有“全站十大”，连“分类十大”都删掉之后的样子。</p><p>既然如此，为什么这类模型还要假设数据是指数族分布的呢？——实在是不得已。指数族分布是一种数值计算上非常方便的数学元素。拿LDA来说，它利用了Dirichlet和multinomial两种分布的共轭性，使得其计算过程中，模型的参数都被积分给积掉了（integrated out）。这是AD-LDA这样的ad hoc并行算法——在其他模型上都不好使的做法——在LDA上好用的原因之一。换句话说，这是为了计算方便，掩耳盗铃地假设数据是指数族分布的。</p><p>实际上，这种掩耳盗铃在机器学习领域很普遍。比如有个兄弟听了上面的故事后说：“那我们就别用概率模型做语义分析了，咱们还用矩阵分解吧？SVD分解怎么样？” 很不好意思的，当我们把SVD分解用在语义分析（称为LSA，latent semantic analysis）上的时候，我们还是引入了指数族分布假设——Gaussian assumption或者叫normality assumption。这怎么可能呢？SVD不就是个矩阵分解方法吗？确实传统SVD没有对数据分布的假设，但是当我们用EM之类的算法解决存在missing data的问题——比如LSA，还有推荐系统里的协同过滤（collaborative filtering）——这时不仅引入了Gaussian assumption，而且引入了linearity assumption。当我们用其他很多矩阵分解方法做，都存在同样的问题。</p><p>掩耳盗铃的做法怎么能存在得如此自然呢？这是因为指数族分布假设（尤其是Gaussian assumption）有过很多成功的应用，包括通信、数据压缩、制导系统等。这些应用里，我们关注的就是数据中的低频部分；而高频部分（或者说距离mean比较远的数据）即使丢掉了，电话里的声音也能听懂，压缩还原的图像也看得明白，导弹也还是能沿着“最可能”靠谱的路线飞行。我们当然会假设数据是指数族分布的，这样不仅省计算开销，而且自然的忽略高频数据，我们还鄙夷地称之为outlier或者noise。</p><p>可是在互联网的世界里，正是这些五花八门的outliers和noise，蕴含了世间百态，让数据不可压缩，从而产生了“大数据”这么个概念。处理好大数据的公司，赚得盆满钵满，塑造了一个个传奇。这里有一个听起来比较极端的说法大数据里无噪声——很多一开始频率很低，相当长尾，会被词过滤系统认为是拼写错误的queries，都能后来居上成为主流。比如“神马”，“酱紫”。</p><p>Rephil系统实现的模型是一个神经元网络模型（neural network）。它的设计的主要考虑，就是要能尽量好的描述长尾分布的文本数据和其中蕴含的语义。Rephil模型的具体技术细节因为没有在论文中发表过，所以不便在这里透露。但是Rephil模型描述长尾数据的能力，是下文将要介绍的Peacock系统的原动力，虽然两者在模型上完全不同。</p><p>Rephil系统是基于Google MapReduce构建的。如上节所述，MapReduce在用来实现迭代算法的时候，效率是比较低的。这也是Peacock要设计全新框架的原动力——使其比MapReduce高效，但同时像MapReduce一样支持fault recovery。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/note/">note</category>
      
      
      <category domain="http://example.com/tags/LDA/">LDA</category>
      
      
      <comments>http://example.com/2016/06/04/2016-06-04-rephil-and-mapreduce/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>note for CS224d:1</title>
      <link>http://example.com/2016/06/04/2016-06-04-note-for-cs224d-1/</link>
      <guid>http://example.com/2016/06/04/2016-06-04-note-for-cs224d-1/</guid>
      <pubDate>Sat, 04 Jun 2016 06:51:38 GMT</pubDate>
      
      <description>&lt;p&gt;最近学习了斯坦福的&lt;a href=&quot;http://cs224d.stanford.edu/syllabus.html&quot;&gt;CS224d&lt;/a&gt;课程，该课 程的主要内容是神经网络在自然语言处理领域的应用。 这里记录相关的学习笔记，大概分 成以下几个部分：word2vec，窗口分类，神经网络，循环神经网络，递归神经网络，卷积 神经网络。&lt;/p&gt;
&lt;p&gt;##为什么需要深度学习&lt;/p&gt;
&lt;p&gt;传统的机器学习方法都是人为的设计特征或者表示，深度学习的目的是希望能够通过神经网络让机器自动学习到有效的特征表示，这里所说的深度学习更偏向于关注各种类型的神经网络。探索机器学习的原因主要有以下几方面：&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>最近学习了斯坦福的<a href="http://cs224d.stanford.edu/syllabus.html">CS224d</a>课程，该课 程的主要内容是神经网络在自然语言处理领域的应用。 这里记录相关的学习笔记，大概分 成以下几个部分：word2vec，窗口分类，神经网络，循环神经网络，递归神经网络，卷积 神经网络。</p><p>##为什么需要深度学习</p><p>传统的机器学习方法都是人为的设计特征或者表示，深度学习的目的是希望能够通过神经网络让机器自动学习到有效的特征表示，这里所说的深度学习更偏向于关注各种类型的神经网络。探索机器学习的原因主要有以下几方面：</p><span id="more"></span><ul><li>人工设计的特征常常定义过多，不完整并且需要花费大量的时间去设计和验证</li><li>自动学习的特征容易自适应，并且可以很快的学习</li><li>深度学习提供了一个弹性的，通用的学习框架用来表征自然的，视觉的和语言的信息。</li><li>深度学习可以用来学习非监督的（来自于生文本）和有监督的（带有特别标记的文本，例如正向和负向标记）</li></ul><p>在2006年深度学习技术开始在一些任务中表现出众，为什么现在才热起来？</p><ul><li>深度学习技术受益于越来越多的数据</li><li>更快的机器与更多核CPU/GPU对深度学习的普及起了很大的促进作用</li><li>新的模型，算法和idea层出不穷</li><li>通过深度学习技术提升效果首先发生在语音识别和机器视觉领域，然后开始过渡到NLP领域</li></ul><p>深度学习在所有的NLP层次（音素、形态学、句法、语义）都得到了应用，而所有的NLP层次的表示都涉及到向量（Vectors），下面主要讲如何用向量来表示词。</p><p>##词向量</p><p>###语义词典</p><p>我们要如何表示一个词的意思呢？常识上，在词典中我们通过更加简单常用的词来构成例句来解释一个词的意思。那在计算机中，我们通常使用<a href="http://wordnet.princeton.edu/">Wordnet</a>来表示词义：</p><p>![](/images/2016/06/Screenshot from 2016-06-01 20-44-21.png)</p><p>但语义词典存在如下问题：</p><ul><li>语义词典资源很棒但是可能在一些细微之处有缺失，例如这些同义词准确吗：adept, expert, good, practiced, proficient,skillful?</li><li>会错过一些新词，几乎不可能做到及时更新: wicked, badass, nifty, crack, ace, wizard, genius, ninjia</li><li>有一定的主观倾向</li><li>需要大量的人力物力</li><li>很难用来计算两个词语的相似度</li></ul><p>###One-hot Representation<br>首先我们把词表中的词从$$0到|V|−1$$进行编号，ont-hot向量把每个词表示成一个$$|V|$$维 （词表大小为$$|V|$$）的向量，该向量只有特定词的编号对应的位置为1，其他位置全部为0 。这种方法把每个词表示成独立的个体，无法通过one-hot向量直接表示出词之间的关系。解决方法是通过一个词的上下文来表示一个词。 例如,比如</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/note/">note</category>
      
      
      <category domain="http://example.com/tags/NLP/">NLP</category>
      
      <category domain="http://example.com/tags/Deep-Learning/">Deep Learning</category>
      
      
      <comments>http://example.com/2016/06/04/2016-06-04-note-for-cs224d-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>char-rnn-chinese</title>
      <link>http://example.com/2016/05/26/2016-05-26-char-rnn-chinese/</link>
      <guid>http://example.com/2016/05/26/2016-05-26-char-rnn-chinese/</guid>
      <pubDate>Thu, 26 May 2016 07:37:32 GMT</pubDate>
      
      <description>&lt;p&gt;本文主要根据&lt;a href=&quot;https://github.com/zhangzibin/char-rnn-chinese&quot;&gt;Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch&lt;/a&gt;的内容来进行试验。&lt;/p&gt;
&lt;p&gt;#准备工作&lt;/p&gt;
&lt;p&gt;根据原文“This code is written in Lua and requires Torch. Additionally, you need to install the nngraph and optim packages using LuaRocks”，安装以下依赖。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>本文主要根据<a href="https://github.com/zhangzibin/char-rnn-chinese">Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch</a>的内容来进行试验。</p><p>#准备工作</p><p>根据原文“This code is written in Lua and requires Torch. Additionally, you need to install the nngraph and optim packages using LuaRocks”，安装以下依赖。</p><span id="more"></span><p>##安装Torch</p><p>使用如下的命令安装Torch</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd ~/</span><br><span class="line">curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash</span><br><span class="line">git clone https://github.com/torch/distro.git ~/torch --recursive</span><br><span class="line">cd ~/torch; ./install.sh</span><br></pre></td></tr></table></figure><p>再用如下命令更新：<br><code>source ~/.bashrc</code></p><p>出现如下画面，代表Torch已经装好！</p><p>![](/images/2016/05/Screenshot from 2016-05-26 19-51-17.png)</p><p>##安装lua<br><code>sudo apt-get install lua5.2</code></p><p>##安装其他依赖</p><p>使用<code>LuaRocks</code>来安装<code>nngraph</code>和<code>optim</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">luarocks install nngraph</span><br><span class="line">luarocks install optim</span><br></pre></td></tr></table></figure><p>首先安装<a href="https://luarocks.org/"><code>LuaRocks</code></a><br>安装时在<code>config</code>部分遇到问题，参考<a href="https://segmentfault.com/a/1190000003920034">安装Luarocks</a>和<a href="http://www.2cto.com/os/201506/412629.html">linux下lua开发环境安装</a><br>这时可能遇到安装了<code>lua</code>但是却提示无法找到<code>lua.h</code>可能是因为还需要安装<code>liblua5.1-0-dev</code>的缘故。<br><del>使用<code>apt-get</code>安装luarocks后在安装<code>nngraph</code>时报错，需要解决</del></p><p>==其实使用<code>torch</code>内自带的<code>luarocks</code>安装即可==：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ~/torch/install/bin/luarocks install</span><br></pre></td></tr></table></figure><p>因为本机只有英特尔核显，所以只打算用CPU计算，就不安装<code>CUDA</code>了。</p><p>#开始实验</p><h2 id="karpathy的example实验-cpu版本"><a href="#karpathy的example实验-cpu版本" class="headerlink" title="karpathy的example实验-cpu版本"></a>karpathy的example实验-cpu版本</h2><p>###training过程</p><p>使用<code>th train.lua --help</code>查看一下各参数的作用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Options</span><br><span class="line">  -data_dir                  data directory. Should contain the file input.txt with input data [data/tinyshakespeare] 训练语料</span><br><span class="line">  -min_freq                  min frequent of character [0]</span><br><span class="line">  -rnn_size                  size of LSTM internal state [128]</span><br><span class="line">  -num_layers                number of layers in the LSTM [2]</span><br><span class="line">  -model                     for now only lstm is supported. keep fixed [lstm]</span><br><span class="line">  -learning_rate             learning rate [0.002]</span><br><span class="line">  -learning_rate_decay       learning rate decay [0.97]</span><br><span class="line">  -learning_rate_decay_after in number of epochs, when to start decaying the learning rate [10]</span><br><span class="line">  -decay_rate                decay rate for rmsprop [0.95]</span><br><span class="line">  -dropout                   dropout for regularization, used after each RNN hidden layer. 0 = no dropout [0]</span><br><span class="line">  -seq_length                number of timesteps to unroll for [50]</span><br><span class="line">  -batch_size                number of sequences to train on in parallel [50]</span><br><span class="line">  -max_epochs                number of full passes through the training data [50]</span><br><span class="line">  -grad_clip                 clip gradients at this value [5]</span><br><span class="line">  -train_frac                fraction of data that goes into train set [0.95]</span><br><span class="line">  -val_frac                  fraction of data that goes into validation set [0.05]</span><br><span class="line">  -init_from                 initialize network parameters from checkpoint at this path []</span><br><span class="line">  -seed                      torch manual random number generator seed [123]</span><br><span class="line">  -print_every               how many steps/minibatches between printing out the loss [1]</span><br><span class="line">  -eval_val_every            every how many iterations should we evaluate on validation data? [2000]</span><br><span class="line">  -checkpoint_dir            output directory where checkpoints get written [cv]</span><br><span class="line">  -savefile                  filename to autosave the checkpont to. Will be inside checkpoint_dir/ [lstm]</span><br><span class="line">  -accurate_gpu_timing       set this flag to 1 to get precise timings when using GPU. Might make code bit slower but reports accurate timings. [0]</span><br><span class="line">  -gpuid                     which gpu to use. -1 = use CPU [0]</span><br><span class="line">  -opencl                    use OpenCL (instead of CUDA) [0]</span><br><span class="line">  -use_ss                    whether use scheduled sampling during training [1]</span><br><span class="line">  -start_ss                  start amount of truth data to be given to the model when using ss [1]</span><br><span class="line">  -decay_ss                  ss amount decay rate of each epoch [0.005]</span><br><span class="line">  -min_ss                    minimum amount of truth data to be given to the model when using ss [0.9]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>按照Github上的说明进行实验，使用原文件夹里的语料，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">th train.lua -data_dir data/tinyshakespeare/shakespeare_input.txt -gpuid -1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> th train.lua -data_dir data/tinyshakespeare/shakespeare_input.txt -gpuid -1</span><br><span class="line">vocab.t7 and data.t7 do not exist. Running preprocessing...</span><br><span class="line">one-time setup: preprocessing input text file data/tinyshakespeare/shakespeare_input.txt/input.txt...</span><br><span class="line">loading text file...</span><br><span class="line">/home/frank/torch/install/bin/luajit: cannot open &lt;data/tinyshakespeare/shakespeare_input.txt/input.txt&gt; in mode r  at /home/frank/torch/pkg/torch/lib/TH/THDiskFile.c:649</span><br><span class="line">stack traceback:</span><br><span class="line">[C]: at 0x7f9c42473540</span><br><span class="line">[C]: in function &#x27;DiskFile&#x27;</span><br><span class="line">./util/CharSplitLMMinibatchLoader.lua:201: in function &#x27;text_to_tensor&#x27;</span><br><span class="line">./util/CharSplitLMMinibatchLoader.lua:38: in function &#x27;create&#x27;</span><br><span class="line">train.lua:118: in main chunk</span><br><span class="line">[C]: in function &#x27;dofile&#x27;</span><br><span class="line">...rank/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk</span><br><span class="line">[C]: at 0x00405d70</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里出现了问题，因为本文是中国作者按照原<a href="https://github.com/karpathy/char-rnn">karpathy的char-rnn</a>改写的，我认为或许使用karpathy作者的原版本教程可能会更加方便一些。于是使用<em>As a sanity check</em>，运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">th train.lua -gpuid -1</span><br></pre></td></tr></table></figure><p>这指的是使用CPU并不指定任何参数来训练example。</p><p>15:42开始训练</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> th train.lua -gpuid -1</span><br><span class="line">loading data files...</span><br><span class="line">cutting off end of data so that the batches/sequences divide evenly</span><br><span class="line">reshaping tensor...</span><br><span class="line">data load done. Number of data batches in train: 423, val: 23, test: 0</span><br><span class="line">vocab size: 65</span><br><span class="line">creating an LSTM with 2 layers</span><br><span class="line">setting forget gate biases to 1 in LSTM layer 1</span><br><span class="line">setting forget gate biases to 1 in LSTM layer 2</span><br><span class="line">number of parameters in the model: 240321</span><br><span class="line">cloning rnn</span><br><span class="line">cloning criterion</span><br><span class="line">1/21150 (epoch 0.002), train_loss = 4.19803724, grad/param norm = 5.1721e-01, time/batch = 2.3129s</span><br><span class="line">2/21150 (epoch 0.005), train_loss = 3.93712133, grad/param norm = 1.4679e+00, time/batch = 2.3114s</span><br><span class="line">3/21150 (epoch 0.007), train_loss = 3.43764434, grad/param norm = 9.5800e-01, time/batch = 2.3022s</span><br><span class="line">4/21150 (epoch 0.009), train_loss = 3.41313742, grad/param norm = 7.5143e-01, time/batch = 2.5311s</span><br><span class="line">5/21150 (epoch 0.012), train_loss = 3.33707270, grad/param norm = 6.9269e-01, time/batch = 2.4913s</span><br></pre></td></tr></table></figure><p>到第300次迭代后，<code>time/batch</code>稳定在2.3s左右，也就是说，使用GPU训练这个1Mb的example，需要约14小时！<br>次日08:24训练完毕</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">21148/21150 (epoch 49.995), train_loss = 1.53254314, grad/param norm = 5.9157e-02, time/batch = 2.8658s</span><br><span class="line">21149/21150 (epoch 49.998), train_loss = 1.50882624, grad/param norm = 5.7123e-02, time/batch = 2.8737s</span><br><span class="line">decayed learning rate by a factor 0.97 to 0.00057368183755432</span><br><span class="line">evaluating loss over split index 2</span><br><span class="line">saving checkpoint to cv/lm_lstm_epoch50.00_1.3568.t7</span><br><span class="line">21150/21150 (epoch 50.000), train_loss = 1.46142484, grad/param norm = 5.9032e-02, time/batch = 2.8834s</span><br></pre></td></tr></table></figure><p>###Sample过程<br>查看<code>help</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">th sample.lua --help</span><br><span class="line">Usage: /home/frank/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th [options] &lt;model&gt;</span><br><span class="line"></span><br><span class="line">Sample from a character-level language model</span><br><span class="line"></span><br><span class="line">Options</span><br><span class="line">  &lt;model&gt;      model checkpoint to use for sampling</span><br><span class="line">  -seed        random number generator&#x27;s seed [123]</span><br><span class="line">  -sample       0 to use max at each timestep, 1 to sample at each timestep [1]</span><br><span class="line">  -primetext   used as a prompt to &quot;seed&quot; the state of the LSTM using a given sequence, before we sample. []</span><br><span class="line">  -length      max number of characters to sample [2000] 采样字符大小，最大2000</span><br><span class="line">  -temperature temperature of sampling [1]</span><br><span class="line">  -gpuid       which gpu to use. -1 = use CPU [0] 和训练时设置应该保持一致</span><br><span class="line">  -verbose     set to 0 to ONLY print the sampled text, no diagnostics [1]</span><br><span class="line">  -stop        stop sampling when detected [</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>先试运行一下<br><code>th sample.lua cv/lm_lstm_epoch50.00_1.3568.t7 -gpuid -1 </code><br>生成了如下语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">giff,</span><br><span class="line">Some sweet amends, aasher, had therein, not he had wot on</span><br><span class="line">man&#x27;s friends, for her own blow: for my men&#x27;s</span><br><span class="line">ackingly knight, it cannot hear upon yield.</span><br><span class="line"></span><br><span class="line">GLOUCESTER:</span><br><span class="line">How now again?</span><br><span class="line">i</span><br><span class="line">March, that&#x27;s my arm determitness,</span><br><span class="line">The temper of the vrowal; ere from the grove</span><br><span class="line">Tut wilh &#x27;goom&#x27;d Carulea.</span><br><span class="line">&#x27;Mwailich, tne shy had lost in When Ied the way</span><br><span class="line">The bower to a late his body, grim on you:</span><br><span class="line">His opicious shames a booy, infairs,&#x27;</span><br><span class="line">From her, I tell you, ay, as we mean him</span><br><span class="line">Dear &#x27;tis a giving o&#x27; thur back&#x27;s empass&#x27;d,</span><br><span class="line">That nrost, I&#x27;ll havk him cume thee for &#x27;t.</span><br><span class="line"></span><br><span class="line">LAONTES:</span><br><span class="line">&#x27;Twi&#x27;l love thy sronowing.</span><br><span class="line"></span><br><span class="line">VALYRAN:</span><br><span class="line">Beord mocdoch him for thy follight</span><br><span class="line">snn</span><br><span class="line">hours,</span><br><span class="line">But thank yours lodkes, my good journeding,</span><br><span class="line">His jealousisposour thee are both abomish</span><br><span class="line">That noom that&#x27;s easembelland. Camest, sir, more</span><br><span class="line">kia; one, in this highty be the un</span><br><span class="line">Since of a gournor on thy friendshall swow</span><br><span class="line">Some painon; and I, and lord, the  at the kins</span><br><span class="line">Wise rit hable surliments. Shd, believh gone.</span><br><span class="line"></span><br><span class="line">voisted tleace:</span><br><span class="line">Tock him what all you di turn up to celent</span><br><span class="line">To my sistinge. Frranch, good night, your child, so fatus;</span><br><span class="line">Aor he shall be my trueking:</span><br><span class="line">Come on my quarrel of the way:</span><br><span class="line">Methinks the letters; for this ctome-steers</span><br><span class="line">Tad mousd my smodered pouncy to</span><br><span class="line">haw up another sense tlays underttry</span><br><span class="line">Tut bonscuration fair all purpose,</span><br><span class="line">then be vesegt me: do not, yet rustle cannot,</span><br><span class="line">But for thy mustered a dust, let me</span><br><span class="line">Tncerfact me tresmer of his father:</span><br><span class="line">therefore by hanging,</span><br><span class="line">ANd</span><br><span class="line">Ays, my lord: you do here in coumisant.</span><br><span class="line"></span><br><span class="line">LORD:</span><br><span class="line">How lond the brown!</span><br><span class="line">So majp me; bonch, smmily  lovely blotters,</span><br><span class="line">When Ie my hoeaty threat and virlume these things,</span><br><span class="line">Make fasting garlands dfar the sack&#x27;d my servictught</span><br><span class="line">Not knows the crowns: one air, Aumerle,</span><br><span class="line">Ere wear not so nour Bidagle? What Aphark is fury</span><br><span class="line">Tld meens them, faireyou consides to no more</span><br><span class="line">Ihis wantond frown and pollitueser&#x27;d city.</span><br><span class="line">Can should put him more recounders to impudesnt poison on</span><br><span class="line">thet hour from hunt to Rame, supp to bere</span><br><span class="line">Flowerd and his friend is une dewn ao pirt,</span><br><span class="line">You know by join&#x27;d guilty, whathout we e.</span><br><span class="line"></span><br><span class="line">ANd</span><br><span class="line">Ays, my lord: you do here in coumisant.</span><br><span class="line"></span><br><span class="line">LORD:</span><br><span class="line">How lond the brown!</span><br><span class="line">So majp me; bonch, smmily  lovely blotters,</span><br><span class="line">When Ie my hoeaty threat and virlume these things,</span><br><span class="line">Make fasting garlands dfar the sack&#x27;d my servictught</span><br><span class="line">Not knows the crowns: one air, Aumerle,</span><br><span class="line">Ere wear not so nour Bidagle? What Aphark is fury</span><br><span class="line">Tld meens them, faire</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="karpathy的example实验-gpu版本"><a href="#karpathy的example实验-gpu版本" class="headerlink" title="karpathy的example实验-gpu版本"></a>karpathy的example实验-gpu版本</h2><p>使用和cpu版本相同的指令，只是<code>th train.lua -gpuid 0</code><br>得到的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">th sample.lua cv/lm_lstm_epoch50.00_1.3622.t7 -gpuid 0</span><br></pre></td></tr></table></figure><p>sample为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">--------------------------</span><br><span class="line">ge</span><br><span class="line">I prithee; nor in the day of all report?</span><br><span class="line">Nou shall be you that lances stoson quarrel:</span><br><span class="line">We mits most stone, &#x27;aim, upeed his forticent</span><br><span class="line">Ahen I was, yet for her, but of lovels Clarencel</span><br><span class="line">And past her got and father there, one weep</span><br><span class="line">In mine  wroth nightlys, smileed. Cantleye An York,</span><br><span class="line">A druls marriage, that though Service hated me</span><br><span class="line">Their duen of iflock, we are here in berieved</span><br><span class="line">and more than tanise them with suterept</span><br><span class="line">He rt in some pickle.</span><br><span class="line"></span><br><span class="line">SePSERTER:</span><br><span class="line">Or I have safe all thou depustere andthe before him.</span><br><span class="line"></span><br><span class="line">FRIAR LAURENCE:</span><br><span class="line">What art my government, cosbude, and hence; if Onfrawn? provest tor my duty?</span><br><span class="line"></span><br><span class="line">CATESBY:</span><br><span class="line"></span><br><span class="line">KARIANA:</span><br><span class="line">My love noe is are  with t herman and his,</span><br><span class="line">It should she well deeauring our consent:</span><br><span class="line">They hang me bointed on the king, let so two</span><br><span class="line">Nature by my sighsing pleasing &#x27;jabe</span><br><span class="line">That leaven and grue, at her Richard&#x27;s blood.</span><br><span class="line">More ends it likipenortnive, nor each of him</span><br><span class="line">ic.</span><br><span class="line"></span><br><span class="line">SLY:</span><br><span class="line">How dachors, Richmend, henr dack but like it?</span><br><span class="line">Be long, anon since your kingdom and us,</span><br><span class="line">And we that aver el</span><br><span class="line">aunter, my eee to toucurt tomends.</span><br><span class="line">It this her great fawn&#x27;s birds,, sir! you&#x27;er head.</span><br><span class="line"></span><br><span class="line">PAULINA:</span><br><span class="line">Upternalt cost of his hands for their tricks my father,</span><br><span class="line">Who ts it most seunt to live te and she were all.</span><br><span class="line">-kill</span><br><span class="line">O to thy son os shall not on your childrs,</span><br><span class="line">one next, for she did formly consixent</span><br><span class="line">Above, my life, and wew me worthy deeming tvenge!</span><br><span class="line">My mustere be exploience, aot come n leave where ahe knees in.</span><br><span class="line">dear, thus wild up tilt on the county, hath be one.</span><br><span class="line">See this sword of thee with the deepito man,</span><br><span class="line">For sunier ene first sears. Where&#x27;s turn on to be.</span><br><span class="line">Unctious blunlest terrocate doves</span><br><span class="line">Trades Marcius aines of hlends</span><br><span class="line">My&#x27;s learth an old--ay.</span><br><span class="line"></span><br><span class="line">LEONTES:</span><br><span class="line">Marcius?</span><br><span class="line"></span><br><span class="line">PRONVO:</span><br><span class="line">You would no gue.</span><br><span class="line"></span><br><span class="line">VOLUMNIA:</span><br><span class="line">Oovine s fetch to tight, thou must but loods.</span><br><span class="line"></span><br><span class="line">HASTINGS:</span><br><span class="line">And was with her, nor yonder to be sworn,</span><br><span class="line">What are you allady that I should have purpose.</span><br><span class="line">What men  revenge is a well patient</span><br><span class="line">And who seth sxoleng to knowled ed to myself;</span><br><span class="line">And married me in the joy:</span><br><span class="line">So reve I made to find me speak,</span><br><span class="line">how he been tou.</span><br><span class="line"></span><br><span class="line">PETCA:</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>##《水浒传》语料实验</p><p>###cpu版本</p><p>把下载好的《水浒传》改名为<code>input.txt</code><br>使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">th train.lua -data_dir data/mydata/ -gpuid -1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练，可以看到很明显，速度很慢</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">th train.lua -data_dir data/mydata/ -gpuid -1</span><br><span class="line">vocab.t7 and data.t7 do not exist. Running preprocessing...</span><br><span class="line">one-time setup: preprocessing input text file data/mydata/input.txt...</span><br><span class="line">loading text file...</span><br><span class="line">creating vocabulary mapping...</span><br><span class="line">putting data into tensor, it takes a lot of time...</span><br><span class="line">saving data/mydata/vocab.t7</span><br><span class="line">saving data/mydata/data.t7</span><br><span class="line">loading data files...</span><br><span class="line">cutting off end of data so that the batches/sequences divide evenly</span><br><span class="line">reshaping tensor...</span><br><span class="line">data load done. Number of data batches in train: 345, val: 19, test: 0</span><br><span class="line">vocab size: 4129</span><br><span class="line">creating an LSTM with 2 layers</span><br><span class="line">setting forget gate biases to 1 in LSTM layer 1</span><br><span class="line">setting forget gate biases to 1 in LSTM layer 2</span><br><span class="line">number of parameters in the model: 2845345</span><br><span class="line">cloning rnn</span><br><span class="line">cloning criterion</span><br><span class="line">1/17250 (epoch 0.003), train_loss = 8.32795887, grad/param norm = 9.6310e-02, time/batch = 28.8711s</span><br><span class="line">2/17250 (epoch 0.006), train_loss = 8.06433859, grad/param norm = 4.2826e-01, time/batch = 25.2184s</span><br><span class="line">3/17250 (epoch 0.009), train_loss = 7.28941094, grad/param norm = 3.9537e-01, time/batch = 25.2195s</span><br><span class="line">4/17250 (epoch 0.012), train_loss = 6.85331761, grad/param norm = 4.0576e-01, time/batch = 25.2011s</span><br><span class="line">5/17250 (epoch 0.014), train_loss = 6.69327439, grad/param norm = 3.8309e-01, time/batch = 24.9642s</span><br><span class="line">6/17250 (epoch 0.017), train_loss = 6.50776019, grad/param norm = 3.1042e-01, time/batch = 24.9203s</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>预计需要120小时训练时间！但是，这都是未经过处理的语料，后续使用处理过的余料（如去掉低频词语等）再来训练应该会更快。因为时间太长，所以这个实验被放弃了。<br>###GPU版本的未处理语料实验<br>首先对未处理语料做训练：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">th train.lua -data_dir data/mydata/ -gpuid 0</span><br></pre></td></tr></table></figure><p>begin at 10:20<br>可以看到<code>time/batch</code>稳定在0.08s左右，也就是半小时就可以训练完成！GPU比cpu在科学计算上面实在是太强大了。<br>训练完毕，使用：<br><code>th sample.lua cv/lm_lstm_epoch50.00_3.9309.t7 </code></p><blockquote><p>者，却得出来的物细物，没面少管生渔人。后来的知府时是乱色早晚，拾了几个。李逵惊得忙忙轻梳药穿在大牢里，摆在延安家处，推慰九节的。当下径到居中饮酒，牌门头，戴宗又焦躁。只见屏风背后转出一个小风大来，暗暗听得道：“反细放俺!兄弟拿着，趁这为害天明地清，我休要推道别事的都要做伴当拆投到会耳，便有进漏？”时迁舞起树下探人，的了夹搭，都拽了拽开，胸皮虽是好了六分惊得，是他麻。吐女棒放火了，走不向前，及宋江那道个留守他做个辩察的，先自去州里请明地烧了钱用，但有过京回家，听得状子好!这高老袋内却是出张招安，又都是他的欺负民，如何是计信?必须要和郎相会。且。”趁早起楼去了。两个连夜时候，仓治时，年二十八执迷者多要都要去行叶，早是亲家洒家，径挨到府前来。灯烛纸敌官，方才脱漏。亦被乱窝中有人等好人知蔡京道：“那个人也是他甚么?因此教大军打劫俺那干干金珠的。”母子那妇人来到大王尚安着，相交酒追惹三清酒搦战。不过半夜之事，早饭相烦，心里出对知府说：“官家初时在时，欲要市上时，兀自和我觅家劫犯了他，如何不赶我里来?我大小心定得，不分便了。”叉军转回，已做些小头，要打抵敌他!且把身，带了七个人时，都抢出家，但见：　　<br>    壮中醪浑纷领，腰细轻露。阔尺三层挺刀，鱼厚夸敌庆孙。高人有八句诗单道身心强似莽?；小付敲柴的，真多呼圣殿之主贞锋欣乐词。头邬闻丹腊良夫，耍达缘矮岁龙；四虎间，寒暮难以偷黄；牢记仁诸作像，显宝一根红佛。微。善得山迎能指挥，直救清天马星。　　<br>    话说上阵法， 师皇帝展得有?宫殿，雨翠云也上田地里。幸观非乃帝重了，宋江心如有誓，同宋受迷。却诗名唤，只传说开门，因此是贼人心腹事务，到宋江纠合生灵害，在忠渐存母亲来宋江以心却才，惊得义既灵垂德，对公孙胜为然无智真道好法，正为：须游六十为聚义，好像原林密寨郎山神保。　　<br>    当日宋庄客帐前，与晁保、公二位头领，众头领发起作法。　　<br>    石裂更兼地分都拨人汉，且不杀得蒙恩干人结义，下山只是锦袋百把，们有父亲孔宾，同商量。宋江又道：“自是好生，莫非也只是是有哥哥下了。”吴用笑道：“兄弟，不到山寨，吴用命作商量，将军不与他长犬马，力休曾平他：一话难以安身，宋江一力不东昌下几日，谁想大哥哥教小晁盖哥哥会合当的事。我们人投随天军来，又有伤损；若不连环甲关，着李横其不似火体，车藏御上尽挂玉水；军卒许多，无无不难之际?他但**，可等兵，可以斩遣。”众军健都管入庄，要把鲜血迸成，赶起来，背后解水边，唤车军跨城疮只等，原来正是之福，后往，来不见三个使汉。因弟清风船救应。路，至是路买酒，又拨五七百名、罩、白、孔亮，正将费珍、薛霸，尽是钱十二十军，其余的人在彼，欲得众兵险道地广花荣抵敌人住。这一队节度使士都军，被两个军猛，呐声喊，都抢过城里，并无腰迎敌，被贼兵赶上，时，却被花荣战箭射来。童太人、杨志正是南安江韩杨龙、穆弘、李逵、索超正定敌。孙军纵马。琼清马挺着枪，入来，尽被史进和贼人杀死贼兵，擒做霹雳。邬梨因成让风，连鼓上马，将股斧，却飞入阵，大小张清见了见乱军阵前卒法败坑回阵，宋江旭前只是：　　<br>    主人问姓，五应风万。侯海道正：“恶平可逃奔：。时们村野阴血，呼往天兵消波。正被杨志聚领渡江，望宋江攻还山庵；拔寨教活林冲、公万一通，并添下山南二王庆名事虚权，再被小人在戴上探山泊路，几路去报，不敢准备。不知这个人说起是百庄小黑凌州，已曾见了，对别无缘。”吴用道道：“便队军马解到此时，必是殡隘为百谷岭。原师悬流水军头二头领，结识江湖上好汉姓石，名给鬼，便乃五家庄二多情。我去这里地路，望会便行。”廊进雷车把人来不止，李应拈着诏书，自此付话。　　<br>    且说山客渡过了三只路，教穆弘扮做伴当，扮做阎婆者，带拢是臭镇一个没赌什门，分顺了同行，自去寻闭了的。原自去被人运烧将下去了。宋江等远远，一路进兵。十来县不在大路途来，又怕了到得闲意的张社长，听得监押一声，货钱便是。任原陈达在中，不知处打那华州，特使他来掳去太安军肆，只待下山。戴宗告随张小人，蔡九知府不得，连夜回话，同张招讨干办、众部吉。于路，忽报探知样悔，景珍全过，领回商议，“军师赵枢密喜绯金带，身上悬面草板，护道国师，服，神色不通。是奇诈将丘留的人，准备起船走径来借粮，业不同何遇一深困马灵夫，便因密的月色渐砂来完，斋。小温皇威，被宣刚引军来，武松彼朵并顾大嫂，赴了逃去，自逃命探了。被那几人娅?在古靖军吟涂炭，，态纪士，接应喊道，漏转身来，复有神诗，燕世曰：“寡人仰云监斩辽王康公外交法，何”奈阵圣怒须性重。铁挨填丹靴，万边狄行鉴。见。田户观看草畔，红日影豪困催急绩。宋玉游战，听听了大喜。话说宿太师诏奏道：“宿元帅差有敕入请罗真人，密封官军等八员高名，封当同达宋先锋。”日收选润之主，奏为圣旨，特着州殿府探知。太尉宿太尉回到内，启转马，众军方可亦成开大事，放起出来，更兼小一个唤做</p></blockquote><p>##使用增强RNN网络训练</p><p>如下，使用512个隐藏节点的3层RNN网络训练模型</p><p><code>th train.lua -data_dir data/shuihuzhuan/ -gpuid 0  -rnn_size 512 -num_layers 3 </code><br><code>th sample.lua cv/lm_lstm_epoch50.00_5.4830.t7 -sample 0 -temperature 0.8 -verbose 0 -length 500</code></p><blockquote><p>弟兄两个，也得个信名之人。”那个也是个道理。童家四更，被张顺斩的粉碎，以下人人家拿去了。一面叫酒保打两桶酒来。小二哥叫道：“师父，你不是我来也！”那小牢子道：“我也不曾你，你便叫我上来。”　　 石秀道：“你且说他三宫百里吃酒了来，你便抢入去，你便先来看，却被这畜生说不得了。”那妇人道：“你真人要打这里话?你却不认你，你便叫我儿来寻。”李逵道：“你敢作吃的，便揪我做脚！”赤条条地寻谁，只得骂道：“爹娘，你且休了，我自不信，砍我头便打那老娘。”那妇人道：“也好。”便把袖儿丢下去了。那妇人也把刀带在一边，却似小窗????胡乱道：“好拳脚！”急叫开了店看。”王庆听了，连声叫道：“阿也!你不要吃！”把手一指，提倒上岸来，把朴刀倚在被里。就把篙子门内，倒做五六斤了，将把木鱼来摆下桶桶。少时，张顺吃了一回。两个回到店前，再出来赏赐，解了戒刀，包了水出去，到四更，把船渡入去，便叫艄公下楼，买了些鱼吃，把些酒肉吃了，酒保做些桶汤、盘酒、些肉。下来穿瓶与酒。一瓶儿酒肉，买些肉吃，只见店主人把包裹插下，那妇人也吃得饱了，口里说道：“娘子，老身等这几个泼，不要吃酒钱。”店小二道：“好酒好肉要打，我吃便饱</p></blockquote><p>很明显，此时sample的样本语句更加通顺，错误很少，从品味小说的角度来讲，增强了的RNN训练得到的模型更加完美了。 可以看到，**增加了节点数和隐藏层的RNN具有更强的学习能力。<br>**</p><h2 id="对比训练过程模型表现力"><a href="#对比训练过程模型表现力" class="headerlink" title="对比训练过程模型表现力"></a>对比训练过程模型表现力</h2><p>与此同时我们可以对比一下，训练开始阶段与训练结束时的模型表现力的差异：</p><p><code>th sample.lua cv/06-01-shz_sp/lm_lstm_epoch5.80_4.0451.t7 -sample 0 -temperature 0.8 -verbose 0 -length 500</code></p><p>训练刚刚进行到5.8（为50时完成）得到的是：</p><blockquote><p>只见一个人从来，一个人，都来做一个。那人道：“你这厮们，我自去寻你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要瞒我，你便不要你。”那人道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那婆娘笑道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不要吃，我自去寻你。”那妇人道：“你不</p></blockquote><p>此时语料具有较多的重复，模型还没有良好的收敛。</p><p>继续观察，当进行到四分之一左右时：</p><blockquote><p>那汉子听了，便问道：“你这厮不是歹人，如何不来?我们不曾有这般的，如何不来?你的那里去了？”那汉道：“我们不曾说谎。”那汉道：“我不曾说谎。”那汉道：“我不曾说谎。”那汉道：“我不曾说谎。”那汉道：“我不曾说谎。”那汉道：“既是恁地，我们自去。”那汉道：“既是恁地，我们自去。”那汉道：“既然恁地，我们自去买碗酒吃。”那汉道：“既是恁地，我们自去。”那汉道：“既然恁地，我们自去买碗酒吃。”那汉道：“既是恁地，我们自去。”那挑酒的汉子道：“我们自有计较，我们自有些钱，与你些银两，却去商议。”董超道：“我们不曾有这般的事，如何不来?你们自去取路，我和你如何不去?若还了他时，便是要去的。”李逵道：“你们不曾说的，你便是个老儿，如何不来?我们自去取他，你便不曾与他厮见。”那妇人道：“你的，你不省得。”那妇人道：“你的，不要胡说!我们自有钱帛，便要去便了。”那妇人道：“既是恁地，我们自去买些银子与我。”那妇人道：“我们自有钱与你，你便不曾去了。”那妇人道：“既是恁地，我们便去。”那妇人道：“既是恁地，我们便去。”那妇人道：“你的，不要胡说!我如何肯去这里？”那妇人道：“便是这般使棒，不曾得得他。</p></blockquote><p>再看看训练继续进行到一半左右时候的表现力：</p><blockquote><p>张都监为副将急体己人，不敢不依，只得随行众军，掌行送行。只留下降，尽皆欢喜，以此忠义。在府行军中，有使枪棒卖药的，将王庆领军到来，并不必说。当下宋江传令，教中军计策，与卢俊义等商议：“今日折了两阵，俺们自去了。”宋江道：“军师之言甚善！”当下即日便传将令，教军士点营，斩动军马。将及初五更战后，攻打常州，催趱军兵，一齐进发。 寨中，只听得高声叫道：“萧让等救兵！”宋江看那军将，尽数放起，对幽州一个大汉，乃古头上大叫道：“水洼草寇，怎敢轻慢！”只见里面关胜、呼延灼、关胜等探有一人，只见唐斌从人骑马，直到宋江寨前，喝请宋先锋。宋江听了大喜，传令令军士且去寨中坐地，备说宋先锋军马，攻打北京。吴用道：“且教两路军马，攻打北门。”宋江便令吴用、朱武商议：“今日可去，只是国师吴用，坐一件事，我等随顺到此，可用两处夹攻，那厮必然有人来。”宋江道：“军师言之极当。”便唤军士计策。”宋江道：“军师言之极当。”吴用道：“小生直作妙计，即且闻见。”宋江道：“先生之言，是不得这般忧疑。”宋江道：“既然如此，与你四位豪杰，不堪员外大王。”宋江道：“贤弟，你休要疑心，我便去请来。”吴用道：“不须你两个与我箭，只</p></blockquote><p>此时低级的重复没有了，但是可以看到，“宋江道”反复出现，而且说的内容类似，可以得到模型已在进一步完善之中。</p><p>这是模型接近训练完成的时候的sample：</p><blockquote><p>张青、孙二娘、顾大嫂、孙二娘，并四个好汉，引着一千余人，吹造大小船只，都投水路。不多时，只见松树背后转出一个小小人来，簇拥着两个人，各提着朴刀，背后有人，叫一声：“捉下！”　　 那汉子把船只一招，扶着一干人，把那碗饭打伤，打的粉碎，把头头割在一边，口里放火。那人见了是惊得呆了，又不来吃了一惊，扑地只顾走。却待再走，再去脱人避凉。李逵却亦不肯拦他，只得走了。可怜救他两个性命，那里敢?别人。前日被捉死了性命，杀了人，逃走在江州，被害人陷害，方得正中了。今日幸得相见，如何使得?便得是个知县过来的，也喜得及。他便是本人的人，须是高太尉的人，却不知是那里人。”任原道：“这个便是我的儿么？”王婆道：“便是前日那官司亲亲叔孝，为何到此？”那婆子答道：“老身只道不妨，只怕小人自有措置。老身看了，便忘了回去。”老都管道：“这个容易。老身先把银酒去了。”老儿道：“你们自不要吃酒。”那婆子也笑起来道：“这个便是我的老小人家。”那婆子道：“便是老身也不怕你，休要胡主干娘，只怕你疑心。”那妇人道：“不干了。你的女儿，老娘儿只做买些衣服来送与你。”王婆道：“娘子，你要知这几个字？”那婆子道：“有甚么哭处？”</p></blockquote><p>模型进一步完善，接近完成训练。</p><p>##《全唐诗》实验</p><h3 id="下载下来的全唐诗-txt是gbk编码的，首先需要转换为utf-8编码："><a href="#下载下来的全唐诗-txt是gbk编码的，首先需要转换为utf-8编码：" class="headerlink" title="下载下来的全唐诗.txt是gbk编码的，首先需要转换为utf-8编码："></a>下载下来的<code>全唐诗.txt</code>是<code>gbk</code>编码的，首先需要转换为<code>utf-8</code>编码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    s = <span class="built_in">open</span>(<span class="string">&quot;全唐诗.txt&quot;</span>)</span><br><span class="line">    r = s.read()</span><br><span class="line">    r_uni = r.decode(<span class="string">&#x27;gb2312&#x27;</span>,<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    r_en = r_uni.encode(<span class="string">&#x27;utf-8&#x27;</span>,<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">    fp=<span class="built_in">open</span>(<span class="string">&quot;全唐诗转换.txt&quot;</span>,<span class="string">&quot;w&quot;</span>)</span><br><span class="line">    fp.write(r_en)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span> :</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>这样就得到了<code>utf-8</code>编码的文件。</p><p>开始想直接把这个文件丢给rnn训练，后来想一想，“全唐诗”包括了众多诗人的杰作，也许训练出来的模型sample不到什么特点鲜明的诗句，于是我首先想对诗仙李白的诗做一个实验。把得到的全唐诗文件中李白的诗切分出来作为一个文件。<br>开始训练：<br><code>th train.lua -data_dir data/tangshi/ -gpuid 0</code><br>得到模型后sample：</p><p><code>th sample.lua cv/lm_lstm_epoch50.00_5.3967.t7 </code></p><blockquote><p>耶翳妃在。流明湖草，岂舞高散纷。小剑宫底寒，石思怀士。<br>归来相烟叹，又余未老此。此在见携节，气帝皇彩川。<br>尝君凌天鸟，羞从臂山中。何旋俱所偃，造愧翻遗耻。<br>悠挥李明云，坐月得相迟。君作成景鸡，暮日清膺发。<br>胡步垂洞松，三年延未莱。贤迢坐橐山，嗤楼谋疏川。<br>诗君九安菲，别去写日流。五时谢及洒，相魄三有玄。</p></blockquote><blockquote><p>卷177_21 【长道送秀士寄之十南国古松游明，》妓此蛾书此下见逃之始崔至六以吟酒宁】李白</p></blockquote><blockquote><p>仙阳壶我王，谣荣日茫过。幸生天行寒，半持见九忧。<br>早毂此楼宰歌，鹗税金归名。宾托昼宇闻，高汶堕臣泉。<br>峻悟湍素都，凤生鸟远才。虎傥亦成一，蹭据锁炳垣。<br>回谷闻叹波，摧人翼昆衣。丑德皆复贵，何袂自见宝。<br>黄然奉傍及，戾酒悲溪情。何悟下罗灭，壁令还济然。</p></blockquote><blockquote><p> 卷177_16 【送沙门饯元佛之嵩使归少丞寺辅晔年亭山云】李白</p></blockquote><blockquote><p>行道一狂日，陆杯欲我园。相寄属相者，不歌流成书。<br>幽景神兰马，今云乃相知。相能拂此门，娟笑无生魂。<br>肠后扫天所，罗瑟心世桥。</p></blockquote><blockquote><p> 卷169_11 【金松二炎师】李白</p></blockquote><blockquote><p>丽劝发何凤，含东药宛锦。且忍咏尺鳌，梦杯池月<br>。<br>罗鸟思归人，兼我无风歇。太色东草树，壮早游罗息。<br>别来青神极，谒长不陵寒。君忧东海鹤，吹欲得彩好。<br>梦君来太情，秦子忆延薪。闻干凌楼息，松水接廉才。<br>且识辞犹之，众断罗里中。</p></blockquote><blockquote><p>水羊远重，引飒高新策。目布愁霜亲，，随火赤云道。<br>解毂四上牛，以且汶云年。宁迎清巴寒，种欺清名风。<br>海坐去不意，思丹酩期然。闻钓曾帆景，一弄暗长雪。<br>且亦留我辉，杀讼韵中楼。</p></blockquote><blockquote><p>  卷174_7 【赠崔司州十三青寺黔洞姑圣毛闲华忘兼塔宅石】李白</p></blockquote><blockquote><p>窜笑敬鹤见梦走去留僧。地筑从尺人，泪树平众烂。<br>窈箸有吉氲，久聪欲洲真。朝春离相兽，飞此何垣发。<br>绿日偶可言，我言经精存。君卒限汉水，绿月相成失。<br>恋虏一登事，但乘涂应星。</p></blockquote><blockquote><p> 卷177_18 【咏夜别（人作帝阳之为昆者）】李白</p></blockquote><blockquote><p>笑乃度将明，蛾洞蕊山发。花坐新合露镜日边归溪。<br>长面云蓬立，自颜谢鸳分。灭用欲得碑，不云当天舟。<br>一来但不霄，乘我涉路来。怀子广陵远，夕人不元阙。<br>笑天亦望好，驱令适谁手。思此有门上，举与满丝君。<br>醉年归敬山，松藏谢未笑。却思笑古兴，凭凌泪高尺。</p></blockquote><blockquote><p>钱文1淮作3<br> 　<br>卷一两十七三北欢宁三元四慈平难名】李白</p></blockquote><blockquote><p>水乘黄楼镜君客绿1起，山门天阙已忍春。不喜出庭作，乎<br>晖酒苔。麒惊美。绮门，我见秦心遂天雪，只行天花流。<br>相随夔山肉烟喧，武斗吹齐而公还。以开玉去戟如雨，<br>欲席上醉鹊里洪。世闻燕弦对士去，曳不笑丘瞳中嗟。<br>国昔逢眼青山鸟，扫水长丘双泉空。</p></blockquote><blockquote><p>  卷165_8 【玉崔将言刺判池，一还精孰日君）】李白</p></blockquote><blockquote><p>军莫荆壮悲，揽迈宋钟客。高当愤酒酒，渴臣达庭边。<br>沙箸佳花诏，映河讵窗中。为交上梧空，空在猛杯闻。<br>惜缅何烦柯，屈笑献神然。万情上者溪，相以陶毫逸。</p></blockquote><blockquote><p>更闻无袂，小必笑伤穷。</p></blockquote><blockquote><p>  卷169_12 【高陵黄入蜀，寄纪侍御二首】李白</p></blockquote><blockquote><p>爱来游山子，北照有华宅。岩歧难碑李，独承崔滹鼙。<br>巨君亦不处，常阖之此酒。思君穷莫术，却成愁庄隈。征六此与玄，，羞逐但应君。</p></blockquote><blockquote><p>  卷189_26 【登溪马归歌，归石怀道怀山】】。<br>长腾明花屏爱心春，寄心入良素断。</p></blockquote><blockquote><p>  卷188_7 【送侍御从尔史崔崖赴天】白山年粲赤浑，书别诗游泛风】李白</p></blockquote><blockquote><p>祖国一官食，二藏系冠鹇。无砚号盆水，浮发王青吟。<br>登水惜不母，殷古启与游。萧觉留见去，待泪复相思。<br>绿风吹中信，江山知洞宫。宾阔未孤里，空可向江峤。<br>西舟青溟云，一浪摇苗彩。流镜沙青辉，夕落得寒洲。<br>妾头海弦弓，而多何皇笑。欢辰虽欢心，此鸣暗清飞。<br>广松春人草，为啸李田。。思君鸾可得，萧论以天风。<br>今家高去路，酌藏无云功。为时壮罢邑，陈不见长名。<br>闻啸不可在，玉服汉寒情。愿昆隐山水，更将谢敬离。</p></blockquote><blockquote><p>大说词隐开，夜子庐鹤行。他烛不知尽，逸君徒风草。<br>把柯南幽山，超血彩森兵。吊窈赤微鸟，娇若相踪。<br>笑乏惜香门，夜酌闻岩欢。<br>我此一可驰，三刀瓦风樽。东秋清柱晚，意歌送高颜。<br>别留一失在，推时悲紫踪。群远亭我顶，机赠沾酒旋。<br>明镜若相巨，明窗忘语平。桃水凌瑶心，茫讼落清眉。<br>横产无商娥，万流应长生。</p></blockquote><blockquote><p>  卷171_2 【酬纪寿阳送官】李白</p></blockquote><blockquote><p>白浦欲溪山，去入北酒人。云水薄阶弄，乃啾迹风声。<br>诗命侍飞儿，百结清霞杯。何言思君去，但然谢无歇。</p></blockquote><blockquote><p>  卷176_21 【荆闺崔嵩人宰】李白</p></blockquote><blockquote><p>常鹉别帝家，绮书逐惟安。西世东山玉，雕是金东辉。<br>绿登紫鹿色，张看弄月萝。思手穷津水，弄是俨归人。<br>相恐新鹉道，渌声赠恨公。</p></blockquote><p>这里出来的效果就很惊人了，我们从小就在课本上学习了诗仙李白的许多佳作，可以说大家对于一个诗人的诗的韵味是怎样是很有体会的，在这些字里行间仔细品味，我们完全可以体会到李太白的豪放与洒脱。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/DNN/">DNN</category>
      
      
      <comments>http://example.com/2016/05/26/2016-05-26-char-rnn-chinese/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Python OOP（Object Oriented Programming）</title>
      <link>http://example.com/2016/05/25/2016-05-25-pythonoop/</link>
      <guid>http://example.com/2016/05/25/2016-05-25-pythonoop/</guid>
      <pubDate>Wed, 25 May 2016 13:35:32 GMT</pubDate>
      
      <description>&lt;p&gt;面向对象编程——Object Oriented Programming，简称OOP，是一种程序设计思想。OOP把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。&lt;/p&gt;
&lt;p&gt;面向过程的程序设计把计算机程序视为一系列的命令集合，即一组函数的顺序执行。为了简化程序设计，面向过程把函数继续切分为子函数，即把大块函数通过切割成小块函数来降低系统的复杂度。&lt;/p&gt;
&lt;p&gt;而面向对象的程序设计把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，计算机程序的执行就是一系列消息在各个对象之间传递。&lt;/p&gt;
&lt;p&gt;在Python中，所有数据类型都可以视为对象，当然也可以自定义对象。自定义的对象数据类型就是面向对象中的类（Class）的概念。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>面向对象编程——Object Oriented Programming，简称OOP，是一种程序设计思想。OOP把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。</p><p>面向过程的程序设计把计算机程序视为一系列的命令集合，即一组函数的顺序执行。为了简化程序设计，面向过程把函数继续切分为子函数，即把大块函数通过切割成小块函数来降低系统的复杂度。</p><p>而面向对象的程序设计把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，计算机程序的执行就是一系列消息在各个对象之间传递。</p><p>在Python中，所有数据类型都可以视为对象，当然也可以自定义对象。自定义的对象数据类型就是面向对象中的类（Class）的概念。</p><span id="more"></span><p>我们以一个例子来说明面向过程和面向对象在程序流程上的不同之处。</p><p>假设我们需要处理学生的成绩表，为了表示一个学生的成绩，面向过程的程序可以用一个dict表示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">std1 = &#123; <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Michael&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">98</span> &#125;</span><br><span class="line">std2 = &#123; <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;score&#x27;</span>: <span class="number">81</span> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>而处理学生成绩可以通过函数实现，比如打印学生的成绩：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_score</span>(<span class="params">std</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (std[<span class="string">&#x27;name&#x27;</span>], std[<span class="string">&#x27;score&#x27;</span>]))</span><br></pre></td></tr></table></figure><p>如果采用面向对象的程序设计思想，我们首选思考的不是程序的执行流程，而是<code>Student</code>这种数据类型应该被视为一个对象，这个对象拥有<code>name</code>和<code>score</code>这两个属性（Property）。如果要打印一个学生的成绩，首先必须创建出这个学生对应的对象，然后，给对象发一个<code>print_score</code>消息，让对象自己把自己的数据打印出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, score</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (self.name, self.score))</span><br></pre></td></tr></table></figure><p>给对象发消息实际上就是调用对象对应的关联函数，我们称之为对象的方法（Method）。面向对象的程序写出来就像这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bart = Student(<span class="string">&#x27;Bart Simpson&#x27;</span>, <span class="number">59</span>)</span><br><span class="line">lisa = Student(<span class="string">&#x27;Lisa Simpson&#x27;</span>, <span class="number">87</span>)</span><br><span class="line">bart.print_score()</span><br><span class="line">lisa.print_score()</span><br></pre></td></tr></table></figure><p>面向对象的设计思想是从自然界中来的，因为在自然界中，类（Class）和实例（Instance）的概念是很自然的。Class是一种抽象概念，比如我们定义的Class——Student，是指学生这个概念，而实例（Instance）则是一个个具体的Student，比如，Bart Simpson和Lisa Simpson是两个具体的Student。</p><p>所以，面向对象的设计思想是抽象出Class，根据Class创建Instance。</p><p>面向对象的抽象程度又比函数要高，因为一个Class既包含数据，又包含操作数据的方法。</p><p>##类和实例<br>面向对象最重要的概念就是类（Class）和实例（Instance），必须牢记类是抽象的模板，比如Student类，而实例是根据类创建出来的一个个具体的“对象”，每个对象都拥有相同的方法，但各自的数据可能不同。</p><p>仍以Student类为例，在Python中，定义类是通过<code>class</code>关键字：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p><code>class</code>后面紧接着是类名，即<code>Student</code>，类名通常是大写开头的单词，紧接着是<code>(object)</code>，表示该类是从哪个类继承下来的，继承的概念我们后面再讲，通常，如果没有合适的继承类，就使用<code>object</code>类，这是所有类最终都会继承的类。</p><p>定义好了<code>Student</code>类，就可以根据<code>Student</code>类创建出<code>Student</code>的实例，创建实例是通过类名+()实现的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart = Student()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart</span><br><span class="line">&lt;__main__.Student <span class="built_in">object</span> at <span class="number">0x10a67a590</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Student</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">__main__</span>.<span class="title">Student</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure><p>可以看到，变量<code>bart</code>指向的就是一个<code>Student</code>的实例，后面的<code>0x10a67a590</code>是内存地址，每个object的地址都不一样，而<code>Student</code>本身则是一个类。</p><p>可以自由地给一个实例变量绑定属性，比如，给实例<code>bart</code>绑定一个<code>name</code>属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.name = <span class="string">&#x27;Bart Simpson&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.name</span><br><span class="line"><span class="string">&#x27;Bart Simpson&#x27;</span></span><br></pre></td></tr></table></figure><p>由于类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。通过定义一个特殊的<code>__init__</code>方法，在创建实例的时候，就把<code>name</code>，<code>score</code>等属性绑上去：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, score</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br></pre></td></tr></table></figure><p>注意到<code>__init__</code>方法的第一个参数永远是<code>self</code>，表示创建的实例本身，因此，在<code>__init__</code>方法内部，就可以把各种属性绑定到<code>self</code>，因为<code>self</code>就指向创建的实例本身。</p><p>有了<code>__init__</code>方法，在创建实例的时候，就不能传入空的参数了，必须传入与<code>__init__</code>方法匹配的参数，但<code>self</code>不需要传，Python解释器自己会把实例变量传进去：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart = Student(<span class="string">&#x27;Bart Simpson&#x27;</span>, <span class="number">59</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.name</span><br><span class="line"><span class="string">&#x27;Bart Simpson&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.score</span><br><span class="line"><span class="number">59</span></span><br></pre></td></tr></table></figure><p>和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数。除此之外，类的方法和普通函数没有什么区别，所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。<br>###数据封装<br>面向对象编程的一个重要特点就是数据封装。在上面的<code>Student</code>类中，每个实例就拥有各自的<code>name</code>和<code>score</code>这些数据。我们可以通过函数来访问这些数据，比如打印一个学生的成绩：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">print_score</span>(<span class="params">std</span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (std.name, std.score))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print_score(bart)</span><br><span class="line">Bart Simpson: <span class="number">59</span></span><br></pre></td></tr></table></figure><p>但是，既然<code>Student</code>实例本身就拥有这些数据，要访问这些数据，就没有必要从外面的函数去访问，可以直接在<code>Student</code>类的内部定义访问数据的函数，这样，就把“数据”给封装起来了。这些封装数据的函数是和<code>Student</code>类本身是关联起来的，我们称之为类的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, score</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.score = score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (self.name, self.score))</span><br></pre></td></tr></table></figure><p>要定义一个方法，除了第一个参数是<code>self</code>外，其他和普通函数一样。要调用一个方法，只需要在实例变量上直接调用，除了<code>self</code>不用传递，其他参数正常传入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.print_score()</span><br><span class="line">Bart Simpson: <span class="number">59</span></span><br></pre></td></tr></table></figure><p>这样一来，我们从外部看<code>Student</code>类，就只需要知道，创建实例需要给出<code>name</code>和<code>score</code>，而如何打印，都是在<code>Student</code>类的内部定义的，这些数据和逻辑被“封装”起来了，调用很容易，但却不用知道内部实现的细节。</p><p>封装的另一个好处是可以给<code>Student</code>类增加新的方法，比如<code>get_grade</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_grade</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.score &gt;= <span class="number">90</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;A&#x27;</span></span><br><span class="line">        <span class="keyword">elif</span> self.score &gt;= <span class="number">60</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;B&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br></pre></td></tr></table></figure><p>同样的，<code>get_grade</code>方法可以直接在实例变量上调用，不需要知道内部实现细节：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.get_grade()</span><br><span class="line"><span class="string">&#x27;C&#x27;</span></span><br></pre></td></tr></table></figure><p>###小结<br>类是创建实例的模板，而实例则是一个一个具体的对象，各个实例拥有的数据都互相独立，互不影响；</p><p>方法就是与实例绑定的函数，和普通函数不同，方法可以直接访问实例的数据；</p><p>通过在实例上调用方法，我们就直接操作了对象内部的数据，但无需知道方法内部的实现细节。</p><p>和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart = Student(<span class="string">&#x27;Bart Simpson&#x27;</span>, <span class="number">59</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lisa = Student(<span class="string">&#x27;Lisa Simpson&#x27;</span>, <span class="number">87</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.age = <span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.age</span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lisa.age</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">AttributeError: <span class="string">&#x27;Student&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;age&#x27;</span></span><br></pre></td></tr></table></figure><p>##访问限制<br>在Class内部，可以有属性和方法，而外部代码可以通过直接调用实例变量的方法来操作数据，这样，就隐藏了内部的复杂逻辑。</p><p>但是，从前面Student类的定义来看，外部代码还是可以自由地修改一个实例的<code>name</code>、<code>score</code>属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart = Student(<span class="string">&#x27;Bart Simpson&#x27;</span>, <span class="number">98</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.score</span><br><span class="line"><span class="number">98</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.score = <span class="number">59</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.score</span><br><span class="line"><span class="number">59</span></span><br></pre></td></tr></table></figure><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以__开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问，所以，我们把Student类改一改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, score</span>):</span></span><br><span class="line">        self.__name = name</span><br><span class="line">        self.__score = score</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (self.__name, self.__score))</span><br></pre></td></tr></table></figure><p>改完后，对于外部代码来说，没什么变动，但是已经无法从外部访问<code>实例变量.__name</code>和<code>实例变量.__score</code>了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart = Student(<span class="string">&#x27;Bart Simpson&#x27;</span>, <span class="number">98</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart.__name</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">AttributeError: <span class="string">&#x27;Student&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;__name&#x27;</span></span><br></pre></td></tr></table></figure><p>这样就确保了外部代码不能随意修改对象内部的状态，这样通过访问限制的保护，代码更加健壮。</p><p>但是如果外部代码要获取name和score怎么办？可以给Student类增加<code>get_name</code>和<code>get_score</code>这样的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.__name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_score</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.__score</span><br></pre></td></tr></table></figure><p>如果又要允许外部代码修改score怎么办？可以再给Student类增加<code>set_score</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_score</span>(<span class="params">self, score</span>):</span></span><br><span class="line">        self.__score = score</span><br></pre></td></tr></table></figure><p>你也许会问，原先那种直接通过<code>bart.score = 59</code>也可以修改啊，为什么要定义一个方法大费周折？因为在方法中，可以对参数做检查，避免传入无效的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_score</span>(<span class="params">self, score</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> &lt;= score &lt;= <span class="number">100</span>:</span><br><span class="line">            self.__score = score</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;bad score&#x27;</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，在Python中，变量名类似<code>__xxx__</code>的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，所以，不能用<code>__name__</code>、<code>__score__</code>这样的变量名。</p><p>有些时候，你会看到以一个下划线开头的实例变量名，比如<code>_name</code>，这样的实例变量外部是可以访问的，但是，按照约定俗成的规定，当你看到这样的变量时，意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。</p><p>双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。不能直接访问<code>__name</code>是因为Python解释器对外把<code>__name</code>变量改成了<code>_Student__name</code>，所以，仍然可以通过<code>_Student__name</code>来访问<code>__name</code>变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bart._Student__name</span><br><span class="line"><span class="string">&#x27;Bart Simpson&#x27;</span></span><br></pre></td></tr></table></figure><p>但是强烈建议你不要这么干，因为不同版本的Python解释器可能会把<code>__name</code>改成不同的变量名。</p><p>总的来说就是，Python本身没有任何机制阻止你干坏事，一切全靠自觉。<br>##继承和多态<br>在OOP程序设计中，当我们定义一个class的时候，可以从某个现有的class继承，新的class称为子类（Subclass），而被继承的class称为基类、父类或超类（Base class、Super class）。</p><p>比如，我们已经编写了一个名为<code>Animal</code>的class，有一个<code>run()</code>方法可以直接打印：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Animal is running...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>当我们需要编写<code>Dog</code>和<code>Cat</code>类时，就可以直接从<code>Animal</code>类继承：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>(<span class="params">Animal</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span>(<span class="params">Animal</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>对于<code>Dog</code>来说，<code>Animal</code>就是它的父类，对于<code>Animal</code>来说，<code>Dog</code>就是它的子类。<code>Cat</code>和<code>Dog</code>类似。<br>继承有什么好处？最大的好处是子类获得了父类的全部功能。由于<code>Animial</code>实现了<code>run()</code>方法，因此，<code>Dog</code>和<code>Cat</code>作为它的子类，什么事也没干，就自动拥有了<code>run()</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dog = Dog()</span><br><span class="line">dog.run()</span><br><span class="line"></span><br><span class="line">cat = Cat()</span><br><span class="line">cat.run()</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Animal <span class="keyword">is</span> running...</span><br><span class="line">Animal <span class="keyword">is</span> running...</span><br></pre></td></tr></table></figure><p>当然，也可以对子类增加一些方法，比如Dog类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>(<span class="params">Animal</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Dog is running...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eat</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Eating meat...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>继承的第二个好处需要我们对代码做一点改进。你看到了，无论是<code>Dog</code>还是<code>Cat</code>，它们<code>run()</code>的时候，显示的都是<code>Animal is running...</code>，符合逻辑的做法是分别显示<code>Dog is running...</code>和<code>Cat is running...</code>，因此，对<code>Dog</code>和<code>Cat</code>类改进如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>(<span class="params">Animal</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Dog is running...&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span>(<span class="params">Animal</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Cat is running...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>再次运行，结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Dog <span class="keyword">is</span> running...</span><br><span class="line">Cat <span class="keyword">is</span> running...</span><br></pre></td></tr></table></figure><p>当子类和父类都存在相同的<code>run()</code>方法时，我们说，子类的<code>run()</code>覆盖了父类的<code>run()</code>，在代码运行的时候，总是会调用子类的<code>run()</code>。这样，我们就获得了继承的另一个好处：多态。</p><p>要理解什么是多态，我们首先要对数据类型再作一点说明。当我们定义一个class的时候，我们实际上就定义了一种数据类型。我们定义的数据类型和Python自带的数据类型，比如str、list、dict没什么两样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="built_in">list</span>() <span class="comment"># a是list类型</span></span><br><span class="line">b = Animal() <span class="comment"># b是Animal类型</span></span><br><span class="line">c = Dog() <span class="comment"># c是Dog类型</span></span><br></pre></td></tr></table></figure><p>判断一个变量是否是某个类型可以用isinstance()判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(a, <span class="built_in">list</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(b, Animal)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(c, Dog)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>看来<code>a</code>、<code>b</code>、<code>c</code>确实对应着<code>list</code>、<code>Animal</code>、<code>Dog</code>这3种类型。</p><p>但是等等，试试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(c, Animal)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>看来<code>c</code>不仅仅是<code>Dog</code>，<code>c</code>还是<code>Animal</code>！<br>不过仔细想想，这是有道理的，因为<code>Dog</code>是从<code>Animal</code>继承下来的，当我们创建了一个<code>Dog</code>的实例<code>c</code>时，我们认为<code>c</code>的数据类型是<code>Dog</code>没错，但<code>c</code>同时也是<code>Animal</code>也没错，<code>Dog</code>本来就是<code>Animal</code>的一种！</p><p>所以，在继承关系中，如果一个实例的数据类型是某个子类，那它的数据类型也可以被看做是父类。但是，反过来就不行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = Animal()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(b, Dog)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p><code>Dog</code>可以看成<code>Animal</code>，但<code>Animal</code>不可以看成<code>Dog</code>。</p><p>要理解多态的好处，我们还需要再编写一个函数，这个函数接受一个<code>Animal</code>类型的变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_twice</span>(<span class="params">animal</span>):</span></span><br><span class="line">    animal.run()</span><br><span class="line">    animal.run()</span><br></pre></td></tr></table></figure><p>当我们传入<code>Animal</code>的实例时，<code>run_twice()</code>就打印出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>run_twice(Animal())</span><br><span class="line">Animal <span class="keyword">is</span> running...</span><br><span class="line">Animal <span class="keyword">is</span> running...</span><br></pre></td></tr></table></figure><p>当我们传入<code>Dog</code>的实例时，<code>run_twice()</code>就打印出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>run_twice(Dog())</span><br><span class="line">Dog <span class="keyword">is</span> running...</span><br><span class="line">Dog <span class="keyword">is</span> running...</span><br></pre></td></tr></table></figure><p>当我们传入<code>Cat</code>的实例时，<code>run_twice()</code>就打印出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>run_twice(Cat())</span><br><span class="line">Cat <span class="keyword">is</span> running...</span><br><span class="line">Cat <span class="keyword">is</span> running...</span><br></pre></td></tr></table></figure><p>看上去没啥意思，但是仔细想想，现在，如果我们再定义一个<code>Tortoise</code>类型，也从<code>Animal</code>派生：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tortoise</span>(<span class="params">Animal</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Tortoise is running slowly...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>当我们调用<code>run_twice()</code>时，传入<code>Tortoise</code>的实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>run_twice(Tortoise())</span><br><span class="line">Tortoise <span class="keyword">is</span> running slowly...</span><br><span class="line">Tortoise <span class="keyword">is</span> running slowly...</span><br></pre></td></tr></table></figure><p>你会发现，新增一个<code>Animal</code>的子类，不必对<code>run_twice()</code>做任何修改，实际上，任何依赖<code>Animal</code>作为参数的函数或者方法都可以不加修改地正常运行，原因就在于多态。</p><p>多态的好处就是，当我们需要传入<code>Dog</code>、<code>Cat</code>、<code>Tortoise……</code>时，我们只需要接收<code>Animal</code>类型就可以了，因为<code>Dog</code>、<code>Cat</code>、<code>Tortoise</code>……都是<code>Animal</code>类型，然后，按照<code>Animal</code>类型进行操作即可。由于<code>Animal</code>类型有<code>run()</code>方法，因此，传入的任意类型，只要是Animal类或者子类，就会自动调用实际类型的<code>run()</code>方法，这就是多态的意思：</p><p>对于一个变量，我们只需要知道它是<code>Animal</code>类型，无需确切地知道它的子类型，就可以放心地调用<code>run()</code>方法，而具体调用的<code>run()</code>方法是作用在<code>Animal</code>、<code>Dog</code>、<code>Cat</code>还是<code>Tortoise</code>对象上，由运行时该对象的确切类型决定，这就是多态真正的威力：调用方只管调用，不管细节，而当我们新增一种<code>Animal</code>的子类时，只要确保<code>run()</code>方法编写正确，不用管原来的代码是如何调用的。这就是著名的“开闭”原则：</p><p>对扩展开放：允许新增<code>Animal</code>子类；</p><p>对修改封闭：不需要修改依赖<code>Animal</code>类型的<code>run_twice()</code>等函数。</p><p>继承还可以一级一级地继承下来，就好比从爷爷到爸爸、再到儿子这样的关系。而任何类，最终都可以追溯到根类object，这些继承关系看上去就像一颗倒着的树。比如如下的继承树：<br><img src="http://img.blog.csdn.net/20160407150809352" alt="此处输入图片的描述"><br>###静态语言 vs 动态语言<br>对于静态语言（例如Java）来说，如果需要传入<code>Animal</code>类型，则传入的对象必须是<code>Animal</code>类型或者它的子类，否则，将无法调用<code>run()</code>方法。</p><p>对于Python这样的动态语言来说，则不一定需要传入<code>Animal</code>类型。我们只需要保证传入的对象有一个<code>run()</code>方法就可以了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Timer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Start...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。</p><p>Python的“file-like object“就是一种鸭子类型。对真正的文件对象，它有一个<code>read()</code>方法，返回其内容。但是，许多对象，只要有<code>read()</code>方法，都被视为“file-like object“。许多函数接收的参数就是“file-like object“，你不一定要传入真正的文件对象，完全可以传入任何实现了<code>read()</code>方法的对象。<br>###小结<br>继承可以把父类的所有功能都直接拿过来，这样就不必重零做起，子类只需要新增自己特有的方法，也可以把父类不适合的方法覆盖重写。</p><p>动态语言的鸭子类型特点决定了继承不像静态语言那样是必须的。<br>##获取对象信息<br>当我们拿到一个对象的引用时，如何知道这个对象是什么类型、有哪些方法呢？<br>###使用type()</p><p>首先，我们来判断对象类型，使用<code>type()</code>函数：</p><p>基本类型都可以用<code>type()</code>判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="number">123</span>)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">int</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span>(<span class="params"><span class="string">&#x27;str&#x27;</span></span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span>(<span class="params"><span class="literal">None</span></span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">type</span>(<span class="params"><span class="literal">None</span></span>) &#x27;<span class="title">NoneType</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure><p>如果一个变量指向函数或者类，也可以用<code>type()</code>判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="built_in">abs</span>)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">builtin_function_or_method</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span>(<span class="params">a</span>)</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> &#x27;<span class="title">__main__</span>.<span class="title">Animal</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure><p>但是<code>type()</code>函数返回的是什么类型呢？它返回对应的Class类型。如果我们要在<code>if</code>语句中判断，就需要比较两个变量的type类型是否相同：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="number">123</span>)==<span class="built_in">type</span>(<span class="number">456</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="number">123</span>)==<span class="built_in">int</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="string">&#x27;abc&#x27;</span>)==<span class="built_in">type</span>(<span class="string">&#x27;123&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="string">&#x27;abc&#x27;</span>)==<span class="built_in">str</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="string">&#x27;abc&#x27;</span>)==<span class="built_in">type</span>(<span class="number">123</span>)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p>判断基本数据类型可以直接写<code>int</code>，<code>str</code>等，但如果要判断一个对象是否是函数怎么办？可以使用<code>types</code>模块中定义的常量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> types</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fn</span>():</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(fn)==types.FunctionType</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="built_in">abs</span>)==types.BuiltinFunctionType</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="keyword">lambda</span> x: x)==types.LambdaType</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>((x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)))==types.GeneratorType</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>###使用isinstance()<br>对于class的继承关系来说，使用<code>type()</code>就很不方便。我们要判断class的类型，可以使用<code>isinstance()</code>函数。</p><p>我们回顾上次的例子，如果继承关系是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">object</span> -&gt; Animal -&gt; Dog -&gt; Husky</span><br></pre></td></tr></table></figure><p>那么，<code>isinstance()</code>就可以告诉我们，一个对象是否是某种类型。先创建3种类型的对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = Animal()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = Dog()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>h = Husky()</span><br></pre></td></tr></table></figure><p>然后，判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(h, Husky)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>没有问题，因为<code>h</code>变量指向的就是Husky对象。</p><p>再判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(h, Dog)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p><code>h</code>虽然自身是Husky类型，但由于Husky是从Dog继承下来的，所以，<code>h</code>也还是Dog类型。换句话说，<code>isinstance()</code>判断的是一个对象是否是该类型本身，或者位于该类型的父继承链上。</p><p>因此，我们可以确信，<code>h</code>还是Animal类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(h, Animal)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>同理，实际类型是Dog的<code>d</code>也是Animal类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(d, Dog) <span class="keyword">and</span> <span class="built_in">isinstance</span>(d, Animal)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>但是，<code>d</code>不是Husky类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(d, Husky)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p>能用<code>type()</code>判断的基本类型也可以用<code>isinstance()</code>判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">&#x27;a&#x27;</span>, <span class="built_in">str</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="number">123</span>, <span class="built_in">int</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">b&#x27;a&#x27;</span>, <span class="built_in">bytes</span>)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>并且还可以判断一个变量是否是某些类型中的一种，比如下面的代码就可以判断是否是list或者tuple：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (<span class="built_in">list</span>, <span class="built_in">tuple</span>))</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="built_in">list</span>, <span class="built_in">tuple</span>))</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>###使用dir()</p><p>如果要获得一个对象的所有属性和方法，可以使用<code>dir()</code>函数，它返回一个包含字符串的list，比如，获得一个str对象的所有属性和方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line">[<span class="string">&#x27;__add__&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__contains__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__getitem__&#x27;</span>, <span class="string">&#x27;__getnewargs__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__iter__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__len__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__mod__&#x27;</span>, <span class="string">&#x27;__mul__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__rmod__&#x27;</span>, <span class="string">&#x27;__rmul__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;capitalize&#x27;</span>, <span class="string">&#x27;casefold&#x27;</span>, <span class="string">&#x27;center&#x27;</span>, <span class="string">&#x27;count&#x27;</span>, <span class="string">&#x27;encode&#x27;</span>, <span class="string">&#x27;endswith&#x27;</span>, <span class="string">&#x27;expandtabs&#x27;</span>, <span class="string">&#x27;find&#x27;</span>, <span class="string">&#x27;format&#x27;</span>, <span class="string">&#x27;format_map&#x27;</span>, <span class="string">&#x27;index&#x27;</span>, <span class="string">&#x27;isalnum&#x27;</span>, <span class="string">&#x27;isalpha&#x27;</span>, <span class="string">&#x27;isdecimal&#x27;</span>, <span class="string">&#x27;isdigit&#x27;</span>, <span class="string">&#x27;isidentifier&#x27;</span>, <span class="string">&#x27;islower&#x27;</span>, <span class="string">&#x27;isnumeric&#x27;</span>, <span class="string">&#x27;isprintable&#x27;</span>, <span class="string">&#x27;isspace&#x27;</span>, <span class="string">&#x27;istitle&#x27;</span>, <span class="string">&#x27;isupper&#x27;</span>, <span class="string">&#x27;join&#x27;</span>, <span class="string">&#x27;ljust&#x27;</span>, <span class="string">&#x27;lower&#x27;</span>, <span class="string">&#x27;lstrip&#x27;</span>, <span class="string">&#x27;maketrans&#x27;</span>, <span class="string">&#x27;partition&#x27;</span>, <span class="string">&#x27;replace&#x27;</span>, <span class="string">&#x27;rfind&#x27;</span>, <span class="string">&#x27;rindex&#x27;</span>, <span class="string">&#x27;rjust&#x27;</span>, <span class="string">&#x27;rpartition&#x27;</span>, <span class="string">&#x27;rsplit&#x27;</span>, <span class="string">&#x27;rstrip&#x27;</span>, <span class="string">&#x27;split&#x27;</span>, <span class="string">&#x27;splitlines&#x27;</span>, <span class="string">&#x27;startswith&#x27;</span>, <span class="string">&#x27;strip&#x27;</span>, <span class="string">&#x27;swapcase&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;translate&#x27;</span>, <span class="string">&#x27;upper&#x27;</span>, <span class="string">&#x27;zfill&#x27;</span>]</span><br></pre></td></tr></table></figure><p>类似<code>__xxx__</code>的属性和方法在Python中都是有特殊用途的，比如<code>__len__</code>方法返回长度。在Python中，如果你调用<code>len()</code>函数试图获取一个对象的长度，实际上，在<code>len()</code>函数内部，它自动去调用该对象的<code>__len__()</code>方法，所以，下面的代码是等价的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;ABC&#x27;</span>.__len__()</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure><p>我们自己写的类，如果也想用len(myObj)的话，就自己写一个__len__()方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">MyDog</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="number">100</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dog = MyDog()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(dog)</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure><p>剩下的都是普通属性或方法，比如<code>lower()</code>返回小写的字符串：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;ABC&#x27;</span>.lower()</span><br><span class="line"><span class="string">&#x27;abc&#x27;</span></span><br></pre></td></tr></table></figure><p>仅仅把属性和方法列出来是不够的，配合<code>getattr()</code>、<code>setattr()</code>以及<code>hasattr()</code>，我们可以直接操作一个对象的状态：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">MyObject</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="meta">... </span>        self.x = <span class="number">9</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">power</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> self.x * self.x</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>obj = MyObject()</span><br></pre></td></tr></table></figure><p>紧接着，可以测试该对象的属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(obj, <span class="string">&#x27;x&#x27;</span>) <span class="comment"># 有属性&#x27;x&#x27;吗？</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>obj.x</span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(obj, <span class="string">&#x27;y&#x27;</span>) <span class="comment"># 有属性&#x27;y&#x27;吗？</span></span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">setattr</span>(obj, <span class="string">&#x27;y&#x27;</span>, <span class="number">19</span>) <span class="comment"># 设置一个属性&#x27;y&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(obj, <span class="string">&#x27;y&#x27;</span>) <span class="comment"># 有属性&#x27;y&#x27;吗？</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">getattr</span>(obj, <span class="string">&#x27;y&#x27;</span>) <span class="comment"># 获取属性&#x27;y&#x27;</span></span><br><span class="line"><span class="number">19</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>obj.y <span class="comment"># 获取属性&#x27;y&#x27;</span></span><br><span class="line"><span class="number">19</span></span><br></pre></td></tr></table></figure><p>如果试图获取不存在的属性，会抛出AttributeError的错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">getattr</span>(obj, <span class="string">&#x27;z&#x27;</span>) <span class="comment"># 获取属性&#x27;z&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">AttributeError: <span class="string">&#x27;MyObject&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;z&#x27;</span></span><br></pre></td></tr></table></figure><p>可以传入一个default参数，如果属性不存在，就返回默认值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">getattr</span>(obj, <span class="string">&#x27;z&#x27;</span>, <span class="number">404</span>) <span class="comment"># 获取属性&#x27;z&#x27;，如果不存在，返回默认值404</span></span><br><span class="line"><span class="number">404</span></span><br></pre></td></tr></table></figure><p>也可以获得对象的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(obj, <span class="string">&#x27;power&#x27;</span>) <span class="comment"># 有属性&#x27;power&#x27;吗？</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">getattr</span>(obj, <span class="string">&#x27;power&#x27;</span>) <span class="comment"># 获取属性&#x27;power&#x27;</span></span><br><span class="line">&lt;bound method MyObject.power of &lt;__main__.MyObject <span class="built_in">object</span> at <span class="number">0x10077a6a0</span>&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fn = <span class="built_in">getattr</span>(obj, <span class="string">&#x27;power&#x27;</span>) <span class="comment"># 获取属性&#x27;power&#x27;并赋值到变量fn</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fn <span class="comment"># fn指向obj.power</span></span><br><span class="line">&lt;bound method MyObject.power of &lt;__main__.MyObject <span class="built_in">object</span> at <span class="number">0x10077a6a0</span>&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fn() <span class="comment"># 调用fn()与调用obj.power()是一样的</span></span><br><span class="line"><span class="number">81</span></span><br></pre></td></tr></table></figure><p>###小结<br>通过内置的一系列函数，我们可以对任意一个Python对象进行剖析，拿到其内部的数据。要注意的是，只有在不知道对象信息的时候，我们才会去获取对象信息。如果可以直接写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span> = obj.x + obj.y</span><br></pre></td></tr></table></figure><p>就不要写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span> = <span class="built_in">getattr</span>(obj, <span class="string">&#x27;x&#x27;</span>) + <span class="built_in">getattr</span>(obj, <span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure><p>一个正确的用法的例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readImage</span>(<span class="params">fp</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(fp, <span class="string">&#x27;read&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> readData(fp)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>假设我们希望从文件流fp中读取图像，我们首先要判断该fp对象是否存在read方法，如果存在，则该对象是一个流，如果不存在，则无法读取。<code>hasattr()</code>就派上了用场。</p><p>请注意，在Python这类动态语言中，根据鸭子类型，有<code>read()</code>方法，不代表该fp对象就是一个文件流，它也可能是网络流，也可能是内存中的一个字节流，但只要<code>read()</code>方法返回的是有效的图像数据，就不影响读取图像的功能。<br>##实例属性和类属性<br>由于Python是动态语言，根据类创建的实例可以任意绑定属性。</p><p>给实例绑定属性的方法是通过实例变量，或者通过<code>self</code>变量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">s = Student(<span class="string">&#x27;Bob&#x27;</span>)</span><br><span class="line">s.score = <span class="number">90</span></span><br></pre></td></tr></table></figure><p>但是，如果<code>Student</code>类本身需要绑定一个属性呢？可以直接在class中定义属性，这种属性是类属性，归<code>Student</code>类所有：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    name = <span class="string">&#x27;Student&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"><span class="meta">... </span>    name = <span class="string">&#x27;Student&#x27;</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student() <span class="comment"># 创建实例s</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(s.name) <span class="comment"># 打印name属性，因为实例并没有name属性，所以会继续查找class的name属性</span></span><br><span class="line">Student</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(Student.name) <span class="comment"># 打印类的name属性</span></span><br><span class="line">Student</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.name = <span class="string">&#x27;Michael&#x27;</span> <span class="comment"># 给实例绑定name属性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(s.name) <span class="comment"># 由于实例属性优先级比类属性高，因此，它会屏蔽掉类的name属性</span></span><br><span class="line">Michael</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(Student.name) <span class="comment"># 但是类属性并未消失，用Student.name仍然可以访问</span></span><br><span class="line">Student</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">del</span> s.name <span class="comment"># 如果删除实例的name属性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(s.name) <span class="comment"># 再次调用s.name，由于实例的name属性没有找到，类的name属性就显示出来了</span></span><br><span class="line">Student</span><br></pre></td></tr></table></figure><p>从上面的例子可以看出，在编写程序的时候，千万不要把实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/python/">python</category>
      
      
      <category domain="http://example.com/tags/python/">python</category>
      
      
      <comments>http://example.com/2016/05/25/2016-05-25-pythonoop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>使用文本处理命令获取链接批量下载</title>
      <link>http://example.com/2016/05/24/2016-05-24-di-pian-bo-ke/</link>
      <guid>http://example.com/2016/05/24/2016-05-24-di-pian-bo-ke/</guid>
      <pubDate>Tue, 24 May 2016 11:48:48 GMT</pubDate>
      
      <description>&lt;hr&gt;
&lt;p&gt;前几天看到一个不错的方法，现在分享给大家，希望有帮助&lt;/p&gt;
&lt;p&gt;比如我看到Nmap的资源很想把他全部下载到本地怎么办呐？右键一个个点？用工具镜像整个站点？&lt;/p&gt;
&lt;p&gt;以前我用的方法是左边打开浏览器，右边打开Notepad++ 一个个链接拖到Notepad++里，最后就有了一个完整的下载列表&lt;/p&gt;
&lt;p&gt;现在有更好的方法，利用Linux的文本处理工具提取完整的下载链接，文本处理工具我很早就学过了，但是平常不用，学了就忘&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><p>前几天看到一个不错的方法，现在分享给大家，希望有帮助</p><p>比如我看到Nmap的资源很想把他全部下载到本地怎么办呐？右键一个个点？用工具镜像整个站点？</p><p>以前我用的方法是左边打开浏览器，右边打开Notepad++ 一个个链接拖到Notepad++里，最后就有了一个完整的下载列表</p><p>现在有更好的方法，利用Linux的文本处理工具提取完整的下载链接，文本处理工具我很早就学过了，但是平常不用，学了就忘</p><span id="more"></span><ol><li>打开你要处理网站的页面<a href="https://nmap.org/dist/">https://nmap.org/dist/</a> 右键保存网页</li><li>用编辑器打开删除HTML文件顶部的代码和底部代码留下链接部分</li><li>使用文本处理命令剔除多余文本，留下完整链接</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk &#x27;&#123;print $7&#125;&#x27; index-of.html | cut -d &#x27;&quot;&#x27; -f2 &gt; output.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  解释如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">awk &#x27;&#123;print $7&#125;&#x27;           // 打印出第7列文本，按空格或者制表符(Tab)</span><br><span class="line">    index-of.html              // 要处理的文件</span><br><span class="line">    | cut -d &#x27;&quot;&#x27; -f2           // 通过管道传递给 cut -d 指定分隔符为&quot; -f2 指定输出地2列文本</span><br><span class="line">    &gt; output.txt           // 重定向标准输出到output.txt</span><br></pre></td></tr></table></figure><p>然后就可以使用获取到的链接列表自动批量下载了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget -i output.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>原链接地址：<a href="http://t66y.com/htm_data/7/1605/1940146.html">使用文本处理命令获取链接批量下载</a></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/tutorial/">tutorial</category>
      
      
      <category domain="http://example.com/tags/tutorial/">tutorial</category>
      
      
      <comments>http://example.com/2016/05/24/2016-05-24-di-pian-bo-ke/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
